{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'libs.pconv_model'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-949524f266e6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mticker\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mNullFormatter\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mlibs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpconv_model\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPConvUnet\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mlibs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutil\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mMaskGenerator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'libs.pconv_model'"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import gc\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "\n",
    "from argparse import ArgumentParser\n",
    "from copy import deepcopy\n",
    "from tqdm import tqdm\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, LambdaCallback\n",
    "from keras import backend as K\n",
    "from keras.utils import Sequence\n",
    "from keras_tqdm import TQDMCallback\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import NullFormatter\n",
    "\n",
    "from libs.pconv_model import PConvUnet\n",
    "from libs.util import MaskGenerator\n",
    "\n",
    "\n",
    "# Sample call\n",
    "r\"\"\"\n",
    "# Train on CelebaHQ\n",
    "python main.py --name CelebHQ --train C:\\Documents\\Kaggle\\celebaHQ-512\\train\\ --validation C:\\Documents\\Kaggle\\celebaHQ-512\\val\\ --test C:\\Documents\\Kaggle\\celebaHQ-512\\test\\ --checkpoint \"C:\\Users\\Mathias Felix Gruber\\Documents\\GitHub\\PConv-Keras\\data\\logs\\imagenet_phase1_paperMasks\\weights.35-0.70.h5\"\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def parse_args():\n",
    "    parser = ArgumentParser(description='Training script for PConv inpainting')\n",
    "\n",
    "    parser.add_argument(\n",
    "        '-stage', '--stage',\n",
    "        type=str, default='train',\n",
    "        help='Which stage of training to run',\n",
    "        choices=['train', 'finetune']\n",
    "    )\n",
    "\n",
    "    parser.add_argument(\n",
    "        '-train', '--train',\n",
    "        type=str,\n",
    "        help='Folder with training images'\n",
    "    )\n",
    "    \n",
    "    parser.add_argument(\n",
    "        '-validation', '--validation',\n",
    "        type=str,\n",
    "        help='Folder with validation images'\n",
    "    )\n",
    "\n",
    "    parser.add_argument(\n",
    "        '-test', '--test',\n",
    "        type=str,\n",
    "        help='Folder with testing images'\n",
    "    )\n",
    "        \n",
    "    parser.add_argument(\n",
    "        '-name', '--name',\n",
    "        type=str, default='myDataset',\n",
    "        help='Dataset name, e.g. \\'imagenet\\''\n",
    "    )\n",
    "        \n",
    "    parser.add_argument(\n",
    "        '-batch_size', '--batch_size',\n",
    "        type=int, default=4,\n",
    "        help='What batch-size should we use'\n",
    "    )\n",
    "\n",
    "    parser.add_argument(\n",
    "        '-test_path', '--test_path',\n",
    "        type=str, default='./data/test_samples/',\n",
    "        help='Where to output test images during training'\n",
    "    )\n",
    "        \n",
    "    parser.add_argument(\n",
    "        '-weight_path', '--weight_path',\n",
    "        type=str, default='./data/logs/',\n",
    "        help='Where to output weights during training'\n",
    "    )\n",
    "        \n",
    "    parser.add_argument(\n",
    "        '-log_path', '--log_path',\n",
    "        type=str, default='./data/logs/',\n",
    "        help='Where to output tensorboard logs during training'\n",
    "    )\n",
    "\n",
    "    parser.add_argument(\n",
    "        '-vgg_path', '--vgg_path',\n",
    "        type=str, default='./data/logs/pytorch_to_keras_vgg16.h5',\n",
    "        help='VGG16 weights trained on PyTorch with pixel scaling 1/255.'\n",
    "    )\n",
    "\n",
    "    parser.add_argument(\n",
    "        '-checkpoint', '--checkpoint',\n",
    "        type=str, \n",
    "        help='Previous weights to be loaded onto model'\n",
    "    )\n",
    "        \n",
    "    return  parser.parse_args()\n",
    "\n",
    "\n",
    "class AugmentingDataGenerator(ImageDataGenerator):\n",
    "    \"\"\"Wrapper for ImageDataGenerator to return mask & image\"\"\"\n",
    "    def flow_from_directory(self, directory, mask_generator, *args, **kwargs):\n",
    "        generator = super().flow_from_directory(directory, class_mode=None, *args, **kwargs)        \n",
    "        seed = None if 'seed' not in kwargs else kwargs['seed']\n",
    "        while True:\n",
    "            \n",
    "            # Get augmentend image samples\n",
    "            ori = next(generator)\n",
    "\n",
    "            # Get masks for each image sample            \n",
    "            mask = np.stack([\n",
    "                mask_generator.sample(seed)\n",
    "                for _ in range(ori.shape[0])], axis=0\n",
    "            )\n",
    "\n",
    "            # Apply masks to all image sample\n",
    "            masked = deepcopy(ori)\n",
    "            masked[mask==0] = 1\n",
    "\n",
    "            # Yield ([ori, masl],  ori) training batches\n",
    "            # print(masked.shape, ori.shape)\n",
    "            gc.collect()\n",
    "            yield [masked, mask], ori\n",
    "\n",
    "# Run script\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    # Parse command-line arguments\n",
    "    args = parse_args()\n",
    "\n",
    "    if args.stage == 'finetune' and not args.checkpoint:\n",
    "        raise AttributeError('If you are finetuning your model, you must supply a checkpoint file')\n",
    "\n",
    "    # Create training generator\n",
    "    train_datagen = AugmentingDataGenerator(  \n",
    "        rotation_range=10,\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        rescale=1./255,\n",
    "        horizontal_flip=True\n",
    "    )\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "        args.train, \n",
    "        MaskGenerator(512, 512, 3),\n",
    "        target_size=(512, 512), \n",
    "        batch_size=args.batch_size\n",
    "    )\n",
    "\n",
    "    # Create validation generator\n",
    "    val_datagen = AugmentingDataGenerator(rescale=1./255)\n",
    "    val_generator = val_datagen.flow_from_directory(\n",
    "        args.validation, \n",
    "        MaskGenerator(512, 512, 3), \n",
    "        target_size=(512, 512), \n",
    "        batch_size=args.batch_size, \n",
    "        classes=['val'], \n",
    "        seed=42\n",
    "    )\n",
    "\n",
    "    # Create testing generator\n",
    "    test_datagen = AugmentingDataGenerator(rescale=1./255)\n",
    "    test_generator = test_datagen.flow_from_directory(\n",
    "        args.test, \n",
    "        MaskGenerator(512, 512, 3), \n",
    "        target_size=(512, 512), \n",
    "        batch_size=args.batch_size, \n",
    "        seed=42\n",
    "    )\n",
    "\n",
    "    # Pick out an example to be send to test samples folder\n",
    "    test_data = next(test_generator)\n",
    "    (masked, mask), ori = test_data\n",
    "\n",
    "    def plot_callback(model, path):\n",
    "        \"\"\"Called at the end of each epoch, displaying our previous test images,\n",
    "        as well as their masked predictions and saving them to disk\"\"\"\n",
    "        \n",
    "        # Get samples & Display them        \n",
    "        pred_img = model.predict([masked, mask])\n",
    "        pred_time = datetime.datetime.now().strftime('%Y-%m-%d-%H-%M-%S')\n",
    "\n",
    "        # Clear current output and display test images\n",
    "        for i in range(len(ori)):\n",
    "            _, axes = plt.subplots(1, 3, figsize=(20, 5))\n",
    "            axes[0].imshow(masked[i,:,:,:])\n",
    "            axes[1].imshow(pred_img[i,:,:,:] * 1.)\n",
    "            axes[2].imshow(ori[i,:,:,:])\n",
    "            axes[0].set_title('Masked Image')\n",
    "            axes[1].set_title('Predicted Image')\n",
    "            axes[2].set_title('Original Image')\n",
    "                    \n",
    "            plt.savefig(os.path.join(path, '/img_{}_{}.png'.format(i, pred_time)))\n",
    "            plt.close()\n",
    "\n",
    "    # Load the model\n",
    "    if args.vgg_path:\n",
    "        model = PConvUnet(vgg_weights=args.vgg_path)\n",
    "    else:\n",
    "        model = PConvUnet()\n",
    "    \n",
    "    # Loading of checkpoint\n",
    "    if args.checkpoint:\n",
    "        if args.stage == 'train':\n",
    "            model.load(args.checkpoint)\n",
    "        elif args.stage == 'finetune':\n",
    "            model.load(args.checkpoint, train_bn=False, lr=0.00005)\n",
    "\n",
    "    # Fit model\n",
    "    model.fit_generator(\n",
    "        train_generator, \n",
    "        steps_per_epoch=10000,\n",
    "        validation_data=val_generator,\n",
    "        validation_steps=1000,\n",
    "        epochs=100,  \n",
    "        verbose=0,\n",
    "        callbacks=[\n",
    "            TensorBoard(\n",
    "                log_dir=os.path.join(args.log_path, args.name+'_phase1'),\n",
    "                write_graph=False\n",
    "            ),\n",
    "            ModelCheckpoint(\n",
    "                os.path.join(args.log_path, args.name+'_phase1', 'weights.{epoch:02d}-{loss:.2f}.h5'),\n",
    "                monitor='val_loss', \n",
    "                save_best_only=True, \n",
    "                save_weights_only=True\n",
    "            ),\n",
    "            LambdaCallback(\n",
    "                on_epoch_end=lambda epoch, logs: plot_callback(model, args.test_path)\n",
    "            ),\n",
    "            TQDMCallback()\n",
    "        ]\n",
    "    )\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
