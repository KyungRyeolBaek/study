{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network Training\n",
    "Having implemented and tested all the components of the final networks in steps 1-3, we are now ready to train the network on a large dataset (ImageNet)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "\n",
    "from copy import deepcopy\n",
    "from tqdm import tqdm\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, LambdaCallback\n",
    "from keras import backend as K\n",
    "from keras.utils import Sequence\n",
    "from keras_tqdm import TQDMNotebookCallback\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import NullFormatter\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# Change to root path\n",
    "if os.path.basename(os.getcwd()) != 'PConv-Keras':\n",
    "    os.chdir('..')\n",
    "\n",
    "from libs.pconv_model import PConvUnet\n",
    "from libs.util import MaskGenerator\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "plt.ioff()\n",
    "\n",
    "# SETTINGS\n",
    "TRAIN_DIR = r\"C:\\Documents\\Kaggle\\Kaggle-imagenet\\ILSVRC\\Data\\CLS-LOC\\train\"\n",
    "VAL_DIR = r\"C:\\Documents\\Kaggle\\Kaggle-imagenet\\ILSVRC\\Data\\CLS-LOC\\\\\"\n",
    "TEST_DIR = r\"C:\\Documents\\Kaggle\\pexels\\\\\"\n",
    "\n",
    "BATCH_SIZE = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating train & test data generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AugmentingDataGenerator(ImageDataGenerator):\n",
    "    def flow_from_directory(self, directory, mask_generator, *args, **kwargs):\n",
    "        generator = super().flow_from_directory(directory, class_mode=None, *args, **kwargs)        \n",
    "        seed = None if 'seed' not in kwargs else kwargs['seed']\n",
    "        while True:\n",
    "            \n",
    "            # Get augmentend image samples\n",
    "            ori = next(generator)\n",
    "\n",
    "            # Get masks for each image sample            \n",
    "            mask = np.stack([\n",
    "                mask_generator.sample(seed)\n",
    "                for _ in range(ori.shape[0])], axis=0\n",
    "            )\n",
    "\n",
    "            # Apply masks to all image sample\n",
    "            masked = deepcopy(ori)\n",
    "            masked[mask==0] = 1\n",
    "\n",
    "            # Yield ([ori, masl],  ori) training batches\n",
    "            # print(masked.shape, ori.shape)\n",
    "            gc.collect()\n",
    "            yield [masked, mask], ori\n",
    "            \n",
    "\n",
    "# Create training generator\n",
    "train_datagen = AugmentingDataGenerator(  \n",
    "    rotation_range=10,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    rescale=1./255,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    TRAIN_DIR, \n",
    "    MaskGenerator(512, 512, 3),\n",
    "    target_size=(512, 512), \n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "# Create validation generator\n",
    "val_datagen = AugmentingDataGenerator(rescale=1./255)\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    VAL_DIR, \n",
    "    MaskGenerator(512, 512, 3), \n",
    "    target_size=(512, 512), \n",
    "    batch_size=BATCH_SIZE, \n",
    "    classes=['val'], \n",
    "    seed=42\n",
    ")\n",
    "\n",
    "# Create testing generator\n",
    "test_datagen = AugmentingDataGenerator(rescale=1./255)\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    TEST_DIR, \n",
    "    MaskGenerator(512, 512, 3), \n",
    "    target_size=(512, 512), \n",
    "    batch_size=BATCH_SIZE, \n",
    "    seed=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] 지정된 경로를 찾을 수 없습니다: 'C:\\\\Documents\\\\Kaggle\\\\pexels\\\\\\\\'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-638825d3ed00>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Pick out an example\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtest_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_generator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mmasked\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mori\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# Show side by side\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-8c63307420df>\u001b[0m in \u001b[0;36mflow_from_directory\u001b[1;34m(self, directory, mask_generator, *args, **kwargs)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mAugmentingDataGenerator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mImageDataGenerator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mflow_from_directory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdirectory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask_generator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m         \u001b[0mgenerator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflow_from_directory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_mode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m         \u001b[0mseed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;34m'seed'\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'seed'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras_preprocessing\\image\\image_data_generator.py\u001b[0m in \u001b[0;36mflow_from_directory\u001b[1;34m(self, directory, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation)\u001b[0m\n\u001b[0;32m    541\u001b[0m             \u001b[0msubset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msubset\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    542\u001b[0m             \u001b[0minterpolation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 543\u001b[1;33m             \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    544\u001b[0m         )\n\u001b[0;32m    545\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras_preprocessing\\image\\directory_iterator.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, dtype)\u001b[0m\n\u001b[0;32m    113\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mclasses\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m             \u001b[0mclasses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 115\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0msubdir\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    116\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubdir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m                     \u001b[0mclasses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubdir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] 지정된 경로를 찾을 수 없습니다: 'C:\\\\Documents\\\\Kaggle\\\\pexels\\\\\\\\'"
     ]
    }
   ],
   "source": [
    "# Pick out an example\n",
    "test_data = next(test_generator)\n",
    "(masked, mask), ori = test_data\n",
    "\n",
    "# Show side by side\n",
    "for i in range(len(ori)):\n",
    "    _, axes = plt.subplots(1, 3, figsize=(20, 5))\n",
    "    axes[0].imshow(masked[i,:,:,:])\n",
    "    axes[1].imshow(mask[i,:,:,:] * 1.)\n",
    "    axes[2].imshow(ori[i,:,:,:])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training on ImageNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_callback(model):\n",
    "    \"\"\"Called at the end of each epoch, displaying our previous test images,\n",
    "    as well as their masked predictions and saving them to disk\"\"\"\n",
    "    \n",
    "    # Get samples & Display them        \n",
    "    pred_img = model.predict([masked, mask])\n",
    "    pred_time = datetime.datetime.now().strftime('%Y-%m-%d-%H-%M-%S')\n",
    "\n",
    "    # Clear current output and display test images\n",
    "    for i in range(len(ori)):\n",
    "        _, axes = plt.subplots(1, 3, figsize=(20, 5))\n",
    "        axes[0].imshow(masked[i,:,:,:])\n",
    "        axes[1].imshow(pred_img[i,:,:,:] * 1.)\n",
    "        axes[2].imshow(ori[i,:,:,:])\n",
    "        axes[0].set_title('Masked Image')\n",
    "        axes[1].set_title('Predicted Image')\n",
    "        axes[2].set_title('Original Image')\n",
    "                \n",
    "        plt.savefig(r'data/test_samples/img_{}_{}.png'.format(i, pred_time))\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 1 - with batch normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model\n",
    "model = PConvUnet(vgg_weights='./data/logs/pytorch_vgg16.h5')\n",
    "model.load(r\"C:\\Users\\Mathias Felix Gruber\\Documents\\GitHub\\PConv-Keras\\data\\logs\\single_image_test\\weights.10-0.89.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "FOLDER = './data/logs/imagenet_phase1_paperMasks'\n",
    "\n",
    "# Run training for certain amount of epochs\n",
    "model.fit_generator(\n",
    "    train_generator, \n",
    "    steps_per_epoch=10000,\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=1000,\n",
    "    epochs=50,  \n",
    "    verbose=0,\n",
    "    callbacks=[\n",
    "        TensorBoard(\n",
    "            log_dir=FOLDER,\n",
    "            write_graph=False\n",
    "        ),\n",
    "        ModelCheckpoint(\n",
    "            FOLDER+'weights.{epoch:02d}-{loss:.2f}.h5',\n",
    "            monitor='val_loss', \n",
    "            save_best_only=True, \n",
    "            save_weights_only=True\n",
    "        ),\n",
    "        LambdaCallback(\n",
    "            on_epoch_end=lambda epoch, logs: plot_callback(model)\n",
    "        ),\n",
    "        TQDMNotebookCallback()\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 2 - without batch normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load weights from previous run\n",
    "model = PConvUnet(vgg_weights='./data/logs/pytorch_vgg16.h5')\n",
    "model.load(\n",
    "    r\"C:\\Users\\Mathias Felix Gruber\\Documents\\GitHub\\PConv-Keras\\data\\logs\\imagenet_phase1\\weights.23-1.18.h5\",\n",
    "    train_bn=False,\n",
    "    lr=0.00005\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run training for certain amount of epochs\n",
    "model.fit_generator(\n",
    "    train_generator, \n",
    "    steps_per_epoch=10000,\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=1000,\n",
    "    epochs=50,  \n",
    "    verbose=0,\n",
    "    callbacks=[\n",
    "        TensorBoard(\n",
    "            log_dir='./data/logs/imagenet_phase2',\n",
    "            write_graph=False\n",
    "        ),\n",
    "        ModelCheckpoint(\n",
    "            './data/logs/imagenet_phase2/weights.{epoch:02d}-{loss:.2f}.h5',\n",
    "            monitor='val_loss', \n",
    "            save_best_only=True, \n",
    "            save_weights_only=True\n",
    "        ),\n",
    "        LambdaCallback(\n",
    "            on_epoch_end=lambda epoch, logs: plot_callback(model)\n",
    "        ),\n",
    "        TQDMNotebookCallback()\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 3 - Generating samples\n",
    "Let us use the fine-tuned network to get some sample. We will save results in `data/test_samples` folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load weights from previous run\n",
    "model = PConvUnet()\n",
    "model.load(\n",
    "    r\"C:\\Users\\Mathias Felix Gruber\\Documents\\GitHub\\PConv-Keras\\data\\logs\\imagenet_phase2\\weights.26-1.07.h5\",\n",
    "    train_bn=False,\n",
    "    lr=0.00005\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 0\n",
    "for (masked, mask), ori in tqdm(test_generator):\n",
    "    \n",
    "    # Run predictions for this batch of images\n",
    "    pred_img = model.predict([masked, mask])\n",
    "    pred_time = datetime.datetime.now().strftime('%Y-%m-%d-%H-%M-%S')\n",
    "    \n",
    "    # Clear current output and display test images\n",
    "    for i in range(len(ori)):\n",
    "        _, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "        axes[0].imshow(masked[i,:,:,:])\n",
    "        axes[1].imshow(pred_img[i,:,:,:] * 1.)\n",
    "        axes[0].set_title('Masked Image')\n",
    "        axes[1].set_title('Predicted Image')\n",
    "        axes[0].xaxis.set_major_formatter(NullFormatter())\n",
    "        axes[0].yaxis.set_major_formatter(NullFormatter())\n",
    "        axes[1].xaxis.set_major_formatter(NullFormatter())\n",
    "        axes[1].yaxis.set_major_formatter(NullFormatter())\n",
    "                \n",
    "        plt.savefig(r'data/test_samples/img_{}_{}.png'.format(i, pred_time))\n",
    "        plt.close()\n",
    "        n += 1\n",
    "        \n",
    "    # Only create predictions for about 100 images\n",
    "    if n > 100:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance Evaluation\n",
    "To evaluate the performance of the network, in this notebook I'll try loading the test masks used in the original paper, and see which PSNR scores we get on imagenet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store data\n",
    "ratios = []\n",
    "psnrs = []\n",
    "\n",
    "# Loop through test masks released with paper\n",
    "test_masks = os.listdir('./data/masks/test')\n",
    "for filename in tqdm(test_masks):\n",
    "    \n",
    "    # Load mask from paper\n",
    "    filepath = os.path.join('./data/masks/test', filename)\n",
    "    mask = cv2.imread(filepath) / 255\n",
    "    ratios.append(mask[:,:,0].sum() / (512 * 512))\n",
    "    mask = np.array([1-mask for _ in range(BATCH_SIZE)])\n",
    "    \n",
    "    # Pick out image from test generator\n",
    "    test_data = next(val_generator)\n",
    "    (_, _), ori = test_data\n",
    "    \n",
    "    masked = deepcopy(ori)\n",
    "    masked[mask==0] = 1\n",
    "    \n",
    "    # Run prediction on image & mask\n",
    "    pred = model.predict([ori, mask])\n",
    "    \n",
    "    # Calculate PSNR\n",
    "    psnrs.append(-10.0 * np.log10(np.mean(np.square(pred - ori))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'ratios': ratios[:2408], 'psnrs': psnrs})\n",
    "\n",
    "means, stds = [], []\n",
    "idx1 = [0.01, 0.1, 0.2, 0.3, 0.4, 0.5]\n",
    "idx2 = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6]\n",
    "\n",
    "for mi, ma in zip(idx1, idx2):\n",
    "    means.append(df[(df.ratios >= mi) & (df.ratios <= ma)].mean())\n",
    "    stds.append(df[(df.ratios >= mi) & (df.ratios <= ma)].std())\n",
    "    \n",
    "pd.DataFrame(means, index=['{}-{}'.format(a, b) for a, b in zip(idx1, idx2)])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
