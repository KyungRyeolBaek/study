{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using data [Only 4 moments]\n",
      "Epoch 0: D (0.6823088526725769 real_err, 0.7057886719703674 fake_err) G (0.6807411909103394 err); Real Dist ([3.9953169950544836, 1.2309185407190693]),  Fake Dist ([-0.6090686653852463, 0.04882808239917081]) \n",
      "Epoch 100: D (0.6275230050086975 real_err, 0.5386764407157898 fake_err) G (0.8515862822532654 err); Real Dist ([3.898732497036457, 1.2180357224465588]),  Fake Dist ([5.2026840000152585, 0.030768768601101008]) \n",
      "Epoch 200: D (0.5841841697692871 real_err, 0.5453552007675171 fake_err) G (0.7024859189987183 err); Real Dist ([4.056903672531247, 1.3026213745096649]),  Fake Dist ([3.7693134455680846, 1.8123883511091876]) \n",
      "Epoch 300: D (0.6286107301712036 real_err, 0.7267289757728577 fake_err) G (0.7515316605567932 err); Real Dist ([4.091080518305302, 1.3097316868357143]),  Fake Dist ([5.492975116610527, 2.1591350110098486]) \n",
      "Epoch 400: D (0.6723830699920654 real_err, 0.4573628008365631 fake_err) G (0.5961846709251404 err); Real Dist ([4.073510091483593, 1.27145817404508]),  Fake Dist ([4.854646634817123, 1.5482232647518617]) \n",
      "Epoch 500: D (0.7836103439331055 real_err, 0.701673150062561 fake_err) G (0.6913440823554993 err); Real Dist ([3.8948673999905585, 1.2264735097931085]),  Fake Dist ([4.066789601564407, 1.338842197057529]) \n",
      "Epoch 600: D (0.7027650475502014 real_err, 0.7104023098945618 fake_err) G (0.6744208335876465 err); Real Dist ([4.015059415265918, 1.249941745961575]),  Fake Dist ([4.062842547893524, 0.8680424109442503]) \n",
      "Epoch 700: D (0.6769353747367859 real_err, 0.6863899230957031 fake_err) G (0.6951419115066528 err); Real Dist ([3.971672362938523, 1.271011415268333]),  Fake Dist ([4.006536915063858, 1.4314501731486535]) \n",
      "Epoch 800: D (0.6952416300773621 real_err, 0.6979479193687439 fake_err) G (0.6768513917922974 err); Real Dist ([4.00326837310195, 1.2768155082925419]),  Fake Dist ([3.8815667185783385, 1.3047973444783127]) \n",
      "Epoch 900: D (0.6969694495201111 real_err, 0.7043419480323792 fake_err) G (0.6606972813606262 err); Real Dist ([3.9565503042340278, 1.2719629891579158]),  Fake Dist ([3.8622142610549925, 1.1975775264898942]) \n",
      "Epoch 1000: D (0.677773654460907 real_err, 0.7022393345832825 fake_err) G (0.6855522990226746 err); Real Dist ([3.9188169385790825, 1.3398842222229599]),  Fake Dist ([4.080103050947189, 1.3635768983154004]) \n",
      "Epoch 1100: D (0.6942914128303528 real_err, 0.6997845768928528 fake_err) G (0.6853435039520264 err); Real Dist ([4.002904641032219, 1.2512866243935556]),  Fake Dist ([3.992624885082245, 1.1019499304228184]) \n",
      "Epoch 1200: D (0.6913779973983765 real_err, 0.6938976645469666 fake_err) G (0.6911104321479797 err); Real Dist ([3.954518195092678, 1.2995174244745087]),  Fake Dist ([4.099638043403625, 1.3750693846400215]) \n",
      "Epoch 1300: D (0.6994694471359253 real_err, 0.6906375288963318 fake_err) G (0.6974490284919739 err); Real Dist ([3.991606997638941, 1.2760178103987507]),  Fake Dist ([3.953213937997818, 1.1349489840491245]) \n",
      "Epoch 1400: D (0.6996704339981079 real_err, 0.6858340501785278 fake_err) G (0.6913530230522156 err); Real Dist ([3.9944811785668133, 1.2805169017344444]),  Fake Dist ([3.853642071723938, 1.3254268163767853]) \n",
      "Epoch 1500: D (0.684369683265686 real_err, 0.6836144328117371 fake_err) G (0.6978389620780945 err); Real Dist ([4.011869674146175, 1.274567877434919]),  Fake Dist ([3.7756879665851595, 1.249940903378006]) \n",
      "Epoch 1600: D (0.67952960729599 real_err, 0.6893302202224731 fake_err) G (0.6949729919433594 err); Real Dist ([3.9760938032865525, 1.253571254121109]),  Fake Dist ([4.011450232505799, 1.2709303543410098]) \n",
      "Epoch 1700: D (0.6982399225234985 real_err, 0.6957858800888062 fake_err) G (0.6871098279953003 err); Real Dist ([4.129859356462956, 1.2724056715842398]),  Fake Dist ([3.951348867177963, 1.228068564574275]) \n",
      "Epoch 1800: D (0.69987553358078 real_err, 0.6903613209724426 fake_err) G (0.6925486922264099 err); Real Dist ([4.024560021102428, 1.225032788237838]),  Fake Dist ([3.8809562706947327, 1.1933420767616139]) \n",
      "Epoch 1900: D (0.6970553398132324 real_err, 0.7017295360565186 fake_err) G (0.695327877998352 err); Real Dist ([3.9091356506347656, 1.225573439344703]),  Fake Dist ([3.7733705105781556, 1.1539808506366307]) \n",
      "Epoch 2000: D (0.690721333026886 real_err, 0.6962814331054688 fake_err) G (0.6948893070220947 err); Real Dist ([3.9959789636731147, 1.2618581537752243]),  Fake Dist ([3.9344337282180786, 1.0842447778717434]) \n",
      "Epoch 2100: D (0.6934525370597839 real_err, 0.6907199025154114 fake_err) G (0.6934150457382202 err); Real Dist ([3.900517722308636, 1.2591782235116091]),  Fake Dist ([4.067968440771103, 1.3017829944403507]) \n",
      "Epoch 2200: D (0.6933586001396179 real_err, 0.6923049688339233 fake_err) G (0.6950772404670715 err); Real Dist ([4.046671994760633, 1.2578535706773524]),  Fake Dist ([3.943978450536728, 1.1419175683754281]) \n",
      "Epoch 2300: D (0.6940651535987854 real_err, 0.7019752264022827 fake_err) G (0.6851921081542969 err); Real Dist ([4.05869332909584, 1.3397561668220184]),  Fake Dist ([4.039163964986801, 1.3293560622439553]) \n",
      "Epoch 2400: D (0.6982496380805969 real_err, 0.6895425915718079 fake_err) G (0.6993775367736816 err); Real Dist ([4.018486117482185, 1.1689490873067891]),  Fake Dist ([3.9804702937602996, 1.284471854686801]) \n",
      "Epoch 2500: D (0.695404052734375 real_err, 0.7086009383201599 fake_err) G (0.6950209140777588 err); Real Dist ([3.9693319781422614, 1.2553820054656653]),  Fake Dist ([3.947137462854385, 1.1051254286397465]) \n",
      "Epoch 2600: D (0.6942704916000366 real_err, 0.6887380480766296 fake_err) G (0.6877617835998535 err); Real Dist ([3.9591968843340872, 1.3050210212281559]),  Fake Dist ([4.004576375961304, 1.2651586780427373]) \n",
      "Epoch 2700: D (0.6961489915847778 real_err, 0.6868321299552917 fake_err) G (0.6999152898788452 err); Real Dist ([3.9193653483986854, 1.298166630573732]),  Fake Dist ([3.983271071434021, 1.175776271220224]) \n",
      "Epoch 2800: D (0.6779718399047852 real_err, 0.6993557810783386 fake_err) G (0.6851338148117065 err); Real Dist ([3.984510970830917, 1.267747308564491]),  Fake Dist ([3.8992642002105713, 1.4325894195470756]) \n",
      "Epoch 2900: D (0.6876794695854187 real_err, 0.692390501499176 fake_err) G (0.6945351362228394 err); Real Dist ([3.906950552865863, 1.2646665650196518]),  Fake Dist ([3.9505092635154724, 1.2734017991141642]) \n",
      "Epoch 3000: D (0.6929631233215332 real_err, 0.6896982192993164 fake_err) G (0.6903119683265686 err); Real Dist ([3.926043993830681, 1.2448673252104814]),  Fake Dist ([4.019152556657791, 1.207561736100176]) \n",
      "Epoch 3100: D (0.7029414772987366 real_err, 0.6764746308326721 fake_err) G (0.6955225467681885 err); Real Dist ([3.9612924798727036, 1.224032171509208]),  Fake Dist ([3.9134339249134062, 1.1263915431781901]) \n",
      "Epoch 3200: D (0.694634199142456 real_err, 0.7088574171066284 fake_err) G (0.6901737451553345 err); Real Dist ([3.9927507755458356, 1.2282640278717682]),  Fake Dist ([3.954987550020218, 1.3147677847381825]) \n",
      "Epoch 3300: D (0.6988223791122437 real_err, 0.6918970942497253 fake_err) G (0.6832780838012695 err); Real Dist ([4.002271595835686, 1.2147346354680202]),  Fake Dist ([4.020187745571136, 1.2275750380359445]) \n",
      "Epoch 3400: D (0.6809230446815491 real_err, 0.6878695487976074 fake_err) G (0.6829947233200073 err); Real Dist ([4.005377878546715, 1.2225604791651934]),  Fake Dist ([3.7734991714954376, 1.2838554693172766]) \n",
      "Epoch 3500: D (0.46411725878715515 real_err, 0.4425281286239624 fake_err) G (0.9416552186012268 err); Real Dist ([3.9413311076760293, 1.2435676527349633]),  Fake Dist ([5.617798517227173, 1.3289694060748636]) \n",
      "Epoch 3600: D (0.673059344291687 real_err, 0.7031309008598328 fake_err) G (0.68730229139328 err); Real Dist ([4.015575672864914, 1.2094196291734305]),  Fake Dist ([4.137200605869293, 1.3671816757148476]) \n",
      "Epoch 3700: D (0.6761854290962219 real_err, 0.7061647772789001 fake_err) G (0.7015829682350159 err); Real Dist ([3.94674443423748, 1.2986695601760732]),  Fake Dist ([4.1264446306228635, 1.1408987193115288]) \n",
      "Epoch 3800: D (0.7197774052619934 real_err, 0.6988173127174377 fake_err) G (0.6871308088302612 err); Real Dist ([4.0285732276439665, 1.2601548272402567]),  Fake Dist ([4.074303023815155, 1.2571501523794875]) \n",
      "Epoch 3900: D (0.6969807147979736 real_err, 0.6958405375480652 fake_err) G (0.6938974857330322 err); Real Dist ([3.948624137878418, 1.1959583385954689]),  Fake Dist ([4.002697417020798, 1.1831716146342612]) \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4000: D (0.69149249792099 real_err, 0.6964555978775024 fake_err) G (0.6959967613220215 err); Real Dist ([4.081953996688127, 1.2588708412448975]),  Fake Dist ([4.004896726131439, 1.2113531474872563]) \n",
      "Epoch 4100: D (0.6939083933830261 real_err, 0.6977357864379883 fake_err) G (0.6902146339416504 err); Real Dist ([4.0208653854131695, 1.2750797691069617]),  Fake Dist ([4.014469630479812, 1.232849401597852]) \n",
      "Epoch 4200: D (0.6931314468383789 real_err, 0.6968011856079102 fake_err) G (0.6888427734375 err); Real Dist ([3.956171581864357, 1.3078877505543587]),  Fake Dist ([4.081760303258896, 1.2559740600012983]) \n",
      "Epoch 4300: D (0.6904502511024475 real_err, 0.6907795071601868 fake_err) G (0.6924232244491577 err); Real Dist ([3.9896430433094503, 1.2711039673129447]),  Fake Dist ([4.070723392009735, 1.3123616443456858]) \n",
      "Epoch 4400: D (0.6972880363464355 real_err, 0.6954759955406189 fake_err) G (0.6906437277793884 err); Real Dist ([4.002094895966351, 1.2267097324103944]),  Fake Dist ([4.015418831348419, 1.241615893042251]) \n",
      "Epoch 4500: D (0.6945044994354248 real_err, 0.6862127780914307 fake_err) G (0.6912187933921814 err); Real Dist ([3.996485529214144, 1.2417238951138239]),  Fake Dist ([4.03943277311325, 1.2930100594608127]) \n",
      "Epoch 4600: D (0.6936905980110168 real_err, 0.6940677762031555 fake_err) G (0.6935768723487854 err); Real Dist ([3.9540551790446044, 1.1718662742699342]),  Fake Dist ([3.946234018802643, 1.233545512049225]) \n",
      "Epoch 4700: D (0.6944493055343628 real_err, 0.6853688359260559 fake_err) G (0.6933464407920837 err); Real Dist ([3.9595691541731357, 1.260876495021189]),  Fake Dist ([3.9477109529972076, 1.3098514520706463]) \n",
      "Epoch 4800: D (0.6923336982727051 real_err, 0.6950656771659851 fake_err) G (0.6912317872047424 err); Real Dist ([4.012592257142067, 1.2668639635949435]),  Fake Dist ([3.9785270030498503, 1.2704809903262184]) \n",
      "Epoch 4900: D (0.6915345191955566 real_err, 0.6922319531440735 fake_err) G (0.6913391947746277 err); Real Dist ([3.9250175736546518, 1.2436023800345584]),  Fake Dist ([4.074829113483429, 1.328164443140844]) \n",
      "Plotting the generated distribution...\n",
      " Values: [2.9170970916748047, 1.1797726154327393, 3.1430044174194336, 3.8668644428253174, 4.811631202697754, 6.432001113891602, 5.707503795623779, 6.385275840759277, 5.451992034912109, 3.4600555896759033, 3.5254855155944824, 3.975876569747925, 5.343208312988281, 3.671427011489868, 3.5842771530151367, 3.108077049255371, 1.1513340473175049, 4.4110565185546875, 3.356067180633545, 2.0481770038604736, 5.05495023727417, 3.4547364711761475, 4.881824493408203, 5.441551208496094, 3.155728340148926, 1.7894024848937988, 6.526805877685547, 4.183290481567383, 3.630124568939209, 3.778890371322632, 6.377885818481445, 3.988527774810791, 3.6808695793151855, 4.17164421081543, 4.29060173034668, 4.855037689208984, 3.466464042663574, 3.6837568283081055, 3.4246606826782227, 3.5660934448242188, 4.192688941955566, 1.7124054431915283, 1.4763095378875732, 6.069165229797363, 4.425055503845215, 3.292922258377075, 3.8619937896728516, 3.8956806659698486, 4.47971248626709, 3.0853748321533203, 1.6703966856002808, 3.804307460784912, 3.840332269668579, 1.0136510133743286, 5.616840362548828, 5.3752055168151855, 3.29008150100708, 4.4977264404296875, 3.566343069076538, 3.7014966011047363, 4.607911109924316, 3.2725977897644043, 3.9702248573303223, 3.627974033355713, 2.2878427505493164, 6.050622940063477, 2.0421860218048096, 6.466325283050537, 4.8729400634765625, 4.118185043334961, 3.5745978355407715, 2.849246025085449, 6.343747138977051, 6.271739959716797, 3.514439105987549, 2.4385807514190674, 1.0971307754516602, 4.029059410095215, 4.750336170196533, 4.329490661621094, 2.225707769393921, 3.531878709793091, 3.4959630966186523, 3.734063148498535, 4.293262481689453, 1.2519304752349854, 3.2565855979919434, 3.770139694213867, 5.206432342529297, 2.8602325916290283, 3.6691861152648926, 4.657173156738281, 2.831969738006592, 1.7549307346343994, 5.233711242675781, 4.844656467437744, 3.609506845474243, 1.163373351097107, 4.296782970428467, 3.3114702701568604, 4.429108619689941, 2.2770159244537354, 3.48256254196167, 5.8821539878845215, 4.519249439239502, 2.503427028656006, 3.751598358154297, 3.650648355484009, 3.8597323894500732, 3.6523032188415527, 3.917309284210205, 6.0200982093811035, 3.375683307647705, 6.41122579574585, 3.236374616622925, 3.729228973388672, 4.811267852783203, 3.8011984825134277, 6.36073112487793, 4.54716682434082, 3.666419744491577, 4.997448921203613, 1.568436622619629, 5.933671951293945, 4.667149543762207, 3.494875907897949, 4.246162414550781, 5.393204689025879, 4.202596187591553, 4.360604286193848, 3.689415454864502, 5.313326835632324, 3.5309557914733887, 6.359990119934082, 3.30063533782959, 3.5111687183380127, 3.7749783992767334, 3.4709229469299316, 3.6056408882141113, 1.2714003324508667, 4.3900299072265625, 1.425980567932129, 3.8929760456085205, 1.7956247329711914, 5.147363662719727, 2.84506893157959, 4.632756233215332, 2.060655117034912, 4.058595180511475, 1.7467089891433716, 4.935146331787109, 4.167339324951172, 4.064756870269775, 3.110461711883545, 4.6880340576171875, 3.8534305095672607, 5.979287147521973, 4.85733699798584, 4.061708450317383, 3.586935043334961, 3.6222121715545654, 3.55332350730896, 5.262925148010254, 4.193174362182617, 6.177390098571777, 1.9373526573181152, 3.6488685607910156, 3.5919342041015625, 3.1287078857421875, 3.8866658210754395, 5.07666015625, 4.82747220993042, 3.613285541534424, 5.467853546142578, 3.770963191986084, 2.097158670425415, 5.121964454650879, 6.583508491516113, 5.553928375244141, 3.6303963661193848, 6.021087646484375, 2.1944146156311035, 3.767571449279785, 4.177580833435059, 3.3244240283966064, 4.018838882446289, 1.406690239906311, 3.2870242595672607, 1.0904282331466675, 3.79028058052063, 5.132285118103027, 1.1588083505630493, 1.8012709617614746, 3.4415178298950195, 5.795711994171143, 4.144331932067871, 3.697133779525757, 5.881625175476074, 4.885180473327637, 4.32846736907959, 5.698347091674805, 4.355808258056641, 2.852304458618164, 3.5382704734802246, 4.581252574920654, 5.8806962966918945, 3.631408452987671, 3.54172420501709, 3.525841236114502, 5.810808181762695, 3.452911138534546, 5.825016498565674, 4.279679298400879, 2.6056032180786133, 4.110466957092285, 4.058163642883301, 3.5343403816223145, 3.614637613296509, 3.833103895187378, 3.5381007194519043, 3.348200798034668, 4.160494804382324, 5.0451979637146, 1.3032927513122559, 4.278891086578369, 3.7458882331848145, 1.3804593086242676, 6.231526851654053, 3.680229425430298, 4.259893417358398, 3.6398677825927734, 3.6403799057006836, 3.284262180328369, 3.613736629486084, 3.5923776626586914, 3.2218856811523438, 4.271739959716797, 3.5183310508728027, 1.4956337213516235, 3.6538639068603516, 2.794539451599121, 3.377422571182251, 3.3922648429870605, 2.7461321353912354, 5.985980033874512, 3.8221545219421387, 4.234916687011719, 3.595402479171753, 4.9416890144348145, 3.4328298568725586, 5.657871723175049, 3.10849666595459, 6.366044044494629, 6.262820243835449, 3.8600001335144043, 3.488943576812744, 3.5773844718933105, 1.3200550079345703, 6.344932556152344, 1.2908945083618164, 6.516888618469238, 6.036508083343506, 2.093764305114746, 1.8163254261016846, 1.2686688899993896, 2.051384687423706, 3.5744667053222656, 6.247555255889893, 5.259080410003662, 3.3470888137817383, 1.816795825958252, 3.566635847091675, 4.2227067947387695, 5.9092864990234375, 6.469297409057617, 3.6849451065063477, 6.3254804611206055, 6.090638160705566, 1.3965948820114136, 3.9132747650146484, 3.8238556385040283, 5.02493953704834, 5.858498573303223, 3.4910988807678223, 6.069859504699707, 4.021690845489502, 4.018653392791748, 4.170628070831299, 3.734297037124634, 5.219805717468262, 4.325449466705322, 4.7596659660339355, 0.9032515287399292, 6.072780609130859, 4.118329048156738, 5.129090309143066, 5.444334506988525, 1.8215386867523193, 3.544332981109619, 3.4797585010528564, 6.389840126037598, 3.4772982597351074, 2.042191505432129, 3.9248790740966797, 3.733745574951172, 3.6060280799865723, 3.5470497608184814, 4.069858551025391, 3.571572780609131, 3.938910961151123, 3.6576271057128906, 3.702526330947876, 4.376387119293213, 3.6066317558288574, 6.555118560791016, 2.6209051609039307, 3.813312292098999, 3.5921730995178223, 6.412286758422852, 3.7433180809020996, 3.637554168701172, 3.566981792449951, 3.2188069820404053, 3.5279293060302734, 4.854675769805908, 3.486717700958252, 5.183073997497559, 4.5114641189575195, 1.365798830986023, 1.1438332796096802, 4.065525531768799, 3.7696335315704346, 5.885270118713379, 5.119595050811768, 6.017530918121338, 4.757282257080078, 3.9488320350646973, 6.2489190101623535, 2.6400089263916016, 3.585418939590454, 3.495058536529541, 3.889218330383301, 5.852492332458496, 3.114227294921875, 0.8907078504562378, 3.5118932723999023, 1.7281181812286377, 1.1111997365951538, 5.233076572418213, 5.601366996765137, 3.461980104446411, 3.486262321472168, 4.462536334991455, 3.531057119369507, 0.9550817012786865, 3.530412435531616, 2.695425271987915, 6.176014423370361, 3.5731029510498047, 4.261481761932373, 4.032958030700684, 3.954355478286743, 3.739781379699707, 2.5715856552124023, 3.712050437927246, 3.162675380706787, 4.531423568725586, 4.981146812438965, 3.342672824859619, 4.887946605682373, 3.4489192962646484, 3.970363140106201, 4.1134748458862305, 3.4176206588745117, 3.5816760063171387, 3.4358530044555664, 3.395458459854126, 5.145477771759033, 6.2218756675720215, 6.37939453125, 2.4410033226013184, 3.716503620147705, 5.637183666229248, 2.082940101623535, 3.6078271865844727, 4.355687141418457, 4.514976501464844, 3.5191640853881836, 1.5505962371826172, 2.584082841873169, 2.1360490322113037, 4.525669097900391, 3.57542085647583, 5.114969253540039, 2.016545295715332, 4.896265983581543, 3.595855712890625, 3.1442742347717285, 0.9058706760406494, 3.5113677978515625, 3.480501174926758, 5.1955647468566895, 5.692556858062744, 4.543879508972168, 4.8085408210754395, 3.675461769104004, 3.707051992416382, 3.812502384185791, 4.064090728759766, 1.1932575702667236, 4.392987251281738, 4.461897850036621, 4.066230773925781, 1.530639886856079, 4.385494709014893, 4.6365180015563965, 3.231401205062866, 3.491966485977173, 3.4298248291015625, 3.7304582595825195, 3.3430275917053223, 6.06868839263916, 2.4009251594543457, 5.784857749938965, 6.4724578857421875, 5.718235969543457, 6.553279876708984, 3.795576810836792, 4.447227478027344, 4.921086311340332, 3.483133316040039, 3.314288854598999, 3.953294277191162, 3.996584415435791, 3.5583481788635254, 3.4476146697998047, 3.703481912612915, 4.2408013343811035, 4.320720672607422, 3.9005043506622314, 5.616379737854004, 6.609673023223877, 4.768103122711182, 2.174546241760254, 3.559833526611328, 5.603170394897461, 1.5529627799987793, 3.5950634479522705, 2.5687408447265625, 6.298949241638184, 3.4075324535369873, 5.7989678382873535, 4.7028350830078125, 3.606191635131836, 4.076633453369141, 3.757174253463745, 6.174803256988525, 3.233680248260498, 4.610392093658447, 3.4573073387145996, 4.306331634521484, 3.657345771789551, 6.47621488571167, 3.923048496246338, 3.638256311416626, 3.568965435028076, 6.617990493774414, 4.361361503601074, 3.8511528968811035, 3.691366672515869, 3.5381884574890137, 1.9185371398925781, 2.9163284301757812, 3.5732405185699463, 4.359860420227051, 2.334369659423828, 5.511781692504883, 5.1657514572143555, 1.2230464220046997, 5.280760765075684, 3.752098560333252, 3.5886001586914062, 3.6128034591674805, 4.6089396476745605, 3.9895777702331543, 3.4285507202148438, 3.8234519958496094, 5.159120082855225, 6.008195877075195, 3.561509609222412, 4.98739767074585, 3.5415897369384766, 3.554352283477783, 3.8095574378967285, 5.3345441818237305, 3.529749870300293, 3.620103359222412, 3.7631778717041016, 6.473702907562256, 3.5286598205566406]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "# Generative Adversarial Networks (GAN) example in PyTorch. Tested with PyTorch 0.4.1, Python 3.6.7 (Nov 2018)\n",
    "# See related blog post at https://medium.com/@devnag/generative-adversarial-networks-gans-in-50-lines-of-code-pytorch-e81b79659e3f#.sch4xgsa9\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "matplotlib_is_available = True\n",
    "try:\n",
    "  from matplotlib import pyplot as plt\n",
    "except ImportError:\n",
    "  print(\"Will skip plotting; matplotlib is not available.\")\n",
    "  matplotlib_is_available = False\n",
    "\n",
    "# Data params\n",
    "data_mean = 4\n",
    "data_stddev = 1.25\n",
    "\n",
    "# ### Uncomment only one of these to define what data is actually sent to the Discriminator\n",
    "#(name, preprocess, d_input_func) = (\"Raw data\", lambda data: data, lambda x: x)\n",
    "#(name, preprocess, d_input_func) = (\"Data and variances\", lambda data: decorate_with_diffs(data, 2.0), lambda x: x * 2)\n",
    "#(name, preprocess, d_input_func) = (\"Data and diffs\", lambda data: decorate_with_diffs(data, 1.0), lambda x: x * 2)\n",
    "(name, preprocess, d_input_func) = (\"Only 4 moments\", lambda data: get_moments(data), lambda x: 4)\n",
    "\n",
    "print(\"Using data [%s]\" % (name))\n",
    "\n",
    "# ##### DATA: Target data and generator input data\n",
    "\n",
    "def get_distribution_sampler(mu, sigma):\n",
    "    return lambda n: torch.Tensor(np.random.normal(mu, sigma, (1, n)))  # Gaussian\n",
    "\n",
    "def get_generator_input_sampler():\n",
    "    return lambda m, n: torch.rand(m, n)  # Uniform-dist data into generator, _NOT_ Gaussian\n",
    "\n",
    "# ##### MODELS: Generator model and discriminator model\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, f):\n",
    "        super(Generator, self).__init__()\n",
    "        self.map1 = nn.Linear(input_size, hidden_size)\n",
    "        self.map2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.map3 = nn.Linear(hidden_size, output_size)\n",
    "        self.f = f\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.map1(x)\n",
    "        x = self.f(x)\n",
    "        x = self.map2(x)\n",
    "        x = self.f(x)\n",
    "        x = self.map3(x)\n",
    "        return x\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, f):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.map1 = nn.Linear(input_size, hidden_size)\n",
    "        self.map2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.map3 = nn.Linear(hidden_size, output_size)\n",
    "        self.f = f\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.f(self.map1(x))\n",
    "        x = self.f(self.map2(x))\n",
    "        return self.f(self.map3(x))\n",
    "\n",
    "def extract(v):\n",
    "    return v.data.storage().tolist()\n",
    "\n",
    "def stats(d):\n",
    "    return [np.mean(d), np.std(d)]\n",
    "\n",
    "def get_moments(d):\n",
    "    # Return the first 4 moments of the data provided\n",
    "    mean = torch.mean(d)\n",
    "    diffs = d - mean\n",
    "    var = torch.mean(torch.pow(diffs, 2.0))\n",
    "    std = torch.pow(var, 0.5)\n",
    "    zscores = diffs / std\n",
    "    skews = torch.mean(torch.pow(zscores, 3.0))\n",
    "    kurtoses = torch.mean(torch.pow(zscores, 4.0)) - 3.0  # excess kurtosis, should be 0 for Gaussian\n",
    "    final = torch.cat((mean.reshape(1,), std.reshape(1,), skews.reshape(1,), kurtoses.reshape(1,)))\n",
    "    return final\n",
    "\n",
    "def decorate_with_diffs(data, exponent, remove_raw_data=False):\n",
    "    mean = torch.mean(data.data, 1, keepdim=True)\n",
    "    mean_broadcast = torch.mul(torch.ones(data.size()), mean.tolist()[0][0])\n",
    "    diffs = torch.pow(data - Variable(mean_broadcast), exponent)\n",
    "    if remove_raw_data:\n",
    "        return torch.cat([diffs], 1)\n",
    "    else:\n",
    "        return torch.cat([data, diffs], 1)\n",
    "\n",
    "def train():\n",
    "    # Model parameters\n",
    "    g_input_size = 1      # Random noise dimension coming into generator, per output vector\n",
    "    g_hidden_size = 5     # Generator complexity\n",
    "    g_output_size = 1     # Size of generated output vector\n",
    "    d_input_size = 500    # Minibatch size - cardinality of distributions\n",
    "    d_hidden_size = 10    # Discriminator complexity\n",
    "    d_output_size = 1     # Single dimension for 'real' vs. 'fake' classification\n",
    "    minibatch_size = d_input_size\n",
    "\n",
    "    d_learning_rate = 1e-3\n",
    "    g_learning_rate = 1e-3\n",
    "    sgd_momentum = 0.9\n",
    "\n",
    "    num_epochs = 5000\n",
    "    print_interval = 100\n",
    "    d_steps = 20\n",
    "    g_steps = 20\n",
    "\n",
    "    dfe, dre, ge = 0, 0, 0\n",
    "    d_real_data, d_fake_data, g_fake_data = None, None, None\n",
    "\n",
    "    discriminator_activation_function = torch.sigmoid\n",
    "    generator_activation_function = torch.tanh\n",
    "\n",
    "    d_sampler = get_distribution_sampler(data_mean, data_stddev)\n",
    "    gi_sampler = get_generator_input_sampler()\n",
    "    G = Generator(input_size=g_input_size,\n",
    "                  hidden_size=g_hidden_size,\n",
    "                  output_size=g_output_size,\n",
    "                  f=generator_activation_function)\n",
    "    D = Discriminator(input_size=d_input_func(d_input_size),\n",
    "                      hidden_size=d_hidden_size,\n",
    "                      output_size=d_output_size,\n",
    "                      f=discriminator_activation_function)\n",
    "    criterion = nn.BCELoss()  # Binary cross entropy: http://pytorch.org/docs/nn.html#bceloss\n",
    "    d_optimizer = optim.SGD(D.parameters(), lr=d_learning_rate, momentum=sgd_momentum)\n",
    "    g_optimizer = optim.SGD(G.parameters(), lr=g_learning_rate, momentum=sgd_momentum)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for d_index in range(d_steps):\n",
    "            # 1. Train D on real+fake\n",
    "            D.zero_grad()\n",
    "\n",
    "            #  1A: Train D on real\n",
    "            d_real_data = Variable(d_sampler(d_input_size))\n",
    "            d_real_decision = D(preprocess(d_real_data))\n",
    "            d_real_error = criterion(d_real_decision, Variable(torch.ones([1,1])))  # ones = true\n",
    "            d_real_error.backward() # compute/store gradients, but don't change params\n",
    "\n",
    "            #  1B: Train D on fake\n",
    "            d_gen_input = Variable(gi_sampler(minibatch_size, g_input_size))\n",
    "            d_fake_data = G(d_gen_input).detach()  # detach to avoid training G on these labels\n",
    "            d_fake_decision = D(preprocess(d_fake_data.t()))\n",
    "            d_fake_error = criterion(d_fake_decision, Variable(torch.zeros([1,1])))  # zeros = fake\n",
    "            d_fake_error.backward()\n",
    "            d_optimizer.step()     # Only optimizes D's parameters; changes based on stored gradients from backward()\n",
    "\n",
    "            dre, dfe = extract(d_real_error)[0], extract(d_fake_error)[0]\n",
    "\n",
    "        for g_index in range(g_steps):\n",
    "            # 2. Train G on D's response (but DO NOT train D on these labels)\n",
    "            G.zero_grad()\n",
    "\n",
    "            gen_input = Variable(gi_sampler(minibatch_size, g_input_size))\n",
    "            g_fake_data = G(gen_input)\n",
    "            dg_fake_decision = D(preprocess(g_fake_data.t()))\n",
    "            g_error = criterion(dg_fake_decision, Variable(torch.ones([1,1])))  # Train G to pretend it's genuine\n",
    "\n",
    "            g_error.backward()\n",
    "            g_optimizer.step()  # Only optimizes G's parameters\n",
    "            ge = extract(g_error)[0]\n",
    "\n",
    "        if epoch % print_interval == 0:\n",
    "            print(\"Epoch %s: D (%s real_err, %s fake_err) G (%s err); Real Dist (%s),  Fake Dist (%s) \" %\n",
    "                  (epoch, dre, dfe, ge, stats(extract(d_real_data)), stats(extract(d_fake_data))))\n",
    "\n",
    "    if matplotlib_is_available:\n",
    "        print(\"Plotting the generated distribution...\")\n",
    "        values = extract(g_fake_data)\n",
    "        print(\" Values: %s\" % (str(values)))\n",
    "        plt.hist(values, bins=50)\n",
    "        plt.xlabel('Value')\n",
    "        plt.ylabel('Count')\n",
    "        plt.title('Histogram of Generated Distribution')\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
