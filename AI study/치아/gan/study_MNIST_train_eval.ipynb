{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: EPOCH 0001/0010 | BATCH 0001/0938 | LOSS: 2.2945 | ACC 0.1094\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0002/0938 | LOSS: 2.3011 | ACC 0.1250\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0003/0938 | LOSS: 2.2943 | ACC 0.1094\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0004/0938 | LOSS: 2.2997 | ACC 0.1133\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0005/0938 | LOSS: 2.2941 | ACC 0.1219\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0006/0938 | LOSS: 2.2936 | ACC 0.1224\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0007/0938 | LOSS: 2.2925 | ACC 0.1272\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0008/0938 | LOSS: 2.2925 | ACC 0.1270\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0009/0938 | LOSS: 2.2939 | ACC 0.1285\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0010/0938 | LOSS: 2.2891 | ACC 0.1328\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0011/0938 | LOSS: 2.2857 | ACC 0.1435\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0012/0938 | LOSS: 2.2817 | ACC 0.1432\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0013/0938 | LOSS: 2.2793 | ACC 0.1454\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0014/0938 | LOSS: 2.2752 | ACC 0.1529\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0015/0938 | LOSS: 2.2734 | ACC 0.1531\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0016/0938 | LOSS: 2.2707 | ACC 0.1553\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0017/0938 | LOSS: 2.2691 | ACC 0.1572\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0018/0938 | LOSS: 2.2662 | ACC 0.1606\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0019/0938 | LOSS: 2.2634 | ACC 0.1612\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0020/0938 | LOSS: 2.2587 | ACC 0.1625\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0021/0938 | LOSS: 2.2526 | ACC 0.1696\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0022/0938 | LOSS: 2.2512 | ACC 0.1726\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0023/0938 | LOSS: 2.2494 | ACC 0.1726\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0024/0938 | LOSS: 2.2436 | ACC 0.1771\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0025/0938 | LOSS: 2.2386 | ACC 0.1831\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0026/0938 | LOSS: 2.2331 | ACC 0.1887\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0027/0938 | LOSS: 2.2282 | ACC 0.1950\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0028/0938 | LOSS: 2.2218 | ACC 0.2009\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0029/0938 | LOSS: 2.2145 | ACC 0.2069\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0030/0938 | LOSS: 2.2116 | ACC 0.2089\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0031/0938 | LOSS: 2.2045 | ACC 0.2152\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0032/0938 | LOSS: 2.2021 | ACC 0.2158\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0033/0938 | LOSS: 2.1952 | ACC 0.2206\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0034/0938 | LOSS: 2.1877 | ACC 0.2266\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0035/0938 | LOSS: 2.1796 | ACC 0.2304\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0036/0938 | LOSS: 2.1704 | ACC 0.2370\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0037/0938 | LOSS: 2.1614 | ACC 0.2428\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0038/0938 | LOSS: 2.1531 | ACC 0.2463\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0039/0938 | LOSS: 2.1452 | ACC 0.2492\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0040/0938 | LOSS: 2.1403 | ACC 0.2520\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0041/0938 | LOSS: 2.1332 | ACC 0.2550\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0042/0938 | LOSS: 2.1244 | ACC 0.2597\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0043/0938 | LOSS: 2.1169 | ACC 0.2627\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0044/0938 | LOSS: 2.1062 | ACC 0.2663\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0045/0938 | LOSS: 2.0980 | ACC 0.2687\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0046/0938 | LOSS: 2.0895 | ACC 0.2711\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0047/0938 | LOSS: 2.0809 | ACC 0.2749\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0048/0938 | LOSS: 2.0695 | ACC 0.2793\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0049/0938 | LOSS: 2.0578 | ACC 0.2848\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0050/0938 | LOSS: 2.0460 | ACC 0.2903\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0051/0938 | LOSS: 2.0345 | ACC 0.2947\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0052/0938 | LOSS: 2.0242 | ACC 0.2984\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0053/0938 | LOSS: 2.0133 | ACC 0.3028\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0054/0938 | LOSS: 2.0032 | ACC 0.3070\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0055/0938 | LOSS: 1.9941 | ACC 0.3102\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0056/0938 | LOSS: 1.9869 | ACC 0.3133\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0057/0938 | LOSS: 1.9771 | ACC 0.3172\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0058/0938 | LOSS: 1.9671 | ACC 0.3211\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0059/0938 | LOSS: 1.9602 | ACC 0.3242\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0060/0938 | LOSS: 1.9473 | ACC 0.3294\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0061/0938 | LOSS: 1.9406 | ACC 0.3322\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0062/0938 | LOSS: 1.9298 | ACC 0.3357\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0063/0938 | LOSS: 1.9238 | ACC 0.3378\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0064/0938 | LOSS: 1.9152 | ACC 0.3403\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0065/0938 | LOSS: 1.9083 | ACC 0.3423\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0066/0938 | LOSS: 1.9011 | ACC 0.3449\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0067/0938 | LOSS: 1.8897 | ACC 0.3493\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0068/0938 | LOSS: 1.8801 | ACC 0.3525\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0069/0938 | LOSS: 1.8686 | ACC 0.3562\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0070/0938 | LOSS: 1.8567 | ACC 0.3605\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0071/0938 | LOSS: 1.8464 | ACC 0.3638\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0072/0938 | LOSS: 1.8379 | ACC 0.3668\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0073/0938 | LOSS: 1.8302 | ACC 0.3699\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0074/0938 | LOSS: 1.8205 | ACC 0.3737\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0075/0938 | LOSS: 1.8120 | ACC 0.3771\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0076/0938 | LOSS: 1.8031 | ACC 0.3793\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0077/0938 | LOSS: 1.7958 | ACC 0.3811\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0078/0938 | LOSS: 1.7852 | ACC 0.3856\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0079/0938 | LOSS: 1.7766 | ACC 0.3883\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0080/0938 | LOSS: 1.7672 | ACC 0.3924\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0081/0938 | LOSS: 1.7574 | ACC 0.3958\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0082/0938 | LOSS: 1.7488 | ACC 0.3990\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0083/0938 | LOSS: 1.7398 | ACC 0.4025\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0084/0938 | LOSS: 1.7343 | ACC 0.4046\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0085/0938 | LOSS: 1.7273 | ACC 0.4070\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0086/0938 | LOSS: 1.7223 | ACC 0.4090\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0087/0938 | LOSS: 1.7133 | ACC 0.4125\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0088/0938 | LOSS: 1.7058 | ACC 0.4150\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0089/0938 | LOSS: 1.6960 | ACC 0.4189\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0090/0938 | LOSS: 1.6888 | ACC 0.4217\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0091/0938 | LOSS: 1.6814 | ACC 0.4243\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0092/0938 | LOSS: 1.6749 | ACC 0.4273\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0093/0938 | LOSS: 1.6660 | ACC 0.4296\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0094/0938 | LOSS: 1.6582 | ACC 0.4330\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0095/0938 | LOSS: 1.6513 | ACC 0.4359\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0096/0938 | LOSS: 1.6450 | ACC 0.4390\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0097/0938 | LOSS: 1.6395 | ACC 0.4409\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0098/0938 | LOSS: 1.6337 | ACC 0.4428\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0099/0938 | LOSS: 1.6255 | ACC 0.4462\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0100/0938 | LOSS: 1.6168 | ACC 0.4491\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0101/0938 | LOSS: 1.6114 | ACC 0.4519\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0102/0938 | LOSS: 1.6061 | ACC 0.4540\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0103/0938 | LOSS: 1.5983 | ACC 0.4569\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0104/0938 | LOSS: 1.5918 | ACC 0.4594\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0105/0938 | LOSS: 1.5873 | ACC 0.4604\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0106/0938 | LOSS: 1.5796 | ACC 0.4637\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0107/0938 | LOSS: 1.5745 | ACC 0.4655\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0108/0938 | LOSS: 1.5680 | ACC 0.4679\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0109/0938 | LOSS: 1.5604 | ACC 0.4705\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0110/0938 | LOSS: 1.5540 | ACC 0.4733\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0111/0938 | LOSS: 1.5479 | ACC 0.4752\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0112/0938 | LOSS: 1.5419 | ACC 0.4778\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0113/0938 | LOSS: 1.5350 | ACC 0.4797\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0114/0938 | LOSS: 1.5307 | ACC 0.4814\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0115/0938 | LOSS: 1.5252 | ACC 0.4830\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0116/0938 | LOSS: 1.5207 | ACC 0.4846\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0117/0938 | LOSS: 1.5161 | ACC 0.4862\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0118/0938 | LOSS: 1.5098 | ACC 0.4889\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0119/0938 | LOSS: 1.5036 | ACC 0.4908\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0120/0938 | LOSS: 1.4976 | ACC 0.4928\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0121/0938 | LOSS: 1.4920 | ACC 0.4952\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0122/0938 | LOSS: 1.4852 | ACC 0.4974\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0123/0938 | LOSS: 1.4787 | ACC 0.4999\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0124/0938 | LOSS: 1.4753 | ACC 0.5010\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0125/0938 | LOSS: 1.4693 | ACC 0.5032\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0126/0938 | LOSS: 1.4638 | ACC 0.5056\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0127/0938 | LOSS: 1.4597 | ACC 0.5076\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: EPOCH 0001/0010 | BATCH 0128/0938 | LOSS: 1.4562 | ACC 0.5089\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0129/0938 | LOSS: 1.4515 | ACC 0.5109\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0130/0938 | LOSS: 1.4451 | ACC 0.5132\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0131/0938 | LOSS: 1.4397 | ACC 0.5153\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0132/0938 | LOSS: 1.4346 | ACC 0.5168\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0133/0938 | LOSS: 1.4286 | ACC 0.5186\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0134/0938 | LOSS: 1.4250 | ACC 0.5199\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0135/0938 | LOSS: 1.4213 | ACC 0.5215\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0136/0938 | LOSS: 1.4153 | ACC 0.5240\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0137/0938 | LOSS: 1.4097 | ACC 0.5260\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0138/0938 | LOSS: 1.4062 | ACC 0.5273\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0139/0938 | LOSS: 1.4007 | ACC 0.5293\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0140/0938 | LOSS: 1.3954 | ACC 0.5309\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0141/0938 | LOSS: 1.3908 | ACC 0.5327\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0142/0938 | LOSS: 1.3873 | ACC 0.5342\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0143/0938 | LOSS: 1.3824 | ACC 0.5357\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0144/0938 | LOSS: 1.3756 | ACC 0.5380\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0145/0938 | LOSS: 1.3685 | ACC 0.5405\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0146/0938 | LOSS: 1.3634 | ACC 0.5422\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0147/0938 | LOSS: 1.3574 | ACC 0.5442\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0148/0938 | LOSS: 1.3533 | ACC 0.5456\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0149/0938 | LOSS: 1.3475 | ACC 0.5474\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0150/0938 | LOSS: 1.3426 | ACC 0.5487\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0151/0938 | LOSS: 1.3390 | ACC 0.5499\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0152/0938 | LOSS: 1.3338 | ACC 0.5511\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0153/0938 | LOSS: 1.3309 | ACC 0.5527\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0154/0938 | LOSS: 1.3251 | ACC 0.5551\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0155/0938 | LOSS: 1.3219 | ACC 0.5560\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0156/0938 | LOSS: 1.3192 | ACC 0.5575\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0157/0938 | LOSS: 1.3160 | ACC 0.5583\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0158/0938 | LOSS: 1.3125 | ACC 0.5596\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0159/0938 | LOSS: 1.3090 | ACC 0.5610\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0160/0938 | LOSS: 1.3061 | ACC 0.5621\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0161/0938 | LOSS: 1.3034 | ACC 0.5632\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0162/0938 | LOSS: 1.2990 | ACC 0.5649\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0163/0938 | LOSS: 1.2955 | ACC 0.5662\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0164/0938 | LOSS: 1.2914 | ACC 0.5677\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0165/0938 | LOSS: 1.2882 | ACC 0.5689\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0166/0938 | LOSS: 1.2852 | ACC 0.5702\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0167/0938 | LOSS: 1.2829 | ACC 0.5709\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0168/0938 | LOSS: 1.2807 | ACC 0.5717\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0169/0938 | LOSS: 1.2767 | ACC 0.5727\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0170/0938 | LOSS: 1.2724 | ACC 0.5740\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0171/0938 | LOSS: 1.2688 | ACC 0.5753\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0172/0938 | LOSS: 1.2663 | ACC 0.5760\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0173/0938 | LOSS: 1.2645 | ACC 0.5772\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0174/0938 | LOSS: 1.2616 | ACC 0.5785\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0175/0938 | LOSS: 1.2573 | ACC 0.5799\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0176/0938 | LOSS: 1.2543 | ACC 0.5811\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0177/0938 | LOSS: 1.2510 | ACC 0.5824\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0178/0938 | LOSS: 1.2475 | ACC 0.5835\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0179/0938 | LOSS: 1.2437 | ACC 0.5845\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0180/0938 | LOSS: 1.2402 | ACC 0.5853\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0181/0938 | LOSS: 1.2372 | ACC 0.5865\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0182/0938 | LOSS: 1.2337 | ACC 0.5876\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0183/0938 | LOSS: 1.2316 | ACC 0.5882\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0184/0938 | LOSS: 1.2291 | ACC 0.5892\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0185/0938 | LOSS: 1.2270 | ACC 0.5900\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0186/0938 | LOSS: 1.2243 | ACC 0.5906\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0187/0938 | LOSS: 1.2195 | ACC 0.5923\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0188/0938 | LOSS: 1.2167 | ACC 0.5935\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0189/0938 | LOSS: 1.2149 | ACC 0.5943\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0190/0938 | LOSS: 1.2106 | ACC 0.5959\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0191/0938 | LOSS: 1.2074 | ACC 0.5969\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0192/0938 | LOSS: 1.2041 | ACC 0.5979\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0193/0938 | LOSS: 1.2009 | ACC 0.5992\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0194/0938 | LOSS: 1.1971 | ACC 0.6006\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0195/0938 | LOSS: 1.1947 | ACC 0.6012\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0196/0938 | LOSS: 1.1911 | ACC 0.6023\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0197/0938 | LOSS: 1.1890 | ACC 0.6033\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0198/0938 | LOSS: 1.1850 | ACC 0.6047\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0199/0938 | LOSS: 1.1821 | ACC 0.6059\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0200/0938 | LOSS: 1.1790 | ACC 0.6070\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0201/0938 | LOSS: 1.1767 | ACC 0.6077\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0202/0938 | LOSS: 1.1740 | ACC 0.6085\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0203/0938 | LOSS: 1.1710 | ACC 0.6095\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0204/0938 | LOSS: 1.1674 | ACC 0.6108\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0205/0938 | LOSS: 1.1646 | ACC 0.6118\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0206/0938 | LOSS: 1.1621 | ACC 0.6128\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0207/0938 | LOSS: 1.1599 | ACC 0.6133\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0208/0938 | LOSS: 1.1576 | ACC 0.6141\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0209/0938 | LOSS: 1.1541 | ACC 0.6153\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0210/0938 | LOSS: 1.1523 | ACC 0.6158\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0211/0938 | LOSS: 1.1487 | ACC 0.6170\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0212/0938 | LOSS: 1.1471 | ACC 0.6176\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0213/0938 | LOSS: 1.1434 | ACC 0.6188\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0214/0938 | LOSS: 1.1413 | ACC 0.6198\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0215/0938 | LOSS: 1.1384 | ACC 0.6206\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0216/0938 | LOSS: 1.1353 | ACC 0.6217\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0217/0938 | LOSS: 1.1324 | ACC 0.6228\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0218/0938 | LOSS: 1.1301 | ACC 0.6239\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0219/0938 | LOSS: 1.1278 | ACC 0.6248\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0220/0938 | LOSS: 1.1249 | ACC 0.6257\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0221/0938 | LOSS: 1.1221 | ACC 0.6265\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0222/0938 | LOSS: 1.1197 | ACC 0.6274\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0223/0938 | LOSS: 1.1177 | ACC 0.6280\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0224/0938 | LOSS: 1.1156 | ACC 0.6288\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0225/0938 | LOSS: 1.1136 | ACC 0.6296\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0226/0938 | LOSS: 1.1122 | ACC 0.6299\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0227/0938 | LOSS: 1.1106 | ACC 0.6305\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0228/0938 | LOSS: 1.1077 | ACC 0.6315\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0229/0938 | LOSS: 1.1056 | ACC 0.6320\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0230/0938 | LOSS: 1.1036 | ACC 0.6329\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0231/0938 | LOSS: 1.1016 | ACC 0.6338\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0232/0938 | LOSS: 1.0992 | ACC 0.6347\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0233/0938 | LOSS: 1.0978 | ACC 0.6351\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0234/0938 | LOSS: 1.0947 | ACC 0.6362\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0235/0938 | LOSS: 1.0919 | ACC 0.6371\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0236/0938 | LOSS: 1.0902 | ACC 0.6376\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0237/0938 | LOSS: 1.0872 | ACC 0.6387\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0238/0938 | LOSS: 1.0852 | ACC 0.6393\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0239/0938 | LOSS: 1.0843 | ACC 0.6398\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0240/0938 | LOSS: 1.0820 | ACC 0.6406\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0241/0938 | LOSS: 1.0802 | ACC 0.6413\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0242/0938 | LOSS: 1.0783 | ACC 0.6421\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0243/0938 | LOSS: 1.0759 | ACC 0.6428\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0244/0938 | LOSS: 1.0738 | ACC 0.6434\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0245/0938 | LOSS: 1.0722 | ACC 0.6440\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0246/0938 | LOSS: 1.0702 | ACC 0.6445\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0247/0938 | LOSS: 1.0679 | ACC 0.6452\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0248/0938 | LOSS: 1.0655 | ACC 0.6459\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0249/0938 | LOSS: 1.0633 | ACC 0.6469\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0250/0938 | LOSS: 1.0609 | ACC 0.6478\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0251/0938 | LOSS: 1.0585 | ACC 0.6485\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0252/0938 | LOSS: 1.0573 | ACC 0.6491\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0253/0938 | LOSS: 1.0561 | ACC 0.6498\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0254/0938 | LOSS: 1.0535 | ACC 0.6508\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: EPOCH 0001/0010 | BATCH 0255/0938 | LOSS: 1.0511 | ACC 0.6518\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0256/0938 | LOSS: 1.0499 | ACC 0.6522\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0257/0938 | LOSS: 1.0484 | ACC 0.6528\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0258/0938 | LOSS: 1.0460 | ACC 0.6537\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0259/0938 | LOSS: 1.0442 | ACC 0.6544\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0260/0938 | LOSS: 1.0426 | ACC 0.6550\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0261/0938 | LOSS: 1.0409 | ACC 0.6558\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0262/0938 | LOSS: 1.0388 | ACC 0.6564\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0263/0938 | LOSS: 1.0368 | ACC 0.6571\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0264/0938 | LOSS: 1.0344 | ACC 0.6580\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0265/0938 | LOSS: 1.0325 | ACC 0.6586\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0266/0938 | LOSS: 1.0303 | ACC 0.6595\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0267/0938 | LOSS: 1.0287 | ACC 0.6601\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0268/0938 | LOSS: 1.0261 | ACC 0.6610\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0269/0938 | LOSS: 1.0249 | ACC 0.6615\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0270/0938 | LOSS: 1.0231 | ACC 0.6622\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0271/0938 | LOSS: 1.0212 | ACC 0.6629\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0272/0938 | LOSS: 1.0187 | ACC 0.6638\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0273/0938 | LOSS: 1.0168 | ACC 0.6644\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0274/0938 | LOSS: 1.0151 | ACC 0.6651\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0275/0938 | LOSS: 1.0130 | ACC 0.6659\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0276/0938 | LOSS: 1.0112 | ACC 0.6665\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0277/0938 | LOSS: 1.0100 | ACC 0.6669\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0278/0938 | LOSS: 1.0085 | ACC 0.6675\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0279/0938 | LOSS: 1.0069 | ACC 0.6681\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0280/0938 | LOSS: 1.0043 | ACC 0.6690\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0281/0938 | LOSS: 1.0021 | ACC 0.6697\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0282/0938 | LOSS: 1.0007 | ACC 0.6701\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0283/0938 | LOSS: 0.9992 | ACC 0.6708\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0284/0938 | LOSS: 0.9968 | ACC 0.6715\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0285/0938 | LOSS: 0.9951 | ACC 0.6720\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0286/0938 | LOSS: 0.9937 | ACC 0.6724\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0287/0938 | LOSS: 0.9922 | ACC 0.6730\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0288/0938 | LOSS: 0.9901 | ACC 0.6737\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0289/0938 | LOSS: 0.9881 | ACC 0.6744\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0290/0938 | LOSS: 0.9866 | ACC 0.6749\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0291/0938 | LOSS: 0.9849 | ACC 0.6755\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0292/0938 | LOSS: 0.9829 | ACC 0.6761\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0293/0938 | LOSS: 0.9812 | ACC 0.6768\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0294/0938 | LOSS: 0.9797 | ACC 0.6774\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0295/0938 | LOSS: 0.9781 | ACC 0.6780\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0296/0938 | LOSS: 0.9763 | ACC 0.6786\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0297/0938 | LOSS: 0.9747 | ACC 0.6791\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0298/0938 | LOSS: 0.9726 | ACC 0.6797\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0299/0938 | LOSS: 0.9706 | ACC 0.6803\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0300/0938 | LOSS: 0.9685 | ACC 0.6810\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0301/0938 | LOSS: 0.9666 | ACC 0.6817\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0302/0938 | LOSS: 0.9647 | ACC 0.6824\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0303/0938 | LOSS: 0.9633 | ACC 0.6829\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0304/0938 | LOSS: 0.9623 | ACC 0.6833\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0305/0938 | LOSS: 0.9601 | ACC 0.6840\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0306/0938 | LOSS: 0.9583 | ACC 0.6847\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0307/0938 | LOSS: 0.9567 | ACC 0.6853\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0308/0938 | LOSS: 0.9553 | ACC 0.6857\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0309/0938 | LOSS: 0.9537 | ACC 0.6862\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0310/0938 | LOSS: 0.9519 | ACC 0.6869\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0311/0938 | LOSS: 0.9508 | ACC 0.6872\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0312/0938 | LOSS: 0.9507 | ACC 0.6877\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0313/0938 | LOSS: 0.9496 | ACC 0.6879\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0314/0938 | LOSS: 0.9486 | ACC 0.6884\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0315/0938 | LOSS: 0.9470 | ACC 0.6888\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0316/0938 | LOSS: 0.9456 | ACC 0.6893\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0317/0938 | LOSS: 0.9439 | ACC 0.6900\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0318/0938 | LOSS: 0.9421 | ACC 0.6905\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0319/0938 | LOSS: 0.9404 | ACC 0.6910\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0320/0938 | LOSS: 0.9389 | ACC 0.6915\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0321/0938 | LOSS: 0.9368 | ACC 0.6921\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0322/0938 | LOSS: 0.9356 | ACC 0.6925\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0323/0938 | LOSS: 0.9340 | ACC 0.6930\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0324/0938 | LOSS: 0.9321 | ACC 0.6936\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0325/0938 | LOSS: 0.9308 | ACC 0.6940\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0326/0938 | LOSS: 0.9297 | ACC 0.6944\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0327/0938 | LOSS: 0.9283 | ACC 0.6948\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0328/0938 | LOSS: 0.9267 | ACC 0.6953\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0329/0938 | LOSS: 0.9249 | ACC 0.6959\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0330/0938 | LOSS: 0.9238 | ACC 0.6963\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0331/0938 | LOSS: 0.9217 | ACC 0.6970\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0332/0938 | LOSS: 0.9202 | ACC 0.6977\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0333/0938 | LOSS: 0.9186 | ACC 0.6982\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0334/0938 | LOSS: 0.9173 | ACC 0.6986\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0335/0938 | LOSS: 0.9158 | ACC 0.6991\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0336/0938 | LOSS: 0.9141 | ACC 0.6997\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0337/0938 | LOSS: 0.9126 | ACC 0.7003\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0338/0938 | LOSS: 0.9109 | ACC 0.7010\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0339/0938 | LOSS: 0.9098 | ACC 0.7014\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0340/0938 | LOSS: 0.9081 | ACC 0.7020\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0341/0938 | LOSS: 0.9064 | ACC 0.7027\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0342/0938 | LOSS: 0.9050 | ACC 0.7031\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0343/0938 | LOSS: 0.9036 | ACC 0.7036\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0344/0938 | LOSS: 0.9023 | ACC 0.7041\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0345/0938 | LOSS: 0.9010 | ACC 0.7046\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0346/0938 | LOSS: 0.8994 | ACC 0.7052\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0347/0938 | LOSS: 0.8981 | ACC 0.7056\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0348/0938 | LOSS: 0.8964 | ACC 0.7062\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0349/0938 | LOSS: 0.8955 | ACC 0.7067\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0350/0938 | LOSS: 0.8943 | ACC 0.7070\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0351/0938 | LOSS: 0.8927 | ACC 0.7075\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0352/0938 | LOSS: 0.8912 | ACC 0.7081\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0353/0938 | LOSS: 0.8898 | ACC 0.7085\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0354/0938 | LOSS: 0.8884 | ACC 0.7090\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0355/0938 | LOSS: 0.8867 | ACC 0.7096\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0356/0938 | LOSS: 0.8852 | ACC 0.7100\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0357/0938 | LOSS: 0.8848 | ACC 0.7102\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0358/0938 | LOSS: 0.8834 | ACC 0.7106\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0359/0938 | LOSS: 0.8830 | ACC 0.7108\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0360/0938 | LOSS: 0.8814 | ACC 0.7112\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0361/0938 | LOSS: 0.8798 | ACC 0.7118\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0362/0938 | LOSS: 0.8782 | ACC 0.7124\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0363/0938 | LOSS: 0.8774 | ACC 0.7128\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0364/0938 | LOSS: 0.8760 | ACC 0.7133\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0365/0938 | LOSS: 0.8745 | ACC 0.7138\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0366/0938 | LOSS: 0.8735 | ACC 0.7143\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0367/0938 | LOSS: 0.8722 | ACC 0.7147\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0368/0938 | LOSS: 0.8708 | ACC 0.7152\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0369/0938 | LOSS: 0.8694 | ACC 0.7157\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0370/0938 | LOSS: 0.8680 | ACC 0.7161\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0371/0938 | LOSS: 0.8666 | ACC 0.7166\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0372/0938 | LOSS: 0.8657 | ACC 0.7170\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0373/0938 | LOSS: 0.8643 | ACC 0.7174\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0374/0938 | LOSS: 0.8628 | ACC 0.7180\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0375/0938 | LOSS: 0.8624 | ACC 0.7183\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0376/0938 | LOSS: 0.8611 | ACC 0.7189\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0377/0938 | LOSS: 0.8598 | ACC 0.7192\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0378/0938 | LOSS: 0.8585 | ACC 0.7197\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0379/0938 | LOSS: 0.8571 | ACC 0.7202\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0380/0938 | LOSS: 0.8555 | ACC 0.7207\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0381/0938 | LOSS: 0.8540 | ACC 0.7213\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: EPOCH 0001/0010 | BATCH 0382/0938 | LOSS: 0.8526 | ACC 0.7218\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0383/0938 | LOSS: 0.8516 | ACC 0.7221\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0384/0938 | LOSS: 0.8502 | ACC 0.7226\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0385/0938 | LOSS: 0.8487 | ACC 0.7230\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0386/0938 | LOSS: 0.8478 | ACC 0.7234\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0387/0938 | LOSS: 0.8463 | ACC 0.7240\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0388/0938 | LOSS: 0.8453 | ACC 0.7242\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0389/0938 | LOSS: 0.8441 | ACC 0.7247\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0390/0938 | LOSS: 0.8432 | ACC 0.7249\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0391/0938 | LOSS: 0.8421 | ACC 0.7252\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0392/0938 | LOSS: 0.8414 | ACC 0.7256\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0393/0938 | LOSS: 0.8406 | ACC 0.7259\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0394/0938 | LOSS: 0.8394 | ACC 0.7264\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0395/0938 | LOSS: 0.8384 | ACC 0.7267\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0396/0938 | LOSS: 0.8373 | ACC 0.7271\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0397/0938 | LOSS: 0.8366 | ACC 0.7273\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0398/0938 | LOSS: 0.8353 | ACC 0.7277\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0399/0938 | LOSS: 0.8346 | ACC 0.7279\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0400/0938 | LOSS: 0.8338 | ACC 0.7281\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0401/0938 | LOSS: 0.8330 | ACC 0.7286\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0402/0938 | LOSS: 0.8317 | ACC 0.7289\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0403/0938 | LOSS: 0.8309 | ACC 0.7291\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0404/0938 | LOSS: 0.8300 | ACC 0.7294\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0405/0938 | LOSS: 0.8289 | ACC 0.7297\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0406/0938 | LOSS: 0.8280 | ACC 0.7300\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0407/0938 | LOSS: 0.8268 | ACC 0.7304\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0408/0938 | LOSS: 0.8257 | ACC 0.7307\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0409/0938 | LOSS: 0.8246 | ACC 0.7310\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0410/0938 | LOSS: 0.8236 | ACC 0.7314\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0411/0938 | LOSS: 0.8229 | ACC 0.7315\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0412/0938 | LOSS: 0.8218 | ACC 0.7320\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0413/0938 | LOSS: 0.8206 | ACC 0.7324\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0414/0938 | LOSS: 0.8197 | ACC 0.7326\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0415/0938 | LOSS: 0.8184 | ACC 0.7331\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0416/0938 | LOSS: 0.8175 | ACC 0.7335\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0417/0938 | LOSS: 0.8165 | ACC 0.7338\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0418/0938 | LOSS: 0.8154 | ACC 0.7342\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0419/0938 | LOSS: 0.8144 | ACC 0.7345\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0420/0938 | LOSS: 0.8134 | ACC 0.7349\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0421/0938 | LOSS: 0.8123 | ACC 0.7353\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0422/0938 | LOSS: 0.8111 | ACC 0.7357\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0423/0938 | LOSS: 0.8103 | ACC 0.7360\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0424/0938 | LOSS: 0.8092 | ACC 0.7363\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0425/0938 | LOSS: 0.8083 | ACC 0.7367\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0426/0938 | LOSS: 0.8072 | ACC 0.7371\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0427/0938 | LOSS: 0.8065 | ACC 0.7374\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0428/0938 | LOSS: 0.8051 | ACC 0.7379\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0429/0938 | LOSS: 0.8039 | ACC 0.7383\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0430/0938 | LOSS: 0.8028 | ACC 0.7386\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0431/0938 | LOSS: 0.8024 | ACC 0.7389\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0432/0938 | LOSS: 0.8015 | ACC 0.7392\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0433/0938 | LOSS: 0.8006 | ACC 0.7394\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0434/0938 | LOSS: 0.8007 | ACC 0.7395\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0435/0938 | LOSS: 0.7996 | ACC 0.7398\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0436/0938 | LOSS: 0.7984 | ACC 0.7402\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0437/0938 | LOSS: 0.7977 | ACC 0.7406\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0438/0938 | LOSS: 0.7976 | ACC 0.7409\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0439/0938 | LOSS: 0.7969 | ACC 0.7411\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0440/0938 | LOSS: 0.7957 | ACC 0.7415\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0441/0938 | LOSS: 0.7950 | ACC 0.7417\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0442/0938 | LOSS: 0.7942 | ACC 0.7419\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0443/0938 | LOSS: 0.7931 | ACC 0.7424\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0444/0938 | LOSS: 0.7924 | ACC 0.7427\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0445/0938 | LOSS: 0.7918 | ACC 0.7429\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0446/0938 | LOSS: 0.7909 | ACC 0.7432\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0447/0938 | LOSS: 0.7902 | ACC 0.7435\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0448/0938 | LOSS: 0.7899 | ACC 0.7436\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0449/0938 | LOSS: 0.7887 | ACC 0.7439\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0450/0938 | LOSS: 0.7877 | ACC 0.7443\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0451/0938 | LOSS: 0.7874 | ACC 0.7444\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0452/0938 | LOSS: 0.7869 | ACC 0.7446\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0453/0938 | LOSS: 0.7862 | ACC 0.7449\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0454/0938 | LOSS: 0.7852 | ACC 0.7452\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0455/0938 | LOSS: 0.7842 | ACC 0.7455\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0456/0938 | LOSS: 0.7835 | ACC 0.7457\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0457/0938 | LOSS: 0.7825 | ACC 0.7460\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0458/0938 | LOSS: 0.7818 | ACC 0.7462\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0459/0938 | LOSS: 0.7811 | ACC 0.7466\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0460/0938 | LOSS: 0.7803 | ACC 0.7469\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0461/0938 | LOSS: 0.7798 | ACC 0.7471\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0462/0938 | LOSS: 0.7791 | ACC 0.7473\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0463/0938 | LOSS: 0.7783 | ACC 0.7474\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0464/0938 | LOSS: 0.7777 | ACC 0.7478\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0465/0938 | LOSS: 0.7770 | ACC 0.7480\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0466/0938 | LOSS: 0.7762 | ACC 0.7483\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0467/0938 | LOSS: 0.7754 | ACC 0.7485\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0468/0938 | LOSS: 0.7751 | ACC 0.7488\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0469/0938 | LOSS: 0.7739 | ACC 0.7492\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0470/0938 | LOSS: 0.7732 | ACC 0.7495\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0471/0938 | LOSS: 0.7725 | ACC 0.7498\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0472/0938 | LOSS: 0.7721 | ACC 0.7500\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0473/0938 | LOSS: 0.7716 | ACC 0.7502\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0474/0938 | LOSS: 0.7710 | ACC 0.7506\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0475/0938 | LOSS: 0.7705 | ACC 0.7508\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0476/0938 | LOSS: 0.7694 | ACC 0.7512\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0477/0938 | LOSS: 0.7686 | ACC 0.7514\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0478/0938 | LOSS: 0.7679 | ACC 0.7517\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0479/0938 | LOSS: 0.7673 | ACC 0.7519\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0480/0938 | LOSS: 0.7661 | ACC 0.7521\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0481/0938 | LOSS: 0.7654 | ACC 0.7523\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0482/0938 | LOSS: 0.7646 | ACC 0.7527\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0483/0938 | LOSS: 0.7641 | ACC 0.7527\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0484/0938 | LOSS: 0.7631 | ACC 0.7530\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0485/0938 | LOSS: 0.7621 | ACC 0.7534\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0486/0938 | LOSS: 0.7610 | ACC 0.7537\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0487/0938 | LOSS: 0.7602 | ACC 0.7541\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0488/0938 | LOSS: 0.7594 | ACC 0.7544\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0489/0938 | LOSS: 0.7589 | ACC 0.7546\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0490/0938 | LOSS: 0.7580 | ACC 0.7549\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0491/0938 | LOSS: 0.7573 | ACC 0.7551\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0492/0938 | LOSS: 0.7565 | ACC 0.7554\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0493/0938 | LOSS: 0.7560 | ACC 0.7556\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0494/0938 | LOSS: 0.7554 | ACC 0.7557\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0495/0938 | LOSS: 0.7547 | ACC 0.7559\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0496/0938 | LOSS: 0.7542 | ACC 0.7561\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0497/0938 | LOSS: 0.7536 | ACC 0.7564\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0498/0938 | LOSS: 0.7530 | ACC 0.7566\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0499/0938 | LOSS: 0.7527 | ACC 0.7567\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0500/0938 | LOSS: 0.7520 | ACC 0.7569\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0501/0938 | LOSS: 0.7512 | ACC 0.7572\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0502/0938 | LOSS: 0.7502 | ACC 0.7575\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0503/0938 | LOSS: 0.7492 | ACC 0.7579\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0504/0938 | LOSS: 0.7481 | ACC 0.7583\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0505/0938 | LOSS: 0.7479 | ACC 0.7584\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0506/0938 | LOSS: 0.7471 | ACC 0.7587\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0507/0938 | LOSS: 0.7462 | ACC 0.7590\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0508/0938 | LOSS: 0.7453 | ACC 0.7593\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0509/0938 | LOSS: 0.7444 | ACC 0.7596\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: EPOCH 0001/0010 | BATCH 0510/0938 | LOSS: 0.7441 | ACC 0.7598\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0511/0938 | LOSS: 0.7435 | ACC 0.7600\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0512/0938 | LOSS: 0.7431 | ACC 0.7602\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0513/0938 | LOSS: 0.7425 | ACC 0.7604\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0514/0938 | LOSS: 0.7419 | ACC 0.7606\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0515/0938 | LOSS: 0.7410 | ACC 0.7609\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0516/0938 | LOSS: 0.7408 | ACC 0.7610\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0517/0938 | LOSS: 0.7398 | ACC 0.7614\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0518/0938 | LOSS: 0.7389 | ACC 0.7616\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0519/0938 | LOSS: 0.7381 | ACC 0.7619\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0520/0938 | LOSS: 0.7379 | ACC 0.7621\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0521/0938 | LOSS: 0.7372 | ACC 0.7624\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0522/0938 | LOSS: 0.7365 | ACC 0.7627\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0523/0938 | LOSS: 0.7359 | ACC 0.7630\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0524/0938 | LOSS: 0.7356 | ACC 0.7631\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0525/0938 | LOSS: 0.7350 | ACC 0.7633\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0526/0938 | LOSS: 0.7348 | ACC 0.7634\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0527/0938 | LOSS: 0.7343 | ACC 0.7636\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0528/0938 | LOSS: 0.7336 | ACC 0.7638\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0529/0938 | LOSS: 0.7331 | ACC 0.7639\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0530/0938 | LOSS: 0.7326 | ACC 0.7641\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0531/0938 | LOSS: 0.7318 | ACC 0.7644\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0532/0938 | LOSS: 0.7313 | ACC 0.7647\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0533/0938 | LOSS: 0.7307 | ACC 0.7649\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0534/0938 | LOSS: 0.7300 | ACC 0.7651\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0535/0938 | LOSS: 0.7294 | ACC 0.7652\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0536/0938 | LOSS: 0.7290 | ACC 0.7655\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0537/0938 | LOSS: 0.7280 | ACC 0.7659\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0538/0938 | LOSS: 0.7271 | ACC 0.7662\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0539/0938 | LOSS: 0.7260 | ACC 0.7666\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0540/0938 | LOSS: 0.7254 | ACC 0.7668\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0541/0938 | LOSS: 0.7245 | ACC 0.7671\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0542/0938 | LOSS: 0.7235 | ACC 0.7674\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0543/0938 | LOSS: 0.7229 | ACC 0.7677\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0544/0938 | LOSS: 0.7223 | ACC 0.7679\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0545/0938 | LOSS: 0.7215 | ACC 0.7681\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0546/0938 | LOSS: 0.7210 | ACC 0.7684\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0547/0938 | LOSS: 0.7206 | ACC 0.7686\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0548/0938 | LOSS: 0.7200 | ACC 0.7688\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0549/0938 | LOSS: 0.7192 | ACC 0.7691\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0550/0938 | LOSS: 0.7185 | ACC 0.7693\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0551/0938 | LOSS: 0.7180 | ACC 0.7695\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0552/0938 | LOSS: 0.7173 | ACC 0.7698\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0553/0938 | LOSS: 0.7166 | ACC 0.7700\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0554/0938 | LOSS: 0.7161 | ACC 0.7701\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0555/0938 | LOSS: 0.7156 | ACC 0.7702\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0556/0938 | LOSS: 0.7152 | ACC 0.7704\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0557/0938 | LOSS: 0.7148 | ACC 0.7705\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0558/0938 | LOSS: 0.7142 | ACC 0.7707\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0559/0938 | LOSS: 0.7135 | ACC 0.7710\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0560/0938 | LOSS: 0.7127 | ACC 0.7713\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0561/0938 | LOSS: 0.7122 | ACC 0.7715\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0562/0938 | LOSS: 0.7118 | ACC 0.7716\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0563/0938 | LOSS: 0.7115 | ACC 0.7717\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0564/0938 | LOSS: 0.7110 | ACC 0.7719\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0565/0938 | LOSS: 0.7103 | ACC 0.7721\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0566/0938 | LOSS: 0.7100 | ACC 0.7723\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0567/0938 | LOSS: 0.7094 | ACC 0.7725\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0568/0938 | LOSS: 0.7090 | ACC 0.7726\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0569/0938 | LOSS: 0.7085 | ACC 0.7729\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0570/0938 | LOSS: 0.7080 | ACC 0.7731\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0571/0938 | LOSS: 0.7072 | ACC 0.7734\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0572/0938 | LOSS: 0.7067 | ACC 0.7736\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0573/0938 | LOSS: 0.7061 | ACC 0.7738\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0574/0938 | LOSS: 0.7053 | ACC 0.7741\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0575/0938 | LOSS: 0.7049 | ACC 0.7742\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0576/0938 | LOSS: 0.7048 | ACC 0.7742\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0577/0938 | LOSS: 0.7041 | ACC 0.7744\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0578/0938 | LOSS: 0.7035 | ACC 0.7746\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0579/0938 | LOSS: 0.7028 | ACC 0.7748\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0580/0938 | LOSS: 0.7023 | ACC 0.7750\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0581/0938 | LOSS: 0.7020 | ACC 0.7752\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0582/0938 | LOSS: 0.7015 | ACC 0.7754\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0583/0938 | LOSS: 0.7009 | ACC 0.7756\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0584/0938 | LOSS: 0.7003 | ACC 0.7758\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0585/0938 | LOSS: 0.7000 | ACC 0.7760\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0586/0938 | LOSS: 0.6994 | ACC 0.7763\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0587/0938 | LOSS: 0.6990 | ACC 0.7764\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0588/0938 | LOSS: 0.6986 | ACC 0.7766\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0589/0938 | LOSS: 0.6977 | ACC 0.7768\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0590/0938 | LOSS: 0.6968 | ACC 0.7771\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0591/0938 | LOSS: 0.6960 | ACC 0.7774\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0592/0938 | LOSS: 0.6956 | ACC 0.7775\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0593/0938 | LOSS: 0.6950 | ACC 0.7778\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0594/0938 | LOSS: 0.6944 | ACC 0.7780\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0595/0938 | LOSS: 0.6940 | ACC 0.7781\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0596/0938 | LOSS: 0.6933 | ACC 0.7784\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0597/0938 | LOSS: 0.6926 | ACC 0.7786\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0598/0938 | LOSS: 0.6921 | ACC 0.7787\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0599/0938 | LOSS: 0.6915 | ACC 0.7790\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0600/0938 | LOSS: 0.6909 | ACC 0.7792\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0601/0938 | LOSS: 0.6903 | ACC 0.7793\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0602/0938 | LOSS: 0.6895 | ACC 0.7796\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0603/0938 | LOSS: 0.6891 | ACC 0.7797\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0604/0938 | LOSS: 0.6884 | ACC 0.7800\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0605/0938 | LOSS: 0.6880 | ACC 0.7801\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0606/0938 | LOSS: 0.6873 | ACC 0.7803\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0607/0938 | LOSS: 0.6867 | ACC 0.7805\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0608/0938 | LOSS: 0.6862 | ACC 0.7807\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0609/0938 | LOSS: 0.6859 | ACC 0.7807\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0610/0938 | LOSS: 0.6853 | ACC 0.7808\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0611/0938 | LOSS: 0.6847 | ACC 0.7810\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0612/0938 | LOSS: 0.6841 | ACC 0.7812\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0613/0938 | LOSS: 0.6837 | ACC 0.7813\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0614/0938 | LOSS: 0.6832 | ACC 0.7815\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0615/0938 | LOSS: 0.6828 | ACC 0.7816\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0616/0938 | LOSS: 0.6824 | ACC 0.7817\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0617/0938 | LOSS: 0.6822 | ACC 0.7818\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0618/0938 | LOSS: 0.6820 | ACC 0.7819\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0619/0938 | LOSS: 0.6815 | ACC 0.7821\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0620/0938 | LOSS: 0.6810 | ACC 0.7822\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0621/0938 | LOSS: 0.6804 | ACC 0.7824\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0622/0938 | LOSS: 0.6796 | ACC 0.7826\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0623/0938 | LOSS: 0.6789 | ACC 0.7828\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0624/0938 | LOSS: 0.6786 | ACC 0.7829\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0625/0938 | LOSS: 0.6780 | ACC 0.7831\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0626/0938 | LOSS: 0.6773 | ACC 0.7833\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0627/0938 | LOSS: 0.6767 | ACC 0.7835\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0628/0938 | LOSS: 0.6764 | ACC 0.7836\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0629/0938 | LOSS: 0.6759 | ACC 0.7838\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0630/0938 | LOSS: 0.6753 | ACC 0.7840\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0631/0938 | LOSS: 0.6748 | ACC 0.7842\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0632/0938 | LOSS: 0.6741 | ACC 0.7844\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0633/0938 | LOSS: 0.6736 | ACC 0.7845\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0634/0938 | LOSS: 0.6731 | ACC 0.7847\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0635/0938 | LOSS: 0.6725 | ACC 0.7849\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: EPOCH 0001/0010 | BATCH 0636/0938 | LOSS: 0.6723 | ACC 0.7850\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0637/0938 | LOSS: 0.6718 | ACC 0.7852\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0638/0938 | LOSS: 0.6715 | ACC 0.7853\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0639/0938 | LOSS: 0.6709 | ACC 0.7855\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0640/0938 | LOSS: 0.6704 | ACC 0.7857\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0641/0938 | LOSS: 0.6700 | ACC 0.7858\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0642/0938 | LOSS: 0.6694 | ACC 0.7859\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0643/0938 | LOSS: 0.6688 | ACC 0.7861\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0644/0938 | LOSS: 0.6682 | ACC 0.7863\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0645/0938 | LOSS: 0.6677 | ACC 0.7864\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0646/0938 | LOSS: 0.6674 | ACC 0.7865\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0647/0938 | LOSS: 0.6669 | ACC 0.7867\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0648/0938 | LOSS: 0.6663 | ACC 0.7868\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0649/0938 | LOSS: 0.6660 | ACC 0.7869\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0650/0938 | LOSS: 0.6653 | ACC 0.7871\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0651/0938 | LOSS: 0.6649 | ACC 0.7873\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0652/0938 | LOSS: 0.6645 | ACC 0.7875\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0653/0938 | LOSS: 0.6641 | ACC 0.7876\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0654/0938 | LOSS: 0.6639 | ACC 0.7877\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0655/0938 | LOSS: 0.6633 | ACC 0.7879\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0656/0938 | LOSS: 0.6629 | ACC 0.7880\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0657/0938 | LOSS: 0.6624 | ACC 0.7881\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0658/0938 | LOSS: 0.6619 | ACC 0.7883\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0659/0938 | LOSS: 0.6614 | ACC 0.7885\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0660/0938 | LOSS: 0.6609 | ACC 0.7887\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0661/0938 | LOSS: 0.6605 | ACC 0.7888\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0662/0938 | LOSS: 0.6609 | ACC 0.7889\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0663/0938 | LOSS: 0.6602 | ACC 0.7891\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0664/0938 | LOSS: 0.6600 | ACC 0.7892\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0665/0938 | LOSS: 0.6593 | ACC 0.7894\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0666/0938 | LOSS: 0.6587 | ACC 0.7896\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0667/0938 | LOSS: 0.6583 | ACC 0.7897\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0668/0938 | LOSS: 0.6576 | ACC 0.7900\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0669/0938 | LOSS: 0.6570 | ACC 0.7901\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0670/0938 | LOSS: 0.6566 | ACC 0.7903\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0671/0938 | LOSS: 0.6562 | ACC 0.7903\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0672/0938 | LOSS: 0.6557 | ACC 0.7905\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0673/0938 | LOSS: 0.6553 | ACC 0.7906\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0674/0938 | LOSS: 0.6548 | ACC 0.7908\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0675/0938 | LOSS: 0.6543 | ACC 0.7909\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0676/0938 | LOSS: 0.6539 | ACC 0.7911\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0677/0938 | LOSS: 0.6535 | ACC 0.7913\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0678/0938 | LOSS: 0.6531 | ACC 0.7915\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0679/0938 | LOSS: 0.6527 | ACC 0.7916\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0680/0938 | LOSS: 0.6524 | ACC 0.7917\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0681/0938 | LOSS: 0.6520 | ACC 0.7918\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0682/0938 | LOSS: 0.6514 | ACC 0.7919\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0683/0938 | LOSS: 0.6508 | ACC 0.7921\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0684/0938 | LOSS: 0.6504 | ACC 0.7922\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0685/0938 | LOSS: 0.6499 | ACC 0.7924\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0686/0938 | LOSS: 0.6494 | ACC 0.7925\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0687/0938 | LOSS: 0.6491 | ACC 0.7927\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0688/0938 | LOSS: 0.6484 | ACC 0.7929\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0689/0938 | LOSS: 0.6486 | ACC 0.7929\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0690/0938 | LOSS: 0.6482 | ACC 0.7931\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0691/0938 | LOSS: 0.6477 | ACC 0.7933\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0692/0938 | LOSS: 0.6471 | ACC 0.7935\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0693/0938 | LOSS: 0.6472 | ACC 0.7935\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0694/0938 | LOSS: 0.6471 | ACC 0.7936\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0695/0938 | LOSS: 0.6466 | ACC 0.7938\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0696/0938 | LOSS: 0.6461 | ACC 0.7939\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0697/0938 | LOSS: 0.6458 | ACC 0.7941\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0698/0938 | LOSS: 0.6459 | ACC 0.7941\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0699/0938 | LOSS: 0.6457 | ACC 0.7941\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0700/0938 | LOSS: 0.6455 | ACC 0.7942\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0701/0938 | LOSS: 0.6451 | ACC 0.7943\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0702/0938 | LOSS: 0.6448 | ACC 0.7944\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0703/0938 | LOSS: 0.6444 | ACC 0.7946\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0704/0938 | LOSS: 0.6441 | ACC 0.7947\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0705/0938 | LOSS: 0.6435 | ACC 0.7950\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0706/0938 | LOSS: 0.6433 | ACC 0.7951\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0707/0938 | LOSS: 0.6427 | ACC 0.7952\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0708/0938 | LOSS: 0.6424 | ACC 0.7953\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0709/0938 | LOSS: 0.6418 | ACC 0.7955\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0710/0938 | LOSS: 0.6414 | ACC 0.7956\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0711/0938 | LOSS: 0.6409 | ACC 0.7958\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0712/0938 | LOSS: 0.6402 | ACC 0.7960\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0713/0938 | LOSS: 0.6399 | ACC 0.7961\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0714/0938 | LOSS: 0.6395 | ACC 0.7962\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0715/0938 | LOSS: 0.6388 | ACC 0.7965\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0716/0938 | LOSS: 0.6385 | ACC 0.7966\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0717/0938 | LOSS: 0.6381 | ACC 0.7967\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0718/0938 | LOSS: 0.6376 | ACC 0.7968\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0719/0938 | LOSS: 0.6376 | ACC 0.7969\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0720/0938 | LOSS: 0.6374 | ACC 0.7969\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0721/0938 | LOSS: 0.6369 | ACC 0.7971\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0722/0938 | LOSS: 0.6364 | ACC 0.7973\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0723/0938 | LOSS: 0.6359 | ACC 0.7975\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0724/0938 | LOSS: 0.6353 | ACC 0.7977\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0725/0938 | LOSS: 0.6352 | ACC 0.7978\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0726/0938 | LOSS: 0.6346 | ACC 0.7980\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0727/0938 | LOSS: 0.6340 | ACC 0.7981\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0728/0938 | LOSS: 0.6336 | ACC 0.7983\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0729/0938 | LOSS: 0.6332 | ACC 0.7984\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0730/0938 | LOSS: 0.6325 | ACC 0.7987\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0731/0938 | LOSS: 0.6321 | ACC 0.7987\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0732/0938 | LOSS: 0.6318 | ACC 0.7989\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0733/0938 | LOSS: 0.6313 | ACC 0.7991\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0734/0938 | LOSS: 0.6309 | ACC 0.7993\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0735/0938 | LOSS: 0.6307 | ACC 0.7994\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0736/0938 | LOSS: 0.6303 | ACC 0.7994\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0737/0938 | LOSS: 0.6299 | ACC 0.7995\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0738/0938 | LOSS: 0.6295 | ACC 0.7997\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0739/0938 | LOSS: 0.6289 | ACC 0.7999\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0740/0938 | LOSS: 0.6285 | ACC 0.8001\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0741/0938 | LOSS: 0.6279 | ACC 0.8003\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0742/0938 | LOSS: 0.6273 | ACC 0.8005\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0743/0938 | LOSS: 0.6267 | ACC 0.8006\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0744/0938 | LOSS: 0.6265 | ACC 0.8007\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0745/0938 | LOSS: 0.6266 | ACC 0.8006\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0746/0938 | LOSS: 0.6267 | ACC 0.8007\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0747/0938 | LOSS: 0.6264 | ACC 0.8008\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0748/0938 | LOSS: 0.6263 | ACC 0.8009\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0749/0938 | LOSS: 0.6261 | ACC 0.8011\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0750/0938 | LOSS: 0.6255 | ACC 0.8013\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0751/0938 | LOSS: 0.6249 | ACC 0.8014\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0752/0938 | LOSS: 0.6246 | ACC 0.8015\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0753/0938 | LOSS: 0.6242 | ACC 0.8016\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0754/0938 | LOSS: 0.6242 | ACC 0.8016\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0755/0938 | LOSS: 0.6236 | ACC 0.8018\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0756/0938 | LOSS: 0.6232 | ACC 0.8019\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0757/0938 | LOSS: 0.6228 | ACC 0.8021\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0758/0938 | LOSS: 0.6224 | ACC 0.8022\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0759/0938 | LOSS: 0.6220 | ACC 0.8024\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0760/0938 | LOSS: 0.6217 | ACC 0.8024\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0761/0938 | LOSS: 0.6215 | ACC 0.8025\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0762/0938 | LOSS: 0.6213 | ACC 0.8026\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: EPOCH 0001/0010 | BATCH 0763/0938 | LOSS: 0.6209 | ACC 0.8026\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0764/0938 | LOSS: 0.6207 | ACC 0.8027\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0765/0938 | LOSS: 0.6202 | ACC 0.8029\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0766/0938 | LOSS: 0.6197 | ACC 0.8030\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0767/0938 | LOSS: 0.6194 | ACC 0.8032\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0768/0938 | LOSS: 0.6189 | ACC 0.8034\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0769/0938 | LOSS: 0.6186 | ACC 0.8035\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0770/0938 | LOSS: 0.6186 | ACC 0.8036\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0771/0938 | LOSS: 0.6181 | ACC 0.8038\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0772/0938 | LOSS: 0.6176 | ACC 0.8040\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0773/0938 | LOSS: 0.6171 | ACC 0.8041\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0774/0938 | LOSS: 0.6168 | ACC 0.8042\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0775/0938 | LOSS: 0.6164 | ACC 0.8043\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0776/0938 | LOSS: 0.6160 | ACC 0.8045\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0777/0938 | LOSS: 0.6155 | ACC 0.8047\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0778/0938 | LOSS: 0.6152 | ACC 0.8048\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0779/0938 | LOSS: 0.6150 | ACC 0.8048\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0780/0938 | LOSS: 0.6145 | ACC 0.8050\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0781/0938 | LOSS: 0.6143 | ACC 0.8051\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0782/0938 | LOSS: 0.6140 | ACC 0.8051\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0783/0938 | LOSS: 0.6136 | ACC 0.8053\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0784/0938 | LOSS: 0.6134 | ACC 0.8053\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0785/0938 | LOSS: 0.6132 | ACC 0.8053\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0786/0938 | LOSS: 0.6128 | ACC 0.8054\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0787/0938 | LOSS: 0.6126 | ACC 0.8055\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0788/0938 | LOSS: 0.6122 | ACC 0.8057\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0789/0938 | LOSS: 0.6118 | ACC 0.8058\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0790/0938 | LOSS: 0.6114 | ACC 0.8059\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0791/0938 | LOSS: 0.6111 | ACC 0.8060\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0792/0938 | LOSS: 0.6108 | ACC 0.8061\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0793/0938 | LOSS: 0.6107 | ACC 0.8062\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0794/0938 | LOSS: 0.6110 | ACC 0.8061\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0795/0938 | LOSS: 0.6105 | ACC 0.8063\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0796/0938 | LOSS: 0.6103 | ACC 0.8065\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0797/0938 | LOSS: 0.6098 | ACC 0.8066\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0798/0938 | LOSS: 0.6095 | ACC 0.8068\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0799/0938 | LOSS: 0.6091 | ACC 0.8069\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0800/0938 | LOSS: 0.6086 | ACC 0.8071\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0801/0938 | LOSS: 0.6082 | ACC 0.8072\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0802/0938 | LOSS: 0.6078 | ACC 0.8073\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0803/0938 | LOSS: 0.6075 | ACC 0.8074\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0804/0938 | LOSS: 0.6071 | ACC 0.8075\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0805/0938 | LOSS: 0.6068 | ACC 0.8076\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0806/0938 | LOSS: 0.6065 | ACC 0.8077\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0807/0938 | LOSS: 0.6059 | ACC 0.8079\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0808/0938 | LOSS: 0.6058 | ACC 0.8080\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0809/0938 | LOSS: 0.6055 | ACC 0.8080\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0810/0938 | LOSS: 0.6055 | ACC 0.8081\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0811/0938 | LOSS: 0.6053 | ACC 0.8082\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0812/0938 | LOSS: 0.6050 | ACC 0.8082\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0813/0938 | LOSS: 0.6046 | ACC 0.8084\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0814/0938 | LOSS: 0.6040 | ACC 0.8085\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0815/0938 | LOSS: 0.6037 | ACC 0.8087\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0816/0938 | LOSS: 0.6037 | ACC 0.8086\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0817/0938 | LOSS: 0.6034 | ACC 0.8087\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0818/0938 | LOSS: 0.6031 | ACC 0.8089\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0819/0938 | LOSS: 0.6025 | ACC 0.8091\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0820/0938 | LOSS: 0.6020 | ACC 0.8092\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0821/0938 | LOSS: 0.6017 | ACC 0.8093\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0822/0938 | LOSS: 0.6014 | ACC 0.8095\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0823/0938 | LOSS: 0.6010 | ACC 0.8096\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0824/0938 | LOSS: 0.6007 | ACC 0.8097\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0825/0938 | LOSS: 0.6004 | ACC 0.8098\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0826/0938 | LOSS: 0.6001 | ACC 0.8100\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0827/0938 | LOSS: 0.5996 | ACC 0.8101\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0828/0938 | LOSS: 0.5992 | ACC 0.8103\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0829/0938 | LOSS: 0.5988 | ACC 0.8104\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0830/0938 | LOSS: 0.5986 | ACC 0.8105\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0831/0938 | LOSS: 0.5985 | ACC 0.8106\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0832/0938 | LOSS: 0.5983 | ACC 0.8106\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0833/0938 | LOSS: 0.5978 | ACC 0.8107\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0834/0938 | LOSS: 0.5974 | ACC 0.8108\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0835/0938 | LOSS: 0.5969 | ACC 0.8110\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0836/0938 | LOSS: 0.5967 | ACC 0.8111\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0837/0938 | LOSS: 0.5964 | ACC 0.8112\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0838/0938 | LOSS: 0.5960 | ACC 0.8113\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0839/0938 | LOSS: 0.5956 | ACC 0.8115\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0840/0938 | LOSS: 0.5952 | ACC 0.8117\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0841/0938 | LOSS: 0.5948 | ACC 0.8118\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0842/0938 | LOSS: 0.5943 | ACC 0.8119\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0843/0938 | LOSS: 0.5939 | ACC 0.8120\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0844/0938 | LOSS: 0.5936 | ACC 0.8121\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0845/0938 | LOSS: 0.5933 | ACC 0.8122\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0846/0938 | LOSS: 0.5928 | ACC 0.8124\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0847/0938 | LOSS: 0.5925 | ACC 0.8124\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0848/0938 | LOSS: 0.5921 | ACC 0.8126\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0849/0938 | LOSS: 0.5916 | ACC 0.8127\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0850/0938 | LOSS: 0.5914 | ACC 0.8127\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0851/0938 | LOSS: 0.5915 | ACC 0.8127\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0852/0938 | LOSS: 0.5913 | ACC 0.8127\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0853/0938 | LOSS: 0.5916 | ACC 0.8127\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0854/0938 | LOSS: 0.5915 | ACC 0.8128\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0855/0938 | LOSS: 0.5914 | ACC 0.8128\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0856/0938 | LOSS: 0.5909 | ACC 0.8130\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0857/0938 | LOSS: 0.5907 | ACC 0.8131\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0858/0938 | LOSS: 0.5904 | ACC 0.8132\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0859/0938 | LOSS: 0.5903 | ACC 0.8132\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0860/0938 | LOSS: 0.5900 | ACC 0.8134\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0861/0938 | LOSS: 0.5895 | ACC 0.8135\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0862/0938 | LOSS: 0.5892 | ACC 0.8136\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0863/0938 | LOSS: 0.5890 | ACC 0.8137\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0864/0938 | LOSS: 0.5887 | ACC 0.8138\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0865/0938 | LOSS: 0.5883 | ACC 0.8139\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0866/0938 | LOSS: 0.5881 | ACC 0.8139\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0867/0938 | LOSS: 0.5878 | ACC 0.8140\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0868/0938 | LOSS: 0.5875 | ACC 0.8141\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0869/0938 | LOSS: 0.5872 | ACC 0.8142\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0870/0938 | LOSS: 0.5869 | ACC 0.8143\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0871/0938 | LOSS: 0.5865 | ACC 0.8145\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0872/0938 | LOSS: 0.5862 | ACC 0.8145\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0873/0938 | LOSS: 0.5857 | ACC 0.8147\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0874/0938 | LOSS: 0.5853 | ACC 0.8148\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0875/0938 | LOSS: 0.5852 | ACC 0.8149\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0876/0938 | LOSS: 0.5849 | ACC 0.8149\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0877/0938 | LOSS: 0.5844 | ACC 0.8151\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0878/0938 | LOSS: 0.5841 | ACC 0.8153\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0879/0938 | LOSS: 0.5837 | ACC 0.8154\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0880/0938 | LOSS: 0.5833 | ACC 0.8155\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0881/0938 | LOSS: 0.5829 | ACC 0.8157\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0882/0938 | LOSS: 0.5827 | ACC 0.8158\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0883/0938 | LOSS: 0.5824 | ACC 0.8159\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0884/0938 | LOSS: 0.5820 | ACC 0.8160\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0885/0938 | LOSS: 0.5818 | ACC 0.8161\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0886/0938 | LOSS: 0.5815 | ACC 0.8162\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0887/0938 | LOSS: 0.5811 | ACC 0.8163\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0888/0938 | LOSS: 0.5808 | ACC 0.8164\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0889/0938 | LOSS: 0.5804 | ACC 0.8166\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: EPOCH 0001/0010 | BATCH 0890/0938 | LOSS: 0.5801 | ACC 0.8167\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0891/0938 | LOSS: 0.5797 | ACC 0.8168\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0892/0938 | LOSS: 0.5794 | ACC 0.8169\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0893/0938 | LOSS: 0.5792 | ACC 0.8170\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0894/0938 | LOSS: 0.5790 | ACC 0.8170\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0895/0938 | LOSS: 0.5787 | ACC 0.8171\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0896/0938 | LOSS: 0.5787 | ACC 0.8172\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0897/0938 | LOSS: 0.5785 | ACC 0.8173\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0898/0938 | LOSS: 0.5784 | ACC 0.8173\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0899/0938 | LOSS: 0.5781 | ACC 0.8174\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0900/0938 | LOSS: 0.5778 | ACC 0.8175\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0901/0938 | LOSS: 0.5775 | ACC 0.8177\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0902/0938 | LOSS: 0.5771 | ACC 0.8178\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0903/0938 | LOSS: 0.5769 | ACC 0.8178\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0904/0938 | LOSS: 0.5768 | ACC 0.8178\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0905/0938 | LOSS: 0.5766 | ACC 0.8179\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0906/0938 | LOSS: 0.5762 | ACC 0.8180\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0907/0938 | LOSS: 0.5759 | ACC 0.8182\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0908/0938 | LOSS: 0.5756 | ACC 0.8182\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0909/0938 | LOSS: 0.5753 | ACC 0.8184\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0910/0938 | LOSS: 0.5749 | ACC 0.8185\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0911/0938 | LOSS: 0.5745 | ACC 0.8186\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0912/0938 | LOSS: 0.5743 | ACC 0.8187\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0913/0938 | LOSS: 0.5739 | ACC 0.8188\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0914/0938 | LOSS: 0.5736 | ACC 0.8189\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0915/0938 | LOSS: 0.5734 | ACC 0.8189\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0916/0938 | LOSS: 0.5731 | ACC 0.8190\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0917/0938 | LOSS: 0.5731 | ACC 0.8190\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0918/0938 | LOSS: 0.5729 | ACC 0.8191\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0919/0938 | LOSS: 0.5726 | ACC 0.8192\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0920/0938 | LOSS: 0.5722 | ACC 0.8193\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0921/0938 | LOSS: 0.5718 | ACC 0.8195\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0922/0938 | LOSS: 0.5714 | ACC 0.8196\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0923/0938 | LOSS: 0.5711 | ACC 0.8197\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0924/0938 | LOSS: 0.5707 | ACC 0.8198\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0925/0938 | LOSS: 0.5705 | ACC 0.8199\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0926/0938 | LOSS: 0.5702 | ACC 0.8200\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0927/0938 | LOSS: 0.5697 | ACC 0.8202\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0928/0938 | LOSS: 0.5696 | ACC 0.8202\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0929/0938 | LOSS: 0.5693 | ACC 0.8203\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0930/0938 | LOSS: 0.5690 | ACC 0.8204\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0931/0938 | LOSS: 0.5686 | ACC 0.8205\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0932/0938 | LOSS: 0.5686 | ACC 0.8206\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0933/0938 | LOSS: 0.5684 | ACC 0.8206\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0934/0938 | LOSS: 0.5682 | ACC 0.8207\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0935/0938 | LOSS: 0.5681 | ACC 0.8208\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0936/0938 | LOSS: 0.5678 | ACC 0.8209\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0937/0938 | LOSS: 0.5677 | ACC 0.8210\n",
      "TRAIN: EPOCH 0001/0010 | BATCH 0938/0938 | LOSS: 0.5674 | ACC 0.8211\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0001/0938 | LOSS: 0.2101 | ACC 0.9531\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0002/0938 | LOSS: 0.2474 | ACC 0.9453\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0003/0938 | LOSS: 0.2382 | ACC 0.9375\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0004/0938 | LOSS: 0.2879 | ACC 0.9180\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0005/0938 | LOSS: 0.3035 | ACC 0.9125\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0006/0938 | LOSS: 0.3174 | ACC 0.9141\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0007/0938 | LOSS: 0.3195 | ACC 0.9129\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0008/0938 | LOSS: 0.3105 | ACC 0.9141\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0009/0938 | LOSS: 0.3186 | ACC 0.9062\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0010/0938 | LOSS: 0.3265 | ACC 0.9016\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0011/0938 | LOSS: 0.3153 | ACC 0.9062\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0012/0938 | LOSS: 0.3066 | ACC 0.9102\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0013/0938 | LOSS: 0.3133 | ACC 0.9099\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0014/0938 | LOSS: 0.3171 | ACC 0.9074\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0015/0938 | LOSS: 0.3126 | ACC 0.9104\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0016/0938 | LOSS: 0.3244 | ACC 0.9082\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0017/0938 | LOSS: 0.3308 | ACC 0.9062\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0018/0938 | LOSS: 0.3364 | ACC 0.9080\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0019/0938 | LOSS: 0.3368 | ACC 0.9062\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0020/0938 | LOSS: 0.3286 | ACC 0.9094\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0021/0938 | LOSS: 0.3249 | ACC 0.9100\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0022/0938 | LOSS: 0.3203 | ACC 0.9119\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0023/0938 | LOSS: 0.3345 | ACC 0.9096\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0024/0938 | LOSS: 0.3399 | ACC 0.9076\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0025/0938 | LOSS: 0.3317 | ACC 0.9100\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0026/0938 | LOSS: 0.3294 | ACC 0.9093\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0027/0938 | LOSS: 0.3266 | ACC 0.9103\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0028/0938 | LOSS: 0.3240 | ACC 0.9113\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0029/0938 | LOSS: 0.3294 | ACC 0.9100\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0030/0938 | LOSS: 0.3244 | ACC 0.9109\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0031/0938 | LOSS: 0.3212 | ACC 0.9118\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0032/0938 | LOSS: 0.3205 | ACC 0.9106\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0033/0938 | LOSS: 0.3197 | ACC 0.9115\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0034/0938 | LOSS: 0.3188 | ACC 0.9104\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0035/0938 | LOSS: 0.3172 | ACC 0.9094\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0036/0938 | LOSS: 0.3145 | ACC 0.9097\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0037/0938 | LOSS: 0.3135 | ACC 0.9109\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0038/0938 | LOSS: 0.3149 | ACC 0.9104\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0039/0938 | LOSS: 0.3128 | ACC 0.9111\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0040/0938 | LOSS: 0.3111 | ACC 0.9113\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0041/0938 | LOSS: 0.3148 | ACC 0.9101\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0042/0938 | LOSS: 0.3101 | ACC 0.9111\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0043/0938 | LOSS: 0.3066 | ACC 0.9124\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0044/0938 | LOSS: 0.3031 | ACC 0.9134\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0045/0938 | LOSS: 0.3012 | ACC 0.9142\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0046/0938 | LOSS: 0.3031 | ACC 0.9141\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0047/0938 | LOSS: 0.3011 | ACC 0.9142\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0048/0938 | LOSS: 0.2993 | ACC 0.9150\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0049/0938 | LOSS: 0.2987 | ACC 0.9155\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0050/0938 | LOSS: 0.3001 | ACC 0.9153\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0051/0938 | LOSS: 0.3031 | ACC 0.9142\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0052/0938 | LOSS: 0.3018 | ACC 0.9144\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0053/0938 | LOSS: 0.3020 | ACC 0.9142\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0054/0938 | LOSS: 0.3002 | ACC 0.9149\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0055/0938 | LOSS: 0.3027 | ACC 0.9151\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0056/0938 | LOSS: 0.3044 | ACC 0.9141\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0057/0938 | LOSS: 0.3057 | ACC 0.9139\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0058/0938 | LOSS: 0.3059 | ACC 0.9143\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0059/0938 | LOSS: 0.3062 | ACC 0.9142\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0060/0938 | LOSS: 0.3069 | ACC 0.9143\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0061/0938 | LOSS: 0.3073 | ACC 0.9134\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0062/0938 | LOSS: 0.3100 | ACC 0.9120\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0063/0938 | LOSS: 0.3105 | ACC 0.9117\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0064/0938 | LOSS: 0.3103 | ACC 0.9121\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0065/0938 | LOSS: 0.3109 | ACC 0.9120\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0066/0938 | LOSS: 0.3123 | ACC 0.9112\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0067/0938 | LOSS: 0.3130 | ACC 0.9100\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0068/0938 | LOSS: 0.3130 | ACC 0.9095\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0069/0938 | LOSS: 0.3112 | ACC 0.9103\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0070/0938 | LOSS: 0.3122 | ACC 0.9098\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0071/0938 | LOSS: 0.3115 | ACC 0.9100\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0072/0938 | LOSS: 0.3105 | ACC 0.9104\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0073/0938 | LOSS: 0.3087 | ACC 0.9103\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0074/0938 | LOSS: 0.3089 | ACC 0.9101\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0075/0938 | LOSS: 0.3107 | ACC 0.9094\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0076/0938 | LOSS: 0.3096 | ACC 0.9097\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0077/0938 | LOSS: 0.3084 | ACC 0.9101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: EPOCH 0002/0010 | BATCH 0078/0938 | LOSS: 0.3080 | ACC 0.9099\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0079/0938 | LOSS: 0.3076 | ACC 0.9098\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0080/0938 | LOSS: 0.3102 | ACC 0.9100\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0081/0938 | LOSS: 0.3101 | ACC 0.9097\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0082/0938 | LOSS: 0.3107 | ACC 0.9093\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0083/0938 | LOSS: 0.3107 | ACC 0.9093\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0084/0938 | LOSS: 0.3115 | ACC 0.9092\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0085/0938 | LOSS: 0.3108 | ACC 0.9096\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0086/0938 | LOSS: 0.3110 | ACC 0.9095\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0087/0938 | LOSS: 0.3094 | ACC 0.9102\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0088/0938 | LOSS: 0.3094 | ACC 0.9103\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0089/0938 | LOSS: 0.3087 | ACC 0.9103\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0090/0938 | LOSS: 0.3072 | ACC 0.9106\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0091/0938 | LOSS: 0.3075 | ACC 0.9104\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0092/0938 | LOSS: 0.3077 | ACC 0.9103\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0093/0938 | LOSS: 0.3079 | ACC 0.9105\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0094/0938 | LOSS: 0.3085 | ACC 0.9104\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0095/0938 | LOSS: 0.3076 | ACC 0.9107\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0096/0938 | LOSS: 0.3065 | ACC 0.9106\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0097/0938 | LOSS: 0.3059 | ACC 0.9106\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0098/0938 | LOSS: 0.3037 | ACC 0.9114\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0099/0938 | LOSS: 0.3023 | ACC 0.9119\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0100/0938 | LOSS: 0.3029 | ACC 0.9117\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0101/0938 | LOSS: 0.3035 | ACC 0.9115\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0102/0938 | LOSS: 0.3039 | ACC 0.9108\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0103/0938 | LOSS: 0.3060 | ACC 0.9106\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0104/0938 | LOSS: 0.3056 | ACC 0.9106\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0105/0938 | LOSS: 0.3042 | ACC 0.9110\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0106/0938 | LOSS: 0.3040 | ACC 0.9110\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0107/0938 | LOSS: 0.3029 | ACC 0.9111\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0108/0938 | LOSS: 0.3026 | ACC 0.9107\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0109/0938 | LOSS: 0.3018 | ACC 0.9111\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0110/0938 | LOSS: 0.3010 | ACC 0.9114\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0111/0938 | LOSS: 0.3007 | ACC 0.9113\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0112/0938 | LOSS: 0.3013 | ACC 0.9114\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0113/0938 | LOSS: 0.3012 | ACC 0.9114\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0114/0938 | LOSS: 0.3002 | ACC 0.9117\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0115/0938 | LOSS: 0.3018 | ACC 0.9113\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0116/0938 | LOSS: 0.3009 | ACC 0.9114\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0117/0938 | LOSS: 0.2994 | ACC 0.9119\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0118/0938 | LOSS: 0.2983 | ACC 0.9122\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0119/0938 | LOSS: 0.2990 | ACC 0.9123\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0120/0938 | LOSS: 0.3011 | ACC 0.9118\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0121/0938 | LOSS: 0.3011 | ACC 0.9119\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0122/0938 | LOSS: 0.3013 | ACC 0.9120\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0123/0938 | LOSS: 0.3000 | ACC 0.9126\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0124/0938 | LOSS: 0.3006 | ACC 0.9123\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0125/0938 | LOSS: 0.3002 | ACC 0.9125\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0126/0938 | LOSS: 0.3015 | ACC 0.9123\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0127/0938 | LOSS: 0.3008 | ACC 0.9128\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0128/0938 | LOSS: 0.3004 | ACC 0.9126\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0129/0938 | LOSS: 0.2998 | ACC 0.9127\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0130/0938 | LOSS: 0.3017 | ACC 0.9123\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0131/0938 | LOSS: 0.3011 | ACC 0.9123\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0132/0938 | LOSS: 0.3027 | ACC 0.9122\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0133/0938 | LOSS: 0.3015 | ACC 0.9125\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0134/0938 | LOSS: 0.3019 | ACC 0.9122\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0135/0938 | LOSS: 0.3028 | ACC 0.9124\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0136/0938 | LOSS: 0.3026 | ACC 0.9128\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0137/0938 | LOSS: 0.3026 | ACC 0.9130\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0138/0938 | LOSS: 0.3019 | ACC 0.9134\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0139/0938 | LOSS: 0.3022 | ACC 0.9130\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0140/0938 | LOSS: 0.3047 | ACC 0.9126\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0141/0938 | LOSS: 0.3064 | ACC 0.9126\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0142/0938 | LOSS: 0.3072 | ACC 0.9124\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0143/0938 | LOSS: 0.3078 | ACC 0.9122\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0144/0938 | LOSS: 0.3067 | ACC 0.9127\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0145/0938 | LOSS: 0.3068 | ACC 0.9124\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0146/0938 | LOSS: 0.3064 | ACC 0.9127\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0147/0938 | LOSS: 0.3056 | ACC 0.9131\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0148/0938 | LOSS: 0.3059 | ACC 0.9130\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0149/0938 | LOSS: 0.3062 | ACC 0.9126\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0150/0938 | LOSS: 0.3063 | ACC 0.9126\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0151/0938 | LOSS: 0.3064 | ACC 0.9128\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0152/0938 | LOSS: 0.3057 | ACC 0.9131\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0153/0938 | LOSS: 0.3057 | ACC 0.9133\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0154/0938 | LOSS: 0.3067 | ACC 0.9131\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0155/0938 | LOSS: 0.3062 | ACC 0.9134\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0156/0938 | LOSS: 0.3054 | ACC 0.9136\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0157/0938 | LOSS: 0.3054 | ACC 0.9136\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0158/0938 | LOSS: 0.3045 | ACC 0.9139\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0159/0938 | LOSS: 0.3052 | ACC 0.9137\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0160/0938 | LOSS: 0.3045 | ACC 0.9141\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0161/0938 | LOSS: 0.3045 | ACC 0.9141\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0162/0938 | LOSS: 0.3037 | ACC 0.9143\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0163/0938 | LOSS: 0.3029 | ACC 0.9144\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0164/0938 | LOSS: 0.3026 | ACC 0.9145\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0165/0938 | LOSS: 0.3017 | ACC 0.9147\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0166/0938 | LOSS: 0.3014 | ACC 0.9147\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0167/0938 | LOSS: 0.3015 | ACC 0.9148\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0168/0938 | LOSS: 0.3007 | ACC 0.9150\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0169/0938 | LOSS: 0.3003 | ACC 0.9152\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0170/0938 | LOSS: 0.2999 | ACC 0.9150\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0171/0938 | LOSS: 0.3003 | ACC 0.9147\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0172/0938 | LOSS: 0.3003 | ACC 0.9149\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0173/0938 | LOSS: 0.3001 | ACC 0.9147\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0174/0938 | LOSS: 0.2999 | ACC 0.9148\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0175/0938 | LOSS: 0.2996 | ACC 0.9148\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0176/0938 | LOSS: 0.2991 | ACC 0.9150\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0177/0938 | LOSS: 0.2994 | ACC 0.9151\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0178/0938 | LOSS: 0.2994 | ACC 0.9149\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0179/0938 | LOSS: 0.2989 | ACC 0.9149\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0180/0938 | LOSS: 0.2989 | ACC 0.9148\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0181/0938 | LOSS: 0.2990 | ACC 0.9148\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0182/0938 | LOSS: 0.2987 | ACC 0.9146\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0183/0938 | LOSS: 0.2990 | ACC 0.9144\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0184/0938 | LOSS: 0.2989 | ACC 0.9146\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0185/0938 | LOSS: 0.3018 | ACC 0.9141\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0186/0938 | LOSS: 0.3011 | ACC 0.9143\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0187/0938 | LOSS: 0.3018 | ACC 0.9143\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0188/0938 | LOSS: 0.3018 | ACC 0.9143\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0189/0938 | LOSS: 0.3017 | ACC 0.9145\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0190/0938 | LOSS: 0.3007 | ACC 0.9148\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0191/0938 | LOSS: 0.3001 | ACC 0.9152\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0192/0938 | LOSS: 0.3001 | ACC 0.9153\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0193/0938 | LOSS: 0.2999 | ACC 0.9152\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0194/0938 | LOSS: 0.3008 | ACC 0.9148\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0195/0938 | LOSS: 0.3018 | ACC 0.9147\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0196/0938 | LOSS: 0.3021 | ACC 0.9145\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0197/0938 | LOSS: 0.3020 | ACC 0.9145\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0198/0938 | LOSS: 0.3017 | ACC 0.9145\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0199/0938 | LOSS: 0.3013 | ACC 0.9145\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0200/0938 | LOSS: 0.3018 | ACC 0.9144\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0201/0938 | LOSS: 0.3019 | ACC 0.9143\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0202/0938 | LOSS: 0.3015 | ACC 0.9144\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: EPOCH 0002/0010 | BATCH 0203/0938 | LOSS: 0.3018 | ACC 0.9144\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0204/0938 | LOSS: 0.3017 | ACC 0.9145\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0205/0938 | LOSS: 0.3015 | ACC 0.9145\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0206/0938 | LOSS: 0.3009 | ACC 0.9146\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0207/0938 | LOSS: 0.3009 | ACC 0.9147\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0208/0938 | LOSS: 0.3002 | ACC 0.9150\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0209/0938 | LOSS: 0.2994 | ACC 0.9151\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0210/0938 | LOSS: 0.2995 | ACC 0.9153\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0211/0938 | LOSS: 0.2995 | ACC 0.9154\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0212/0938 | LOSS: 0.2992 | ACC 0.9153\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0213/0938 | LOSS: 0.2989 | ACC 0.9153\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0214/0938 | LOSS: 0.2982 | ACC 0.9156\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0215/0938 | LOSS: 0.2982 | ACC 0.9154\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0216/0938 | LOSS: 0.2977 | ACC 0.9154\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0217/0938 | LOSS: 0.2976 | ACC 0.9153\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0218/0938 | LOSS: 0.2973 | ACC 0.9154\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0219/0938 | LOSS: 0.2969 | ACC 0.9155\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0220/0938 | LOSS: 0.2971 | ACC 0.9157\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0221/0938 | LOSS: 0.2997 | ACC 0.9153\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0222/0938 | LOSS: 0.2993 | ACC 0.9153\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0223/0938 | LOSS: 0.2989 | ACC 0.9154\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0224/0938 | LOSS: 0.2987 | ACC 0.9153\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0225/0938 | LOSS: 0.2992 | ACC 0.9150\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0226/0938 | LOSS: 0.2992 | ACC 0.9151\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0227/0938 | LOSS: 0.2993 | ACC 0.9151\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0228/0938 | LOSS: 0.2992 | ACC 0.9151\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0229/0938 | LOSS: 0.2986 | ACC 0.9153\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0230/0938 | LOSS: 0.2983 | ACC 0.9154\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0231/0938 | LOSS: 0.2978 | ACC 0.9155\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0232/0938 | LOSS: 0.2974 | ACC 0.9156\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0233/0938 | LOSS: 0.2976 | ACC 0.9156\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0234/0938 | LOSS: 0.2977 | ACC 0.9155\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0235/0938 | LOSS: 0.2988 | ACC 0.9152\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0236/0938 | LOSS: 0.2988 | ACC 0.9152\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0237/0938 | LOSS: 0.2983 | ACC 0.9152\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0238/0938 | LOSS: 0.2981 | ACC 0.9152\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0239/0938 | LOSS: 0.2977 | ACC 0.9153\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0240/0938 | LOSS: 0.2988 | ACC 0.9151\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0241/0938 | LOSS: 0.2987 | ACC 0.9152\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0242/0938 | LOSS: 0.2991 | ACC 0.9150\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0243/0938 | LOSS: 0.2993 | ACC 0.9150\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0244/0938 | LOSS: 0.2995 | ACC 0.9149\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0245/0938 | LOSS: 0.2996 | ACC 0.9147\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0246/0938 | LOSS: 0.2994 | ACC 0.9148\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0247/0938 | LOSS: 0.2993 | ACC 0.9148\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0248/0938 | LOSS: 0.2987 | ACC 0.9149\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0249/0938 | LOSS: 0.2981 | ACC 0.9151\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0250/0938 | LOSS: 0.2985 | ACC 0.9149\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0251/0938 | LOSS: 0.2991 | ACC 0.9150\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0252/0938 | LOSS: 0.2987 | ACC 0.9151\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0253/0938 | LOSS: 0.2983 | ACC 0.9152\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0254/0938 | LOSS: 0.2980 | ACC 0.9152\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0255/0938 | LOSS: 0.2977 | ACC 0.9153\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0256/0938 | LOSS: 0.2980 | ACC 0.9150\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0257/0938 | LOSS: 0.2986 | ACC 0.9151\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0258/0938 | LOSS: 0.2984 | ACC 0.9150\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0259/0938 | LOSS: 0.2982 | ACC 0.9151\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0260/0938 | LOSS: 0.2986 | ACC 0.9150\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0261/0938 | LOSS: 0.2986 | ACC 0.9149\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0262/0938 | LOSS: 0.2986 | ACC 0.9147\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0263/0938 | LOSS: 0.2984 | ACC 0.9147\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0264/0938 | LOSS: 0.2983 | ACC 0.9145\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0265/0938 | LOSS: 0.2979 | ACC 0.9146\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0266/0938 | LOSS: 0.2981 | ACC 0.9145\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0267/0938 | LOSS: 0.2979 | ACC 0.9146\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0268/0938 | LOSS: 0.2979 | ACC 0.9145\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0269/0938 | LOSS: 0.2989 | ACC 0.9142\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0270/0938 | LOSS: 0.2990 | ACC 0.9143\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0271/0938 | LOSS: 0.2988 | ACC 0.9143\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0272/0938 | LOSS: 0.2988 | ACC 0.9141\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0273/0938 | LOSS: 0.2982 | ACC 0.9143\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0274/0938 | LOSS: 0.2982 | ACC 0.9142\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0275/0938 | LOSS: 0.2983 | ACC 0.9141\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0276/0938 | LOSS: 0.2983 | ACC 0.9141\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0277/0938 | LOSS: 0.2976 | ACC 0.9143\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0278/0938 | LOSS: 0.2980 | ACC 0.9142\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0279/0938 | LOSS: 0.2976 | ACC 0.9143\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0280/0938 | LOSS: 0.2974 | ACC 0.9142\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0281/0938 | LOSS: 0.2973 | ACC 0.9143\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0282/0938 | LOSS: 0.2976 | ACC 0.9141\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0283/0938 | LOSS: 0.2971 | ACC 0.9142\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0284/0938 | LOSS: 0.2969 | ACC 0.9142\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0285/0938 | LOSS: 0.2968 | ACC 0.9143\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0286/0938 | LOSS: 0.2966 | ACC 0.9142\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0287/0938 | LOSS: 0.2964 | ACC 0.9144\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0288/0938 | LOSS: 0.2960 | ACC 0.9145\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0289/0938 | LOSS: 0.2958 | ACC 0.9147\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0290/0938 | LOSS: 0.2954 | ACC 0.9148\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0291/0938 | LOSS: 0.2957 | ACC 0.9147\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0292/0938 | LOSS: 0.2955 | ACC 0.9147\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0293/0938 | LOSS: 0.2954 | ACC 0.9148\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0294/0938 | LOSS: 0.2956 | ACC 0.9147\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0295/0938 | LOSS: 0.2955 | ACC 0.9146\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0296/0938 | LOSS: 0.2951 | ACC 0.9147\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0297/0938 | LOSS: 0.2949 | ACC 0.9148\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0298/0938 | LOSS: 0.2950 | ACC 0.9147\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0299/0938 | LOSS: 0.2951 | ACC 0.9146\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0300/0938 | LOSS: 0.2953 | ACC 0.9144\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0301/0938 | LOSS: 0.2954 | ACC 0.9145\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0302/0938 | LOSS: 0.2950 | ACC 0.9147\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0303/0938 | LOSS: 0.2950 | ACC 0.9146\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0304/0938 | LOSS: 0.2951 | ACC 0.9144\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0305/0938 | LOSS: 0.2949 | ACC 0.9145\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0306/0938 | LOSS: 0.2947 | ACC 0.9146\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0307/0938 | LOSS: 0.2946 | ACC 0.9146\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0308/0938 | LOSS: 0.2952 | ACC 0.9145\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0309/0938 | LOSS: 0.2950 | ACC 0.9144\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0310/0938 | LOSS: 0.2949 | ACC 0.9144\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0311/0938 | LOSS: 0.2950 | ACC 0.9142\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0312/0938 | LOSS: 0.2950 | ACC 0.9143\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0313/0938 | LOSS: 0.2954 | ACC 0.9142\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0314/0938 | LOSS: 0.2952 | ACC 0.9142\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0315/0938 | LOSS: 0.2953 | ACC 0.9141\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0316/0938 | LOSS: 0.2948 | ACC 0.9143\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0317/0938 | LOSS: 0.2942 | ACC 0.9144\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0318/0938 | LOSS: 0.2937 | ACC 0.9146\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0319/0938 | LOSS: 0.2935 | ACC 0.9146\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0320/0938 | LOSS: 0.2935 | ACC 0.9146\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0321/0938 | LOSS: 0.2931 | ACC 0.9146\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0322/0938 | LOSS: 0.2931 | ACC 0.9146\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0323/0938 | LOSS: 0.2929 | ACC 0.9145\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: EPOCH 0002/0010 | BATCH 0324/0938 | LOSS: 0.2928 | ACC 0.9144\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0325/0938 | LOSS: 0.2931 | ACC 0.9146\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0326/0938 | LOSS: 0.2930 | ACC 0.9146\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0327/0938 | LOSS: 0.2925 | ACC 0.9149\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0328/0938 | LOSS: 0.2928 | ACC 0.9148\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0329/0938 | LOSS: 0.2928 | ACC 0.9148\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0330/0938 | LOSS: 0.2929 | ACC 0.9148\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0331/0938 | LOSS: 0.2927 | ACC 0.9149\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0332/0938 | LOSS: 0.2923 | ACC 0.9150\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0333/0938 | LOSS: 0.2920 | ACC 0.9150\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0334/0938 | LOSS: 0.2916 | ACC 0.9151\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0335/0938 | LOSS: 0.2920 | ACC 0.9150\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0336/0938 | LOSS: 0.2917 | ACC 0.9150\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0337/0938 | LOSS: 0.2915 | ACC 0.9152\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0338/0938 | LOSS: 0.2921 | ACC 0.9151\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0339/0938 | LOSS: 0.2915 | ACC 0.9152\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0340/0938 | LOSS: 0.2920 | ACC 0.9152\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0341/0938 | LOSS: 0.2923 | ACC 0.9151\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0342/0938 | LOSS: 0.2919 | ACC 0.9153\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0343/0938 | LOSS: 0.2915 | ACC 0.9154\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0344/0938 | LOSS: 0.2910 | ACC 0.9156\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0345/0938 | LOSS: 0.2919 | ACC 0.9153\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0346/0938 | LOSS: 0.2917 | ACC 0.9152\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0347/0938 | LOSS: 0.2924 | ACC 0.9151\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0348/0938 | LOSS: 0.2922 | ACC 0.9151\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0349/0938 | LOSS: 0.2920 | ACC 0.9151\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0350/0938 | LOSS: 0.2916 | ACC 0.9152\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0351/0938 | LOSS: 0.2915 | ACC 0.9152\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0352/0938 | LOSS: 0.2914 | ACC 0.9153\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0353/0938 | LOSS: 0.2917 | ACC 0.9153\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0354/0938 | LOSS: 0.2920 | ACC 0.9153\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0355/0938 | LOSS: 0.2923 | ACC 0.9151\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0356/0938 | LOSS: 0.2920 | ACC 0.9152\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0357/0938 | LOSS: 0.2917 | ACC 0.9154\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0358/0938 | LOSS: 0.2915 | ACC 0.9153\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0359/0938 | LOSS: 0.2912 | ACC 0.9153\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0360/0938 | LOSS: 0.2909 | ACC 0.9155\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0361/0938 | LOSS: 0.2908 | ACC 0.9155\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0362/0938 | LOSS: 0.2905 | ACC 0.9156\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0363/0938 | LOSS: 0.2905 | ACC 0.9155\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0364/0938 | LOSS: 0.2904 | ACC 0.9154\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0365/0938 | LOSS: 0.2905 | ACC 0.9155\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0366/0938 | LOSS: 0.2905 | ACC 0.9155\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0367/0938 | LOSS: 0.2910 | ACC 0.9153\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0368/0938 | LOSS: 0.2907 | ACC 0.9153\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0369/0938 | LOSS: 0.2913 | ACC 0.9151\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0370/0938 | LOSS: 0.2911 | ACC 0.9151\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0371/0938 | LOSS: 0.2907 | ACC 0.9152\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0372/0938 | LOSS: 0.2911 | ACC 0.9152\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0373/0938 | LOSS: 0.2910 | ACC 0.9153\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0374/0938 | LOSS: 0.2909 | ACC 0.9152\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0375/0938 | LOSS: 0.2913 | ACC 0.9150\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0376/0938 | LOSS: 0.2911 | ACC 0.9151\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0377/0938 | LOSS: 0.2912 | ACC 0.9150\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0378/0938 | LOSS: 0.2919 | ACC 0.9149\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0379/0938 | LOSS: 0.2919 | ACC 0.9149\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0380/0938 | LOSS: 0.2916 | ACC 0.9150\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0381/0938 | LOSS: 0.2918 | ACC 0.9150\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0382/0938 | LOSS: 0.2915 | ACC 0.9150\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0383/0938 | LOSS: 0.2916 | ACC 0.9150\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0384/0938 | LOSS: 0.2920 | ACC 0.9149\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0385/0938 | LOSS: 0.2917 | ACC 0.9150\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0386/0938 | LOSS: 0.2915 | ACC 0.9151\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0387/0938 | LOSS: 0.2915 | ACC 0.9151\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0388/0938 | LOSS: 0.2911 | ACC 0.9152\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0389/0938 | LOSS: 0.2914 | ACC 0.9150\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0390/0938 | LOSS: 0.2914 | ACC 0.9150\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0391/0938 | LOSS: 0.2916 | ACC 0.9149\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0392/0938 | LOSS: 0.2915 | ACC 0.9148\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0393/0938 | LOSS: 0.2910 | ACC 0.9150\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0394/0938 | LOSS: 0.2906 | ACC 0.9151\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0395/0938 | LOSS: 0.2903 | ACC 0.9152\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0396/0938 | LOSS: 0.2900 | ACC 0.9153\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0397/0938 | LOSS: 0.2899 | ACC 0.9151\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0398/0938 | LOSS: 0.2901 | ACC 0.9150\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0399/0938 | LOSS: 0.2900 | ACC 0.9150\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0400/0938 | LOSS: 0.2903 | ACC 0.9149\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0401/0938 | LOSS: 0.2902 | ACC 0.9149\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0402/0938 | LOSS: 0.2902 | ACC 0.9149\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0403/0938 | LOSS: 0.2900 | ACC 0.9149\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0404/0938 | LOSS: 0.2895 | ACC 0.9151\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0405/0938 | LOSS: 0.2891 | ACC 0.9152\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0406/0938 | LOSS: 0.2894 | ACC 0.9152\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0407/0938 | LOSS: 0.2895 | ACC 0.9152\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0408/0938 | LOSS: 0.2892 | ACC 0.9152\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0409/0938 | LOSS: 0.2893 | ACC 0.9153\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0410/0938 | LOSS: 0.2893 | ACC 0.9153\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0411/0938 | LOSS: 0.2890 | ACC 0.9154\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0412/0938 | LOSS: 0.2894 | ACC 0.9153\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0413/0938 | LOSS: 0.2894 | ACC 0.9154\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0414/0938 | LOSS: 0.2893 | ACC 0.9154\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0415/0938 | LOSS: 0.2895 | ACC 0.9154\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0416/0938 | LOSS: 0.2895 | ACC 0.9153\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0417/0938 | LOSS: 0.2892 | ACC 0.9154\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0418/0938 | LOSS: 0.2891 | ACC 0.9154\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0419/0938 | LOSS: 0.2890 | ACC 0.9155\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0420/0938 | LOSS: 0.2888 | ACC 0.9155\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0421/0938 | LOSS: 0.2889 | ACC 0.9154\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0422/0938 | LOSS: 0.2889 | ACC 0.9154\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0423/0938 | LOSS: 0.2894 | ACC 0.9152\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0424/0938 | LOSS: 0.2894 | ACC 0.9152\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0425/0938 | LOSS: 0.2891 | ACC 0.9152\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0426/0938 | LOSS: 0.2889 | ACC 0.9153\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0427/0938 | LOSS: 0.2892 | ACC 0.9151\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0428/0938 | LOSS: 0.2889 | ACC 0.9152\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0429/0938 | LOSS: 0.2889 | ACC 0.9152\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0430/0938 | LOSS: 0.2885 | ACC 0.9153\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0431/0938 | LOSS: 0.2887 | ACC 0.9152\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0432/0938 | LOSS: 0.2885 | ACC 0.9153\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0433/0938 | LOSS: 0.2882 | ACC 0.9154\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0434/0938 | LOSS: 0.2883 | ACC 0.9155\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0435/0938 | LOSS: 0.2883 | ACC 0.9156\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0436/0938 | LOSS: 0.2883 | ACC 0.9155\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0437/0938 | LOSS: 0.2888 | ACC 0.9155\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0438/0938 | LOSS: 0.2886 | ACC 0.9155\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0439/0938 | LOSS: 0.2883 | ACC 0.9156\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0440/0938 | LOSS: 0.2880 | ACC 0.9157\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0441/0938 | LOSS: 0.2882 | ACC 0.9156\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0442/0938 | LOSS: 0.2881 | ACC 0.9157\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0443/0938 | LOSS: 0.2882 | ACC 0.9157\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0444/0938 | LOSS: 0.2886 | ACC 0.9155\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0445/0938 | LOSS: 0.2885 | ACC 0.9154\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0446/0938 | LOSS: 0.2884 | ACC 0.9154\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0447/0938 | LOSS: 0.2886 | ACC 0.9153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: EPOCH 0002/0010 | BATCH 0448/0938 | LOSS: 0.2884 | ACC 0.9154\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0449/0938 | LOSS: 0.2885 | ACC 0.9153\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0450/0938 | LOSS: 0.2888 | ACC 0.9153\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0451/0938 | LOSS: 0.2889 | ACC 0.9154\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0452/0938 | LOSS: 0.2887 | ACC 0.9154\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0453/0938 | LOSS: 0.2886 | ACC 0.9155\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0454/0938 | LOSS: 0.2887 | ACC 0.9155\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0455/0938 | LOSS: 0.2889 | ACC 0.9155\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0456/0938 | LOSS: 0.2890 | ACC 0.9155\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0457/0938 | LOSS: 0.2888 | ACC 0.9155\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0458/0938 | LOSS: 0.2888 | ACC 0.9155\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0459/0938 | LOSS: 0.2887 | ACC 0.9155\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0460/0938 | LOSS: 0.2886 | ACC 0.9156\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0461/0938 | LOSS: 0.2885 | ACC 0.9156\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0462/0938 | LOSS: 0.2881 | ACC 0.9157\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0463/0938 | LOSS: 0.2878 | ACC 0.9158\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0464/0938 | LOSS: 0.2878 | ACC 0.9159\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0465/0938 | LOSS: 0.2876 | ACC 0.9160\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0466/0938 | LOSS: 0.2873 | ACC 0.9160\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0467/0938 | LOSS: 0.2870 | ACC 0.9161\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0468/0938 | LOSS: 0.2872 | ACC 0.9160\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0469/0938 | LOSS: 0.2872 | ACC 0.9160\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0470/0938 | LOSS: 0.2873 | ACC 0.9160\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0471/0938 | LOSS: 0.2871 | ACC 0.9160\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0472/0938 | LOSS: 0.2872 | ACC 0.9159\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0473/0938 | LOSS: 0.2871 | ACC 0.9160\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0474/0938 | LOSS: 0.2869 | ACC 0.9160\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0475/0938 | LOSS: 0.2866 | ACC 0.9161\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0476/0938 | LOSS: 0.2868 | ACC 0.9160\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0477/0938 | LOSS: 0.2867 | ACC 0.9161\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0478/0938 | LOSS: 0.2870 | ACC 0.9160\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0479/0938 | LOSS: 0.2867 | ACC 0.9160\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0480/0938 | LOSS: 0.2865 | ACC 0.9160\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0481/0938 | LOSS: 0.2865 | ACC 0.9160\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0482/0938 | LOSS: 0.2864 | ACC 0.9160\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0483/0938 | LOSS: 0.2868 | ACC 0.9159\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0484/0938 | LOSS: 0.2864 | ACC 0.9160\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0485/0938 | LOSS: 0.2863 | ACC 0.9159\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0486/0938 | LOSS: 0.2861 | ACC 0.9160\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0487/0938 | LOSS: 0.2859 | ACC 0.9160\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0488/0938 | LOSS: 0.2856 | ACC 0.9160\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0489/0938 | LOSS: 0.2854 | ACC 0.9162\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0490/0938 | LOSS: 0.2854 | ACC 0.9161\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0491/0938 | LOSS: 0.2853 | ACC 0.9161\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0492/0938 | LOSS: 0.2852 | ACC 0.9162\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0493/0938 | LOSS: 0.2855 | ACC 0.9161\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0494/0938 | LOSS: 0.2855 | ACC 0.9162\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0495/0938 | LOSS: 0.2853 | ACC 0.9163\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0496/0938 | LOSS: 0.2849 | ACC 0.9163\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0497/0938 | LOSS: 0.2850 | ACC 0.9163\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0498/0938 | LOSS: 0.2850 | ACC 0.9163\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0499/0938 | LOSS: 0.2847 | ACC 0.9164\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0500/0938 | LOSS: 0.2848 | ACC 0.9163\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0501/0938 | LOSS: 0.2847 | ACC 0.9164\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0502/0938 | LOSS: 0.2849 | ACC 0.9164\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0503/0938 | LOSS: 0.2849 | ACC 0.9164\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0504/0938 | LOSS: 0.2848 | ACC 0.9164\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0505/0938 | LOSS: 0.2847 | ACC 0.9165\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0506/0938 | LOSS: 0.2845 | ACC 0.9166\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0507/0938 | LOSS: 0.2846 | ACC 0.9165\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0508/0938 | LOSS: 0.2847 | ACC 0.9165\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0509/0938 | LOSS: 0.2848 | ACC 0.9165\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0510/0938 | LOSS: 0.2844 | ACC 0.9167\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0511/0938 | LOSS: 0.2848 | ACC 0.9166\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0512/0938 | LOSS: 0.2849 | ACC 0.9166\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0513/0938 | LOSS: 0.2851 | ACC 0.9165\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0514/0938 | LOSS: 0.2849 | ACC 0.9165\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0515/0938 | LOSS: 0.2857 | ACC 0.9164\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0516/0938 | LOSS: 0.2858 | ACC 0.9163\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0517/0938 | LOSS: 0.2859 | ACC 0.9163\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0518/0938 | LOSS: 0.2861 | ACC 0.9163\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0519/0938 | LOSS: 0.2859 | ACC 0.9163\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0520/0938 | LOSS: 0.2858 | ACC 0.9163\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0521/0938 | LOSS: 0.2856 | ACC 0.9164\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0522/0938 | LOSS: 0.2859 | ACC 0.9163\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0523/0938 | LOSS: 0.2858 | ACC 0.9163\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0524/0938 | LOSS: 0.2856 | ACC 0.9164\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0525/0938 | LOSS: 0.2853 | ACC 0.9164\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0526/0938 | LOSS: 0.2851 | ACC 0.9165\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0527/0938 | LOSS: 0.2853 | ACC 0.9165\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0528/0938 | LOSS: 0.2854 | ACC 0.9165\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0529/0938 | LOSS: 0.2855 | ACC 0.9164\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0530/0938 | LOSS: 0.2857 | ACC 0.9163\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0531/0938 | LOSS: 0.2855 | ACC 0.9164\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0532/0938 | LOSS: 0.2853 | ACC 0.9164\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0533/0938 | LOSS: 0.2850 | ACC 0.9165\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0534/0938 | LOSS: 0.2854 | ACC 0.9163\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0535/0938 | LOSS: 0.2850 | ACC 0.9164\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0536/0938 | LOSS: 0.2849 | ACC 0.9165\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0537/0938 | LOSS: 0.2849 | ACC 0.9164\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0538/0938 | LOSS: 0.2847 | ACC 0.9164\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0539/0938 | LOSS: 0.2844 | ACC 0.9165\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0540/0938 | LOSS: 0.2844 | ACC 0.9165\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0541/0938 | LOSS: 0.2847 | ACC 0.9164\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0542/0938 | LOSS: 0.2845 | ACC 0.9165\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0543/0938 | LOSS: 0.2847 | ACC 0.9165\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0544/0938 | LOSS: 0.2846 | ACC 0.9165\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0545/0938 | LOSS: 0.2846 | ACC 0.9165\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0546/0938 | LOSS: 0.2844 | ACC 0.9165\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0547/0938 | LOSS: 0.2842 | ACC 0.9166\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0548/0938 | LOSS: 0.2845 | ACC 0.9165\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0549/0938 | LOSS: 0.2843 | ACC 0.9165\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0550/0938 | LOSS: 0.2842 | ACC 0.9165\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0551/0938 | LOSS: 0.2841 | ACC 0.9165\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0552/0938 | LOSS: 0.2838 | ACC 0.9166\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0553/0938 | LOSS: 0.2839 | ACC 0.9166\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0554/0938 | LOSS: 0.2837 | ACC 0.9166\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0555/0938 | LOSS: 0.2834 | ACC 0.9167\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0556/0938 | LOSS: 0.2832 | ACC 0.9168\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0557/0938 | LOSS: 0.2832 | ACC 0.9168\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0558/0938 | LOSS: 0.2832 | ACC 0.9168\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0559/0938 | LOSS: 0.2833 | ACC 0.9167\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0560/0938 | LOSS: 0.2832 | ACC 0.9167\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0561/0938 | LOSS: 0.2831 | ACC 0.9168\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0562/0938 | LOSS: 0.2830 | ACC 0.9168\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0563/0938 | LOSS: 0.2834 | ACC 0.9167\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0564/0938 | LOSS: 0.2836 | ACC 0.9166\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0565/0938 | LOSS: 0.2834 | ACC 0.9167\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0566/0938 | LOSS: 0.2832 | ACC 0.9168\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0567/0938 | LOSS: 0.2830 | ACC 0.9168\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0568/0938 | LOSS: 0.2829 | ACC 0.9169\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0569/0938 | LOSS: 0.2829 | ACC 0.9169\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0570/0938 | LOSS: 0.2831 | ACC 0.9169\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0571/0938 | LOSS: 0.2830 | ACC 0.9169\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0572/0938 | LOSS: 0.2828 | ACC 0.9169\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0573/0938 | LOSS: 0.2827 | ACC 0.9170\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0574/0938 | LOSS: 0.2826 | ACC 0.9170\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: EPOCH 0002/0010 | BATCH 0575/0938 | LOSS: 0.2823 | ACC 0.9171\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0576/0938 | LOSS: 0.2820 | ACC 0.9172\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0577/0938 | LOSS: 0.2822 | ACC 0.9172\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0578/0938 | LOSS: 0.2823 | ACC 0.9172\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0579/0938 | LOSS: 0.2825 | ACC 0.9172\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0580/0938 | LOSS: 0.2826 | ACC 0.9172\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0581/0938 | LOSS: 0.2824 | ACC 0.9172\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0582/0938 | LOSS: 0.2822 | ACC 0.9173\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0583/0938 | LOSS: 0.2823 | ACC 0.9173\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0584/0938 | LOSS: 0.2823 | ACC 0.9173\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0585/0938 | LOSS: 0.2824 | ACC 0.9173\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0586/0938 | LOSS: 0.2824 | ACC 0.9174\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0587/0938 | LOSS: 0.2823 | ACC 0.9174\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0588/0938 | LOSS: 0.2821 | ACC 0.9174\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0589/0938 | LOSS: 0.2822 | ACC 0.9172\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0590/0938 | LOSS: 0.2821 | ACC 0.9173\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0591/0938 | LOSS: 0.2822 | ACC 0.9172\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0592/0938 | LOSS: 0.2820 | ACC 0.9173\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0593/0938 | LOSS: 0.2819 | ACC 0.9172\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0594/0938 | LOSS: 0.2822 | ACC 0.9172\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0595/0938 | LOSS: 0.2818 | ACC 0.9173\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0596/0938 | LOSS: 0.2818 | ACC 0.9173\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0597/0938 | LOSS: 0.2816 | ACC 0.9173\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0598/0938 | LOSS: 0.2816 | ACC 0.9174\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0599/0938 | LOSS: 0.2816 | ACC 0.9173\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0600/0938 | LOSS: 0.2814 | ACC 0.9173\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0601/0938 | LOSS: 0.2814 | ACC 0.9174\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0602/0938 | LOSS: 0.2815 | ACC 0.9173\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0603/0938 | LOSS: 0.2813 | ACC 0.9174\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0604/0938 | LOSS: 0.2812 | ACC 0.9173\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0605/0938 | LOSS: 0.2811 | ACC 0.9173\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0606/0938 | LOSS: 0.2809 | ACC 0.9174\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0607/0938 | LOSS: 0.2811 | ACC 0.9173\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0608/0938 | LOSS: 0.2810 | ACC 0.9174\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0609/0938 | LOSS: 0.2807 | ACC 0.9175\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0610/0938 | LOSS: 0.2805 | ACC 0.9175\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0611/0938 | LOSS: 0.2806 | ACC 0.9176\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0612/0938 | LOSS: 0.2804 | ACC 0.9176\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0613/0938 | LOSS: 0.2804 | ACC 0.9175\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0614/0938 | LOSS: 0.2803 | ACC 0.9175\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0615/0938 | LOSS: 0.2804 | ACC 0.9176\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0616/0938 | LOSS: 0.2808 | ACC 0.9175\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0617/0938 | LOSS: 0.2806 | ACC 0.9176\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0618/0938 | LOSS: 0.2804 | ACC 0.9176\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0619/0938 | LOSS: 0.2804 | ACC 0.9176\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0620/0938 | LOSS: 0.2803 | ACC 0.9176\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0621/0938 | LOSS: 0.2804 | ACC 0.9176\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0622/0938 | LOSS: 0.2804 | ACC 0.9176\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0623/0938 | LOSS: 0.2804 | ACC 0.9176\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0624/0938 | LOSS: 0.2804 | ACC 0.9176\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0625/0938 | LOSS: 0.2804 | ACC 0.9176\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0626/0938 | LOSS: 0.2804 | ACC 0.9176\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0627/0938 | LOSS: 0.2804 | ACC 0.9175\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0628/0938 | LOSS: 0.2803 | ACC 0.9175\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0629/0938 | LOSS: 0.2808 | ACC 0.9175\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0630/0938 | LOSS: 0.2809 | ACC 0.9174\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0631/0938 | LOSS: 0.2807 | ACC 0.9175\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0632/0938 | LOSS: 0.2806 | ACC 0.9175\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0633/0938 | LOSS: 0.2804 | ACC 0.9175\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0634/0938 | LOSS: 0.2802 | ACC 0.9176\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0635/0938 | LOSS: 0.2800 | ACC 0.9176\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0636/0938 | LOSS: 0.2799 | ACC 0.9177\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0637/0938 | LOSS: 0.2798 | ACC 0.9177\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0638/0938 | LOSS: 0.2796 | ACC 0.9177\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0639/0938 | LOSS: 0.2796 | ACC 0.9177\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0640/0938 | LOSS: 0.2797 | ACC 0.9177\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0641/0938 | LOSS: 0.2801 | ACC 0.9176\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0642/0938 | LOSS: 0.2798 | ACC 0.9177\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0643/0938 | LOSS: 0.2798 | ACC 0.9177\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0644/0938 | LOSS: 0.2797 | ACC 0.9176\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0645/0938 | LOSS: 0.2796 | ACC 0.9177\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0646/0938 | LOSS: 0.2798 | ACC 0.9176\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0647/0938 | LOSS: 0.2799 | ACC 0.9176\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0648/0938 | LOSS: 0.2799 | ACC 0.9176\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0649/0938 | LOSS: 0.2802 | ACC 0.9175\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0650/0938 | LOSS: 0.2801 | ACC 0.9176\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0651/0938 | LOSS: 0.2802 | ACC 0.9176\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0652/0938 | LOSS: 0.2800 | ACC 0.9176\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0653/0938 | LOSS: 0.2799 | ACC 0.9177\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0654/0938 | LOSS: 0.2801 | ACC 0.9176\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0655/0938 | LOSS: 0.2801 | ACC 0.9177\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0656/0938 | LOSS: 0.2801 | ACC 0.9177\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0657/0938 | LOSS: 0.2801 | ACC 0.9176\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0658/0938 | LOSS: 0.2803 | ACC 0.9175\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0659/0938 | LOSS: 0.2801 | ACC 0.9176\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0660/0938 | LOSS: 0.2801 | ACC 0.9176\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0661/0938 | LOSS: 0.2800 | ACC 0.9176\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0662/0938 | LOSS: 0.2801 | ACC 0.9175\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0663/0938 | LOSS: 0.2801 | ACC 0.9174\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0664/0938 | LOSS: 0.2799 | ACC 0.9175\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0665/0938 | LOSS: 0.2799 | ACC 0.9176\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0666/0938 | LOSS: 0.2797 | ACC 0.9176\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0667/0938 | LOSS: 0.2796 | ACC 0.9176\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0668/0938 | LOSS: 0.2793 | ACC 0.9178\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0669/0938 | LOSS: 0.2791 | ACC 0.9178\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0670/0938 | LOSS: 0.2791 | ACC 0.9178\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0671/0938 | LOSS: 0.2791 | ACC 0.9178\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0672/0938 | LOSS: 0.2791 | ACC 0.9178\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0673/0938 | LOSS: 0.2793 | ACC 0.9177\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0674/0938 | LOSS: 0.2793 | ACC 0.9177\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0675/0938 | LOSS: 0.2794 | ACC 0.9177\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0676/0938 | LOSS: 0.2791 | ACC 0.9178\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0677/0938 | LOSS: 0.2790 | ACC 0.9178\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0678/0938 | LOSS: 0.2788 | ACC 0.9179\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0679/0938 | LOSS: 0.2788 | ACC 0.9179\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0680/0938 | LOSS: 0.2787 | ACC 0.9179\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0681/0938 | LOSS: 0.2791 | ACC 0.9179\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0682/0938 | LOSS: 0.2790 | ACC 0.9179\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0683/0938 | LOSS: 0.2791 | ACC 0.9179\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0684/0938 | LOSS: 0.2790 | ACC 0.9179\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0685/0938 | LOSS: 0.2790 | ACC 0.9179\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0686/0938 | LOSS: 0.2790 | ACC 0.9178\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0687/0938 | LOSS: 0.2790 | ACC 0.9178\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0688/0938 | LOSS: 0.2789 | ACC 0.9179\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0689/0938 | LOSS: 0.2792 | ACC 0.9178\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0690/0938 | LOSS: 0.2791 | ACC 0.9178\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0691/0938 | LOSS: 0.2794 | ACC 0.9178\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0692/0938 | LOSS: 0.2792 | ACC 0.9179\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0693/0938 | LOSS: 0.2792 | ACC 0.9180\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0694/0938 | LOSS: 0.2791 | ACC 0.9180\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0695/0938 | LOSS: 0.2792 | ACC 0.9179\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0696/0938 | LOSS: 0.2789 | ACC 0.9180\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0697/0938 | LOSS: 0.2788 | ACC 0.9180\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0698/0938 | LOSS: 0.2787 | ACC 0.9180\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0699/0938 | LOSS: 0.2787 | ACC 0.9180\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0700/0938 | LOSS: 0.2787 | ACC 0.9179\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: EPOCH 0002/0010 | BATCH 0701/0938 | LOSS: 0.2786 | ACC 0.9180\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0702/0938 | LOSS: 0.2786 | ACC 0.9179\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0703/0938 | LOSS: 0.2785 | ACC 0.9179\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0704/0938 | LOSS: 0.2784 | ACC 0.9179\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0705/0938 | LOSS: 0.2785 | ACC 0.9179\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0706/0938 | LOSS: 0.2784 | ACC 0.9179\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0707/0938 | LOSS: 0.2783 | ACC 0.9179\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0708/0938 | LOSS: 0.2783 | ACC 0.9179\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0709/0938 | LOSS: 0.2782 | ACC 0.9179\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0710/0938 | LOSS: 0.2781 | ACC 0.9180\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0711/0938 | LOSS: 0.2780 | ACC 0.9180\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0712/0938 | LOSS: 0.2778 | ACC 0.9181\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0713/0938 | LOSS: 0.2777 | ACC 0.9181\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0714/0938 | LOSS: 0.2777 | ACC 0.9181\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0715/0938 | LOSS: 0.2776 | ACC 0.9181\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0716/0938 | LOSS: 0.2774 | ACC 0.9181\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0717/0938 | LOSS: 0.2773 | ACC 0.9181\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0718/0938 | LOSS: 0.2773 | ACC 0.9182\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0719/0938 | LOSS: 0.2775 | ACC 0.9182\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0720/0938 | LOSS: 0.2774 | ACC 0.9182\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0721/0938 | LOSS: 0.2773 | ACC 0.9182\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0722/0938 | LOSS: 0.2771 | ACC 0.9182\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0723/0938 | LOSS: 0.2769 | ACC 0.9183\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0724/0938 | LOSS: 0.2768 | ACC 0.9182\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0725/0938 | LOSS: 0.2767 | ACC 0.9183\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0726/0938 | LOSS: 0.2767 | ACC 0.9183\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0727/0938 | LOSS: 0.2771 | ACC 0.9181\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0728/0938 | LOSS: 0.2771 | ACC 0.9181\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0729/0938 | LOSS: 0.2769 | ACC 0.9182\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0730/0938 | LOSS: 0.2770 | ACC 0.9182\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0731/0938 | LOSS: 0.2768 | ACC 0.9183\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0732/0938 | LOSS: 0.2767 | ACC 0.9183\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0733/0938 | LOSS: 0.2767 | ACC 0.9183\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0734/0938 | LOSS: 0.2766 | ACC 0.9183\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0735/0938 | LOSS: 0.2767 | ACC 0.9183\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0736/0938 | LOSS: 0.2767 | ACC 0.9184\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0737/0938 | LOSS: 0.2765 | ACC 0.9184\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0738/0938 | LOSS: 0.2765 | ACC 0.9184\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0739/0938 | LOSS: 0.2763 | ACC 0.9185\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0740/0938 | LOSS: 0.2765 | ACC 0.9183\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0741/0938 | LOSS: 0.2764 | ACC 0.9184\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0742/0938 | LOSS: 0.2765 | ACC 0.9184\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0743/0938 | LOSS: 0.2764 | ACC 0.9184\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0744/0938 | LOSS: 0.2764 | ACC 0.9184\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0745/0938 | LOSS: 0.2766 | ACC 0.9184\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0746/0938 | LOSS: 0.2767 | ACC 0.9184\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0747/0938 | LOSS: 0.2768 | ACC 0.9183\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0748/0938 | LOSS: 0.2768 | ACC 0.9183\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0749/0938 | LOSS: 0.2768 | ACC 0.9183\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0750/0938 | LOSS: 0.2770 | ACC 0.9183\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0751/0938 | LOSS: 0.2769 | ACC 0.9183\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0752/0938 | LOSS: 0.2768 | ACC 0.9183\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0753/0938 | LOSS: 0.2767 | ACC 0.9184\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0754/0938 | LOSS: 0.2765 | ACC 0.9184\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0755/0938 | LOSS: 0.2768 | ACC 0.9184\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0756/0938 | LOSS: 0.2768 | ACC 0.9184\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0757/0938 | LOSS: 0.2768 | ACC 0.9184\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0758/0938 | LOSS: 0.2768 | ACC 0.9184\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0759/0938 | LOSS: 0.2767 | ACC 0.9184\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0760/0938 | LOSS: 0.2768 | ACC 0.9184\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0761/0938 | LOSS: 0.2768 | ACC 0.9184\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0762/0938 | LOSS: 0.2766 | ACC 0.9185\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0763/0938 | LOSS: 0.2765 | ACC 0.9185\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0764/0938 | LOSS: 0.2765 | ACC 0.9185\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0765/0938 | LOSS: 0.2763 | ACC 0.9186\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0766/0938 | LOSS: 0.2761 | ACC 0.9187\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0767/0938 | LOSS: 0.2761 | ACC 0.9187\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0768/0938 | LOSS: 0.2759 | ACC 0.9187\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0769/0938 | LOSS: 0.2759 | ACC 0.9187\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0770/0938 | LOSS: 0.2758 | ACC 0.9187\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0771/0938 | LOSS: 0.2757 | ACC 0.9188\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0772/0938 | LOSS: 0.2759 | ACC 0.9187\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0773/0938 | LOSS: 0.2758 | ACC 0.9187\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0774/0938 | LOSS: 0.2756 | ACC 0.9188\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0775/0938 | LOSS: 0.2755 | ACC 0.9187\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0776/0938 | LOSS: 0.2755 | ACC 0.9187\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0777/0938 | LOSS: 0.2756 | ACC 0.9187\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0778/0938 | LOSS: 0.2755 | ACC 0.9187\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0779/0938 | LOSS: 0.2754 | ACC 0.9188\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0780/0938 | LOSS: 0.2753 | ACC 0.9187\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0781/0938 | LOSS: 0.2754 | ACC 0.9187\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0782/0938 | LOSS: 0.2754 | ACC 0.9187\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0783/0938 | LOSS: 0.2754 | ACC 0.9187\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0784/0938 | LOSS: 0.2753 | ACC 0.9188\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0785/0938 | LOSS: 0.2752 | ACC 0.9188\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0786/0938 | LOSS: 0.2753 | ACC 0.9188\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0787/0938 | LOSS: 0.2755 | ACC 0.9188\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0788/0938 | LOSS: 0.2753 | ACC 0.9188\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0789/0938 | LOSS: 0.2753 | ACC 0.9188\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0790/0938 | LOSS: 0.2751 | ACC 0.9189\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0791/0938 | LOSS: 0.2753 | ACC 0.9188\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0792/0938 | LOSS: 0.2753 | ACC 0.9189\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0793/0938 | LOSS: 0.2752 | ACC 0.9189\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0794/0938 | LOSS: 0.2750 | ACC 0.9190\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0795/0938 | LOSS: 0.2750 | ACC 0.9189\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0796/0938 | LOSS: 0.2749 | ACC 0.9190\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0797/0938 | LOSS: 0.2751 | ACC 0.9189\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0798/0938 | LOSS: 0.2750 | ACC 0.9189\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0799/0938 | LOSS: 0.2751 | ACC 0.9189\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0800/0938 | LOSS: 0.2750 | ACC 0.9189\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0801/0938 | LOSS: 0.2749 | ACC 0.9190\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0802/0938 | LOSS: 0.2749 | ACC 0.9190\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0803/0938 | LOSS: 0.2749 | ACC 0.9190\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0804/0938 | LOSS: 0.2749 | ACC 0.9190\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0805/0938 | LOSS: 0.2750 | ACC 0.9189\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0806/0938 | LOSS: 0.2750 | ACC 0.9189\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0807/0938 | LOSS: 0.2750 | ACC 0.9190\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0808/0938 | LOSS: 0.2750 | ACC 0.9190\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0809/0938 | LOSS: 0.2749 | ACC 0.9190\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0810/0938 | LOSS: 0.2749 | ACC 0.9189\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0811/0938 | LOSS: 0.2748 | ACC 0.9190\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0812/0938 | LOSS: 0.2749 | ACC 0.9189\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0813/0938 | LOSS: 0.2747 | ACC 0.9190\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0814/0938 | LOSS: 0.2746 | ACC 0.9190\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0815/0938 | LOSS: 0.2746 | ACC 0.9190\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0816/0938 | LOSS: 0.2747 | ACC 0.9190\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0817/0938 | LOSS: 0.2745 | ACC 0.9190\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0818/0938 | LOSS: 0.2744 | ACC 0.9190\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0819/0938 | LOSS: 0.2744 | ACC 0.9190\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0820/0938 | LOSS: 0.2744 | ACC 0.9190\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0821/0938 | LOSS: 0.2742 | ACC 0.9191\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0822/0938 | LOSS: 0.2747 | ACC 0.9190\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0823/0938 | LOSS: 0.2748 | ACC 0.9189\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0824/0938 | LOSS: 0.2748 | ACC 0.9190\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0825/0938 | LOSS: 0.2747 | ACC 0.9190\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: EPOCH 0002/0010 | BATCH 0826/0938 | LOSS: 0.2746 | ACC 0.9191\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0827/0938 | LOSS: 0.2745 | ACC 0.9191\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0828/0938 | LOSS: 0.2745 | ACC 0.9191\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0829/0938 | LOSS: 0.2746 | ACC 0.9191\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0830/0938 | LOSS: 0.2744 | ACC 0.9192\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0831/0938 | LOSS: 0.2744 | ACC 0.9192\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0832/0938 | LOSS: 0.2745 | ACC 0.9192\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0833/0938 | LOSS: 0.2747 | ACC 0.9192\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0834/0938 | LOSS: 0.2746 | ACC 0.9192\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0835/0938 | LOSS: 0.2745 | ACC 0.9192\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0836/0938 | LOSS: 0.2744 | ACC 0.9192\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0837/0938 | LOSS: 0.2744 | ACC 0.9192\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0838/0938 | LOSS: 0.2744 | ACC 0.9191\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0839/0938 | LOSS: 0.2744 | ACC 0.9191\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0840/0938 | LOSS: 0.2743 | ACC 0.9192\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0841/0938 | LOSS: 0.2742 | ACC 0.9192\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0842/0938 | LOSS: 0.2741 | ACC 0.9192\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0843/0938 | LOSS: 0.2740 | ACC 0.9192\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0844/0938 | LOSS: 0.2740 | ACC 0.9192\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0845/0938 | LOSS: 0.2740 | ACC 0.9192\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0846/0938 | LOSS: 0.2738 | ACC 0.9192\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0847/0938 | LOSS: 0.2738 | ACC 0.9192\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0848/0938 | LOSS: 0.2736 | ACC 0.9192\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0849/0938 | LOSS: 0.2737 | ACC 0.9192\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0850/0938 | LOSS: 0.2736 | ACC 0.9192\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0851/0938 | LOSS: 0.2738 | ACC 0.9192\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0852/0938 | LOSS: 0.2738 | ACC 0.9192\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0853/0938 | LOSS: 0.2737 | ACC 0.9192\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0854/0938 | LOSS: 0.2738 | ACC 0.9191\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0855/0938 | LOSS: 0.2736 | ACC 0.9192\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0856/0938 | LOSS: 0.2734 | ACC 0.9193\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0857/0938 | LOSS: 0.2732 | ACC 0.9193\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0858/0938 | LOSS: 0.2730 | ACC 0.9194\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0859/0938 | LOSS: 0.2728 | ACC 0.9194\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0860/0938 | LOSS: 0.2727 | ACC 0.9194\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0861/0938 | LOSS: 0.2725 | ACC 0.9195\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0862/0938 | LOSS: 0.2723 | ACC 0.9195\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0863/0938 | LOSS: 0.2723 | ACC 0.9196\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0864/0938 | LOSS: 0.2727 | ACC 0.9195\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0865/0938 | LOSS: 0.2726 | ACC 0.9195\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0866/0938 | LOSS: 0.2725 | ACC 0.9196\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0867/0938 | LOSS: 0.2723 | ACC 0.9197\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0868/0938 | LOSS: 0.2722 | ACC 0.9197\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0869/0938 | LOSS: 0.2722 | ACC 0.9197\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0870/0938 | LOSS: 0.2720 | ACC 0.9198\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0871/0938 | LOSS: 0.2719 | ACC 0.9198\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0872/0938 | LOSS: 0.2718 | ACC 0.9198\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0873/0938 | LOSS: 0.2717 | ACC 0.9198\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0874/0938 | LOSS: 0.2719 | ACC 0.9198\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0875/0938 | LOSS: 0.2718 | ACC 0.9198\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0876/0938 | LOSS: 0.2717 | ACC 0.9198\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0877/0938 | LOSS: 0.2716 | ACC 0.9198\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0878/0938 | LOSS: 0.2716 | ACC 0.9198\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0879/0938 | LOSS: 0.2715 | ACC 0.9199\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0880/0938 | LOSS: 0.2719 | ACC 0.9198\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0881/0938 | LOSS: 0.2717 | ACC 0.9198\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0882/0938 | LOSS: 0.2717 | ACC 0.9198\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0883/0938 | LOSS: 0.2716 | ACC 0.9199\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0884/0938 | LOSS: 0.2720 | ACC 0.9198\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0885/0938 | LOSS: 0.2721 | ACC 0.9197\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0886/0938 | LOSS: 0.2721 | ACC 0.9197\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0887/0938 | LOSS: 0.2723 | ACC 0.9196\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0888/0938 | LOSS: 0.2720 | ACC 0.9197\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0889/0938 | LOSS: 0.2719 | ACC 0.9197\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0890/0938 | LOSS: 0.2717 | ACC 0.9198\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0891/0938 | LOSS: 0.2718 | ACC 0.9198\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0892/0938 | LOSS: 0.2718 | ACC 0.9198\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0893/0938 | LOSS: 0.2717 | ACC 0.9198\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0894/0938 | LOSS: 0.2715 | ACC 0.9198\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0895/0938 | LOSS: 0.2717 | ACC 0.9198\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0896/0938 | LOSS: 0.2718 | ACC 0.9198\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0897/0938 | LOSS: 0.2718 | ACC 0.9198\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0898/0938 | LOSS: 0.2717 | ACC 0.9198\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0899/0938 | LOSS: 0.2720 | ACC 0.9198\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0900/0938 | LOSS: 0.2719 | ACC 0.9198\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0901/0938 | LOSS: 0.2717 | ACC 0.9199\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0902/0938 | LOSS: 0.2716 | ACC 0.9199\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0903/0938 | LOSS: 0.2715 | ACC 0.9199\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0904/0938 | LOSS: 0.2714 | ACC 0.9200\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0905/0938 | LOSS: 0.2714 | ACC 0.9200\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0906/0938 | LOSS: 0.2714 | ACC 0.9200\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0907/0938 | LOSS: 0.2715 | ACC 0.9199\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0908/0938 | LOSS: 0.2716 | ACC 0.9199\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0909/0938 | LOSS: 0.2714 | ACC 0.9199\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0910/0938 | LOSS: 0.2712 | ACC 0.9200\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0911/0938 | LOSS: 0.2713 | ACC 0.9200\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0912/0938 | LOSS: 0.2712 | ACC 0.9201\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0913/0938 | LOSS: 0.2711 | ACC 0.9201\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0914/0938 | LOSS: 0.2713 | ACC 0.9201\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0915/0938 | LOSS: 0.2712 | ACC 0.9202\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0916/0938 | LOSS: 0.2713 | ACC 0.9202\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0917/0938 | LOSS: 0.2713 | ACC 0.9202\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0918/0938 | LOSS: 0.2713 | ACC 0.9202\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0919/0938 | LOSS: 0.2713 | ACC 0.9202\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0920/0938 | LOSS: 0.2712 | ACC 0.9202\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0921/0938 | LOSS: 0.2711 | ACC 0.9203\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0922/0938 | LOSS: 0.2709 | ACC 0.9203\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0923/0938 | LOSS: 0.2709 | ACC 0.9204\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0924/0938 | LOSS: 0.2709 | ACC 0.9204\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0925/0938 | LOSS: 0.2709 | ACC 0.9204\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0926/0938 | LOSS: 0.2710 | ACC 0.9204\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0927/0938 | LOSS: 0.2710 | ACC 0.9204\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0928/0938 | LOSS: 0.2708 | ACC 0.9205\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0929/0938 | LOSS: 0.2709 | ACC 0.9205\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0930/0938 | LOSS: 0.2708 | ACC 0.9205\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0931/0938 | LOSS: 0.2708 | ACC 0.9205\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0932/0938 | LOSS: 0.2707 | ACC 0.9206\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0933/0938 | LOSS: 0.2707 | ACC 0.9206\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0934/0938 | LOSS: 0.2705 | ACC 0.9206\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0935/0938 | LOSS: 0.2704 | ACC 0.9206\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0936/0938 | LOSS: 0.2704 | ACC 0.9206\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0937/0938 | LOSS: 0.2704 | ACC 0.9206\n",
      "TRAIN: EPOCH 0002/0010 | BATCH 0938/0938 | LOSS: 0.2704 | ACC 0.9206\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0001/0938 | LOSS: 0.1999 | ACC 0.9375\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0002/0938 | LOSS: 0.1711 | ACC 0.9531\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0003/0938 | LOSS: 0.2024 | ACC 0.9531\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0004/0938 | LOSS: 0.1912 | ACC 0.9570\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0005/0938 | LOSS: 0.2065 | ACC 0.9531\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0006/0938 | LOSS: 0.2106 | ACC 0.9453\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0007/0938 | LOSS: 0.1996 | ACC 0.9487\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0008/0938 | LOSS: 0.2045 | ACC 0.9434\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0009/0938 | LOSS: 0.1958 | ACC 0.9444\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0010/0938 | LOSS: 0.1933 | ACC 0.9437\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0011/0938 | LOSS: 0.1826 | ACC 0.9460\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0012/0938 | LOSS: 0.1909 | ACC 0.9427\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0013/0938 | LOSS: 0.1945 | ACC 0.9411\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: EPOCH 0003/0010 | BATCH 0014/0938 | LOSS: 0.2120 | ACC 0.9375\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0015/0938 | LOSS: 0.2094 | ACC 0.9385\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0016/0938 | LOSS: 0.2138 | ACC 0.9375\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0017/0938 | LOSS: 0.2162 | ACC 0.9375\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0018/0938 | LOSS: 0.2143 | ACC 0.9384\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0019/0938 | LOSS: 0.2126 | ACC 0.9367\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0020/0938 | LOSS: 0.2208 | ACC 0.9359\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0021/0938 | LOSS: 0.2171 | ACC 0.9375\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0022/0938 | LOSS: 0.2131 | ACC 0.9389\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0023/0938 | LOSS: 0.2168 | ACC 0.9382\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0024/0938 | LOSS: 0.2117 | ACC 0.9401\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0025/0938 | LOSS: 0.2193 | ACC 0.9381\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0026/0938 | LOSS: 0.2153 | ACC 0.9387\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0027/0938 | LOSS: 0.2174 | ACC 0.9381\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0028/0938 | LOSS: 0.2144 | ACC 0.9386\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0029/0938 | LOSS: 0.2145 | ACC 0.9380\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0030/0938 | LOSS: 0.2112 | ACC 0.9385\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0031/0938 | LOSS: 0.2170 | ACC 0.9385\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0032/0938 | LOSS: 0.2182 | ACC 0.9375\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0033/0938 | LOSS: 0.2240 | ACC 0.9356\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0034/0938 | LOSS: 0.2217 | ACC 0.9366\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0035/0938 | LOSS: 0.2235 | ACC 0.9371\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0036/0938 | LOSS: 0.2274 | ACC 0.9362\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0037/0938 | LOSS: 0.2239 | ACC 0.9367\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0038/0938 | LOSS: 0.2239 | ACC 0.9371\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0039/0938 | LOSS: 0.2239 | ACC 0.9367\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0040/0938 | LOSS: 0.2217 | ACC 0.9371\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0041/0938 | LOSS: 0.2202 | ACC 0.9375\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0042/0938 | LOSS: 0.2220 | ACC 0.9364\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0043/0938 | LOSS: 0.2222 | ACC 0.9353\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0044/0938 | LOSS: 0.2242 | ACC 0.9350\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0045/0938 | LOSS: 0.2261 | ACC 0.9347\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0046/0938 | LOSS: 0.2261 | ACC 0.9338\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0047/0938 | LOSS: 0.2250 | ACC 0.9338\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0048/0938 | LOSS: 0.2238 | ACC 0.9342\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0049/0938 | LOSS: 0.2242 | ACC 0.9343\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0050/0938 | LOSS: 0.2263 | ACC 0.9341\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0051/0938 | LOSS: 0.2252 | ACC 0.9341\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0052/0938 | LOSS: 0.2245 | ACC 0.9348\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0053/0938 | LOSS: 0.2266 | ACC 0.9343\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0054/0938 | LOSS: 0.2318 | ACC 0.9326\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0055/0938 | LOSS: 0.2318 | ACC 0.9324\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0056/0938 | LOSS: 0.2338 | ACC 0.9316\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0057/0938 | LOSS: 0.2362 | ACC 0.9306\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0058/0938 | LOSS: 0.2352 | ACC 0.9308\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0059/0938 | LOSS: 0.2408 | ACC 0.9296\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0060/0938 | LOSS: 0.2392 | ACC 0.9299\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0061/0938 | LOSS: 0.2421 | ACC 0.9296\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0062/0938 | LOSS: 0.2415 | ACC 0.9299\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0063/0938 | LOSS: 0.2451 | ACC 0.9298\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0064/0938 | LOSS: 0.2437 | ACC 0.9299\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0065/0938 | LOSS: 0.2448 | ACC 0.9300\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0066/0938 | LOSS: 0.2455 | ACC 0.9295\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0067/0938 | LOSS: 0.2436 | ACC 0.9303\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0068/0938 | LOSS: 0.2429 | ACC 0.9301\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0069/0938 | LOSS: 0.2426 | ACC 0.9303\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0070/0938 | LOSS: 0.2430 | ACC 0.9295\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0071/0938 | LOSS: 0.2407 | ACC 0.9302\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0072/0938 | LOSS: 0.2407 | ACC 0.9299\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0073/0938 | LOSS: 0.2412 | ACC 0.9298\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0074/0938 | LOSS: 0.2415 | ACC 0.9295\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0075/0938 | LOSS: 0.2414 | ACC 0.9296\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0076/0938 | LOSS: 0.2402 | ACC 0.9301\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0077/0938 | LOSS: 0.2391 | ACC 0.9304\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0078/0938 | LOSS: 0.2388 | ACC 0.9301\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0079/0938 | LOSS: 0.2395 | ACC 0.9300\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0080/0938 | LOSS: 0.2429 | ACC 0.9291\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0081/0938 | LOSS: 0.2429 | ACC 0.9288\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0082/0938 | LOSS: 0.2436 | ACC 0.9282\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0083/0938 | LOSS: 0.2441 | ACC 0.9273\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0084/0938 | LOSS: 0.2435 | ACC 0.9276\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0085/0938 | LOSS: 0.2421 | ACC 0.9279\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0086/0938 | LOSS: 0.2418 | ACC 0.9277\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0087/0938 | LOSS: 0.2416 | ACC 0.9276\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0088/0938 | LOSS: 0.2411 | ACC 0.9277\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0089/0938 | LOSS: 0.2422 | ACC 0.9271\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0090/0938 | LOSS: 0.2428 | ACC 0.9269\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0091/0938 | LOSS: 0.2428 | ACC 0.9269\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0092/0938 | LOSS: 0.2416 | ACC 0.9271\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0093/0938 | LOSS: 0.2420 | ACC 0.9271\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0094/0938 | LOSS: 0.2426 | ACC 0.9270\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0095/0938 | LOSS: 0.2440 | ACC 0.9270\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0096/0938 | LOSS: 0.2440 | ACC 0.9268\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0097/0938 | LOSS: 0.2439 | ACC 0.9265\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0098/0938 | LOSS: 0.2434 | ACC 0.9268\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0099/0938 | LOSS: 0.2426 | ACC 0.9271\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0100/0938 | LOSS: 0.2426 | ACC 0.9269\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0101/0938 | LOSS: 0.2416 | ACC 0.9271\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0102/0938 | LOSS: 0.2416 | ACC 0.9268\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0103/0938 | LOSS: 0.2415 | ACC 0.9263\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0104/0938 | LOSS: 0.2411 | ACC 0.9265\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0105/0938 | LOSS: 0.2409 | ACC 0.9262\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0106/0938 | LOSS: 0.2422 | ACC 0.9256\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0107/0938 | LOSS: 0.2428 | ACC 0.9254\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0108/0938 | LOSS: 0.2430 | ACC 0.9253\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0109/0938 | LOSS: 0.2427 | ACC 0.9250\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0110/0938 | LOSS: 0.2423 | ACC 0.9253\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0111/0938 | LOSS: 0.2415 | ACC 0.9258\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0112/0938 | LOSS: 0.2401 | ACC 0.9262\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0113/0938 | LOSS: 0.2402 | ACC 0.9263\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0114/0938 | LOSS: 0.2404 | ACC 0.9263\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0115/0938 | LOSS: 0.2421 | ACC 0.9255\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0116/0938 | LOSS: 0.2425 | ACC 0.9254\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0117/0938 | LOSS: 0.2418 | ACC 0.9252\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0118/0938 | LOSS: 0.2409 | ACC 0.9256\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0119/0938 | LOSS: 0.2421 | ACC 0.9253\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0120/0938 | LOSS: 0.2411 | ACC 0.9255\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0121/0938 | LOSS: 0.2411 | ACC 0.9255\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0122/0938 | LOSS: 0.2416 | ACC 0.9255\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0123/0938 | LOSS: 0.2418 | ACC 0.9252\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0124/0938 | LOSS: 0.2427 | ACC 0.9249\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0125/0938 | LOSS: 0.2420 | ACC 0.9253\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0126/0938 | LOSS: 0.2428 | ACC 0.9252\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0127/0938 | LOSS: 0.2423 | ACC 0.9253\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0128/0938 | LOSS: 0.2425 | ACC 0.9253\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0129/0938 | LOSS: 0.2418 | ACC 0.9256\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0130/0938 | LOSS: 0.2416 | ACC 0.9258\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0131/0938 | LOSS: 0.2414 | ACC 0.9260\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0132/0938 | LOSS: 0.2414 | ACC 0.9260\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0133/0938 | LOSS: 0.2419 | ACC 0.9256\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0134/0938 | LOSS: 0.2425 | ACC 0.9254\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0135/0938 | LOSS: 0.2433 | ACC 0.9252\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0136/0938 | LOSS: 0.2440 | ACC 0.9251\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0137/0938 | LOSS: 0.2443 | ACC 0.9252\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0138/0938 | LOSS: 0.2432 | ACC 0.9255\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0139/0938 | LOSS: 0.2425 | ACC 0.9257\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0140/0938 | LOSS: 0.2423 | ACC 0.9254\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: EPOCH 0003/0010 | BATCH 0141/0938 | LOSS: 0.2419 | ACC 0.9256\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0142/0938 | LOSS: 0.2416 | ACC 0.9259\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0143/0938 | LOSS: 0.2431 | ACC 0.9259\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0144/0938 | LOSS: 0.2429 | ACC 0.9259\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0145/0938 | LOSS: 0.2432 | ACC 0.9256\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0146/0938 | LOSS: 0.2427 | ACC 0.9259\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0147/0938 | LOSS: 0.2431 | ACC 0.9260\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0148/0938 | LOSS: 0.2425 | ACC 0.9261\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0149/0938 | LOSS: 0.2421 | ACC 0.9261\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0150/0938 | LOSS: 0.2414 | ACC 0.9263\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0151/0938 | LOSS: 0.2421 | ACC 0.9259\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0152/0938 | LOSS: 0.2415 | ACC 0.9261\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0153/0938 | LOSS: 0.2421 | ACC 0.9260\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0154/0938 | LOSS: 0.2420 | ACC 0.9260\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0155/0938 | LOSS: 0.2421 | ACC 0.9261\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0156/0938 | LOSS: 0.2418 | ACC 0.9262\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0157/0938 | LOSS: 0.2415 | ACC 0.9264\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0158/0938 | LOSS: 0.2425 | ACC 0.9260\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0159/0938 | LOSS: 0.2435 | ACC 0.9260\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0160/0938 | LOSS: 0.2429 | ACC 0.9263\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0161/0938 | LOSS: 0.2423 | ACC 0.9264\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0162/0938 | LOSS: 0.2426 | ACC 0.9267\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0163/0938 | LOSS: 0.2424 | ACC 0.9271\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0164/0938 | LOSS: 0.2428 | ACC 0.9269\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0165/0938 | LOSS: 0.2419 | ACC 0.9273\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0166/0938 | LOSS: 0.2411 | ACC 0.9275\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0167/0938 | LOSS: 0.2409 | ACC 0.9274\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0168/0938 | LOSS: 0.2404 | ACC 0.9275\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0169/0938 | LOSS: 0.2400 | ACC 0.9275\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0170/0938 | LOSS: 0.2394 | ACC 0.9278\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0171/0938 | LOSS: 0.2388 | ACC 0.9279\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0172/0938 | LOSS: 0.2383 | ACC 0.9281\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0173/0938 | LOSS: 0.2387 | ACC 0.9279\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0174/0938 | LOSS: 0.2395 | ACC 0.9279\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0175/0938 | LOSS: 0.2391 | ACC 0.9280\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0176/0938 | LOSS: 0.2387 | ACC 0.9283\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0177/0938 | LOSS: 0.2389 | ACC 0.9285\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0178/0938 | LOSS: 0.2392 | ACC 0.9285\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0179/0938 | LOSS: 0.2396 | ACC 0.9286\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0180/0938 | LOSS: 0.2400 | ACC 0.9284\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0181/0938 | LOSS: 0.2397 | ACC 0.9285\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0182/0938 | LOSS: 0.2398 | ACC 0.9286\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0183/0938 | LOSS: 0.2412 | ACC 0.9281\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0184/0938 | LOSS: 0.2416 | ACC 0.9282\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0185/0938 | LOSS: 0.2412 | ACC 0.9284\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0186/0938 | LOSS: 0.2412 | ACC 0.9283\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0187/0938 | LOSS: 0.2410 | ACC 0.9283\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0188/0938 | LOSS: 0.2407 | ACC 0.9284\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0189/0938 | LOSS: 0.2407 | ACC 0.9283\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0190/0938 | LOSS: 0.2405 | ACC 0.9284\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0191/0938 | LOSS: 0.2404 | ACC 0.9285\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0192/0938 | LOSS: 0.2406 | ACC 0.9283\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0193/0938 | LOSS: 0.2411 | ACC 0.9280\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0194/0938 | LOSS: 0.2417 | ACC 0.9280\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0195/0938 | LOSS: 0.2416 | ACC 0.9280\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0196/0938 | LOSS: 0.2417 | ACC 0.9278\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0197/0938 | LOSS: 0.2419 | ACC 0.9277\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0198/0938 | LOSS: 0.2413 | ACC 0.9280\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0199/0938 | LOSS: 0.2405 | ACC 0.9283\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0200/0938 | LOSS: 0.2402 | ACC 0.9283\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0201/0938 | LOSS: 0.2399 | ACC 0.9285\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0202/0938 | LOSS: 0.2405 | ACC 0.9283\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0203/0938 | LOSS: 0.2414 | ACC 0.9283\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0204/0938 | LOSS: 0.2419 | ACC 0.9283\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0205/0938 | LOSS: 0.2421 | ACC 0.9283\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0206/0938 | LOSS: 0.2421 | ACC 0.9285\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0207/0938 | LOSS: 0.2421 | ACC 0.9284\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0208/0938 | LOSS: 0.2416 | ACC 0.9285\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0209/0938 | LOSS: 0.2411 | ACC 0.9288\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0210/0938 | LOSS: 0.2404 | ACC 0.9291\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0211/0938 | LOSS: 0.2401 | ACC 0.9291\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0212/0938 | LOSS: 0.2401 | ACC 0.9291\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0213/0938 | LOSS: 0.2416 | ACC 0.9289\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0214/0938 | LOSS: 0.2417 | ACC 0.9290\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0215/0938 | LOSS: 0.2416 | ACC 0.9290\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0216/0938 | LOSS: 0.2421 | ACC 0.9290\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0217/0938 | LOSS: 0.2422 | ACC 0.9290\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0218/0938 | LOSS: 0.2423 | ACC 0.9289\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0219/0938 | LOSS: 0.2419 | ACC 0.9291\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0220/0938 | LOSS: 0.2412 | ACC 0.9293\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0221/0938 | LOSS: 0.2419 | ACC 0.9289\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0222/0938 | LOSS: 0.2417 | ACC 0.9290\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0223/0938 | LOSS: 0.2415 | ACC 0.9291\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0224/0938 | LOSS: 0.2412 | ACC 0.9293\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0225/0938 | LOSS: 0.2407 | ACC 0.9294\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0226/0938 | LOSS: 0.2409 | ACC 0.9292\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0227/0938 | LOSS: 0.2411 | ACC 0.9292\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0228/0938 | LOSS: 0.2409 | ACC 0.9291\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0229/0938 | LOSS: 0.2407 | ACC 0.9291\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0230/0938 | LOSS: 0.2405 | ACC 0.9291\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0231/0938 | LOSS: 0.2399 | ACC 0.9294\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0232/0938 | LOSS: 0.2398 | ACC 0.9294\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0233/0938 | LOSS: 0.2408 | ACC 0.9293\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0234/0938 | LOSS: 0.2402 | ACC 0.9294\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0235/0938 | LOSS: 0.2402 | ACC 0.9295\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0236/0938 | LOSS: 0.2398 | ACC 0.9296\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0237/0938 | LOSS: 0.2400 | ACC 0.9297\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0238/0938 | LOSS: 0.2402 | ACC 0.9297\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0239/0938 | LOSS: 0.2406 | ACC 0.9297\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0240/0938 | LOSS: 0.2402 | ACC 0.9297\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0241/0938 | LOSS: 0.2407 | ACC 0.9293\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0242/0938 | LOSS: 0.2402 | ACC 0.9294\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0243/0938 | LOSS: 0.2400 | ACC 0.9296\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0244/0938 | LOSS: 0.2399 | ACC 0.9296\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0245/0938 | LOSS: 0.2397 | ACC 0.9296\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0246/0938 | LOSS: 0.2400 | ACC 0.9295\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0247/0938 | LOSS: 0.2407 | ACC 0.9293\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0248/0938 | LOSS: 0.2408 | ACC 0.9294\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0249/0938 | LOSS: 0.2403 | ACC 0.9295\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0250/0938 | LOSS: 0.2401 | ACC 0.9296\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0251/0938 | LOSS: 0.2404 | ACC 0.9295\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0252/0938 | LOSS: 0.2401 | ACC 0.9296\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0253/0938 | LOSS: 0.2396 | ACC 0.9298\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0254/0938 | LOSS: 0.2399 | ACC 0.9297\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0255/0938 | LOSS: 0.2395 | ACC 0.9298\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0256/0938 | LOSS: 0.2393 | ACC 0.9298\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0257/0938 | LOSS: 0.2389 | ACC 0.9299\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0258/0938 | LOSS: 0.2383 | ACC 0.9301\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0259/0938 | LOSS: 0.2385 | ACC 0.9301\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0260/0938 | LOSS: 0.2391 | ACC 0.9302\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0261/0938 | LOSS: 0.2388 | ACC 0.9304\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0262/0938 | LOSS: 0.2393 | ACC 0.9300\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0263/0938 | LOSS: 0.2395 | ACC 0.9298\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0264/0938 | LOSS: 0.2389 | ACC 0.9300\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0265/0938 | LOSS: 0.2389 | ACC 0.9301\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0266/0938 | LOSS: 0.2391 | ACC 0.9301\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0267/0938 | LOSS: 0.2390 | ACC 0.9301\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0268/0938 | LOSS: 0.2397 | ACC 0.9299\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: EPOCH 0003/0010 | BATCH 0269/0938 | LOSS: 0.2395 | ACC 0.9300\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0270/0938 | LOSS: 0.2392 | ACC 0.9300\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0271/0938 | LOSS: 0.2395 | ACC 0.9299\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0272/0938 | LOSS: 0.2391 | ACC 0.9300\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0273/0938 | LOSS: 0.2389 | ACC 0.9299\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0274/0938 | LOSS: 0.2388 | ACC 0.9300\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0275/0938 | LOSS: 0.2384 | ACC 0.9301\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0276/0938 | LOSS: 0.2380 | ACC 0.9303\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0277/0938 | LOSS: 0.2376 | ACC 0.9305\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0278/0938 | LOSS: 0.2376 | ACC 0.9304\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0279/0938 | LOSS: 0.2375 | ACC 0.9305\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0280/0938 | LOSS: 0.2381 | ACC 0.9304\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0281/0938 | LOSS: 0.2381 | ACC 0.9304\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0282/0938 | LOSS: 0.2378 | ACC 0.9305\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0283/0938 | LOSS: 0.2372 | ACC 0.9308\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0284/0938 | LOSS: 0.2370 | ACC 0.9309\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0285/0938 | LOSS: 0.2364 | ACC 0.9311\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0286/0938 | LOSS: 0.2366 | ACC 0.9311\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0287/0938 | LOSS: 0.2374 | ACC 0.9310\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0288/0938 | LOSS: 0.2386 | ACC 0.9309\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0289/0938 | LOSS: 0.2387 | ACC 0.9309\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0290/0938 | LOSS: 0.2395 | ACC 0.9307\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0291/0938 | LOSS: 0.2398 | ACC 0.9308\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0292/0938 | LOSS: 0.2393 | ACC 0.9309\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0293/0938 | LOSS: 0.2392 | ACC 0.9308\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0294/0938 | LOSS: 0.2395 | ACC 0.9309\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0295/0938 | LOSS: 0.2398 | ACC 0.9308\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0296/0938 | LOSS: 0.2397 | ACC 0.9309\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0297/0938 | LOSS: 0.2391 | ACC 0.9311\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0298/0938 | LOSS: 0.2396 | ACC 0.9310\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0299/0938 | LOSS: 0.2394 | ACC 0.9311\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0300/0938 | LOSS: 0.2390 | ACC 0.9313\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0301/0938 | LOSS: 0.2387 | ACC 0.9313\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0302/0938 | LOSS: 0.2386 | ACC 0.9314\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0303/0938 | LOSS: 0.2389 | ACC 0.9313\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0304/0938 | LOSS: 0.2384 | ACC 0.9315\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0305/0938 | LOSS: 0.2384 | ACC 0.9315\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0306/0938 | LOSS: 0.2382 | ACC 0.9315\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0307/0938 | LOSS: 0.2383 | ACC 0.9315\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0308/0938 | LOSS: 0.2385 | ACC 0.9315\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0309/0938 | LOSS: 0.2388 | ACC 0.9314\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0310/0938 | LOSS: 0.2388 | ACC 0.9314\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0311/0938 | LOSS: 0.2393 | ACC 0.9313\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0312/0938 | LOSS: 0.2394 | ACC 0.9313\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0313/0938 | LOSS: 0.2392 | ACC 0.9313\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0314/0938 | LOSS: 0.2392 | ACC 0.9313\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0315/0938 | LOSS: 0.2396 | ACC 0.9311\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0316/0938 | LOSS: 0.2395 | ACC 0.9312\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0317/0938 | LOSS: 0.2393 | ACC 0.9311\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0318/0938 | LOSS: 0.2395 | ACC 0.9311\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0319/0938 | LOSS: 0.2392 | ACC 0.9311\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0320/0938 | LOSS: 0.2389 | ACC 0.9311\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0321/0938 | LOSS: 0.2392 | ACC 0.9310\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0322/0938 | LOSS: 0.2395 | ACC 0.9309\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0323/0938 | LOSS: 0.2393 | ACC 0.9309\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0324/0938 | LOSS: 0.2387 | ACC 0.9311\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0325/0938 | LOSS: 0.2387 | ACC 0.9311\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0326/0938 | LOSS: 0.2385 | ACC 0.9310\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0327/0938 | LOSS: 0.2382 | ACC 0.9311\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0328/0938 | LOSS: 0.2384 | ACC 0.9309\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0329/0938 | LOSS: 0.2389 | ACC 0.9307\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0330/0938 | LOSS: 0.2399 | ACC 0.9306\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0331/0938 | LOSS: 0.2395 | ACC 0.9307\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0332/0938 | LOSS: 0.2394 | ACC 0.9307\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0333/0938 | LOSS: 0.2395 | ACC 0.9307\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0334/0938 | LOSS: 0.2392 | ACC 0.9308\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0335/0938 | LOSS: 0.2394 | ACC 0.9306\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0336/0938 | LOSS: 0.2397 | ACC 0.9307\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0337/0938 | LOSS: 0.2400 | ACC 0.9307\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0338/0938 | LOSS: 0.2398 | ACC 0.9308\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0339/0938 | LOSS: 0.2396 | ACC 0.9309\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0340/0938 | LOSS: 0.2397 | ACC 0.9309\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0341/0938 | LOSS: 0.2395 | ACC 0.9309\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0342/0938 | LOSS: 0.2393 | ACC 0.9310\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0343/0938 | LOSS: 0.2394 | ACC 0.9308\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0344/0938 | LOSS: 0.2390 | ACC 0.9310\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0345/0938 | LOSS: 0.2391 | ACC 0.9310\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0346/0938 | LOSS: 0.2392 | ACC 0.9308\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0347/0938 | LOSS: 0.2390 | ACC 0.9309\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0348/0938 | LOSS: 0.2388 | ACC 0.9309\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0349/0938 | LOSS: 0.2388 | ACC 0.9310\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0350/0938 | LOSS: 0.2388 | ACC 0.9309\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0351/0938 | LOSS: 0.2391 | ACC 0.9309\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0352/0938 | LOSS: 0.2389 | ACC 0.9310\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0353/0938 | LOSS: 0.2395 | ACC 0.9309\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0354/0938 | LOSS: 0.2394 | ACC 0.9309\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0355/0938 | LOSS: 0.2396 | ACC 0.9307\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0356/0938 | LOSS: 0.2400 | ACC 0.9305\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0357/0938 | LOSS: 0.2396 | ACC 0.9306\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0358/0938 | LOSS: 0.2395 | ACC 0.9307\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0359/0938 | LOSS: 0.2398 | ACC 0.9306\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0360/0938 | LOSS: 0.2401 | ACC 0.9306\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0361/0938 | LOSS: 0.2399 | ACC 0.9307\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0362/0938 | LOSS: 0.2399 | ACC 0.9307\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0363/0938 | LOSS: 0.2401 | ACC 0.9307\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0364/0938 | LOSS: 0.2409 | ACC 0.9304\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0365/0938 | LOSS: 0.2404 | ACC 0.9306\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0366/0938 | LOSS: 0.2406 | ACC 0.9306\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0367/0938 | LOSS: 0.2406 | ACC 0.9306\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0368/0938 | LOSS: 0.2407 | ACC 0.9307\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0369/0938 | LOSS: 0.2410 | ACC 0.9306\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0370/0938 | LOSS: 0.2412 | ACC 0.9305\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0371/0938 | LOSS: 0.2411 | ACC 0.9306\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0372/0938 | LOSS: 0.2412 | ACC 0.9305\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0373/0938 | LOSS: 0.2413 | ACC 0.9305\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0374/0938 | LOSS: 0.2412 | ACC 0.9305\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0375/0938 | LOSS: 0.2416 | ACC 0.9304\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0376/0938 | LOSS: 0.2416 | ACC 0.9304\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0377/0938 | LOSS: 0.2416 | ACC 0.9305\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0378/0938 | LOSS: 0.2420 | ACC 0.9305\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0379/0938 | LOSS: 0.2420 | ACC 0.9304\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0380/0938 | LOSS: 0.2421 | ACC 0.9303\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0381/0938 | LOSS: 0.2421 | ACC 0.9303\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0382/0938 | LOSS: 0.2425 | ACC 0.9301\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0383/0938 | LOSS: 0.2422 | ACC 0.9303\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0384/0938 | LOSS: 0.2427 | ACC 0.9302\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0385/0938 | LOSS: 0.2429 | ACC 0.9302\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0386/0938 | LOSS: 0.2429 | ACC 0.9302\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0387/0938 | LOSS: 0.2426 | ACC 0.9303\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0388/0938 | LOSS: 0.2423 | ACC 0.9303\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0389/0938 | LOSS: 0.2426 | ACC 0.9303\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0390/0938 | LOSS: 0.2428 | ACC 0.9302\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0391/0938 | LOSS: 0.2428 | ACC 0.9302\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0392/0938 | LOSS: 0.2429 | ACC 0.9302\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0393/0938 | LOSS: 0.2429 | ACC 0.9301\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0394/0938 | LOSS: 0.2428 | ACC 0.9301\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: EPOCH 0003/0010 | BATCH 0395/0938 | LOSS: 0.2426 | ACC 0.9301\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0396/0938 | LOSS: 0.2429 | ACC 0.9300\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0397/0938 | LOSS: 0.2428 | ACC 0.9301\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0398/0938 | LOSS: 0.2425 | ACC 0.9302\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0399/0938 | LOSS: 0.2427 | ACC 0.9301\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0400/0938 | LOSS: 0.2429 | ACC 0.9301\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0401/0938 | LOSS: 0.2427 | ACC 0.9301\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0402/0938 | LOSS: 0.2425 | ACC 0.9302\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0403/0938 | LOSS: 0.2423 | ACC 0.9302\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0404/0938 | LOSS: 0.2421 | ACC 0.9302\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0405/0938 | LOSS: 0.2419 | ACC 0.9302\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0406/0938 | LOSS: 0.2422 | ACC 0.9302\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0407/0938 | LOSS: 0.2419 | ACC 0.9302\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0408/0938 | LOSS: 0.2427 | ACC 0.9300\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0409/0938 | LOSS: 0.2427 | ACC 0.9300\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0410/0938 | LOSS: 0.2424 | ACC 0.9301\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0411/0938 | LOSS: 0.2421 | ACC 0.9302\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0412/0938 | LOSS: 0.2420 | ACC 0.9301\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0413/0938 | LOSS: 0.2418 | ACC 0.9302\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0414/0938 | LOSS: 0.2418 | ACC 0.9302\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0415/0938 | LOSS: 0.2414 | ACC 0.9304\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0416/0938 | LOSS: 0.2414 | ACC 0.9305\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0417/0938 | LOSS: 0.2418 | ACC 0.9302\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0418/0938 | LOSS: 0.2417 | ACC 0.9302\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0419/0938 | LOSS: 0.2417 | ACC 0.9302\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0420/0938 | LOSS: 0.2417 | ACC 0.9301\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0421/0938 | LOSS: 0.2416 | ACC 0.9301\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0422/0938 | LOSS: 0.2418 | ACC 0.9300\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0423/0938 | LOSS: 0.2418 | ACC 0.9300\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0424/0938 | LOSS: 0.2417 | ACC 0.9299\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0425/0938 | LOSS: 0.2415 | ACC 0.9299\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0426/0938 | LOSS: 0.2413 | ACC 0.9299\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0427/0938 | LOSS: 0.2410 | ACC 0.9300\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0428/0938 | LOSS: 0.2407 | ACC 0.9301\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0429/0938 | LOSS: 0.2408 | ACC 0.9300\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0430/0938 | LOSS: 0.2412 | ACC 0.9300\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0431/0938 | LOSS: 0.2413 | ACC 0.9301\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0432/0938 | LOSS: 0.2409 | ACC 0.9302\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0433/0938 | LOSS: 0.2407 | ACC 0.9302\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0434/0938 | LOSS: 0.2406 | ACC 0.9302\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0435/0938 | LOSS: 0.2415 | ACC 0.9301\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0436/0938 | LOSS: 0.2412 | ACC 0.9302\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0437/0938 | LOSS: 0.2416 | ACC 0.9301\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0438/0938 | LOSS: 0.2414 | ACC 0.9302\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0439/0938 | LOSS: 0.2411 | ACC 0.9303\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0440/0938 | LOSS: 0.2409 | ACC 0.9303\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0441/0938 | LOSS: 0.2409 | ACC 0.9303\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0442/0938 | LOSS: 0.2407 | ACC 0.9304\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0443/0938 | LOSS: 0.2411 | ACC 0.9303\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0444/0938 | LOSS: 0.2413 | ACC 0.9303\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0445/0938 | LOSS: 0.2411 | ACC 0.9303\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0446/0938 | LOSS: 0.2412 | ACC 0.9303\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0447/0938 | LOSS: 0.2415 | ACC 0.9303\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0448/0938 | LOSS: 0.2413 | ACC 0.9304\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0449/0938 | LOSS: 0.2411 | ACC 0.9305\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0450/0938 | LOSS: 0.2414 | ACC 0.9304\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0451/0938 | LOSS: 0.2414 | ACC 0.9304\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0452/0938 | LOSS: 0.2413 | ACC 0.9304\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0453/0938 | LOSS: 0.2410 | ACC 0.9305\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0454/0938 | LOSS: 0.2409 | ACC 0.9304\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0455/0938 | LOSS: 0.2407 | ACC 0.9305\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0456/0938 | LOSS: 0.2406 | ACC 0.9305\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0457/0938 | LOSS: 0.2406 | ACC 0.9305\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0458/0938 | LOSS: 0.2409 | ACC 0.9305\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0459/0938 | LOSS: 0.2408 | ACC 0.9304\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0460/0938 | LOSS: 0.2411 | ACC 0.9304\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0461/0938 | LOSS: 0.2409 | ACC 0.9305\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0462/0938 | LOSS: 0.2410 | ACC 0.9304\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0463/0938 | LOSS: 0.2407 | ACC 0.9305\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0464/0938 | LOSS: 0.2406 | ACC 0.9305\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0465/0938 | LOSS: 0.2407 | ACC 0.9304\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0466/0938 | LOSS: 0.2404 | ACC 0.9306\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0467/0938 | LOSS: 0.2401 | ACC 0.9306\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0468/0938 | LOSS: 0.2400 | ACC 0.9306\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0469/0938 | LOSS: 0.2398 | ACC 0.9306\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0470/0938 | LOSS: 0.2397 | ACC 0.9307\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0471/0938 | LOSS: 0.2398 | ACC 0.9305\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0472/0938 | LOSS: 0.2398 | ACC 0.9306\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0473/0938 | LOSS: 0.2396 | ACC 0.9306\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0474/0938 | LOSS: 0.2394 | ACC 0.9307\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0475/0938 | LOSS: 0.2391 | ACC 0.9308\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0476/0938 | LOSS: 0.2393 | ACC 0.9308\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0477/0938 | LOSS: 0.2394 | ACC 0.9307\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0478/0938 | LOSS: 0.2397 | ACC 0.9307\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0479/0938 | LOSS: 0.2395 | ACC 0.9308\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0480/0938 | LOSS: 0.2396 | ACC 0.9308\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0481/0938 | LOSS: 0.2396 | ACC 0.9308\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0482/0938 | LOSS: 0.2398 | ACC 0.9308\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0483/0938 | LOSS: 0.2397 | ACC 0.9308\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0484/0938 | LOSS: 0.2396 | ACC 0.9308\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0485/0938 | LOSS: 0.2399 | ACC 0.9306\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0486/0938 | LOSS: 0.2397 | ACC 0.9307\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0487/0938 | LOSS: 0.2397 | ACC 0.9307\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0488/0938 | LOSS: 0.2397 | ACC 0.9307\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0489/0938 | LOSS: 0.2395 | ACC 0.9307\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0490/0938 | LOSS: 0.2393 | ACC 0.9308\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0491/0938 | LOSS: 0.2393 | ACC 0.9307\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0492/0938 | LOSS: 0.2391 | ACC 0.9308\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0493/0938 | LOSS: 0.2388 | ACC 0.9308\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0494/0938 | LOSS: 0.2388 | ACC 0.9308\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0495/0938 | LOSS: 0.2387 | ACC 0.9308\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0496/0938 | LOSS: 0.2386 | ACC 0.9308\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0497/0938 | LOSS: 0.2384 | ACC 0.9309\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0498/0938 | LOSS: 0.2384 | ACC 0.9309\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0499/0938 | LOSS: 0.2383 | ACC 0.9310\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0500/0938 | LOSS: 0.2383 | ACC 0.9310\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0501/0938 | LOSS: 0.2383 | ACC 0.9309\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0502/0938 | LOSS: 0.2384 | ACC 0.9308\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0503/0938 | LOSS: 0.2384 | ACC 0.9308\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0504/0938 | LOSS: 0.2382 | ACC 0.9309\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0505/0938 | LOSS: 0.2380 | ACC 0.9309\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0506/0938 | LOSS: 0.2380 | ACC 0.9309\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0507/0938 | LOSS: 0.2380 | ACC 0.9309\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0508/0938 | LOSS: 0.2377 | ACC 0.9310\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0509/0938 | LOSS: 0.2376 | ACC 0.9311\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0510/0938 | LOSS: 0.2375 | ACC 0.9311\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0511/0938 | LOSS: 0.2375 | ACC 0.9311\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0512/0938 | LOSS: 0.2374 | ACC 0.9311\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0513/0938 | LOSS: 0.2374 | ACC 0.9311\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0514/0938 | LOSS: 0.2372 | ACC 0.9311\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0515/0938 | LOSS: 0.2370 | ACC 0.9312\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0516/0938 | LOSS: 0.2372 | ACC 0.9312\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0517/0938 | LOSS: 0.2374 | ACC 0.9312\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0518/0938 | LOSS: 0.2378 | ACC 0.9311\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0519/0938 | LOSS: 0.2376 | ACC 0.9311\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0520/0938 | LOSS: 0.2378 | ACC 0.9311\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0521/0938 | LOSS: 0.2376 | ACC 0.9311\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0522/0938 | LOSS: 0.2376 | ACC 0.9310\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0523/0938 | LOSS: 0.2379 | ACC 0.9310\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: EPOCH 0003/0010 | BATCH 0524/0938 | LOSS: 0.2377 | ACC 0.9311\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0525/0938 | LOSS: 0.2377 | ACC 0.9311\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0526/0938 | LOSS: 0.2378 | ACC 0.9310\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0527/0938 | LOSS: 0.2378 | ACC 0.9310\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0528/0938 | LOSS: 0.2377 | ACC 0.9310\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0529/0938 | LOSS: 0.2375 | ACC 0.9310\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0530/0938 | LOSS: 0.2373 | ACC 0.9311\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0531/0938 | LOSS: 0.2371 | ACC 0.9311\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0532/0938 | LOSS: 0.2374 | ACC 0.9311\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0533/0938 | LOSS: 0.2372 | ACC 0.9311\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0534/0938 | LOSS: 0.2372 | ACC 0.9311\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0535/0938 | LOSS: 0.2371 | ACC 0.9311\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0536/0938 | LOSS: 0.2371 | ACC 0.9311\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0537/0938 | LOSS: 0.2370 | ACC 0.9311\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0538/0938 | LOSS: 0.2370 | ACC 0.9311\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0539/0938 | LOSS: 0.2369 | ACC 0.9311\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0540/0938 | LOSS: 0.2370 | ACC 0.9310\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0541/0938 | LOSS: 0.2370 | ACC 0.9311\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0542/0938 | LOSS: 0.2369 | ACC 0.9311\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0543/0938 | LOSS: 0.2367 | ACC 0.9312\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0544/0938 | LOSS: 0.2367 | ACC 0.9312\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0545/0938 | LOSS: 0.2366 | ACC 0.9312\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0546/0938 | LOSS: 0.2363 | ACC 0.9313\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0547/0938 | LOSS: 0.2363 | ACC 0.9313\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0548/0938 | LOSS: 0.2361 | ACC 0.9314\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0549/0938 | LOSS: 0.2362 | ACC 0.9314\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0550/0938 | LOSS: 0.2361 | ACC 0.9314\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0551/0938 | LOSS: 0.2360 | ACC 0.9314\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0552/0938 | LOSS: 0.2359 | ACC 0.9314\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0553/0938 | LOSS: 0.2359 | ACC 0.9314\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0554/0938 | LOSS: 0.2358 | ACC 0.9315\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0555/0938 | LOSS: 0.2357 | ACC 0.9314\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0556/0938 | LOSS: 0.2357 | ACC 0.9314\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0557/0938 | LOSS: 0.2356 | ACC 0.9314\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0558/0938 | LOSS: 0.2354 | ACC 0.9315\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0559/0938 | LOSS: 0.2354 | ACC 0.9315\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0560/0938 | LOSS: 0.2353 | ACC 0.9315\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0561/0938 | LOSS: 0.2350 | ACC 0.9316\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0562/0938 | LOSS: 0.2348 | ACC 0.9317\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0563/0938 | LOSS: 0.2349 | ACC 0.9316\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0564/0938 | LOSS: 0.2348 | ACC 0.9317\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0565/0938 | LOSS: 0.2346 | ACC 0.9317\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0566/0938 | LOSS: 0.2344 | ACC 0.9318\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0567/0938 | LOSS: 0.2345 | ACC 0.9318\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0568/0938 | LOSS: 0.2346 | ACC 0.9317\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0569/0938 | LOSS: 0.2346 | ACC 0.9316\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0570/0938 | LOSS: 0.2347 | ACC 0.9316\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0571/0938 | LOSS: 0.2347 | ACC 0.9316\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0572/0938 | LOSS: 0.2351 | ACC 0.9315\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0573/0938 | LOSS: 0.2352 | ACC 0.9315\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0574/0938 | LOSS: 0.2354 | ACC 0.9314\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0575/0938 | LOSS: 0.2354 | ACC 0.9315\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0576/0938 | LOSS: 0.2352 | ACC 0.9315\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0577/0938 | LOSS: 0.2353 | ACC 0.9315\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0578/0938 | LOSS: 0.2351 | ACC 0.9315\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0579/0938 | LOSS: 0.2351 | ACC 0.9315\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0580/0938 | LOSS: 0.2354 | ACC 0.9314\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0581/0938 | LOSS: 0.2355 | ACC 0.9314\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0582/0938 | LOSS: 0.2353 | ACC 0.9315\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0583/0938 | LOSS: 0.2351 | ACC 0.9315\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0584/0938 | LOSS: 0.2349 | ACC 0.9316\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0585/0938 | LOSS: 0.2349 | ACC 0.9316\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0586/0938 | LOSS: 0.2348 | ACC 0.9316\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0587/0938 | LOSS: 0.2346 | ACC 0.9317\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0588/0938 | LOSS: 0.2346 | ACC 0.9317\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0589/0938 | LOSS: 0.2346 | ACC 0.9318\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0590/0938 | LOSS: 0.2348 | ACC 0.9318\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0591/0938 | LOSS: 0.2349 | ACC 0.9317\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0592/0938 | LOSS: 0.2351 | ACC 0.9317\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0593/0938 | LOSS: 0.2350 | ACC 0.9317\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0594/0938 | LOSS: 0.2350 | ACC 0.9317\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0595/0938 | LOSS: 0.2350 | ACC 0.9317\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0596/0938 | LOSS: 0.2350 | ACC 0.9317\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0597/0938 | LOSS: 0.2348 | ACC 0.9318\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0598/0938 | LOSS: 0.2345 | ACC 0.9319\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0599/0938 | LOSS: 0.2344 | ACC 0.9319\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0600/0938 | LOSS: 0.2345 | ACC 0.9319\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0601/0938 | LOSS: 0.2345 | ACC 0.9318\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0602/0938 | LOSS: 0.2344 | ACC 0.9318\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0603/0938 | LOSS: 0.2343 | ACC 0.9318\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0604/0938 | LOSS: 0.2343 | ACC 0.9318\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0605/0938 | LOSS: 0.2344 | ACC 0.9318\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0606/0938 | LOSS: 0.2345 | ACC 0.9318\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0607/0938 | LOSS: 0.2346 | ACC 0.9318\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0608/0938 | LOSS: 0.2346 | ACC 0.9318\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0609/0938 | LOSS: 0.2346 | ACC 0.9319\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0610/0938 | LOSS: 0.2349 | ACC 0.9318\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0611/0938 | LOSS: 0.2348 | ACC 0.9318\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0612/0938 | LOSS: 0.2351 | ACC 0.9317\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0613/0938 | LOSS: 0.2352 | ACC 0.9317\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0614/0938 | LOSS: 0.2352 | ACC 0.9317\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0615/0938 | LOSS: 0.2351 | ACC 0.9316\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0616/0938 | LOSS: 0.2357 | ACC 0.9315\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0617/0938 | LOSS: 0.2355 | ACC 0.9316\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0618/0938 | LOSS: 0.2355 | ACC 0.9316\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0619/0938 | LOSS: 0.2355 | ACC 0.9316\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0620/0938 | LOSS: 0.2352 | ACC 0.9316\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0621/0938 | LOSS: 0.2351 | ACC 0.9316\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0622/0938 | LOSS: 0.2349 | ACC 0.9316\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0623/0938 | LOSS: 0.2353 | ACC 0.9316\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0624/0938 | LOSS: 0.2351 | ACC 0.9317\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0625/0938 | LOSS: 0.2351 | ACC 0.9317\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0626/0938 | LOSS: 0.2349 | ACC 0.9317\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0627/0938 | LOSS: 0.2349 | ACC 0.9317\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0628/0938 | LOSS: 0.2347 | ACC 0.9319\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0629/0938 | LOSS: 0.2347 | ACC 0.9319\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0630/0938 | LOSS: 0.2347 | ACC 0.9319\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0631/0938 | LOSS: 0.2345 | ACC 0.9319\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0632/0938 | LOSS: 0.2344 | ACC 0.9319\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0633/0938 | LOSS: 0.2345 | ACC 0.9319\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0634/0938 | LOSS: 0.2344 | ACC 0.9320\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0635/0938 | LOSS: 0.2345 | ACC 0.9319\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0636/0938 | LOSS: 0.2344 | ACC 0.9319\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0637/0938 | LOSS: 0.2344 | ACC 0.9320\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0638/0938 | LOSS: 0.2345 | ACC 0.9320\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0639/0938 | LOSS: 0.2344 | ACC 0.9319\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0640/0938 | LOSS: 0.2344 | ACC 0.9319\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0641/0938 | LOSS: 0.2344 | ACC 0.9320\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0642/0938 | LOSS: 0.2342 | ACC 0.9320\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0643/0938 | LOSS: 0.2341 | ACC 0.9320\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0644/0938 | LOSS: 0.2341 | ACC 0.9320\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0645/0938 | LOSS: 0.2339 | ACC 0.9320\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0646/0938 | LOSS: 0.2339 | ACC 0.9320\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0647/0938 | LOSS: 0.2338 | ACC 0.9320\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0648/0938 | LOSS: 0.2338 | ACC 0.9320\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0649/0938 | LOSS: 0.2336 | ACC 0.9321\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0650/0938 | LOSS: 0.2336 | ACC 0.9320\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0651/0938 | LOSS: 0.2339 | ACC 0.9320\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0652/0938 | LOSS: 0.2340 | ACC 0.9320\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: EPOCH 0003/0010 | BATCH 0653/0938 | LOSS: 0.2340 | ACC 0.9320\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0654/0938 | LOSS: 0.2340 | ACC 0.9320\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0655/0938 | LOSS: 0.2342 | ACC 0.9320\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0656/0938 | LOSS: 0.2342 | ACC 0.9320\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0657/0938 | LOSS: 0.2339 | ACC 0.9321\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0658/0938 | LOSS: 0.2340 | ACC 0.9321\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0659/0938 | LOSS: 0.2340 | ACC 0.9321\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0660/0938 | LOSS: 0.2340 | ACC 0.9321\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0661/0938 | LOSS: 0.2339 | ACC 0.9321\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0662/0938 | LOSS: 0.2339 | ACC 0.9321\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0663/0938 | LOSS: 0.2338 | ACC 0.9321\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0664/0938 | LOSS: 0.2336 | ACC 0.9321\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0665/0938 | LOSS: 0.2335 | ACC 0.9322\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0666/0938 | LOSS: 0.2334 | ACC 0.9322\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0667/0938 | LOSS: 0.2334 | ACC 0.9321\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0668/0938 | LOSS: 0.2338 | ACC 0.9321\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0669/0938 | LOSS: 0.2341 | ACC 0.9320\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0670/0938 | LOSS: 0.2340 | ACC 0.9321\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0671/0938 | LOSS: 0.2348 | ACC 0.9320\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0672/0938 | LOSS: 0.2348 | ACC 0.9319\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0673/0938 | LOSS: 0.2347 | ACC 0.9319\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0674/0938 | LOSS: 0.2347 | ACC 0.9320\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0675/0938 | LOSS: 0.2346 | ACC 0.9320\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0676/0938 | LOSS: 0.2344 | ACC 0.9321\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0677/0938 | LOSS: 0.2343 | ACC 0.9321\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0678/0938 | LOSS: 0.2341 | ACC 0.9322\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0679/0938 | LOSS: 0.2340 | ACC 0.9322\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0680/0938 | LOSS: 0.2341 | ACC 0.9321\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0681/0938 | LOSS: 0.2340 | ACC 0.9321\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0682/0938 | LOSS: 0.2339 | ACC 0.9321\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0683/0938 | LOSS: 0.2339 | ACC 0.9321\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0684/0938 | LOSS: 0.2340 | ACC 0.9321\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0685/0938 | LOSS: 0.2340 | ACC 0.9321\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0686/0938 | LOSS: 0.2338 | ACC 0.9322\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0687/0938 | LOSS: 0.2337 | ACC 0.9322\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0688/0938 | LOSS: 0.2339 | ACC 0.9321\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0689/0938 | LOSS: 0.2338 | ACC 0.9321\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0690/0938 | LOSS: 0.2340 | ACC 0.9321\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0691/0938 | LOSS: 0.2339 | ACC 0.9321\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0692/0938 | LOSS: 0.2339 | ACC 0.9321\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0693/0938 | LOSS: 0.2339 | ACC 0.9320\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0694/0938 | LOSS: 0.2339 | ACC 0.9321\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0695/0938 | LOSS: 0.2339 | ACC 0.9321\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0696/0938 | LOSS: 0.2338 | ACC 0.9321\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0697/0938 | LOSS: 0.2337 | ACC 0.9321\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0698/0938 | LOSS: 0.2337 | ACC 0.9321\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0699/0938 | LOSS: 0.2337 | ACC 0.9321\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0700/0938 | LOSS: 0.2339 | ACC 0.9321\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0701/0938 | LOSS: 0.2339 | ACC 0.9321\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0702/0938 | LOSS: 0.2338 | ACC 0.9321\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0703/0938 | LOSS: 0.2338 | ACC 0.9321\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0704/0938 | LOSS: 0.2337 | ACC 0.9321\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0705/0938 | LOSS: 0.2337 | ACC 0.9321\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0706/0938 | LOSS: 0.2336 | ACC 0.9321\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0707/0938 | LOSS: 0.2334 | ACC 0.9321\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0708/0938 | LOSS: 0.2333 | ACC 0.9322\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0709/0938 | LOSS: 0.2332 | ACC 0.9321\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0710/0938 | LOSS: 0.2331 | ACC 0.9322\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0711/0938 | LOSS: 0.2331 | ACC 0.9322\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0712/0938 | LOSS: 0.2332 | ACC 0.9322\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0713/0938 | LOSS: 0.2331 | ACC 0.9322\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0714/0938 | LOSS: 0.2330 | ACC 0.9322\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0715/0938 | LOSS: 0.2330 | ACC 0.9322\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0716/0938 | LOSS: 0.2331 | ACC 0.9322\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0717/0938 | LOSS: 0.2333 | ACC 0.9321\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0718/0938 | LOSS: 0.2333 | ACC 0.9321\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0719/0938 | LOSS: 0.2335 | ACC 0.9321\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0720/0938 | LOSS: 0.2338 | ACC 0.9321\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0721/0938 | LOSS: 0.2336 | ACC 0.9321\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0722/0938 | LOSS: 0.2335 | ACC 0.9321\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0723/0938 | LOSS: 0.2336 | ACC 0.9321\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0724/0938 | LOSS: 0.2334 | ACC 0.9321\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0725/0938 | LOSS: 0.2333 | ACC 0.9322\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0726/0938 | LOSS: 0.2331 | ACC 0.9322\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0727/0938 | LOSS: 0.2331 | ACC 0.9322\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0728/0938 | LOSS: 0.2332 | ACC 0.9322\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0729/0938 | LOSS: 0.2332 | ACC 0.9322\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0730/0938 | LOSS: 0.2331 | ACC 0.9322\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0731/0938 | LOSS: 0.2329 | ACC 0.9322\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0732/0938 | LOSS: 0.2327 | ACC 0.9323\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0733/0938 | LOSS: 0.2326 | ACC 0.9323\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0734/0938 | LOSS: 0.2327 | ACC 0.9323\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0735/0938 | LOSS: 0.2326 | ACC 0.9324\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0736/0938 | LOSS: 0.2324 | ACC 0.9325\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0737/0938 | LOSS: 0.2323 | ACC 0.9325\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0738/0938 | LOSS: 0.2325 | ACC 0.9324\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0739/0938 | LOSS: 0.2324 | ACC 0.9325\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0740/0938 | LOSS: 0.2322 | ACC 0.9325\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0741/0938 | LOSS: 0.2323 | ACC 0.9325\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0742/0938 | LOSS: 0.2321 | ACC 0.9326\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0743/0938 | LOSS: 0.2322 | ACC 0.9326\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0744/0938 | LOSS: 0.2321 | ACC 0.9326\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0745/0938 | LOSS: 0.2322 | ACC 0.9326\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0746/0938 | LOSS: 0.2321 | ACC 0.9326\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0747/0938 | LOSS: 0.2321 | ACC 0.9326\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0748/0938 | LOSS: 0.2320 | ACC 0.9326\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0749/0938 | LOSS: 0.2318 | ACC 0.9327\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0750/0938 | LOSS: 0.2319 | ACC 0.9326\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0751/0938 | LOSS: 0.2321 | ACC 0.9326\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0752/0938 | LOSS: 0.2323 | ACC 0.9326\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0753/0938 | LOSS: 0.2322 | ACC 0.9326\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0754/0938 | LOSS: 0.2320 | ACC 0.9327\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0755/0938 | LOSS: 0.2320 | ACC 0.9326\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0756/0938 | LOSS: 0.2319 | ACC 0.9327\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0757/0938 | LOSS: 0.2317 | ACC 0.9327\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0758/0938 | LOSS: 0.2314 | ACC 0.9328\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0759/0938 | LOSS: 0.2314 | ACC 0.9328\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0760/0938 | LOSS: 0.2315 | ACC 0.9328\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0761/0938 | LOSS: 0.2318 | ACC 0.9328\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0762/0938 | LOSS: 0.2319 | ACC 0.9328\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0763/0938 | LOSS: 0.2318 | ACC 0.9328\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0764/0938 | LOSS: 0.2317 | ACC 0.9328\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0765/0938 | LOSS: 0.2316 | ACC 0.9328\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0766/0938 | LOSS: 0.2315 | ACC 0.9329\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0767/0938 | LOSS: 0.2314 | ACC 0.9329\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0768/0938 | LOSS: 0.2314 | ACC 0.9329\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0769/0938 | LOSS: 0.2313 | ACC 0.9330\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0770/0938 | LOSS: 0.2312 | ACC 0.9330\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0771/0938 | LOSS: 0.2312 | ACC 0.9330\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0772/0938 | LOSS: 0.2311 | ACC 0.9330\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0773/0938 | LOSS: 0.2313 | ACC 0.9330\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0774/0938 | LOSS: 0.2312 | ACC 0.9331\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0775/0938 | LOSS: 0.2310 | ACC 0.9331\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0776/0938 | LOSS: 0.2313 | ACC 0.9331\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0777/0938 | LOSS: 0.2314 | ACC 0.9331\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0778/0938 | LOSS: 0.2315 | ACC 0.9331\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0779/0938 | LOSS: 0.2315 | ACC 0.9331\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0780/0938 | LOSS: 0.2315 | ACC 0.9331\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0781/0938 | LOSS: 0.2316 | ACC 0.9331\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0782/0938 | LOSS: 0.2315 | ACC 0.9331\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0783/0938 | LOSS: 0.2314 | ACC 0.9331\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: EPOCH 0003/0010 | BATCH 0784/0938 | LOSS: 0.2315 | ACC 0.9331\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0785/0938 | LOSS: 0.2315 | ACC 0.9331\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0786/0938 | LOSS: 0.2315 | ACC 0.9330\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0787/0938 | LOSS: 0.2313 | ACC 0.9331\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0788/0938 | LOSS: 0.2312 | ACC 0.9331\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0789/0938 | LOSS: 0.2312 | ACC 0.9331\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0790/0938 | LOSS: 0.2311 | ACC 0.9331\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0791/0938 | LOSS: 0.2310 | ACC 0.9332\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0792/0938 | LOSS: 0.2308 | ACC 0.9332\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0793/0938 | LOSS: 0.2308 | ACC 0.9332\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0794/0938 | LOSS: 0.2309 | ACC 0.9332\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0795/0938 | LOSS: 0.2310 | ACC 0.9332\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0796/0938 | LOSS: 0.2311 | ACC 0.9331\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0797/0938 | LOSS: 0.2310 | ACC 0.9331\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0798/0938 | LOSS: 0.2312 | ACC 0.9330\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0799/0938 | LOSS: 0.2313 | ACC 0.9330\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0800/0938 | LOSS: 0.2315 | ACC 0.9329\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0801/0938 | LOSS: 0.2314 | ACC 0.9330\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0802/0938 | LOSS: 0.2313 | ACC 0.9330\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0803/0938 | LOSS: 0.2313 | ACC 0.9330\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0804/0938 | LOSS: 0.2313 | ACC 0.9330\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0805/0938 | LOSS: 0.2312 | ACC 0.9330\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0806/0938 | LOSS: 0.2311 | ACC 0.9330\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0807/0938 | LOSS: 0.2314 | ACC 0.9329\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0808/0938 | LOSS: 0.2316 | ACC 0.9329\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0809/0938 | LOSS: 0.2315 | ACC 0.9330\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0810/0938 | LOSS: 0.2316 | ACC 0.9330\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0811/0938 | LOSS: 0.2315 | ACC 0.9330\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0812/0938 | LOSS: 0.2313 | ACC 0.9330\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0813/0938 | LOSS: 0.2312 | ACC 0.9331\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0814/0938 | LOSS: 0.2314 | ACC 0.9330\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0815/0938 | LOSS: 0.2313 | ACC 0.9330\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0816/0938 | LOSS: 0.2312 | ACC 0.9330\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0817/0938 | LOSS: 0.2311 | ACC 0.9330\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0818/0938 | LOSS: 0.2313 | ACC 0.9330\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0819/0938 | LOSS: 0.2312 | ACC 0.9330\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0820/0938 | LOSS: 0.2310 | ACC 0.9330\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0821/0938 | LOSS: 0.2311 | ACC 0.9331\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0822/0938 | LOSS: 0.2313 | ACC 0.9330\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0823/0938 | LOSS: 0.2312 | ACC 0.9330\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0824/0938 | LOSS: 0.2311 | ACC 0.9330\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0825/0938 | LOSS: 0.2310 | ACC 0.9330\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0826/0938 | LOSS: 0.2310 | ACC 0.9330\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0827/0938 | LOSS: 0.2311 | ACC 0.9330\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0828/0938 | LOSS: 0.2309 | ACC 0.9330\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0829/0938 | LOSS: 0.2310 | ACC 0.9330\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0830/0938 | LOSS: 0.2310 | ACC 0.9330\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0831/0938 | LOSS: 0.2309 | ACC 0.9330\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0832/0938 | LOSS: 0.2309 | ACC 0.9330\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0833/0938 | LOSS: 0.2312 | ACC 0.9330\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0834/0938 | LOSS: 0.2310 | ACC 0.9330\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0835/0938 | LOSS: 0.2311 | ACC 0.9330\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0836/0938 | LOSS: 0.2311 | ACC 0.9330\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0837/0938 | LOSS: 0.2312 | ACC 0.9330\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0838/0938 | LOSS: 0.2312 | ACC 0.9330\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0839/0938 | LOSS: 0.2311 | ACC 0.9330\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0840/0938 | LOSS: 0.2310 | ACC 0.9331\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0841/0938 | LOSS: 0.2309 | ACC 0.9331\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0842/0938 | LOSS: 0.2309 | ACC 0.9331\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0843/0938 | LOSS: 0.2308 | ACC 0.9331\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0844/0938 | LOSS: 0.2307 | ACC 0.9332\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0845/0938 | LOSS: 0.2305 | ACC 0.9332\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0846/0938 | LOSS: 0.2306 | ACC 0.9332\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0847/0938 | LOSS: 0.2305 | ACC 0.9332\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0848/0938 | LOSS: 0.2304 | ACC 0.9332\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0849/0938 | LOSS: 0.2304 | ACC 0.9332\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0850/0938 | LOSS: 0.2303 | ACC 0.9332\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0851/0938 | LOSS: 0.2304 | ACC 0.9332\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0852/0938 | LOSS: 0.2302 | ACC 0.9333\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0853/0938 | LOSS: 0.2301 | ACC 0.9333\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0854/0938 | LOSS: 0.2301 | ACC 0.9333\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0855/0938 | LOSS: 0.2300 | ACC 0.9334\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0856/0938 | LOSS: 0.2302 | ACC 0.9334\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0857/0938 | LOSS: 0.2301 | ACC 0.9333\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0858/0938 | LOSS: 0.2301 | ACC 0.9333\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0859/0938 | LOSS: 0.2304 | ACC 0.9332\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0860/0938 | LOSS: 0.2305 | ACC 0.9332\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0861/0938 | LOSS: 0.2304 | ACC 0.9332\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0862/0938 | LOSS: 0.2303 | ACC 0.9332\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0863/0938 | LOSS: 0.2303 | ACC 0.9332\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0864/0938 | LOSS: 0.2302 | ACC 0.9332\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0865/0938 | LOSS: 0.2301 | ACC 0.9332\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0866/0938 | LOSS: 0.2299 | ACC 0.9332\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0867/0938 | LOSS: 0.2300 | ACC 0.9332\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0868/0938 | LOSS: 0.2298 | ACC 0.9333\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0869/0938 | LOSS: 0.2299 | ACC 0.9333\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0870/0938 | LOSS: 0.2300 | ACC 0.9333\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0871/0938 | LOSS: 0.2300 | ACC 0.9333\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0872/0938 | LOSS: 0.2299 | ACC 0.9333\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0873/0938 | LOSS: 0.2299 | ACC 0.9333\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0874/0938 | LOSS: 0.2298 | ACC 0.9333\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0875/0938 | LOSS: 0.2297 | ACC 0.9334\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0876/0938 | LOSS: 0.2297 | ACC 0.9334\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0877/0938 | LOSS: 0.2297 | ACC 0.9333\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0878/0938 | LOSS: 0.2297 | ACC 0.9334\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0879/0938 | LOSS: 0.2297 | ACC 0.9334\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0880/0938 | LOSS: 0.2296 | ACC 0.9334\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0881/0938 | LOSS: 0.2295 | ACC 0.9335\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0882/0938 | LOSS: 0.2296 | ACC 0.9335\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0883/0938 | LOSS: 0.2296 | ACC 0.9334\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0884/0938 | LOSS: 0.2297 | ACC 0.9335\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0885/0938 | LOSS: 0.2296 | ACC 0.9335\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0886/0938 | LOSS: 0.2296 | ACC 0.9335\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0887/0938 | LOSS: 0.2296 | ACC 0.9334\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0888/0938 | LOSS: 0.2296 | ACC 0.9335\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0889/0938 | LOSS: 0.2296 | ACC 0.9335\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0890/0938 | LOSS: 0.2295 | ACC 0.9335\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0891/0938 | LOSS: 0.2294 | ACC 0.9336\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0892/0938 | LOSS: 0.2293 | ACC 0.9336\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0893/0938 | LOSS: 0.2292 | ACC 0.9336\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0894/0938 | LOSS: 0.2291 | ACC 0.9336\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0895/0938 | LOSS: 0.2293 | ACC 0.9336\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0896/0938 | LOSS: 0.2291 | ACC 0.9336\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0897/0938 | LOSS: 0.2292 | ACC 0.9336\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0898/0938 | LOSS: 0.2292 | ACC 0.9336\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0899/0938 | LOSS: 0.2291 | ACC 0.9336\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0900/0938 | LOSS: 0.2294 | ACC 0.9336\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0901/0938 | LOSS: 0.2293 | ACC 0.9336\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0902/0938 | LOSS: 0.2292 | ACC 0.9336\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0903/0938 | LOSS: 0.2291 | ACC 0.9336\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0904/0938 | LOSS: 0.2290 | ACC 0.9336\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0905/0938 | LOSS: 0.2292 | ACC 0.9336\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0906/0938 | LOSS: 0.2293 | ACC 0.9336\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0907/0938 | LOSS: 0.2295 | ACC 0.9335\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0908/0938 | LOSS: 0.2294 | ACC 0.9336\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0909/0938 | LOSS: 0.2293 | ACC 0.9336\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0910/0938 | LOSS: 0.2293 | ACC 0.9336\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0911/0938 | LOSS: 0.2293 | ACC 0.9336\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: EPOCH 0003/0010 | BATCH 0912/0938 | LOSS: 0.2292 | ACC 0.9336\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0913/0938 | LOSS: 0.2292 | ACC 0.9336\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0914/0938 | LOSS: 0.2291 | ACC 0.9336\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0915/0938 | LOSS: 0.2291 | ACC 0.9335\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0916/0938 | LOSS: 0.2291 | ACC 0.9335\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0917/0938 | LOSS: 0.2290 | ACC 0.9336\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0918/0938 | LOSS: 0.2290 | ACC 0.9336\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0919/0938 | LOSS: 0.2290 | ACC 0.9336\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0920/0938 | LOSS: 0.2289 | ACC 0.9336\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0921/0938 | LOSS: 0.2288 | ACC 0.9336\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0922/0938 | LOSS: 0.2287 | ACC 0.9336\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0923/0938 | LOSS: 0.2288 | ACC 0.9336\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0924/0938 | LOSS: 0.2287 | ACC 0.9336\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0925/0938 | LOSS: 0.2286 | ACC 0.9337\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0926/0938 | LOSS: 0.2286 | ACC 0.9337\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0927/0938 | LOSS: 0.2287 | ACC 0.9336\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0928/0938 | LOSS: 0.2286 | ACC 0.9337\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0929/0938 | LOSS: 0.2286 | ACC 0.9337\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0930/0938 | LOSS: 0.2286 | ACC 0.9337\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0931/0938 | LOSS: 0.2285 | ACC 0.9337\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0932/0938 | LOSS: 0.2285 | ACC 0.9337\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0933/0938 | LOSS: 0.2285 | ACC 0.9337\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0934/0938 | LOSS: 0.2284 | ACC 0.9337\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0935/0938 | LOSS: 0.2283 | ACC 0.9338\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0936/0938 | LOSS: 0.2284 | ACC 0.9337\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0937/0938 | LOSS: 0.2282 | ACC 0.9338\n",
      "TRAIN: EPOCH 0003/0010 | BATCH 0938/0938 | LOSS: 0.2282 | ACC 0.9338\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0001/0938 | LOSS: 0.2281 | ACC 0.9219\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0002/0938 | LOSS: 0.2038 | ACC 0.9219\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0003/0938 | LOSS: 0.2302 | ACC 0.9167\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0004/0938 | LOSS: 0.2221 | ACC 0.9180\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0005/0938 | LOSS: 0.1933 | ACC 0.9281\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0006/0938 | LOSS: 0.1801 | ACC 0.9349\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0007/0938 | LOSS: 0.1835 | ACC 0.9330\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0008/0938 | LOSS: 0.2028 | ACC 0.9297\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0009/0938 | LOSS: 0.1947 | ACC 0.9323\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0010/0938 | LOSS: 0.1883 | ACC 0.9375\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0011/0938 | LOSS: 0.1837 | ACC 0.9403\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0012/0938 | LOSS: 0.1924 | ACC 0.9388\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0013/0938 | LOSS: 0.2188 | ACC 0.9339\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0014/0938 | LOSS: 0.2158 | ACC 0.9353\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0015/0938 | LOSS: 0.2139 | ACC 0.9375\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0016/0938 | LOSS: 0.2096 | ACC 0.9355\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0017/0938 | LOSS: 0.2093 | ACC 0.9347\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0018/0938 | LOSS: 0.2052 | ACC 0.9349\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0019/0938 | LOSS: 0.2052 | ACC 0.9350\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0020/0938 | LOSS: 0.2023 | ACC 0.9359\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0021/0938 | LOSS: 0.1974 | ACC 0.9375\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0022/0938 | LOSS: 0.1947 | ACC 0.9396\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0023/0938 | LOSS: 0.2010 | ACC 0.9382\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0024/0938 | LOSS: 0.1965 | ACC 0.9395\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0025/0938 | LOSS: 0.1943 | ACC 0.9400\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0026/0938 | LOSS: 0.1929 | ACC 0.9411\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0027/0938 | LOSS: 0.1942 | ACC 0.9398\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0028/0938 | LOSS: 0.1926 | ACC 0.9408\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0029/0938 | LOSS: 0.1926 | ACC 0.9418\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0030/0938 | LOSS: 0.1933 | ACC 0.9422\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0031/0938 | LOSS: 0.1910 | ACC 0.9430\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0032/0938 | LOSS: 0.1912 | ACC 0.9434\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0033/0938 | LOSS: 0.1940 | ACC 0.9432\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0034/0938 | LOSS: 0.1974 | ACC 0.9416\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0035/0938 | LOSS: 0.1979 | ACC 0.9411\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0036/0938 | LOSS: 0.2033 | ACC 0.9401\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0037/0938 | LOSS: 0.2031 | ACC 0.9400\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0038/0938 | LOSS: 0.1999 | ACC 0.9412\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0039/0938 | LOSS: 0.2020 | ACC 0.9399\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0040/0938 | LOSS: 0.2008 | ACC 0.9398\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0041/0938 | LOSS: 0.2019 | ACC 0.9390\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0042/0938 | LOSS: 0.2048 | ACC 0.9386\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0043/0938 | LOSS: 0.2046 | ACC 0.9382\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0044/0938 | LOSS: 0.2015 | ACC 0.9389\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0045/0938 | LOSS: 0.2003 | ACC 0.9396\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0046/0938 | LOSS: 0.1984 | ACC 0.9402\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0047/0938 | LOSS: 0.2022 | ACC 0.9398\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0048/0938 | LOSS: 0.2036 | ACC 0.9395\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0049/0938 | LOSS: 0.2015 | ACC 0.9404\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0050/0938 | LOSS: 0.1994 | ACC 0.9406\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0051/0938 | LOSS: 0.1994 | ACC 0.9412\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0052/0938 | LOSS: 0.1986 | ACC 0.9414\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0053/0938 | LOSS: 0.1985 | ACC 0.9413\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0054/0938 | LOSS: 0.1984 | ACC 0.9416\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0055/0938 | LOSS: 0.1972 | ACC 0.9418\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0056/0938 | LOSS: 0.1958 | ACC 0.9420\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0057/0938 | LOSS: 0.1941 | ACC 0.9422\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0058/0938 | LOSS: 0.1953 | ACC 0.9415\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0059/0938 | LOSS: 0.1977 | ACC 0.9407\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0060/0938 | LOSS: 0.1978 | ACC 0.9409\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0061/0938 | LOSS: 0.1984 | ACC 0.9403\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0062/0938 | LOSS: 0.1991 | ACC 0.9405\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0063/0938 | LOSS: 0.1993 | ACC 0.9400\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0064/0938 | LOSS: 0.2015 | ACC 0.9399\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0065/0938 | LOSS: 0.2008 | ACC 0.9401\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0066/0938 | LOSS: 0.1987 | ACC 0.9408\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0067/0938 | LOSS: 0.1988 | ACC 0.9405\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0068/0938 | LOSS: 0.2006 | ACC 0.9403\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0069/0938 | LOSS: 0.2003 | ACC 0.9407\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0070/0938 | LOSS: 0.1988 | ACC 0.9406\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0071/0938 | LOSS: 0.1995 | ACC 0.9408\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0072/0938 | LOSS: 0.1982 | ACC 0.9414\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0073/0938 | LOSS: 0.1970 | ACC 0.9416\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0074/0938 | LOSS: 0.1973 | ACC 0.9417\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0075/0938 | LOSS: 0.1961 | ACC 0.9421\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0076/0938 | LOSS: 0.1978 | ACC 0.9416\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0077/0938 | LOSS: 0.1971 | ACC 0.9416\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0078/0938 | LOSS: 0.1991 | ACC 0.9415\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0079/0938 | LOSS: 0.1992 | ACC 0.9417\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0080/0938 | LOSS: 0.1990 | ACC 0.9416\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0081/0938 | LOSS: 0.1991 | ACC 0.9414\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0082/0938 | LOSS: 0.1976 | ACC 0.9419\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0083/0938 | LOSS: 0.1987 | ACC 0.9415\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0084/0938 | LOSS: 0.2007 | ACC 0.9408\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0085/0938 | LOSS: 0.2007 | ACC 0.9404\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0086/0938 | LOSS: 0.1993 | ACC 0.9410\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0087/0938 | LOSS: 0.2008 | ACC 0.9404\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0088/0938 | LOSS: 0.1997 | ACC 0.9405\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0089/0938 | LOSS: 0.2009 | ACC 0.9403\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0090/0938 | LOSS: 0.2012 | ACC 0.9401\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0091/0938 | LOSS: 0.2015 | ACC 0.9399\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0092/0938 | LOSS: 0.2037 | ACC 0.9397\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0093/0938 | LOSS: 0.2028 | ACC 0.9397\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0094/0938 | LOSS: 0.2019 | ACC 0.9400\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0095/0938 | LOSS: 0.2017 | ACC 0.9400\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0096/0938 | LOSS: 0.2004 | ACC 0.9404\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0097/0938 | LOSS: 0.2001 | ACC 0.9404\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0098/0938 | LOSS: 0.2004 | ACC 0.9404\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0099/0938 | LOSS: 0.2000 | ACC 0.9405\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0100/0938 | LOSS: 0.1993 | ACC 0.9408\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: EPOCH 0004/0010 | BATCH 0101/0938 | LOSS: 0.1992 | ACC 0.9409\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0102/0938 | LOSS: 0.1991 | ACC 0.9407\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0103/0938 | LOSS: 0.2003 | ACC 0.9407\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0104/0938 | LOSS: 0.2001 | ACC 0.9405\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0105/0938 | LOSS: 0.2000 | ACC 0.9405\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0106/0938 | LOSS: 0.1991 | ACC 0.9407\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0107/0938 | LOSS: 0.1995 | ACC 0.9407\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0108/0938 | LOSS: 0.2002 | ACC 0.9404\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0109/0938 | LOSS: 0.1993 | ACC 0.9407\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0110/0938 | LOSS: 0.1993 | ACC 0.9405\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0111/0938 | LOSS: 0.1999 | ACC 0.9405\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0112/0938 | LOSS: 0.1997 | ACC 0.9406\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0113/0938 | LOSS: 0.1994 | ACC 0.9404\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0114/0938 | LOSS: 0.2012 | ACC 0.9398\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0115/0938 | LOSS: 0.2003 | ACC 0.9401\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0116/0938 | LOSS: 0.2021 | ACC 0.9397\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0117/0938 | LOSS: 0.2026 | ACC 0.9398\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0118/0938 | LOSS: 0.2018 | ACC 0.9400\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0119/0938 | LOSS: 0.2010 | ACC 0.9403\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0120/0938 | LOSS: 0.2012 | ACC 0.9401\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0121/0938 | LOSS: 0.2016 | ACC 0.9403\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0122/0938 | LOSS: 0.2005 | ACC 0.9408\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0123/0938 | LOSS: 0.2014 | ACC 0.9405\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0124/0938 | LOSS: 0.2016 | ACC 0.9404\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0125/0938 | LOSS: 0.2019 | ACC 0.9404\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0126/0938 | LOSS: 0.2012 | ACC 0.9407\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0127/0938 | LOSS: 0.2007 | ACC 0.9408\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0128/0938 | LOSS: 0.2001 | ACC 0.9410\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0129/0938 | LOSS: 0.2009 | ACC 0.9405\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0130/0938 | LOSS: 0.2014 | ACC 0.9401\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0131/0938 | LOSS: 0.2023 | ACC 0.9399\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0132/0938 | LOSS: 0.2021 | ACC 0.9400\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0133/0938 | LOSS: 0.2026 | ACC 0.9398\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0134/0938 | LOSS: 0.2046 | ACC 0.9396\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0135/0938 | LOSS: 0.2055 | ACC 0.9392\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0136/0938 | LOSS: 0.2064 | ACC 0.9390\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0137/0938 | LOSS: 0.2058 | ACC 0.9391\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0138/0938 | LOSS: 0.2061 | ACC 0.9391\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0139/0938 | LOSS: 0.2057 | ACC 0.9393\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0140/0938 | LOSS: 0.2048 | ACC 0.9396\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0141/0938 | LOSS: 0.2046 | ACC 0.9395\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0142/0938 | LOSS: 0.2049 | ACC 0.9393\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0143/0938 | LOSS: 0.2050 | ACC 0.9391\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0144/0938 | LOSS: 0.2048 | ACC 0.9391\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0145/0938 | LOSS: 0.2055 | ACC 0.9389\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0146/0938 | LOSS: 0.2054 | ACC 0.9389\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0147/0938 | LOSS: 0.2053 | ACC 0.9390\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0148/0938 | LOSS: 0.2049 | ACC 0.9390\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0149/0938 | LOSS: 0.2047 | ACC 0.9391\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0150/0938 | LOSS: 0.2052 | ACC 0.9389\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0151/0938 | LOSS: 0.2050 | ACC 0.9391\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0152/0938 | LOSS: 0.2050 | ACC 0.9388\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0153/0938 | LOSS: 0.2042 | ACC 0.9389\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0154/0938 | LOSS: 0.2033 | ACC 0.9393\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0155/0938 | LOSS: 0.2027 | ACC 0.9395\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0156/0938 | LOSS: 0.2024 | ACC 0.9396\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0157/0938 | LOSS: 0.2030 | ACC 0.9393\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0158/0938 | LOSS: 0.2032 | ACC 0.9391\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0159/0938 | LOSS: 0.2028 | ACC 0.9393\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0160/0938 | LOSS: 0.2036 | ACC 0.9391\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0161/0938 | LOSS: 0.2030 | ACC 0.9391\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0162/0938 | LOSS: 0.2036 | ACC 0.9390\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0163/0938 | LOSS: 0.2027 | ACC 0.9394\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0164/0938 | LOSS: 0.2018 | ACC 0.9397\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0165/0938 | LOSS: 0.2024 | ACC 0.9394\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0166/0938 | LOSS: 0.2031 | ACC 0.9393\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0167/0938 | LOSS: 0.2025 | ACC 0.9395\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0168/0938 | LOSS: 0.2029 | ACC 0.9395\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0169/0938 | LOSS: 0.2032 | ACC 0.9393\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0170/0938 | LOSS: 0.2036 | ACC 0.9392\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0171/0938 | LOSS: 0.2029 | ACC 0.9394\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0172/0938 | LOSS: 0.2029 | ACC 0.9396\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0173/0938 | LOSS: 0.2026 | ACC 0.9395\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0174/0938 | LOSS: 0.2028 | ACC 0.9394\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0175/0938 | LOSS: 0.2036 | ACC 0.9391\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0176/0938 | LOSS: 0.2037 | ACC 0.9391\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0177/0938 | LOSS: 0.2030 | ACC 0.9394\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0178/0938 | LOSS: 0.2029 | ACC 0.9392\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0179/0938 | LOSS: 0.2026 | ACC 0.9393\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0180/0938 | LOSS: 0.2021 | ACC 0.9395\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0181/0938 | LOSS: 0.2025 | ACC 0.9393\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0182/0938 | LOSS: 0.2026 | ACC 0.9394\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0183/0938 | LOSS: 0.2028 | ACC 0.9393\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0184/0938 | LOSS: 0.2026 | ACC 0.9394\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0185/0938 | LOSS: 0.2027 | ACC 0.9392\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0186/0938 | LOSS: 0.2032 | ACC 0.9390\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0187/0938 | LOSS: 0.2029 | ACC 0.9389\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0188/0938 | LOSS: 0.2027 | ACC 0.9390\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0189/0938 | LOSS: 0.2026 | ACC 0.9390\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0190/0938 | LOSS: 0.2017 | ACC 0.9393\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0191/0938 | LOSS: 0.2010 | ACC 0.9396\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0192/0938 | LOSS: 0.2004 | ACC 0.9398\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0193/0938 | LOSS: 0.2006 | ACC 0.9397\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0194/0938 | LOSS: 0.2004 | ACC 0.9397\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0195/0938 | LOSS: 0.2005 | ACC 0.9397\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0196/0938 | LOSS: 0.2006 | ACC 0.9397\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0197/0938 | LOSS: 0.2012 | ACC 0.9396\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0198/0938 | LOSS: 0.2016 | ACC 0.9395\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0199/0938 | LOSS: 0.2031 | ACC 0.9392\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0200/0938 | LOSS: 0.2028 | ACC 0.9393\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0201/0938 | LOSS: 0.2028 | ACC 0.9392\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0202/0938 | LOSS: 0.2027 | ACC 0.9392\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0203/0938 | LOSS: 0.2029 | ACC 0.9391\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0204/0938 | LOSS: 0.2029 | ACC 0.9393\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0205/0938 | LOSS: 0.2023 | ACC 0.9394\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0206/0938 | LOSS: 0.2020 | ACC 0.9393\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0207/0938 | LOSS: 0.2021 | ACC 0.9393\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0208/0938 | LOSS: 0.2029 | ACC 0.9389\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0209/0938 | LOSS: 0.2035 | ACC 0.9388\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0210/0938 | LOSS: 0.2031 | ACC 0.9389\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0211/0938 | LOSS: 0.2029 | ACC 0.9388\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0212/0938 | LOSS: 0.2025 | ACC 0.9389\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0213/0938 | LOSS: 0.2026 | ACC 0.9389\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0214/0938 | LOSS: 0.2022 | ACC 0.9390\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0215/0938 | LOSS: 0.2020 | ACC 0.9391\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0216/0938 | LOSS: 0.2014 | ACC 0.9393\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0217/0938 | LOSS: 0.2013 | ACC 0.9395\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0218/0938 | LOSS: 0.2016 | ACC 0.9395\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0219/0938 | LOSS: 0.2022 | ACC 0.9394\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0220/0938 | LOSS: 0.2025 | ACC 0.9393\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0221/0938 | LOSS: 0.2028 | ACC 0.9395\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0222/0938 | LOSS: 0.2034 | ACC 0.9394\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0223/0938 | LOSS: 0.2028 | ACC 0.9395\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0224/0938 | LOSS: 0.2031 | ACC 0.9396\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0225/0938 | LOSS: 0.2027 | ACC 0.9397\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0226/0938 | LOSS: 0.2025 | ACC 0.9396\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0227/0938 | LOSS: 0.2031 | ACC 0.9394\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0228/0938 | LOSS: 0.2032 | ACC 0.9394\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: EPOCH 0004/0010 | BATCH 0229/0938 | LOSS: 0.2038 | ACC 0.9392\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0230/0938 | LOSS: 0.2035 | ACC 0.9393\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0231/0938 | LOSS: 0.2035 | ACC 0.9393\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0232/0938 | LOSS: 0.2035 | ACC 0.9395\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0233/0938 | LOSS: 0.2039 | ACC 0.9393\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0234/0938 | LOSS: 0.2045 | ACC 0.9390\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0235/0938 | LOSS: 0.2047 | ACC 0.9389\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0236/0938 | LOSS: 0.2049 | ACC 0.9390\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0237/0938 | LOSS: 0.2050 | ACC 0.9389\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0238/0938 | LOSS: 0.2047 | ACC 0.9390\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0239/0938 | LOSS: 0.2046 | ACC 0.9389\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0240/0938 | LOSS: 0.2047 | ACC 0.9389\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0241/0938 | LOSS: 0.2050 | ACC 0.9387\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0242/0938 | LOSS: 0.2044 | ACC 0.9389\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0243/0938 | LOSS: 0.2041 | ACC 0.9389\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0244/0938 | LOSS: 0.2046 | ACC 0.9388\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0245/0938 | LOSS: 0.2040 | ACC 0.9390\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0246/0938 | LOSS: 0.2034 | ACC 0.9393\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0247/0938 | LOSS: 0.2035 | ACC 0.9393\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0248/0938 | LOSS: 0.2032 | ACC 0.9394\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0249/0938 | LOSS: 0.2028 | ACC 0.9395\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0250/0938 | LOSS: 0.2033 | ACC 0.9393\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0251/0938 | LOSS: 0.2036 | ACC 0.9391\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0252/0938 | LOSS: 0.2038 | ACC 0.9391\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0253/0938 | LOSS: 0.2036 | ACC 0.9392\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0254/0938 | LOSS: 0.2033 | ACC 0.9393\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0255/0938 | LOSS: 0.2034 | ACC 0.9392\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0256/0938 | LOSS: 0.2030 | ACC 0.9394\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0257/0938 | LOSS: 0.2031 | ACC 0.9392\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0258/0938 | LOSS: 0.2035 | ACC 0.9391\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0259/0938 | LOSS: 0.2034 | ACC 0.9389\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0260/0938 | LOSS: 0.2036 | ACC 0.9389\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0261/0938 | LOSS: 0.2034 | ACC 0.9390\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0262/0938 | LOSS: 0.2033 | ACC 0.9391\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0263/0938 | LOSS: 0.2034 | ACC 0.9390\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0264/0938 | LOSS: 0.2037 | ACC 0.9389\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0265/0938 | LOSS: 0.2037 | ACC 0.9387\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0266/0938 | LOSS: 0.2033 | ACC 0.9388\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0267/0938 | LOSS: 0.2029 | ACC 0.9390\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0268/0938 | LOSS: 0.2033 | ACC 0.9389\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0269/0938 | LOSS: 0.2032 | ACC 0.9388\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0270/0938 | LOSS: 0.2031 | ACC 0.9388\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0271/0938 | LOSS: 0.2028 | ACC 0.9389\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0272/0938 | LOSS: 0.2039 | ACC 0.9388\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0273/0938 | LOSS: 0.2041 | ACC 0.9388\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0274/0938 | LOSS: 0.2042 | ACC 0.9388\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0275/0938 | LOSS: 0.2040 | ACC 0.9389\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0276/0938 | LOSS: 0.2036 | ACC 0.9390\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0277/0938 | LOSS: 0.2044 | ACC 0.9390\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0278/0938 | LOSS: 0.2044 | ACC 0.9391\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0279/0938 | LOSS: 0.2044 | ACC 0.9391\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0280/0938 | LOSS: 0.2054 | ACC 0.9389\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0281/0938 | LOSS: 0.2053 | ACC 0.9389\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0282/0938 | LOSS: 0.2053 | ACC 0.9389\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0283/0938 | LOSS: 0.2052 | ACC 0.9389\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0284/0938 | LOSS: 0.2054 | ACC 0.9390\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0285/0938 | LOSS: 0.2053 | ACC 0.9391\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0286/0938 | LOSS: 0.2067 | ACC 0.9388\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0287/0938 | LOSS: 0.2068 | ACC 0.9387\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0288/0938 | LOSS: 0.2065 | ACC 0.9388\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0289/0938 | LOSS: 0.2063 | ACC 0.9389\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0290/0938 | LOSS: 0.2063 | ACC 0.9388\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0291/0938 | LOSS: 0.2060 | ACC 0.9390\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0292/0938 | LOSS: 0.2063 | ACC 0.9389\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0293/0938 | LOSS: 0.2066 | ACC 0.9388\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0294/0938 | LOSS: 0.2066 | ACC 0.9387\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0295/0938 | LOSS: 0.2064 | ACC 0.9388\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0296/0938 | LOSS: 0.2067 | ACC 0.9387\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0297/0938 | LOSS: 0.2067 | ACC 0.9387\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0298/0938 | LOSS: 0.2070 | ACC 0.9387\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0299/0938 | LOSS: 0.2067 | ACC 0.9387\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0300/0938 | LOSS: 0.2067 | ACC 0.9387\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0301/0938 | LOSS: 0.2067 | ACC 0.9387\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0302/0938 | LOSS: 0.2068 | ACC 0.9387\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0303/0938 | LOSS: 0.2071 | ACC 0.9386\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0304/0938 | LOSS: 0.2072 | ACC 0.9386\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0305/0938 | LOSS: 0.2073 | ACC 0.9387\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0306/0938 | LOSS: 0.2071 | ACC 0.9387\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0307/0938 | LOSS: 0.2073 | ACC 0.9387\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0308/0938 | LOSS: 0.2071 | ACC 0.9389\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0309/0938 | LOSS: 0.2071 | ACC 0.9389\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0310/0938 | LOSS: 0.2069 | ACC 0.9389\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0311/0938 | LOSS: 0.2065 | ACC 0.9390\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0312/0938 | LOSS: 0.2066 | ACC 0.9389\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0313/0938 | LOSS: 0.2063 | ACC 0.9390\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0314/0938 | LOSS: 0.2061 | ACC 0.9390\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0315/0938 | LOSS: 0.2059 | ACC 0.9391\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0316/0938 | LOSS: 0.2061 | ACC 0.9389\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0317/0938 | LOSS: 0.2062 | ACC 0.9389\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0318/0938 | LOSS: 0.2063 | ACC 0.9389\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0319/0938 | LOSS: 0.2061 | ACC 0.9390\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0320/0938 | LOSS: 0.2064 | ACC 0.9389\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0321/0938 | LOSS: 0.2069 | ACC 0.9389\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0322/0938 | LOSS: 0.2072 | ACC 0.9387\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0323/0938 | LOSS: 0.2071 | ACC 0.9388\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0324/0938 | LOSS: 0.2069 | ACC 0.9388\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0325/0938 | LOSS: 0.2069 | ACC 0.9387\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0326/0938 | LOSS: 0.2067 | ACC 0.9388\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0327/0938 | LOSS: 0.2067 | ACC 0.9388\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0328/0938 | LOSS: 0.2068 | ACC 0.9388\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0329/0938 | LOSS: 0.2067 | ACC 0.9388\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0330/0938 | LOSS: 0.2074 | ACC 0.9388\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0331/0938 | LOSS: 0.2072 | ACC 0.9388\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0332/0938 | LOSS: 0.2071 | ACC 0.9389\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0333/0938 | LOSS: 0.2068 | ACC 0.9389\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0334/0938 | LOSS: 0.2071 | ACC 0.9387\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0335/0938 | LOSS: 0.2077 | ACC 0.9386\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0336/0938 | LOSS: 0.2077 | ACC 0.9387\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0337/0938 | LOSS: 0.2074 | ACC 0.9388\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0338/0938 | LOSS: 0.2071 | ACC 0.9388\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0339/0938 | LOSS: 0.2068 | ACC 0.9388\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0340/0938 | LOSS: 0.2066 | ACC 0.9389\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0341/0938 | LOSS: 0.2063 | ACC 0.9389\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0342/0938 | LOSS: 0.2067 | ACC 0.9388\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0343/0938 | LOSS: 0.2065 | ACC 0.9388\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0344/0938 | LOSS: 0.2063 | ACC 0.9389\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0345/0938 | LOSS: 0.2062 | ACC 0.9389\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0346/0938 | LOSS: 0.2061 | ACC 0.9389\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0347/0938 | LOSS: 0.2061 | ACC 0.9389\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0348/0938 | LOSS: 0.2060 | ACC 0.9389\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0349/0938 | LOSS: 0.2058 | ACC 0.9390\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0350/0938 | LOSS: 0.2060 | ACC 0.9389\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0351/0938 | LOSS: 0.2060 | ACC 0.9389\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0352/0938 | LOSS: 0.2061 | ACC 0.9389\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0353/0938 | LOSS: 0.2061 | ACC 0.9390\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0354/0938 | LOSS: 0.2060 | ACC 0.9389\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0355/0938 | LOSS: 0.2058 | ACC 0.9390\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0356/0938 | LOSS: 0.2055 | ACC 0.9390\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0357/0938 | LOSS: 0.2052 | ACC 0.9392\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: EPOCH 0004/0010 | BATCH 0358/0938 | LOSS: 0.2053 | ACC 0.9392\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0359/0938 | LOSS: 0.2055 | ACC 0.9392\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0360/0938 | LOSS: 0.2053 | ACC 0.9393\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0361/0938 | LOSS: 0.2057 | ACC 0.9393\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0362/0938 | LOSS: 0.2058 | ACC 0.9394\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0363/0938 | LOSS: 0.2060 | ACC 0.9393\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0364/0938 | LOSS: 0.2057 | ACC 0.9394\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0365/0938 | LOSS: 0.2055 | ACC 0.9395\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0366/0938 | LOSS: 0.2059 | ACC 0.9393\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0367/0938 | LOSS: 0.2060 | ACC 0.9393\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0368/0938 | LOSS: 0.2056 | ACC 0.9395\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0369/0938 | LOSS: 0.2054 | ACC 0.9395\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0370/0938 | LOSS: 0.2053 | ACC 0.9395\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0371/0938 | LOSS: 0.2053 | ACC 0.9396\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0372/0938 | LOSS: 0.2054 | ACC 0.9396\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0373/0938 | LOSS: 0.2052 | ACC 0.9397\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0374/0938 | LOSS: 0.2055 | ACC 0.9397\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0375/0938 | LOSS: 0.2056 | ACC 0.9397\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0376/0938 | LOSS: 0.2056 | ACC 0.9397\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0377/0938 | LOSS: 0.2061 | ACC 0.9396\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0378/0938 | LOSS: 0.2065 | ACC 0.9395\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0379/0938 | LOSS: 0.2065 | ACC 0.9394\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0380/0938 | LOSS: 0.2063 | ACC 0.9395\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0381/0938 | LOSS: 0.2061 | ACC 0.9396\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0382/0938 | LOSS: 0.2062 | ACC 0.9395\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0383/0938 | LOSS: 0.2068 | ACC 0.9395\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0384/0938 | LOSS: 0.2066 | ACC 0.9395\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0385/0938 | LOSS: 0.2065 | ACC 0.9396\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0386/0938 | LOSS: 0.2067 | ACC 0.9395\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0387/0938 | LOSS: 0.2069 | ACC 0.9395\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0388/0938 | LOSS: 0.2066 | ACC 0.9396\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0389/0938 | LOSS: 0.2078 | ACC 0.9395\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0390/0938 | LOSS: 0.2078 | ACC 0.9395\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0391/0938 | LOSS: 0.2077 | ACC 0.9396\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0392/0938 | LOSS: 0.2074 | ACC 0.9397\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0393/0938 | LOSS: 0.2074 | ACC 0.9396\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0394/0938 | LOSS: 0.2072 | ACC 0.9396\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0395/0938 | LOSS: 0.2072 | ACC 0.9396\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0396/0938 | LOSS: 0.2069 | ACC 0.9396\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0397/0938 | LOSS: 0.2071 | ACC 0.9395\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0398/0938 | LOSS: 0.2072 | ACC 0.9396\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0399/0938 | LOSS: 0.2070 | ACC 0.9397\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0400/0938 | LOSS: 0.2073 | ACC 0.9396\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0401/0938 | LOSS: 0.2077 | ACC 0.9396\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0402/0938 | LOSS: 0.2079 | ACC 0.9394\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0403/0938 | LOSS: 0.2076 | ACC 0.9395\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0404/0938 | LOSS: 0.2074 | ACC 0.9395\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0405/0938 | LOSS: 0.2074 | ACC 0.9396\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0406/0938 | LOSS: 0.2073 | ACC 0.9395\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0407/0938 | LOSS: 0.2071 | ACC 0.9397\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0408/0938 | LOSS: 0.2072 | ACC 0.9396\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0409/0938 | LOSS: 0.2072 | ACC 0.9396\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0410/0938 | LOSS: 0.2070 | ACC 0.9396\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0411/0938 | LOSS: 0.2069 | ACC 0.9396\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0412/0938 | LOSS: 0.2068 | ACC 0.9397\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0413/0938 | LOSS: 0.2071 | ACC 0.9395\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0414/0938 | LOSS: 0.2071 | ACC 0.9395\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0415/0938 | LOSS: 0.2072 | ACC 0.9394\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0416/0938 | LOSS: 0.2075 | ACC 0.9393\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0417/0938 | LOSS: 0.2078 | ACC 0.9392\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0418/0938 | LOSS: 0.2080 | ACC 0.9392\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0419/0938 | LOSS: 0.2081 | ACC 0.9391\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0420/0938 | LOSS: 0.2080 | ACC 0.9391\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0421/0938 | LOSS: 0.2082 | ACC 0.9392\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0422/0938 | LOSS: 0.2080 | ACC 0.9392\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0423/0938 | LOSS: 0.2079 | ACC 0.9392\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0424/0938 | LOSS: 0.2078 | ACC 0.9393\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0425/0938 | LOSS: 0.2077 | ACC 0.9393\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0426/0938 | LOSS: 0.2077 | ACC 0.9393\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0427/0938 | LOSS: 0.2076 | ACC 0.9394\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0428/0938 | LOSS: 0.2074 | ACC 0.9394\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0429/0938 | LOSS: 0.2072 | ACC 0.9395\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0430/0938 | LOSS: 0.2071 | ACC 0.9395\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0431/0938 | LOSS: 0.2073 | ACC 0.9395\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0432/0938 | LOSS: 0.2077 | ACC 0.9394\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0433/0938 | LOSS: 0.2075 | ACC 0.9394\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0434/0938 | LOSS: 0.2081 | ACC 0.9394\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0435/0938 | LOSS: 0.2080 | ACC 0.9393\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0436/0938 | LOSS: 0.2082 | ACC 0.9393\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0437/0938 | LOSS: 0.2083 | ACC 0.9393\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0438/0938 | LOSS: 0.2081 | ACC 0.9394\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0439/0938 | LOSS: 0.2080 | ACC 0.9394\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0440/0938 | LOSS: 0.2077 | ACC 0.9395\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0441/0938 | LOSS: 0.2078 | ACC 0.9394\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0442/0938 | LOSS: 0.2082 | ACC 0.9394\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0443/0938 | LOSS: 0.2083 | ACC 0.9393\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0444/0938 | LOSS: 0.2080 | ACC 0.9394\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0445/0938 | LOSS: 0.2078 | ACC 0.9395\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0446/0938 | LOSS: 0.2076 | ACC 0.9395\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0447/0938 | LOSS: 0.2075 | ACC 0.9396\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0448/0938 | LOSS: 0.2076 | ACC 0.9396\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0449/0938 | LOSS: 0.2075 | ACC 0.9396\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0450/0938 | LOSS: 0.2075 | ACC 0.9396\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0451/0938 | LOSS: 0.2074 | ACC 0.9396\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0452/0938 | LOSS: 0.2076 | ACC 0.9396\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0453/0938 | LOSS: 0.2076 | ACC 0.9396\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0454/0938 | LOSS: 0.2073 | ACC 0.9397\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0455/0938 | LOSS: 0.2072 | ACC 0.9397\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0456/0938 | LOSS: 0.2068 | ACC 0.9398\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0457/0938 | LOSS: 0.2067 | ACC 0.9399\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0458/0938 | LOSS: 0.2066 | ACC 0.9398\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0459/0938 | LOSS: 0.2063 | ACC 0.9399\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0460/0938 | LOSS: 0.2069 | ACC 0.9398\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0461/0938 | LOSS: 0.2069 | ACC 0.9398\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0462/0938 | LOSS: 0.2069 | ACC 0.9397\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0463/0938 | LOSS: 0.2067 | ACC 0.9398\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0464/0938 | LOSS: 0.2071 | ACC 0.9396\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0465/0938 | LOSS: 0.2071 | ACC 0.9396\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0466/0938 | LOSS: 0.2074 | ACC 0.9396\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0467/0938 | LOSS: 0.2074 | ACC 0.9395\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0468/0938 | LOSS: 0.2072 | ACC 0.9396\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0469/0938 | LOSS: 0.2072 | ACC 0.9396\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0470/0938 | LOSS: 0.2073 | ACC 0.9396\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0471/0938 | LOSS: 0.2072 | ACC 0.9396\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0472/0938 | LOSS: 0.2074 | ACC 0.9395\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0473/0938 | LOSS: 0.2073 | ACC 0.9395\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0474/0938 | LOSS: 0.2072 | ACC 0.9396\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0475/0938 | LOSS: 0.2072 | ACC 0.9396\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0476/0938 | LOSS: 0.2075 | ACC 0.9395\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0477/0938 | LOSS: 0.2074 | ACC 0.9395\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0478/0938 | LOSS: 0.2072 | ACC 0.9396\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0479/0938 | LOSS: 0.2071 | ACC 0.9396\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0480/0938 | LOSS: 0.2069 | ACC 0.9397\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0481/0938 | LOSS: 0.2067 | ACC 0.9397\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0482/0938 | LOSS: 0.2066 | ACC 0.9398\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0483/0938 | LOSS: 0.2066 | ACC 0.9397\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0484/0938 | LOSS: 0.2066 | ACC 0.9398\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0485/0938 | LOSS: 0.2065 | ACC 0.9398\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: EPOCH 0004/0010 | BATCH 0486/0938 | LOSS: 0.2064 | ACC 0.9398\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0487/0938 | LOSS: 0.2062 | ACC 0.9399\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0488/0938 | LOSS: 0.2064 | ACC 0.9397\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0489/0938 | LOSS: 0.2063 | ACC 0.9397\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0490/0938 | LOSS: 0.2060 | ACC 0.9398\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0491/0938 | LOSS: 0.2063 | ACC 0.9398\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0492/0938 | LOSS: 0.2065 | ACC 0.9397\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0493/0938 | LOSS: 0.2064 | ACC 0.9397\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0494/0938 | LOSS: 0.2062 | ACC 0.9397\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0495/0938 | LOSS: 0.2060 | ACC 0.9398\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0496/0938 | LOSS: 0.2057 | ACC 0.9399\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0497/0938 | LOSS: 0.2056 | ACC 0.9400\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0498/0938 | LOSS: 0.2056 | ACC 0.9399\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0499/0938 | LOSS: 0.2056 | ACC 0.9399\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0500/0938 | LOSS: 0.2058 | ACC 0.9399\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0501/0938 | LOSS: 0.2058 | ACC 0.9400\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0502/0938 | LOSS: 0.2060 | ACC 0.9399\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0503/0938 | LOSS: 0.2061 | ACC 0.9399\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0504/0938 | LOSS: 0.2062 | ACC 0.9399\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0505/0938 | LOSS: 0.2063 | ACC 0.9399\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0506/0938 | LOSS: 0.2064 | ACC 0.9398\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0507/0938 | LOSS: 0.2061 | ACC 0.9399\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0508/0938 | LOSS: 0.2063 | ACC 0.9399\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0509/0938 | LOSS: 0.2063 | ACC 0.9398\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0510/0938 | LOSS: 0.2064 | ACC 0.9398\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0511/0938 | LOSS: 0.2062 | ACC 0.9398\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0512/0938 | LOSS: 0.2063 | ACC 0.9397\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0513/0938 | LOSS: 0.2065 | ACC 0.9397\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0514/0938 | LOSS: 0.2063 | ACC 0.9397\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0515/0938 | LOSS: 0.2064 | ACC 0.9397\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0516/0938 | LOSS: 0.2067 | ACC 0.9397\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0517/0938 | LOSS: 0.2067 | ACC 0.9397\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0518/0938 | LOSS: 0.2067 | ACC 0.9397\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0519/0938 | LOSS: 0.2070 | ACC 0.9397\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0520/0938 | LOSS: 0.2069 | ACC 0.9397\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0521/0938 | LOSS: 0.2068 | ACC 0.9398\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0522/0938 | LOSS: 0.2069 | ACC 0.9397\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0523/0938 | LOSS: 0.2066 | ACC 0.9398\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0524/0938 | LOSS: 0.2065 | ACC 0.9399\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0525/0938 | LOSS: 0.2066 | ACC 0.9399\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0526/0938 | LOSS: 0.2067 | ACC 0.9398\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0527/0938 | LOSS: 0.2068 | ACC 0.9398\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0528/0938 | LOSS: 0.2068 | ACC 0.9398\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0529/0938 | LOSS: 0.2066 | ACC 0.9399\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0530/0938 | LOSS: 0.2064 | ACC 0.9400\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0531/0938 | LOSS: 0.2065 | ACC 0.9399\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0532/0938 | LOSS: 0.2065 | ACC 0.9399\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0533/0938 | LOSS: 0.2063 | ACC 0.9401\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0534/0938 | LOSS: 0.2065 | ACC 0.9400\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0535/0938 | LOSS: 0.2066 | ACC 0.9399\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0536/0938 | LOSS: 0.2064 | ACC 0.9399\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0537/0938 | LOSS: 0.2063 | ACC 0.9400\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0538/0938 | LOSS: 0.2063 | ACC 0.9400\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0539/0938 | LOSS: 0.2062 | ACC 0.9400\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0540/0938 | LOSS: 0.2061 | ACC 0.9399\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0541/0938 | LOSS: 0.2060 | ACC 0.9400\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0542/0938 | LOSS: 0.2059 | ACC 0.9400\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0543/0938 | LOSS: 0.2059 | ACC 0.9400\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0544/0938 | LOSS: 0.2059 | ACC 0.9399\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0545/0938 | LOSS: 0.2057 | ACC 0.9400\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0546/0938 | LOSS: 0.2061 | ACC 0.9398\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0547/0938 | LOSS: 0.2061 | ACC 0.9399\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0548/0938 | LOSS: 0.2062 | ACC 0.9398\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0549/0938 | LOSS: 0.2062 | ACC 0.9398\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0550/0938 | LOSS: 0.2064 | ACC 0.9397\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0551/0938 | LOSS: 0.2064 | ACC 0.9397\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0552/0938 | LOSS: 0.2062 | ACC 0.9397\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0553/0938 | LOSS: 0.2060 | ACC 0.9398\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0554/0938 | LOSS: 0.2058 | ACC 0.9398\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0555/0938 | LOSS: 0.2059 | ACC 0.9398\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0556/0938 | LOSS: 0.2060 | ACC 0.9398\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0557/0938 | LOSS: 0.2059 | ACC 0.9399\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0558/0938 | LOSS: 0.2061 | ACC 0.9399\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0559/0938 | LOSS: 0.2063 | ACC 0.9398\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0560/0938 | LOSS: 0.2063 | ACC 0.9398\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0561/0938 | LOSS: 0.2062 | ACC 0.9398\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0562/0938 | LOSS: 0.2062 | ACC 0.9397\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0563/0938 | LOSS: 0.2062 | ACC 0.9397\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0564/0938 | LOSS: 0.2063 | ACC 0.9397\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0565/0938 | LOSS: 0.2063 | ACC 0.9396\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0566/0938 | LOSS: 0.2063 | ACC 0.9397\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0567/0938 | LOSS: 0.2061 | ACC 0.9396\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0568/0938 | LOSS: 0.2060 | ACC 0.9397\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0569/0938 | LOSS: 0.2058 | ACC 0.9398\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0570/0938 | LOSS: 0.2062 | ACC 0.9397\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0571/0938 | LOSS: 0.2062 | ACC 0.9397\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0572/0938 | LOSS: 0.2061 | ACC 0.9397\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0573/0938 | LOSS: 0.2060 | ACC 0.9397\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0574/0938 | LOSS: 0.2058 | ACC 0.9398\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0575/0938 | LOSS: 0.2055 | ACC 0.9399\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0576/0938 | LOSS: 0.2055 | ACC 0.9399\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0577/0938 | LOSS: 0.2053 | ACC 0.9399\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0578/0938 | LOSS: 0.2057 | ACC 0.9398\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0579/0938 | LOSS: 0.2058 | ACC 0.9398\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0580/0938 | LOSS: 0.2058 | ACC 0.9398\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0581/0938 | LOSS: 0.2056 | ACC 0.9399\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0582/0938 | LOSS: 0.2060 | ACC 0.9399\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0583/0938 | LOSS: 0.2059 | ACC 0.9399\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0584/0938 | LOSS: 0.2059 | ACC 0.9399\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0585/0938 | LOSS: 0.2060 | ACC 0.9399\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0586/0938 | LOSS: 0.2061 | ACC 0.9399\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0587/0938 | LOSS: 0.2062 | ACC 0.9399\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0588/0938 | LOSS: 0.2064 | ACC 0.9398\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0589/0938 | LOSS: 0.2063 | ACC 0.9398\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0590/0938 | LOSS: 0.2065 | ACC 0.9397\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0591/0938 | LOSS: 0.2065 | ACC 0.9398\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0592/0938 | LOSS: 0.2065 | ACC 0.9398\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0593/0938 | LOSS: 0.2065 | ACC 0.9397\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0594/0938 | LOSS: 0.2065 | ACC 0.9398\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0595/0938 | LOSS: 0.2065 | ACC 0.9398\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0596/0938 | LOSS: 0.2063 | ACC 0.9398\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0597/0938 | LOSS: 0.2064 | ACC 0.9398\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0598/0938 | LOSS: 0.2064 | ACC 0.9397\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0599/0938 | LOSS: 0.2065 | ACC 0.9397\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0600/0938 | LOSS: 0.2066 | ACC 0.9397\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0601/0938 | LOSS: 0.2067 | ACC 0.9397\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0602/0938 | LOSS: 0.2067 | ACC 0.9398\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0603/0938 | LOSS: 0.2070 | ACC 0.9397\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0604/0938 | LOSS: 0.2071 | ACC 0.9397\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0605/0938 | LOSS: 0.2070 | ACC 0.9397\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0606/0938 | LOSS: 0.2069 | ACC 0.9397\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0607/0938 | LOSS: 0.2068 | ACC 0.9397\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0608/0938 | LOSS: 0.2068 | ACC 0.9397\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0609/0938 | LOSS: 0.2068 | ACC 0.9397\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0610/0938 | LOSS: 0.2067 | ACC 0.9398\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0611/0938 | LOSS: 0.2070 | ACC 0.9398\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0612/0938 | LOSS: 0.2069 | ACC 0.9397\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: EPOCH 0004/0010 | BATCH 0613/0938 | LOSS: 0.2069 | ACC 0.9397\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0614/0938 | LOSS: 0.2068 | ACC 0.9398\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0615/0938 | LOSS: 0.2069 | ACC 0.9397\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0616/0938 | LOSS: 0.2067 | ACC 0.9397\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0617/0938 | LOSS: 0.2069 | ACC 0.9397\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0618/0938 | LOSS: 0.2068 | ACC 0.9397\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0619/0938 | LOSS: 0.2066 | ACC 0.9397\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0620/0938 | LOSS: 0.2067 | ACC 0.9397\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0621/0938 | LOSS: 0.2066 | ACC 0.9397\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0622/0938 | LOSS: 0.2067 | ACC 0.9398\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0623/0938 | LOSS: 0.2066 | ACC 0.9398\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0624/0938 | LOSS: 0.2065 | ACC 0.9398\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0625/0938 | LOSS: 0.2064 | ACC 0.9398\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0626/0938 | LOSS: 0.2064 | ACC 0.9398\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0627/0938 | LOSS: 0.2063 | ACC 0.9399\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0628/0938 | LOSS: 0.2063 | ACC 0.9399\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0629/0938 | LOSS: 0.2063 | ACC 0.9399\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0630/0938 | LOSS: 0.2061 | ACC 0.9399\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0631/0938 | LOSS: 0.2059 | ACC 0.9400\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0632/0938 | LOSS: 0.2059 | ACC 0.9400\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0633/0938 | LOSS: 0.2060 | ACC 0.9400\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0634/0938 | LOSS: 0.2061 | ACC 0.9399\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0635/0938 | LOSS: 0.2061 | ACC 0.9399\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0636/0938 | LOSS: 0.2062 | ACC 0.9399\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0637/0938 | LOSS: 0.2064 | ACC 0.9399\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0638/0938 | LOSS: 0.2063 | ACC 0.9399\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0639/0938 | LOSS: 0.2061 | ACC 0.9399\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0640/0938 | LOSS: 0.2060 | ACC 0.9399\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0641/0938 | LOSS: 0.2061 | ACC 0.9399\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0642/0938 | LOSS: 0.2065 | ACC 0.9399\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0643/0938 | LOSS: 0.2065 | ACC 0.9398\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0644/0938 | LOSS: 0.2065 | ACC 0.9398\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0645/0938 | LOSS: 0.2065 | ACC 0.9398\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0646/0938 | LOSS: 0.2064 | ACC 0.9398\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0647/0938 | LOSS: 0.2064 | ACC 0.9398\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0648/0938 | LOSS: 0.2063 | ACC 0.9399\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0649/0938 | LOSS: 0.2063 | ACC 0.9399\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0650/0938 | LOSS: 0.2062 | ACC 0.9399\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0651/0938 | LOSS: 0.2061 | ACC 0.9399\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0652/0938 | LOSS: 0.2062 | ACC 0.9398\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0653/0938 | LOSS: 0.2067 | ACC 0.9397\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0654/0938 | LOSS: 0.2067 | ACC 0.9396\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0655/0938 | LOSS: 0.2067 | ACC 0.9396\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0656/0938 | LOSS: 0.2066 | ACC 0.9396\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0657/0938 | LOSS: 0.2066 | ACC 0.9396\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0658/0938 | LOSS: 0.2069 | ACC 0.9395\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0659/0938 | LOSS: 0.2068 | ACC 0.9395\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0660/0938 | LOSS: 0.2069 | ACC 0.9395\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0661/0938 | LOSS: 0.2069 | ACC 0.9395\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0662/0938 | LOSS: 0.2068 | ACC 0.9395\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0663/0938 | LOSS: 0.2068 | ACC 0.9396\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0664/0938 | LOSS: 0.2070 | ACC 0.9396\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0665/0938 | LOSS: 0.2069 | ACC 0.9395\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0666/0938 | LOSS: 0.2070 | ACC 0.9395\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0667/0938 | LOSS: 0.2070 | ACC 0.9395\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0668/0938 | LOSS: 0.2071 | ACC 0.9395\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0669/0938 | LOSS: 0.2070 | ACC 0.9395\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0670/0938 | LOSS: 0.2071 | ACC 0.9395\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0671/0938 | LOSS: 0.2071 | ACC 0.9395\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0672/0938 | LOSS: 0.2072 | ACC 0.9395\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0673/0938 | LOSS: 0.2070 | ACC 0.9396\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0674/0938 | LOSS: 0.2070 | ACC 0.9395\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0675/0938 | LOSS: 0.2069 | ACC 0.9395\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0676/0938 | LOSS: 0.2068 | ACC 0.9395\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0677/0938 | LOSS: 0.2069 | ACC 0.9395\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0678/0938 | LOSS: 0.2068 | ACC 0.9395\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0679/0938 | LOSS: 0.2068 | ACC 0.9395\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0680/0938 | LOSS: 0.2068 | ACC 0.9395\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0681/0938 | LOSS: 0.2067 | ACC 0.9395\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0682/0938 | LOSS: 0.2067 | ACC 0.9396\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0683/0938 | LOSS: 0.2068 | ACC 0.9395\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0684/0938 | LOSS: 0.2069 | ACC 0.9395\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0685/0938 | LOSS: 0.2069 | ACC 0.9396\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0686/0938 | LOSS: 0.2067 | ACC 0.9396\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0687/0938 | LOSS: 0.2069 | ACC 0.9395\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0688/0938 | LOSS: 0.2069 | ACC 0.9395\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0689/0938 | LOSS: 0.2067 | ACC 0.9396\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0690/0938 | LOSS: 0.2069 | ACC 0.9396\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0691/0938 | LOSS: 0.2070 | ACC 0.9395\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0692/0938 | LOSS: 0.2069 | ACC 0.9395\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0693/0938 | LOSS: 0.2069 | ACC 0.9396\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0694/0938 | LOSS: 0.2069 | ACC 0.9396\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0695/0938 | LOSS: 0.2068 | ACC 0.9396\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0696/0938 | LOSS: 0.2066 | ACC 0.9397\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0697/0938 | LOSS: 0.2067 | ACC 0.9396\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0698/0938 | LOSS: 0.2066 | ACC 0.9396\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0699/0938 | LOSS: 0.2067 | ACC 0.9396\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0700/0938 | LOSS: 0.2066 | ACC 0.9397\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0701/0938 | LOSS: 0.2065 | ACC 0.9396\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0702/0938 | LOSS: 0.2065 | ACC 0.9396\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0703/0938 | LOSS: 0.2064 | ACC 0.9396\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0704/0938 | LOSS: 0.2063 | ACC 0.9397\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0705/0938 | LOSS: 0.2062 | ACC 0.9397\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0706/0938 | LOSS: 0.2060 | ACC 0.9398\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0707/0938 | LOSS: 0.2060 | ACC 0.9398\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0708/0938 | LOSS: 0.2058 | ACC 0.9398\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0709/0938 | LOSS: 0.2057 | ACC 0.9398\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0710/0938 | LOSS: 0.2058 | ACC 0.9399\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0711/0938 | LOSS: 0.2058 | ACC 0.9399\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0712/0938 | LOSS: 0.2058 | ACC 0.9398\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0713/0938 | LOSS: 0.2058 | ACC 0.9398\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0714/0938 | LOSS: 0.2058 | ACC 0.9398\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0715/0938 | LOSS: 0.2058 | ACC 0.9398\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0716/0938 | LOSS: 0.2057 | ACC 0.9398\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0717/0938 | LOSS: 0.2056 | ACC 0.9398\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0718/0938 | LOSS: 0.2055 | ACC 0.9399\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0719/0938 | LOSS: 0.2055 | ACC 0.9398\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0720/0938 | LOSS: 0.2054 | ACC 0.9398\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0721/0938 | LOSS: 0.2053 | ACC 0.9399\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0722/0938 | LOSS: 0.2053 | ACC 0.9398\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0723/0938 | LOSS: 0.2052 | ACC 0.9399\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0724/0938 | LOSS: 0.2054 | ACC 0.9398\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0725/0938 | LOSS: 0.2052 | ACC 0.9399\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0726/0938 | LOSS: 0.2052 | ACC 0.9399\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0727/0938 | LOSS: 0.2056 | ACC 0.9399\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0728/0938 | LOSS: 0.2057 | ACC 0.9398\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0729/0938 | LOSS: 0.2057 | ACC 0.9398\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0730/0938 | LOSS: 0.2059 | ACC 0.9398\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0731/0938 | LOSS: 0.2058 | ACC 0.9398\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0732/0938 | LOSS: 0.2057 | ACC 0.9398\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0733/0938 | LOSS: 0.2055 | ACC 0.9398\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0734/0938 | LOSS: 0.2055 | ACC 0.9399\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0735/0938 | LOSS: 0.2055 | ACC 0.9399\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0736/0938 | LOSS: 0.2054 | ACC 0.9399\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0737/0938 | LOSS: 0.2052 | ACC 0.9400\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0738/0938 | LOSS: 0.2052 | ACC 0.9400\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0739/0938 | LOSS: 0.2055 | ACC 0.9399\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0740/0938 | LOSS: 0.2056 | ACC 0.9399\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: EPOCH 0004/0010 | BATCH 0741/0938 | LOSS: 0.2056 | ACC 0.9398\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0742/0938 | LOSS: 0.2054 | ACC 0.9399\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0743/0938 | LOSS: 0.2054 | ACC 0.9398\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0744/0938 | LOSS: 0.2054 | ACC 0.9398\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0745/0938 | LOSS: 0.2052 | ACC 0.9399\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0746/0938 | LOSS: 0.2054 | ACC 0.9398\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0747/0938 | LOSS: 0.2056 | ACC 0.9397\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0748/0938 | LOSS: 0.2058 | ACC 0.9397\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0749/0938 | LOSS: 0.2057 | ACC 0.9397\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0750/0938 | LOSS: 0.2056 | ACC 0.9398\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0751/0938 | LOSS: 0.2055 | ACC 0.9398\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0752/0938 | LOSS: 0.2054 | ACC 0.9398\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0753/0938 | LOSS: 0.2052 | ACC 0.9398\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0754/0938 | LOSS: 0.2052 | ACC 0.9398\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0755/0938 | LOSS: 0.2053 | ACC 0.9398\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0756/0938 | LOSS: 0.2053 | ACC 0.9399\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0757/0938 | LOSS: 0.2051 | ACC 0.9399\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0758/0938 | LOSS: 0.2050 | ACC 0.9400\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0759/0938 | LOSS: 0.2051 | ACC 0.9399\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0760/0938 | LOSS: 0.2051 | ACC 0.9399\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0761/0938 | LOSS: 0.2049 | ACC 0.9400\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0762/0938 | LOSS: 0.2052 | ACC 0.9399\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0763/0938 | LOSS: 0.2051 | ACC 0.9400\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0764/0938 | LOSS: 0.2051 | ACC 0.9400\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0765/0938 | LOSS: 0.2051 | ACC 0.9399\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0766/0938 | LOSS: 0.2050 | ACC 0.9400\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0767/0938 | LOSS: 0.2049 | ACC 0.9400\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0768/0938 | LOSS: 0.2051 | ACC 0.9399\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0769/0938 | LOSS: 0.2052 | ACC 0.9399\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0770/0938 | LOSS: 0.2053 | ACC 0.9399\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0771/0938 | LOSS: 0.2054 | ACC 0.9399\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0772/0938 | LOSS: 0.2053 | ACC 0.9399\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0773/0938 | LOSS: 0.2054 | ACC 0.9399\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0774/0938 | LOSS: 0.2052 | ACC 0.9399\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0775/0938 | LOSS: 0.2051 | ACC 0.9400\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0776/0938 | LOSS: 0.2051 | ACC 0.9400\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0777/0938 | LOSS: 0.2050 | ACC 0.9400\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0778/0938 | LOSS: 0.2049 | ACC 0.9400\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0779/0938 | LOSS: 0.2049 | ACC 0.9400\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0780/0938 | LOSS: 0.2049 | ACC 0.9400\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0781/0938 | LOSS: 0.2048 | ACC 0.9400\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0782/0938 | LOSS: 0.2047 | ACC 0.9401\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0783/0938 | LOSS: 0.2047 | ACC 0.9401\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0784/0938 | LOSS: 0.2046 | ACC 0.9400\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0785/0938 | LOSS: 0.2046 | ACC 0.9401\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0786/0938 | LOSS: 0.2048 | ACC 0.9400\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0787/0938 | LOSS: 0.2048 | ACC 0.9400\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0788/0938 | LOSS: 0.2047 | ACC 0.9400\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0789/0938 | LOSS: 0.2047 | ACC 0.9400\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0790/0938 | LOSS: 0.2048 | ACC 0.9400\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0791/0938 | LOSS: 0.2050 | ACC 0.9400\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0792/0938 | LOSS: 0.2051 | ACC 0.9400\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0793/0938 | LOSS: 0.2050 | ACC 0.9399\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0794/0938 | LOSS: 0.2050 | ACC 0.9399\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0795/0938 | LOSS: 0.2049 | ACC 0.9400\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0796/0938 | LOSS: 0.2049 | ACC 0.9400\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0797/0938 | LOSS: 0.2049 | ACC 0.9400\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0798/0938 | LOSS: 0.2048 | ACC 0.9400\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0799/0938 | LOSS: 0.2047 | ACC 0.9401\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0800/0938 | LOSS: 0.2048 | ACC 0.9401\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0801/0938 | LOSS: 0.2048 | ACC 0.9401\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0802/0938 | LOSS: 0.2047 | ACC 0.9401\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0803/0938 | LOSS: 0.2046 | ACC 0.9402\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0804/0938 | LOSS: 0.2045 | ACC 0.9402\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0805/0938 | LOSS: 0.2044 | ACC 0.9402\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0806/0938 | LOSS: 0.2044 | ACC 0.9402\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0807/0938 | LOSS: 0.2043 | ACC 0.9403\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0808/0938 | LOSS: 0.2043 | ACC 0.9402\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0809/0938 | LOSS: 0.2044 | ACC 0.9402\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0810/0938 | LOSS: 0.2043 | ACC 0.9402\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0811/0938 | LOSS: 0.2042 | ACC 0.9402\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0812/0938 | LOSS: 0.2041 | ACC 0.9403\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0813/0938 | LOSS: 0.2040 | ACC 0.9403\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0814/0938 | LOSS: 0.2040 | ACC 0.9403\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0815/0938 | LOSS: 0.2039 | ACC 0.9403\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0816/0938 | LOSS: 0.2039 | ACC 0.9403\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0817/0938 | LOSS: 0.2040 | ACC 0.9403\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0818/0938 | LOSS: 0.2038 | ACC 0.9403\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0819/0938 | LOSS: 0.2038 | ACC 0.9403\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0820/0938 | LOSS: 0.2038 | ACC 0.9403\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0821/0938 | LOSS: 0.2037 | ACC 0.9404\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0822/0938 | LOSS: 0.2037 | ACC 0.9404\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0823/0938 | LOSS: 0.2036 | ACC 0.9404\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0824/0938 | LOSS: 0.2035 | ACC 0.9404\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0825/0938 | LOSS: 0.2036 | ACC 0.9404\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0826/0938 | LOSS: 0.2034 | ACC 0.9404\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0827/0938 | LOSS: 0.2033 | ACC 0.9405\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0828/0938 | LOSS: 0.2033 | ACC 0.9405\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0829/0938 | LOSS: 0.2031 | ACC 0.9405\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0830/0938 | LOSS: 0.2029 | ACC 0.9405\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0831/0938 | LOSS: 0.2029 | ACC 0.9406\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0832/0938 | LOSS: 0.2031 | ACC 0.9406\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0833/0938 | LOSS: 0.2029 | ACC 0.9406\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0834/0938 | LOSS: 0.2028 | ACC 0.9406\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0835/0938 | LOSS: 0.2028 | ACC 0.9406\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0836/0938 | LOSS: 0.2028 | ACC 0.9406\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0837/0938 | LOSS: 0.2027 | ACC 0.9407\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0838/0938 | LOSS: 0.2026 | ACC 0.9406\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0839/0938 | LOSS: 0.2025 | ACC 0.9407\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0840/0938 | LOSS: 0.2025 | ACC 0.9407\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0841/0938 | LOSS: 0.2024 | ACC 0.9407\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0842/0938 | LOSS: 0.2024 | ACC 0.9407\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0843/0938 | LOSS: 0.2023 | ACC 0.9407\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0844/0938 | LOSS: 0.2023 | ACC 0.9406\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0845/0938 | LOSS: 0.2023 | ACC 0.9406\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0846/0938 | LOSS: 0.2022 | ACC 0.9407\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0847/0938 | LOSS: 0.2020 | ACC 0.9408\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0848/0938 | LOSS: 0.2019 | ACC 0.9408\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0849/0938 | LOSS: 0.2019 | ACC 0.9408\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0850/0938 | LOSS: 0.2020 | ACC 0.9408\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0851/0938 | LOSS: 0.2021 | ACC 0.9408\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0852/0938 | LOSS: 0.2022 | ACC 0.9407\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0853/0938 | LOSS: 0.2024 | ACC 0.9407\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0854/0938 | LOSS: 0.2024 | ACC 0.9407\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0855/0938 | LOSS: 0.2027 | ACC 0.9407\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0856/0938 | LOSS: 0.2026 | ACC 0.9406\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0857/0938 | LOSS: 0.2026 | ACC 0.9407\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0858/0938 | LOSS: 0.2027 | ACC 0.9406\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0859/0938 | LOSS: 0.2026 | ACC 0.9406\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0860/0938 | LOSS: 0.2028 | ACC 0.9406\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0861/0938 | LOSS: 0.2028 | ACC 0.9406\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0862/0938 | LOSS: 0.2027 | ACC 0.9407\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0863/0938 | LOSS: 0.2026 | ACC 0.9407\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0864/0938 | LOSS: 0.2025 | ACC 0.9407\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0865/0938 | LOSS: 0.2025 | ACC 0.9407\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0866/0938 | LOSS: 0.2026 | ACC 0.9407\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0867/0938 | LOSS: 0.2027 | ACC 0.9407\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0868/0938 | LOSS: 0.2025 | ACC 0.9408\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0869/0938 | LOSS: 0.2025 | ACC 0.9408\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: EPOCH 0004/0010 | BATCH 0870/0938 | LOSS: 0.2026 | ACC 0.9408\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0871/0938 | LOSS: 0.2026 | ACC 0.9408\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0872/0938 | LOSS: 0.2025 | ACC 0.9408\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0873/0938 | LOSS: 0.2024 | ACC 0.9408\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0874/0938 | LOSS: 0.2026 | ACC 0.9408\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0875/0938 | LOSS: 0.2026 | ACC 0.9408\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0876/0938 | LOSS: 0.2025 | ACC 0.9408\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0877/0938 | LOSS: 0.2024 | ACC 0.9408\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0878/0938 | LOSS: 0.2025 | ACC 0.9408\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0879/0938 | LOSS: 0.2027 | ACC 0.9407\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0880/0938 | LOSS: 0.2027 | ACC 0.9407\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0881/0938 | LOSS: 0.2029 | ACC 0.9406\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0882/0938 | LOSS: 0.2029 | ACC 0.9406\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0883/0938 | LOSS: 0.2029 | ACC 0.9406\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0884/0938 | LOSS: 0.2028 | ACC 0.9406\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0885/0938 | LOSS: 0.2029 | ACC 0.9406\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0886/0938 | LOSS: 0.2029 | ACC 0.9406\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0887/0938 | LOSS: 0.2028 | ACC 0.9407\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0888/0938 | LOSS: 0.2028 | ACC 0.9406\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0889/0938 | LOSS: 0.2029 | ACC 0.9406\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0890/0938 | LOSS: 0.2029 | ACC 0.9406\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0891/0938 | LOSS: 0.2029 | ACC 0.9404\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0892/0938 | LOSS: 0.2029 | ACC 0.9404\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0893/0938 | LOSS: 0.2029 | ACC 0.9404\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0894/0938 | LOSS: 0.2028 | ACC 0.9405\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0895/0938 | LOSS: 0.2029 | ACC 0.9404\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0896/0938 | LOSS: 0.2028 | ACC 0.9404\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0897/0938 | LOSS: 0.2027 | ACC 0.9405\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0898/0938 | LOSS: 0.2027 | ACC 0.9405\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0899/0938 | LOSS: 0.2026 | ACC 0.9405\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0900/0938 | LOSS: 0.2026 | ACC 0.9405\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0901/0938 | LOSS: 0.2027 | ACC 0.9404\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0902/0938 | LOSS: 0.2026 | ACC 0.9405\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0903/0938 | LOSS: 0.2025 | ACC 0.9405\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0904/0938 | LOSS: 0.2024 | ACC 0.9405\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0905/0938 | LOSS: 0.2023 | ACC 0.9406\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0906/0938 | LOSS: 0.2022 | ACC 0.9406\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0907/0938 | LOSS: 0.2021 | ACC 0.9406\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0908/0938 | LOSS: 0.2021 | ACC 0.9406\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0909/0938 | LOSS: 0.2020 | ACC 0.9407\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0910/0938 | LOSS: 0.2021 | ACC 0.9407\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0911/0938 | LOSS: 0.2021 | ACC 0.9407\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0912/0938 | LOSS: 0.2020 | ACC 0.9406\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0913/0938 | LOSS: 0.2021 | ACC 0.9406\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0914/0938 | LOSS: 0.2020 | ACC 0.9407\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0915/0938 | LOSS: 0.2020 | ACC 0.9407\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0916/0938 | LOSS: 0.2021 | ACC 0.9407\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0917/0938 | LOSS: 0.2021 | ACC 0.9407\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0918/0938 | LOSS: 0.2020 | ACC 0.9407\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0919/0938 | LOSS: 0.2020 | ACC 0.9407\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0920/0938 | LOSS: 0.2019 | ACC 0.9407\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0921/0938 | LOSS: 0.2019 | ACC 0.9407\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0922/0938 | LOSS: 0.2018 | ACC 0.9407\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0923/0938 | LOSS: 0.2018 | ACC 0.9407\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0924/0938 | LOSS: 0.2016 | ACC 0.9407\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0925/0938 | LOSS: 0.2017 | ACC 0.9408\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0926/0938 | LOSS: 0.2016 | ACC 0.9408\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0927/0938 | LOSS: 0.2015 | ACC 0.9408\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0928/0938 | LOSS: 0.2015 | ACC 0.9408\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0929/0938 | LOSS: 0.2015 | ACC 0.9408\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0930/0938 | LOSS: 0.2015 | ACC 0.9408\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0931/0938 | LOSS: 0.2014 | ACC 0.9408\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0932/0938 | LOSS: 0.2013 | ACC 0.9408\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0933/0938 | LOSS: 0.2012 | ACC 0.9409\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0934/0938 | LOSS: 0.2011 | ACC 0.9409\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0935/0938 | LOSS: 0.2011 | ACC 0.9409\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0936/0938 | LOSS: 0.2010 | ACC 0.9409\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0937/0938 | LOSS: 0.2009 | ACC 0.9409\n",
      "TRAIN: EPOCH 0004/0010 | BATCH 0938/0938 | LOSS: 0.2008 | ACC 0.9410\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0001/0938 | LOSS: 0.0523 | ACC 0.9844\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0002/0938 | LOSS: 0.1288 | ACC 0.9609\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0003/0938 | LOSS: 0.1507 | ACC 0.9583\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0004/0938 | LOSS: 0.1587 | ACC 0.9609\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0005/0938 | LOSS: 0.1690 | ACC 0.9531\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0006/0938 | LOSS: 0.1678 | ACC 0.9505\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0007/0938 | LOSS: 0.1732 | ACC 0.9509\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0008/0938 | LOSS: 0.1668 | ACC 0.9531\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0009/0938 | LOSS: 0.1797 | ACC 0.9497\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0010/0938 | LOSS: 0.1853 | ACC 0.9469\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0011/0938 | LOSS: 0.1837 | ACC 0.9460\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0012/0938 | LOSS: 0.1805 | ACC 0.9453\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0013/0938 | LOSS: 0.1839 | ACC 0.9423\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0014/0938 | LOSS: 0.2065 | ACC 0.9386\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0015/0938 | LOSS: 0.2113 | ACC 0.9385\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0016/0938 | LOSS: 0.2107 | ACC 0.9385\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0017/0938 | LOSS: 0.2050 | ACC 0.9403\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0018/0938 | LOSS: 0.2044 | ACC 0.9384\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0019/0938 | LOSS: 0.1990 | ACC 0.9391\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0020/0938 | LOSS: 0.1954 | ACC 0.9406\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0021/0938 | LOSS: 0.1919 | ACC 0.9412\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0022/0938 | LOSS: 0.1886 | ACC 0.9411\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0023/0938 | LOSS: 0.1822 | ACC 0.9436\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0024/0938 | LOSS: 0.1823 | ACC 0.9440\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0025/0938 | LOSS: 0.1826 | ACC 0.9444\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0026/0938 | LOSS: 0.1887 | ACC 0.9429\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0027/0938 | LOSS: 0.1899 | ACC 0.9433\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0028/0938 | LOSS: 0.1883 | ACC 0.9431\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0029/0938 | LOSS: 0.1852 | ACC 0.9440\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0030/0938 | LOSS: 0.1841 | ACC 0.9443\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0031/0938 | LOSS: 0.1841 | ACC 0.9441\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0032/0938 | LOSS: 0.1831 | ACC 0.9443\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0033/0938 | LOSS: 0.1822 | ACC 0.9446\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0034/0938 | LOSS: 0.1824 | ACC 0.9435\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0035/0938 | LOSS: 0.1813 | ACC 0.9437\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0036/0938 | LOSS: 0.1795 | ACC 0.9449\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0037/0938 | LOSS: 0.1819 | ACC 0.9438\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0038/0938 | LOSS: 0.1799 | ACC 0.9445\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0039/0938 | LOSS: 0.1800 | ACC 0.9443\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0040/0938 | LOSS: 0.1823 | ACC 0.9445\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0041/0938 | LOSS: 0.1818 | ACC 0.9447\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0042/0938 | LOSS: 0.1818 | ACC 0.9446\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0043/0938 | LOSS: 0.1852 | ACC 0.9437\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0044/0938 | LOSS: 0.1851 | ACC 0.9442\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0045/0938 | LOSS: 0.1836 | ACC 0.9448\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0046/0938 | LOSS: 0.1831 | ACC 0.9450\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0047/0938 | LOSS: 0.1827 | ACC 0.9448\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0048/0938 | LOSS: 0.1819 | ACC 0.9447\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0049/0938 | LOSS: 0.1835 | ACC 0.9439\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0050/0938 | LOSS: 0.1825 | ACC 0.9441\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0051/0938 | LOSS: 0.1835 | ACC 0.9439\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0052/0938 | LOSS: 0.1817 | ACC 0.9447\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0053/0938 | LOSS: 0.1827 | ACC 0.9449\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0054/0938 | LOSS: 0.1823 | ACC 0.9450\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0055/0938 | LOSS: 0.1835 | ACC 0.9449\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0056/0938 | LOSS: 0.1850 | ACC 0.9445\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0057/0938 | LOSS: 0.1870 | ACC 0.9444\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0058/0938 | LOSS: 0.1863 | ACC 0.9442\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0059/0938 | LOSS: 0.1882 | ACC 0.9436\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0060/0938 | LOSS: 0.1895 | ACC 0.9435\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: EPOCH 0005/0010 | BATCH 0061/0938 | LOSS: 0.1897 | ACC 0.9436\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0062/0938 | LOSS: 0.1909 | ACC 0.9441\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0063/0938 | LOSS: 0.1903 | ACC 0.9439\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0064/0938 | LOSS: 0.1886 | ACC 0.9446\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0065/0938 | LOSS: 0.1879 | ACC 0.9445\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0066/0938 | LOSS: 0.1873 | ACC 0.9446\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0067/0938 | LOSS: 0.1862 | ACC 0.9450\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0068/0938 | LOSS: 0.1877 | ACC 0.9446\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0069/0938 | LOSS: 0.1882 | ACC 0.9438\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0070/0938 | LOSS: 0.1878 | ACC 0.9444\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0071/0938 | LOSS: 0.1871 | ACC 0.9448\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0072/0938 | LOSS: 0.1876 | ACC 0.9442\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0073/0938 | LOSS: 0.1867 | ACC 0.9441\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0074/0938 | LOSS: 0.1859 | ACC 0.9443\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0075/0938 | LOSS: 0.1860 | ACC 0.9446\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0076/0938 | LOSS: 0.1862 | ACC 0.9441\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0077/0938 | LOSS: 0.1863 | ACC 0.9438\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0078/0938 | LOSS: 0.1850 | ACC 0.9441\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0079/0938 | LOSS: 0.1844 | ACC 0.9442\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0080/0938 | LOSS: 0.1847 | ACC 0.9443\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0081/0938 | LOSS: 0.1833 | ACC 0.9446\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0082/0938 | LOSS: 0.1833 | ACC 0.9446\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0083/0938 | LOSS: 0.1817 | ACC 0.9452\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0084/0938 | LOSS: 0.1822 | ACC 0.9446\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0085/0938 | LOSS: 0.1822 | ACC 0.9445\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0086/0938 | LOSS: 0.1840 | ACC 0.9442\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0087/0938 | LOSS: 0.1830 | ACC 0.9447\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0088/0938 | LOSS: 0.1849 | ACC 0.9444\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0089/0938 | LOSS: 0.1867 | ACC 0.9442\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0090/0938 | LOSS: 0.1867 | ACC 0.9443\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0091/0938 | LOSS: 0.1857 | ACC 0.9447\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0092/0938 | LOSS: 0.1852 | ACC 0.9450\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0093/0938 | LOSS: 0.1848 | ACC 0.9452\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0094/0938 | LOSS: 0.1832 | ACC 0.9458\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0095/0938 | LOSS: 0.1818 | ACC 0.9464\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0096/0938 | LOSS: 0.1809 | ACC 0.9466\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0097/0938 | LOSS: 0.1811 | ACC 0.9464\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0098/0938 | LOSS: 0.1811 | ACC 0.9461\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0099/0938 | LOSS: 0.1807 | ACC 0.9463\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0100/0938 | LOSS: 0.1797 | ACC 0.9466\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0101/0938 | LOSS: 0.1808 | ACC 0.9463\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0102/0938 | LOSS: 0.1801 | ACC 0.9467\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0103/0938 | LOSS: 0.1795 | ACC 0.9469\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0104/0938 | LOSS: 0.1814 | ACC 0.9470\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0105/0938 | LOSS: 0.1826 | ACC 0.9464\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0106/0938 | LOSS: 0.1832 | ACC 0.9459\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0107/0938 | LOSS: 0.1831 | ACC 0.9458\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0108/0938 | LOSS: 0.1846 | ACC 0.9455\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0109/0938 | LOSS: 0.1836 | ACC 0.9458\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0110/0938 | LOSS: 0.1830 | ACC 0.9459\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0111/0938 | LOSS: 0.1843 | ACC 0.9455\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0112/0938 | LOSS: 0.1852 | ACC 0.9449\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0113/0938 | LOSS: 0.1858 | ACC 0.9447\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0114/0938 | LOSS: 0.1850 | ACC 0.9450\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0115/0938 | LOSS: 0.1860 | ACC 0.9448\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0116/0938 | LOSS: 0.1870 | ACC 0.9448\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0117/0938 | LOSS: 0.1870 | ACC 0.9447\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0118/0938 | LOSS: 0.1886 | ACC 0.9439\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0119/0938 | LOSS: 0.1877 | ACC 0.9441\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0120/0938 | LOSS: 0.1874 | ACC 0.9443\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0121/0938 | LOSS: 0.1870 | ACC 0.9443\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0122/0938 | LOSS: 0.1878 | ACC 0.9442\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0123/0938 | LOSS: 0.1896 | ACC 0.9441\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0124/0938 | LOSS: 0.1892 | ACC 0.9442\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0125/0938 | LOSS: 0.1891 | ACC 0.9440\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0126/0938 | LOSS: 0.1894 | ACC 0.9441\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0127/0938 | LOSS: 0.1892 | ACC 0.9441\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0128/0938 | LOSS: 0.1894 | ACC 0.9443\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0129/0938 | LOSS: 0.1891 | ACC 0.9443\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0130/0938 | LOSS: 0.1897 | ACC 0.9442\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0131/0938 | LOSS: 0.1905 | ACC 0.9438\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0132/0938 | LOSS: 0.1918 | ACC 0.9437\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0133/0938 | LOSS: 0.1921 | ACC 0.9435\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0134/0938 | LOSS: 0.1923 | ACC 0.9436\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0135/0938 | LOSS: 0.1924 | ACC 0.9434\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0136/0938 | LOSS: 0.1914 | ACC 0.9438\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0137/0938 | LOSS: 0.1905 | ACC 0.9442\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0138/0938 | LOSS: 0.1899 | ACC 0.9441\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0139/0938 | LOSS: 0.1896 | ACC 0.9441\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0140/0938 | LOSS: 0.1894 | ACC 0.9443\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0141/0938 | LOSS: 0.1910 | ACC 0.9439\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0142/0938 | LOSS: 0.1902 | ACC 0.9443\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0143/0938 | LOSS: 0.1897 | ACC 0.9445\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0144/0938 | LOSS: 0.1898 | ACC 0.9446\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0145/0938 | LOSS: 0.1897 | ACC 0.9445\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0146/0938 | LOSS: 0.1897 | ACC 0.9446\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0147/0938 | LOSS: 0.1897 | ACC 0.9445\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0148/0938 | LOSS: 0.1892 | ACC 0.9446\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0149/0938 | LOSS: 0.1893 | ACC 0.9446\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0150/0938 | LOSS: 0.1895 | ACC 0.9447\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0151/0938 | LOSS: 0.1901 | ACC 0.9446\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0152/0938 | LOSS: 0.1896 | ACC 0.9448\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0153/0938 | LOSS: 0.1891 | ACC 0.9448\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0154/0938 | LOSS: 0.1899 | ACC 0.9444\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0155/0938 | LOSS: 0.1892 | ACC 0.9447\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0156/0938 | LOSS: 0.1902 | ACC 0.9443\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0157/0938 | LOSS: 0.1902 | ACC 0.9443\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0158/0938 | LOSS: 0.1900 | ACC 0.9442\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0159/0938 | LOSS: 0.1894 | ACC 0.9444\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0160/0938 | LOSS: 0.1894 | ACC 0.9443\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0161/0938 | LOSS: 0.1893 | ACC 0.9445\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0162/0938 | LOSS: 0.1889 | ACC 0.9446\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0163/0938 | LOSS: 0.1898 | ACC 0.9445\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0164/0938 | LOSS: 0.1897 | ACC 0.9445\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0165/0938 | LOSS: 0.1896 | ACC 0.9445\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0166/0938 | LOSS: 0.1897 | ACC 0.9442\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0167/0938 | LOSS: 0.1900 | ACC 0.9440\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0168/0938 | LOSS: 0.1900 | ACC 0.9440\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0169/0938 | LOSS: 0.1906 | ACC 0.9433\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0170/0938 | LOSS: 0.1907 | ACC 0.9431\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0171/0938 | LOSS: 0.1910 | ACC 0.9431\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0172/0938 | LOSS: 0.1906 | ACC 0.9432\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0173/0938 | LOSS: 0.1897 | ACC 0.9436\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0174/0938 | LOSS: 0.1897 | ACC 0.9436\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0175/0938 | LOSS: 0.1889 | ACC 0.9439\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0176/0938 | LOSS: 0.1885 | ACC 0.9439\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0177/0938 | LOSS: 0.1880 | ACC 0.9440\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0178/0938 | LOSS: 0.1874 | ACC 0.9443\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0179/0938 | LOSS: 0.1870 | ACC 0.9443\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0180/0938 | LOSS: 0.1871 | ACC 0.9443\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0181/0938 | LOSS: 0.1866 | ACC 0.9443\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0182/0938 | LOSS: 0.1869 | ACC 0.9444\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0183/0938 | LOSS: 0.1867 | ACC 0.9443\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0184/0938 | LOSS: 0.1870 | ACC 0.9441\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0185/0938 | LOSS: 0.1865 | ACC 0.9442\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0186/0938 | LOSS: 0.1870 | ACC 0.9440\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0187/0938 | LOSS: 0.1868 | ACC 0.9439\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0188/0938 | LOSS: 0.1861 | ACC 0.9441\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0189/0938 | LOSS: 0.1856 | ACC 0.9442\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: EPOCH 0005/0010 | BATCH 0190/0938 | LOSS: 0.1856 | ACC 0.9442\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0191/0938 | LOSS: 0.1852 | ACC 0.9443\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0192/0938 | LOSS: 0.1847 | ACC 0.9445\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0193/0938 | LOSS: 0.1842 | ACC 0.9447\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0194/0938 | LOSS: 0.1839 | ACC 0.9448\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0195/0938 | LOSS: 0.1836 | ACC 0.9450\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0196/0938 | LOSS: 0.1834 | ACC 0.9451\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0197/0938 | LOSS: 0.1836 | ACC 0.9449\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0198/0938 | LOSS: 0.1830 | ACC 0.9451\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0199/0938 | LOSS: 0.1828 | ACC 0.9452\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0200/0938 | LOSS: 0.1826 | ACC 0.9451\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0201/0938 | LOSS: 0.1823 | ACC 0.9451\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0202/0938 | LOSS: 0.1841 | ACC 0.9450\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0203/0938 | LOSS: 0.1844 | ACC 0.9447\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0204/0938 | LOSS: 0.1837 | ACC 0.9449\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0205/0938 | LOSS: 0.1834 | ACC 0.9449\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0206/0938 | LOSS: 0.1835 | ACC 0.9449\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0207/0938 | LOSS: 0.1833 | ACC 0.9449\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0208/0938 | LOSS: 0.1834 | ACC 0.9449\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0209/0938 | LOSS: 0.1830 | ACC 0.9451\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0210/0938 | LOSS: 0.1825 | ACC 0.9453\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0211/0938 | LOSS: 0.1831 | ACC 0.9453\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0212/0938 | LOSS: 0.1833 | ACC 0.9452\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0213/0938 | LOSS: 0.1828 | ACC 0.9455\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0214/0938 | LOSS: 0.1840 | ACC 0.9455\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0215/0938 | LOSS: 0.1852 | ACC 0.9453\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0216/0938 | LOSS: 0.1857 | ACC 0.9454\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0217/0938 | LOSS: 0.1863 | ACC 0.9451\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0218/0938 | LOSS: 0.1858 | ACC 0.9453\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0219/0938 | LOSS: 0.1853 | ACC 0.9455\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0220/0938 | LOSS: 0.1848 | ACC 0.9457\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0221/0938 | LOSS: 0.1844 | ACC 0.9459\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0222/0938 | LOSS: 0.1864 | ACC 0.9454\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0223/0938 | LOSS: 0.1861 | ACC 0.9454\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0224/0938 | LOSS: 0.1857 | ACC 0.9455\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0225/0938 | LOSS: 0.1858 | ACC 0.9456\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0226/0938 | LOSS: 0.1855 | ACC 0.9457\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0227/0938 | LOSS: 0.1863 | ACC 0.9455\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0228/0938 | LOSS: 0.1858 | ACC 0.9455\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0229/0938 | LOSS: 0.1853 | ACC 0.9458\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0230/0938 | LOSS: 0.1855 | ACC 0.9457\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0231/0938 | LOSS: 0.1856 | ACC 0.9457\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0232/0938 | LOSS: 0.1855 | ACC 0.9458\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0233/0938 | LOSS: 0.1853 | ACC 0.9457\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0234/0938 | LOSS: 0.1853 | ACC 0.9458\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0235/0938 | LOSS: 0.1854 | ACC 0.9458\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0236/0938 | LOSS: 0.1856 | ACC 0.9458\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0237/0938 | LOSS: 0.1853 | ACC 0.9460\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0238/0938 | LOSS: 0.1855 | ACC 0.9460\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0239/0938 | LOSS: 0.1860 | ACC 0.9461\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0240/0938 | LOSS: 0.1865 | ACC 0.9459\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0241/0938 | LOSS: 0.1862 | ACC 0.9461\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0242/0938 | LOSS: 0.1860 | ACC 0.9462\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0243/0938 | LOSS: 0.1862 | ACC 0.9461\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0244/0938 | LOSS: 0.1868 | ACC 0.9461\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0245/0938 | LOSS: 0.1876 | ACC 0.9460\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0246/0938 | LOSS: 0.1872 | ACC 0.9461\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0247/0938 | LOSS: 0.1872 | ACC 0.9461\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0248/0938 | LOSS: 0.1868 | ACC 0.9463\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0249/0938 | LOSS: 0.1875 | ACC 0.9460\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0250/0938 | LOSS: 0.1873 | ACC 0.9459\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0251/0938 | LOSS: 0.1872 | ACC 0.9460\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0252/0938 | LOSS: 0.1871 | ACC 0.9459\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0253/0938 | LOSS: 0.1868 | ACC 0.9460\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0254/0938 | LOSS: 0.1873 | ACC 0.9460\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0255/0938 | LOSS: 0.1871 | ACC 0.9460\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0256/0938 | LOSS: 0.1875 | ACC 0.9459\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0257/0938 | LOSS: 0.1874 | ACC 0.9459\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0258/0938 | LOSS: 0.1874 | ACC 0.9458\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0259/0938 | LOSS: 0.1870 | ACC 0.9459\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0260/0938 | LOSS: 0.1869 | ACC 0.9459\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0261/0938 | LOSS: 0.1868 | ACC 0.9458\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0262/0938 | LOSS: 0.1866 | ACC 0.9459\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0263/0938 | LOSS: 0.1863 | ACC 0.9459\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0264/0938 | LOSS: 0.1861 | ACC 0.9459\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0265/0938 | LOSS: 0.1860 | ACC 0.9459\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0266/0938 | LOSS: 0.1858 | ACC 0.9460\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0267/0938 | LOSS: 0.1859 | ACC 0.9459\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0268/0938 | LOSS: 0.1858 | ACC 0.9459\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0269/0938 | LOSS: 0.1856 | ACC 0.9459\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0270/0938 | LOSS: 0.1856 | ACC 0.9459\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0271/0938 | LOSS: 0.1861 | ACC 0.9459\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0272/0938 | LOSS: 0.1858 | ACC 0.9459\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0273/0938 | LOSS: 0.1859 | ACC 0.9459\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0274/0938 | LOSS: 0.1874 | ACC 0.9456\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0275/0938 | LOSS: 0.1873 | ACC 0.9455\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0276/0938 | LOSS: 0.1874 | ACC 0.9454\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0277/0938 | LOSS: 0.1869 | ACC 0.9456\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0278/0938 | LOSS: 0.1870 | ACC 0.9455\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0279/0938 | LOSS: 0.1872 | ACC 0.9457\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0280/0938 | LOSS: 0.1869 | ACC 0.9458\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0281/0938 | LOSS: 0.1869 | ACC 0.9457\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0282/0938 | LOSS: 0.1868 | ACC 0.9457\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0283/0938 | LOSS: 0.1868 | ACC 0.9457\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0284/0938 | LOSS: 0.1867 | ACC 0.9458\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0285/0938 | LOSS: 0.1865 | ACC 0.9457\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0286/0938 | LOSS: 0.1867 | ACC 0.9457\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0287/0938 | LOSS: 0.1867 | ACC 0.9457\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0288/0938 | LOSS: 0.1868 | ACC 0.9457\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0289/0938 | LOSS: 0.1866 | ACC 0.9458\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0290/0938 | LOSS: 0.1868 | ACC 0.9457\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0291/0938 | LOSS: 0.1880 | ACC 0.9457\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0292/0938 | LOSS: 0.1884 | ACC 0.9456\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0293/0938 | LOSS: 0.1886 | ACC 0.9456\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0294/0938 | LOSS: 0.1882 | ACC 0.9457\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0295/0938 | LOSS: 0.1890 | ACC 0.9456\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0296/0938 | LOSS: 0.1894 | ACC 0.9456\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0297/0938 | LOSS: 0.1892 | ACC 0.9456\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0298/0938 | LOSS: 0.1888 | ACC 0.9457\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0299/0938 | LOSS: 0.1889 | ACC 0.9458\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0300/0938 | LOSS: 0.1885 | ACC 0.9459\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0301/0938 | LOSS: 0.1888 | ACC 0.9458\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0302/0938 | LOSS: 0.1886 | ACC 0.9457\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0303/0938 | LOSS: 0.1883 | ACC 0.9459\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0304/0938 | LOSS: 0.1882 | ACC 0.9459\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0305/0938 | LOSS: 0.1880 | ACC 0.9460\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0306/0938 | LOSS: 0.1879 | ACC 0.9460\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0307/0938 | LOSS: 0.1878 | ACC 0.9461\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0308/0938 | LOSS: 0.1879 | ACC 0.9460\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0309/0938 | LOSS: 0.1879 | ACC 0.9460\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0310/0938 | LOSS: 0.1879 | ACC 0.9460\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0311/0938 | LOSS: 0.1883 | ACC 0.9459\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0312/0938 | LOSS: 0.1882 | ACC 0.9458\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0313/0938 | LOSS: 0.1889 | ACC 0.9456\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0314/0938 | LOSS: 0.1886 | ACC 0.9458\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0315/0938 | LOSS: 0.1884 | ACC 0.9459\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0316/0938 | LOSS: 0.1884 | ACC 0.9458\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0317/0938 | LOSS: 0.1887 | ACC 0.9459\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0318/0938 | LOSS: 0.1888 | ACC 0.9458\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: EPOCH 0005/0010 | BATCH 0319/0938 | LOSS: 0.1886 | ACC 0.9457\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0320/0938 | LOSS: 0.1885 | ACC 0.9457\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0321/0938 | LOSS: 0.1883 | ACC 0.9457\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0322/0938 | LOSS: 0.1884 | ACC 0.9457\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0323/0938 | LOSS: 0.1880 | ACC 0.9458\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0324/0938 | LOSS: 0.1877 | ACC 0.9457\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0325/0938 | LOSS: 0.1874 | ACC 0.9458\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0326/0938 | LOSS: 0.1870 | ACC 0.9459\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0327/0938 | LOSS: 0.1872 | ACC 0.9458\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0328/0938 | LOSS: 0.1870 | ACC 0.9458\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0329/0938 | LOSS: 0.1866 | ACC 0.9460\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0330/0938 | LOSS: 0.1868 | ACC 0.9459\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0331/0938 | LOSS: 0.1865 | ACC 0.9459\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0332/0938 | LOSS: 0.1866 | ACC 0.9457\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0333/0938 | LOSS: 0.1864 | ACC 0.9457\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0334/0938 | LOSS: 0.1867 | ACC 0.9456\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0335/0938 | LOSS: 0.1864 | ACC 0.9458\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0336/0938 | LOSS: 0.1861 | ACC 0.9459\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0337/0938 | LOSS: 0.1862 | ACC 0.9459\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0338/0938 | LOSS: 0.1858 | ACC 0.9461\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0339/0938 | LOSS: 0.1855 | ACC 0.9461\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0340/0938 | LOSS: 0.1854 | ACC 0.9461\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0341/0938 | LOSS: 0.1850 | ACC 0.9463\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0342/0938 | LOSS: 0.1847 | ACC 0.9464\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0343/0938 | LOSS: 0.1843 | ACC 0.9465\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0344/0938 | LOSS: 0.1850 | ACC 0.9465\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0345/0938 | LOSS: 0.1851 | ACC 0.9465\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0346/0938 | LOSS: 0.1851 | ACC 0.9464\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0347/0938 | LOSS: 0.1850 | ACC 0.9465\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0348/0938 | LOSS: 0.1850 | ACC 0.9465\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0349/0938 | LOSS: 0.1850 | ACC 0.9465\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0350/0938 | LOSS: 0.1852 | ACC 0.9465\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0351/0938 | LOSS: 0.1855 | ACC 0.9465\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0352/0938 | LOSS: 0.1854 | ACC 0.9466\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0353/0938 | LOSS: 0.1864 | ACC 0.9464\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0354/0938 | LOSS: 0.1863 | ACC 0.9464\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0355/0938 | LOSS: 0.1861 | ACC 0.9465\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0356/0938 | LOSS: 0.1865 | ACC 0.9463\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0357/0938 | LOSS: 0.1869 | ACC 0.9462\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0358/0938 | LOSS: 0.1873 | ACC 0.9461\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0359/0938 | LOSS: 0.1877 | ACC 0.9459\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0360/0938 | LOSS: 0.1875 | ACC 0.9460\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0361/0938 | LOSS: 0.1880 | ACC 0.9458\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0362/0938 | LOSS: 0.1877 | ACC 0.9459\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0363/0938 | LOSS: 0.1875 | ACC 0.9460\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0364/0938 | LOSS: 0.1881 | ACC 0.9458\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0365/0938 | LOSS: 0.1879 | ACC 0.9458\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0366/0938 | LOSS: 0.1878 | ACC 0.9459\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0367/0938 | LOSS: 0.1885 | ACC 0.9459\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0368/0938 | LOSS: 0.1884 | ACC 0.9459\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0369/0938 | LOSS: 0.1885 | ACC 0.9459\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0370/0938 | LOSS: 0.1882 | ACC 0.9460\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0371/0938 | LOSS: 0.1879 | ACC 0.9460\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0372/0938 | LOSS: 0.1878 | ACC 0.9460\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0373/0938 | LOSS: 0.1879 | ACC 0.9460\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0374/0938 | LOSS: 0.1879 | ACC 0.9461\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0375/0938 | LOSS: 0.1876 | ACC 0.9462\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0376/0938 | LOSS: 0.1875 | ACC 0.9462\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0377/0938 | LOSS: 0.1877 | ACC 0.9462\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0378/0938 | LOSS: 0.1878 | ACC 0.9462\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0379/0938 | LOSS: 0.1876 | ACC 0.9462\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0380/0938 | LOSS: 0.1874 | ACC 0.9463\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0381/0938 | LOSS: 0.1872 | ACC 0.9463\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0382/0938 | LOSS: 0.1873 | ACC 0.9462\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0383/0938 | LOSS: 0.1870 | ACC 0.9463\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0384/0938 | LOSS: 0.1868 | ACC 0.9464\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0385/0938 | LOSS: 0.1867 | ACC 0.9464\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0386/0938 | LOSS: 0.1867 | ACC 0.9464\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0387/0938 | LOSS: 0.1868 | ACC 0.9463\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0388/0938 | LOSS: 0.1870 | ACC 0.9463\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0389/0938 | LOSS: 0.1871 | ACC 0.9463\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0390/0938 | LOSS: 0.1871 | ACC 0.9463\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0391/0938 | LOSS: 0.1871 | ACC 0.9463\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0392/0938 | LOSS: 0.1875 | ACC 0.9462\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0393/0938 | LOSS: 0.1875 | ACC 0.9462\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0394/0938 | LOSS: 0.1875 | ACC 0.9463\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0395/0938 | LOSS: 0.1873 | ACC 0.9463\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0396/0938 | LOSS: 0.1874 | ACC 0.9464\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0397/0938 | LOSS: 0.1871 | ACC 0.9465\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0398/0938 | LOSS: 0.1871 | ACC 0.9465\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0399/0938 | LOSS: 0.1868 | ACC 0.9466\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0400/0938 | LOSS: 0.1865 | ACC 0.9467\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0401/0938 | LOSS: 0.1862 | ACC 0.9469\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0402/0938 | LOSS: 0.1866 | ACC 0.9468\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0403/0938 | LOSS: 0.1864 | ACC 0.9468\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0404/0938 | LOSS: 0.1864 | ACC 0.9468\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0405/0938 | LOSS: 0.1862 | ACC 0.9469\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0406/0938 | LOSS: 0.1863 | ACC 0.9469\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0407/0938 | LOSS: 0.1865 | ACC 0.9469\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0408/0938 | LOSS: 0.1862 | ACC 0.9470\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0409/0938 | LOSS: 0.1861 | ACC 0.9471\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0410/0938 | LOSS: 0.1859 | ACC 0.9471\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0411/0938 | LOSS: 0.1856 | ACC 0.9472\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0412/0938 | LOSS: 0.1856 | ACC 0.9472\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0413/0938 | LOSS: 0.1856 | ACC 0.9471\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0414/0938 | LOSS: 0.1855 | ACC 0.9472\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0415/0938 | LOSS: 0.1853 | ACC 0.9472\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0416/0938 | LOSS: 0.1856 | ACC 0.9471\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0417/0938 | LOSS: 0.1857 | ACC 0.9471\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0418/0938 | LOSS: 0.1859 | ACC 0.9471\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0419/0938 | LOSS: 0.1858 | ACC 0.9471\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0420/0938 | LOSS: 0.1861 | ACC 0.9471\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0421/0938 | LOSS: 0.1861 | ACC 0.9471\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0422/0938 | LOSS: 0.1860 | ACC 0.9471\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0423/0938 | LOSS: 0.1867 | ACC 0.9470\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0424/0938 | LOSS: 0.1867 | ACC 0.9470\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0425/0938 | LOSS: 0.1868 | ACC 0.9469\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0426/0938 | LOSS: 0.1867 | ACC 0.9469\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0427/0938 | LOSS: 0.1865 | ACC 0.9470\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0428/0938 | LOSS: 0.1865 | ACC 0.9470\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0429/0938 | LOSS: 0.1866 | ACC 0.9470\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0430/0938 | LOSS: 0.1863 | ACC 0.9471\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0431/0938 | LOSS: 0.1870 | ACC 0.9469\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0432/0938 | LOSS: 0.1871 | ACC 0.9469\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0433/0938 | LOSS: 0.1868 | ACC 0.9470\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0434/0938 | LOSS: 0.1866 | ACC 0.9470\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0435/0938 | LOSS: 0.1864 | ACC 0.9471\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0436/0938 | LOSS: 0.1865 | ACC 0.9471\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0437/0938 | LOSS: 0.1863 | ACC 0.9471\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0438/0938 | LOSS: 0.1862 | ACC 0.9471\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0439/0938 | LOSS: 0.1861 | ACC 0.9471\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0440/0938 | LOSS: 0.1863 | ACC 0.9471\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0441/0938 | LOSS: 0.1863 | ACC 0.9471\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0442/0938 | LOSS: 0.1864 | ACC 0.9470\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0443/0938 | LOSS: 0.1866 | ACC 0.9469\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0444/0938 | LOSS: 0.1862 | ACC 0.9470\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0445/0938 | LOSS: 0.1867 | ACC 0.9470\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0446/0938 | LOSS: 0.1866 | ACC 0.9470\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0447/0938 | LOSS: 0.1866 | ACC 0.9470\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: EPOCH 0005/0010 | BATCH 0448/0938 | LOSS: 0.1870 | ACC 0.9468\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0449/0938 | LOSS: 0.1868 | ACC 0.9469\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0450/0938 | LOSS: 0.1871 | ACC 0.9468\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0451/0938 | LOSS: 0.1872 | ACC 0.9469\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0452/0938 | LOSS: 0.1871 | ACC 0.9469\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0453/0938 | LOSS: 0.1872 | ACC 0.9469\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0454/0938 | LOSS: 0.1870 | ACC 0.9468\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0455/0938 | LOSS: 0.1876 | ACC 0.9467\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0456/0938 | LOSS: 0.1874 | ACC 0.9467\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0457/0938 | LOSS: 0.1873 | ACC 0.9468\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0458/0938 | LOSS: 0.1874 | ACC 0.9467\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0459/0938 | LOSS: 0.1874 | ACC 0.9468\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0460/0938 | LOSS: 0.1873 | ACC 0.9468\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0461/0938 | LOSS: 0.1873 | ACC 0.9469\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0462/0938 | LOSS: 0.1871 | ACC 0.9469\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0463/0938 | LOSS: 0.1870 | ACC 0.9469\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0464/0938 | LOSS: 0.1867 | ACC 0.9470\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0465/0938 | LOSS: 0.1868 | ACC 0.9471\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0466/0938 | LOSS: 0.1867 | ACC 0.9472\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0467/0938 | LOSS: 0.1865 | ACC 0.9472\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0468/0938 | LOSS: 0.1864 | ACC 0.9472\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0469/0938 | LOSS: 0.1862 | ACC 0.9473\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0470/0938 | LOSS: 0.1859 | ACC 0.9473\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0471/0938 | LOSS: 0.1858 | ACC 0.9473\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0472/0938 | LOSS: 0.1858 | ACC 0.9473\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0473/0938 | LOSS: 0.1857 | ACC 0.9474\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0474/0938 | LOSS: 0.1858 | ACC 0.9474\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0475/0938 | LOSS: 0.1858 | ACC 0.9473\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0476/0938 | LOSS: 0.1855 | ACC 0.9474\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0477/0938 | LOSS: 0.1853 | ACC 0.9474\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0478/0938 | LOSS: 0.1856 | ACC 0.9473\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0479/0938 | LOSS: 0.1854 | ACC 0.9473\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0480/0938 | LOSS: 0.1856 | ACC 0.9472\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0481/0938 | LOSS: 0.1857 | ACC 0.9472\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0482/0938 | LOSS: 0.1855 | ACC 0.9473\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0483/0938 | LOSS: 0.1853 | ACC 0.9474\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0484/0938 | LOSS: 0.1850 | ACC 0.9475\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0485/0938 | LOSS: 0.1850 | ACC 0.9475\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0486/0938 | LOSS: 0.1849 | ACC 0.9475\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0487/0938 | LOSS: 0.1850 | ACC 0.9475\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0488/0938 | LOSS: 0.1850 | ACC 0.9475\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0489/0938 | LOSS: 0.1849 | ACC 0.9475\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0490/0938 | LOSS: 0.1847 | ACC 0.9476\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0491/0938 | LOSS: 0.1849 | ACC 0.9476\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0492/0938 | LOSS: 0.1847 | ACC 0.9477\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0493/0938 | LOSS: 0.1848 | ACC 0.9476\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0494/0938 | LOSS: 0.1847 | ACC 0.9477\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0495/0938 | LOSS: 0.1844 | ACC 0.9478\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0496/0938 | LOSS: 0.1846 | ACC 0.9476\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0497/0938 | LOSS: 0.1845 | ACC 0.9477\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0498/0938 | LOSS: 0.1845 | ACC 0.9476\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0499/0938 | LOSS: 0.1849 | ACC 0.9476\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0500/0938 | LOSS: 0.1847 | ACC 0.9476\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0501/0938 | LOSS: 0.1853 | ACC 0.9475\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0502/0938 | LOSS: 0.1852 | ACC 0.9476\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0503/0938 | LOSS: 0.1857 | ACC 0.9475\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0504/0938 | LOSS: 0.1858 | ACC 0.9475\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0505/0938 | LOSS: 0.1858 | ACC 0.9474\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0506/0938 | LOSS: 0.1859 | ACC 0.9474\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0507/0938 | LOSS: 0.1858 | ACC 0.9474\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0508/0938 | LOSS: 0.1858 | ACC 0.9474\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0509/0938 | LOSS: 0.1859 | ACC 0.9473\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0510/0938 | LOSS: 0.1864 | ACC 0.9473\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0511/0938 | LOSS: 0.1863 | ACC 0.9473\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0512/0938 | LOSS: 0.1865 | ACC 0.9472\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0513/0938 | LOSS: 0.1864 | ACC 0.9472\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0514/0938 | LOSS: 0.1865 | ACC 0.9471\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0515/0938 | LOSS: 0.1867 | ACC 0.9471\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0516/0938 | LOSS: 0.1866 | ACC 0.9470\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0517/0938 | LOSS: 0.1866 | ACC 0.9470\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0518/0938 | LOSS: 0.1865 | ACC 0.9470\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0519/0938 | LOSS: 0.1863 | ACC 0.9471\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0520/0938 | LOSS: 0.1863 | ACC 0.9470\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0521/0938 | LOSS: 0.1861 | ACC 0.9471\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0522/0938 | LOSS: 0.1862 | ACC 0.9471\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0523/0938 | LOSS: 0.1861 | ACC 0.9471\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0524/0938 | LOSS: 0.1862 | ACC 0.9470\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0525/0938 | LOSS: 0.1861 | ACC 0.9470\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0526/0938 | LOSS: 0.1864 | ACC 0.9470\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0527/0938 | LOSS: 0.1865 | ACC 0.9469\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0528/0938 | LOSS: 0.1866 | ACC 0.9469\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0529/0938 | LOSS: 0.1870 | ACC 0.9468\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0530/0938 | LOSS: 0.1873 | ACC 0.9468\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0531/0938 | LOSS: 0.1872 | ACC 0.9468\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0532/0938 | LOSS: 0.1872 | ACC 0.9467\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0533/0938 | LOSS: 0.1873 | ACC 0.9467\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0534/0938 | LOSS: 0.1874 | ACC 0.9467\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0535/0938 | LOSS: 0.1878 | ACC 0.9465\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0536/0938 | LOSS: 0.1880 | ACC 0.9464\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0537/0938 | LOSS: 0.1879 | ACC 0.9465\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0538/0938 | LOSS: 0.1880 | ACC 0.9464\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0539/0938 | LOSS: 0.1878 | ACC 0.9465\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0540/0938 | LOSS: 0.1878 | ACC 0.9465\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0541/0938 | LOSS: 0.1877 | ACC 0.9465\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0542/0938 | LOSS: 0.1876 | ACC 0.9466\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0543/0938 | LOSS: 0.1875 | ACC 0.9465\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0544/0938 | LOSS: 0.1873 | ACC 0.9465\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0545/0938 | LOSS: 0.1872 | ACC 0.9465\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0546/0938 | LOSS: 0.1873 | ACC 0.9465\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0547/0938 | LOSS: 0.1873 | ACC 0.9465\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0548/0938 | LOSS: 0.1874 | ACC 0.9464\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0549/0938 | LOSS: 0.1875 | ACC 0.9464\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0550/0938 | LOSS: 0.1878 | ACC 0.9465\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0551/0938 | LOSS: 0.1877 | ACC 0.9465\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0552/0938 | LOSS: 0.1875 | ACC 0.9465\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0553/0938 | LOSS: 0.1876 | ACC 0.9465\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0554/0938 | LOSS: 0.1875 | ACC 0.9465\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0555/0938 | LOSS: 0.1875 | ACC 0.9466\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0556/0938 | LOSS: 0.1873 | ACC 0.9466\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0557/0938 | LOSS: 0.1873 | ACC 0.9466\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0558/0938 | LOSS: 0.1874 | ACC 0.9465\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0559/0938 | LOSS: 0.1874 | ACC 0.9466\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0560/0938 | LOSS: 0.1874 | ACC 0.9465\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0561/0938 | LOSS: 0.1878 | ACC 0.9465\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0562/0938 | LOSS: 0.1879 | ACC 0.9464\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0563/0938 | LOSS: 0.1877 | ACC 0.9464\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0564/0938 | LOSS: 0.1877 | ACC 0.9464\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0565/0938 | LOSS: 0.1877 | ACC 0.9464\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0566/0938 | LOSS: 0.1875 | ACC 0.9464\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0567/0938 | LOSS: 0.1875 | ACC 0.9464\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0568/0938 | LOSS: 0.1875 | ACC 0.9464\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0569/0938 | LOSS: 0.1879 | ACC 0.9463\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0570/0938 | LOSS: 0.1879 | ACC 0.9463\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0571/0938 | LOSS: 0.1878 | ACC 0.9463\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0572/0938 | LOSS: 0.1878 | ACC 0.9463\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0573/0938 | LOSS: 0.1877 | ACC 0.9463\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0574/0938 | LOSS: 0.1881 | ACC 0.9462\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0575/0938 | LOSS: 0.1881 | ACC 0.9462\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0576/0938 | LOSS: 0.1881 | ACC 0.9462\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: EPOCH 0005/0010 | BATCH 0577/0938 | LOSS: 0.1881 | ACC 0.9462\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0578/0938 | LOSS: 0.1883 | ACC 0.9462\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0579/0938 | LOSS: 0.1887 | ACC 0.9462\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0580/0938 | LOSS: 0.1889 | ACC 0.9461\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0581/0938 | LOSS: 0.1887 | ACC 0.9461\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0582/0938 | LOSS: 0.1887 | ACC 0.9461\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0583/0938 | LOSS: 0.1887 | ACC 0.9460\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0584/0938 | LOSS: 0.1886 | ACC 0.9461\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0585/0938 | LOSS: 0.1890 | ACC 0.9460\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0586/0938 | LOSS: 0.1889 | ACC 0.9461\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0587/0938 | LOSS: 0.1890 | ACC 0.9461\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0588/0938 | LOSS: 0.1894 | ACC 0.9460\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0589/0938 | LOSS: 0.1895 | ACC 0.9459\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0590/0938 | LOSS: 0.1894 | ACC 0.9459\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0591/0938 | LOSS: 0.1893 | ACC 0.9459\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0592/0938 | LOSS: 0.1894 | ACC 0.9459\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0593/0938 | LOSS: 0.1894 | ACC 0.9460\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0594/0938 | LOSS: 0.1898 | ACC 0.9458\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0595/0938 | LOSS: 0.1898 | ACC 0.9458\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0596/0938 | LOSS: 0.1897 | ACC 0.9458\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0597/0938 | LOSS: 0.1898 | ACC 0.9458\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0598/0938 | LOSS: 0.1897 | ACC 0.9459\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0599/0938 | LOSS: 0.1897 | ACC 0.9458\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0600/0938 | LOSS: 0.1895 | ACC 0.9459\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0601/0938 | LOSS: 0.1894 | ACC 0.9459\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0602/0938 | LOSS: 0.1894 | ACC 0.9460\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0603/0938 | LOSS: 0.1893 | ACC 0.9460\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0604/0938 | LOSS: 0.1892 | ACC 0.9461\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0605/0938 | LOSS: 0.1892 | ACC 0.9461\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0606/0938 | LOSS: 0.1891 | ACC 0.9461\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0607/0938 | LOSS: 0.1890 | ACC 0.9461\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0608/0938 | LOSS: 0.1890 | ACC 0.9461\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0609/0938 | LOSS: 0.1890 | ACC 0.9462\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0610/0938 | LOSS: 0.1891 | ACC 0.9462\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0611/0938 | LOSS: 0.1890 | ACC 0.9462\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0612/0938 | LOSS: 0.1890 | ACC 0.9462\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0613/0938 | LOSS: 0.1889 | ACC 0.9462\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0614/0938 | LOSS: 0.1890 | ACC 0.9461\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0615/0938 | LOSS: 0.1889 | ACC 0.9460\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0616/0938 | LOSS: 0.1890 | ACC 0.9460\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0617/0938 | LOSS: 0.1889 | ACC 0.9460\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0618/0938 | LOSS: 0.1892 | ACC 0.9459\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0619/0938 | LOSS: 0.1891 | ACC 0.9459\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0620/0938 | LOSS: 0.1892 | ACC 0.9459\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0621/0938 | LOSS: 0.1892 | ACC 0.9459\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0622/0938 | LOSS: 0.1891 | ACC 0.9459\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0623/0938 | LOSS: 0.1894 | ACC 0.9459\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0624/0938 | LOSS: 0.1893 | ACC 0.9459\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0625/0938 | LOSS: 0.1891 | ACC 0.9460\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0626/0938 | LOSS: 0.1894 | ACC 0.9459\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0627/0938 | LOSS: 0.1893 | ACC 0.9459\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0628/0938 | LOSS: 0.1893 | ACC 0.9459\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0629/0938 | LOSS: 0.1893 | ACC 0.9458\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0630/0938 | LOSS: 0.1892 | ACC 0.9458\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0631/0938 | LOSS: 0.1895 | ACC 0.9457\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0632/0938 | LOSS: 0.1894 | ACC 0.9457\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0633/0938 | LOSS: 0.1895 | ACC 0.9456\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0634/0938 | LOSS: 0.1896 | ACC 0.9456\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0635/0938 | LOSS: 0.1895 | ACC 0.9455\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0636/0938 | LOSS: 0.1895 | ACC 0.9455\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0637/0938 | LOSS: 0.1896 | ACC 0.9455\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0638/0938 | LOSS: 0.1894 | ACC 0.9455\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0639/0938 | LOSS: 0.1892 | ACC 0.9456\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0640/0938 | LOSS: 0.1892 | ACC 0.9456\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0641/0938 | LOSS: 0.1892 | ACC 0.9456\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0642/0938 | LOSS: 0.1893 | ACC 0.9456\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0643/0938 | LOSS: 0.1892 | ACC 0.9456\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0644/0938 | LOSS: 0.1895 | ACC 0.9455\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0645/0938 | LOSS: 0.1894 | ACC 0.9454\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0646/0938 | LOSS: 0.1895 | ACC 0.9454\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0647/0938 | LOSS: 0.1895 | ACC 0.9454\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0648/0938 | LOSS: 0.1893 | ACC 0.9454\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0649/0938 | LOSS: 0.1893 | ACC 0.9454\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0650/0938 | LOSS: 0.1893 | ACC 0.9454\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0651/0938 | LOSS: 0.1892 | ACC 0.9454\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0652/0938 | LOSS: 0.1891 | ACC 0.9454\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0653/0938 | LOSS: 0.1891 | ACC 0.9453\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0654/0938 | LOSS: 0.1890 | ACC 0.9453\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0655/0938 | LOSS: 0.1895 | ACC 0.9453\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0656/0938 | LOSS: 0.1894 | ACC 0.9453\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0657/0938 | LOSS: 0.1894 | ACC 0.9453\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0658/0938 | LOSS: 0.1895 | ACC 0.9454\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0659/0938 | LOSS: 0.1893 | ACC 0.9454\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0660/0938 | LOSS: 0.1892 | ACC 0.9454\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0661/0938 | LOSS: 0.1892 | ACC 0.9454\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0662/0938 | LOSS: 0.1893 | ACC 0.9454\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0663/0938 | LOSS: 0.1896 | ACC 0.9454\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0664/0938 | LOSS: 0.1896 | ACC 0.9454\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0665/0938 | LOSS: 0.1895 | ACC 0.9454\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0666/0938 | LOSS: 0.1895 | ACC 0.9454\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0667/0938 | LOSS: 0.1893 | ACC 0.9454\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0668/0938 | LOSS: 0.1895 | ACC 0.9454\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0669/0938 | LOSS: 0.1894 | ACC 0.9454\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0670/0938 | LOSS: 0.1894 | ACC 0.9454\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0671/0938 | LOSS: 0.1893 | ACC 0.9454\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0672/0938 | LOSS: 0.1892 | ACC 0.9455\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0673/0938 | LOSS: 0.1891 | ACC 0.9456\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0674/0938 | LOSS: 0.1893 | ACC 0.9455\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0675/0938 | LOSS: 0.1891 | ACC 0.9455\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0676/0938 | LOSS: 0.1893 | ACC 0.9455\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0677/0938 | LOSS: 0.1895 | ACC 0.9454\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0678/0938 | LOSS: 0.1897 | ACC 0.9454\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0679/0938 | LOSS: 0.1896 | ACC 0.9454\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0680/0938 | LOSS: 0.1896 | ACC 0.9454\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0681/0938 | LOSS: 0.1896 | ACC 0.9453\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0682/0938 | LOSS: 0.1896 | ACC 0.9453\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0683/0938 | LOSS: 0.1894 | ACC 0.9454\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0684/0938 | LOSS: 0.1895 | ACC 0.9454\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0685/0938 | LOSS: 0.1895 | ACC 0.9453\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0686/0938 | LOSS: 0.1894 | ACC 0.9454\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0687/0938 | LOSS: 0.1894 | ACC 0.9454\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0688/0938 | LOSS: 0.1892 | ACC 0.9454\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0689/0938 | LOSS: 0.1892 | ACC 0.9454\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0690/0938 | LOSS: 0.1890 | ACC 0.9455\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0691/0938 | LOSS: 0.1889 | ACC 0.9455\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0692/0938 | LOSS: 0.1889 | ACC 0.9455\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0693/0938 | LOSS: 0.1887 | ACC 0.9455\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0694/0938 | LOSS: 0.1888 | ACC 0.9455\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0695/0938 | LOSS: 0.1888 | ACC 0.9455\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0696/0938 | LOSS: 0.1890 | ACC 0.9455\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0697/0938 | LOSS: 0.1890 | ACC 0.9455\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0698/0938 | LOSS: 0.1888 | ACC 0.9456\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0699/0938 | LOSS: 0.1888 | ACC 0.9456\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0700/0938 | LOSS: 0.1888 | ACC 0.9456\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0701/0938 | LOSS: 0.1890 | ACC 0.9456\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0702/0938 | LOSS: 0.1889 | ACC 0.9456\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0703/0938 | LOSS: 0.1891 | ACC 0.9455\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0704/0938 | LOSS: 0.1891 | ACC 0.9456\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0705/0938 | LOSS: 0.1890 | ACC 0.9456\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0706/0938 | LOSS: 0.1889 | ACC 0.9457\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0707/0938 | LOSS: 0.1890 | ACC 0.9455\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: EPOCH 0005/0010 | BATCH 0708/0938 | LOSS: 0.1890 | ACC 0.9455\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0709/0938 | LOSS: 0.1889 | ACC 0.9455\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0710/0938 | LOSS: 0.1888 | ACC 0.9455\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0711/0938 | LOSS: 0.1887 | ACC 0.9456\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0712/0938 | LOSS: 0.1887 | ACC 0.9456\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0713/0938 | LOSS: 0.1886 | ACC 0.9456\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0714/0938 | LOSS: 0.1886 | ACC 0.9456\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0715/0938 | LOSS: 0.1885 | ACC 0.9456\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0716/0938 | LOSS: 0.1883 | ACC 0.9457\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0717/0938 | LOSS: 0.1882 | ACC 0.9457\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0718/0938 | LOSS: 0.1884 | ACC 0.9456\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0719/0938 | LOSS: 0.1882 | ACC 0.9456\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0720/0938 | LOSS: 0.1880 | ACC 0.9457\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0721/0938 | LOSS: 0.1879 | ACC 0.9457\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0722/0938 | LOSS: 0.1878 | ACC 0.9458\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0723/0938 | LOSS: 0.1878 | ACC 0.9458\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0724/0938 | LOSS: 0.1878 | ACC 0.9458\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0725/0938 | LOSS: 0.1877 | ACC 0.9458\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0726/0938 | LOSS: 0.1878 | ACC 0.9458\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0727/0938 | LOSS: 0.1877 | ACC 0.9458\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0728/0938 | LOSS: 0.1881 | ACC 0.9458\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0729/0938 | LOSS: 0.1880 | ACC 0.9458\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0730/0938 | LOSS: 0.1881 | ACC 0.9458\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0731/0938 | LOSS: 0.1883 | ACC 0.9458\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0732/0938 | LOSS: 0.1880 | ACC 0.9459\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0733/0938 | LOSS: 0.1880 | ACC 0.9460\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0734/0938 | LOSS: 0.1878 | ACC 0.9460\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0735/0938 | LOSS: 0.1878 | ACC 0.9460\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0736/0938 | LOSS: 0.1879 | ACC 0.9460\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0737/0938 | LOSS: 0.1878 | ACC 0.9460\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0738/0938 | LOSS: 0.1878 | ACC 0.9460\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0739/0938 | LOSS: 0.1877 | ACC 0.9460\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0740/0938 | LOSS: 0.1880 | ACC 0.9459\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0741/0938 | LOSS: 0.1880 | ACC 0.9459\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0742/0938 | LOSS: 0.1880 | ACC 0.9459\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0743/0938 | LOSS: 0.1879 | ACC 0.9459\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0744/0938 | LOSS: 0.1878 | ACC 0.9459\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0745/0938 | LOSS: 0.1877 | ACC 0.9459\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0746/0938 | LOSS: 0.1876 | ACC 0.9459\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0747/0938 | LOSS: 0.1877 | ACC 0.9459\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0748/0938 | LOSS: 0.1876 | ACC 0.9460\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0749/0938 | LOSS: 0.1876 | ACC 0.9460\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0750/0938 | LOSS: 0.1878 | ACC 0.9460\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0751/0938 | LOSS: 0.1878 | ACC 0.9460\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0752/0938 | LOSS: 0.1877 | ACC 0.9460\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0753/0938 | LOSS: 0.1876 | ACC 0.9460\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0754/0938 | LOSS: 0.1876 | ACC 0.9460\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0755/0938 | LOSS: 0.1877 | ACC 0.9460\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0756/0938 | LOSS: 0.1877 | ACC 0.9459\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0757/0938 | LOSS: 0.1876 | ACC 0.9459\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0758/0938 | LOSS: 0.1876 | ACC 0.9459\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0759/0938 | LOSS: 0.1876 | ACC 0.9459\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0760/0938 | LOSS: 0.1876 | ACC 0.9459\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0761/0938 | LOSS: 0.1875 | ACC 0.9460\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0762/0938 | LOSS: 0.1874 | ACC 0.9460\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0763/0938 | LOSS: 0.1874 | ACC 0.9460\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0764/0938 | LOSS: 0.1873 | ACC 0.9460\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0765/0938 | LOSS: 0.1873 | ACC 0.9459\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0766/0938 | LOSS: 0.1876 | ACC 0.9459\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0767/0938 | LOSS: 0.1877 | ACC 0.9459\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0768/0938 | LOSS: 0.1876 | ACC 0.9459\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0769/0938 | LOSS: 0.1877 | ACC 0.9459\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0770/0938 | LOSS: 0.1880 | ACC 0.9458\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0771/0938 | LOSS: 0.1880 | ACC 0.9458\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0772/0938 | LOSS: 0.1878 | ACC 0.9458\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0773/0938 | LOSS: 0.1878 | ACC 0.9458\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0774/0938 | LOSS: 0.1877 | ACC 0.9459\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0775/0938 | LOSS: 0.1877 | ACC 0.9459\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0776/0938 | LOSS: 0.1876 | ACC 0.9459\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0777/0938 | LOSS: 0.1875 | ACC 0.9459\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0778/0938 | LOSS: 0.1876 | ACC 0.9459\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0779/0938 | LOSS: 0.1877 | ACC 0.9459\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0780/0938 | LOSS: 0.1876 | ACC 0.9459\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0781/0938 | LOSS: 0.1879 | ACC 0.9458\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0782/0938 | LOSS: 0.1877 | ACC 0.9458\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0783/0938 | LOSS: 0.1877 | ACC 0.9458\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0784/0938 | LOSS: 0.1876 | ACC 0.9459\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0785/0938 | LOSS: 0.1876 | ACC 0.9458\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0786/0938 | LOSS: 0.1875 | ACC 0.9459\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0787/0938 | LOSS: 0.1874 | ACC 0.9459\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0788/0938 | LOSS: 0.1873 | ACC 0.9459\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0789/0938 | LOSS: 0.1873 | ACC 0.9459\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0790/0938 | LOSS: 0.1872 | ACC 0.9459\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0791/0938 | LOSS: 0.1871 | ACC 0.9460\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0792/0938 | LOSS: 0.1871 | ACC 0.9459\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0793/0938 | LOSS: 0.1871 | ACC 0.9459\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0794/0938 | LOSS: 0.1871 | ACC 0.9459\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0795/0938 | LOSS: 0.1871 | ACC 0.9459\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0796/0938 | LOSS: 0.1871 | ACC 0.9459\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0797/0938 | LOSS: 0.1871 | ACC 0.9459\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0798/0938 | LOSS: 0.1871 | ACC 0.9458\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0799/0938 | LOSS: 0.1871 | ACC 0.9458\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0800/0938 | LOSS: 0.1870 | ACC 0.9458\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0801/0938 | LOSS: 0.1871 | ACC 0.9458\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0802/0938 | LOSS: 0.1872 | ACC 0.9457\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0803/0938 | LOSS: 0.1873 | ACC 0.9457\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0804/0938 | LOSS: 0.1872 | ACC 0.9457\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0805/0938 | LOSS: 0.1871 | ACC 0.9458\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0806/0938 | LOSS: 0.1872 | ACC 0.9457\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0807/0938 | LOSS: 0.1873 | ACC 0.9457\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0808/0938 | LOSS: 0.1872 | ACC 0.9457\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0809/0938 | LOSS: 0.1871 | ACC 0.9457\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0810/0938 | LOSS: 0.1873 | ACC 0.9457\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0811/0938 | LOSS: 0.1872 | ACC 0.9457\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0812/0938 | LOSS: 0.1874 | ACC 0.9456\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0813/0938 | LOSS: 0.1873 | ACC 0.9456\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0814/0938 | LOSS: 0.1873 | ACC 0.9456\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0815/0938 | LOSS: 0.1872 | ACC 0.9457\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0816/0938 | LOSS: 0.1871 | ACC 0.9457\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0817/0938 | LOSS: 0.1872 | ACC 0.9457\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0818/0938 | LOSS: 0.1870 | ACC 0.9457\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0819/0938 | LOSS: 0.1872 | ACC 0.9457\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0820/0938 | LOSS: 0.1871 | ACC 0.9457\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0821/0938 | LOSS: 0.1871 | ACC 0.9457\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0822/0938 | LOSS: 0.1872 | ACC 0.9457\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0823/0938 | LOSS: 0.1872 | ACC 0.9457\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0824/0938 | LOSS: 0.1873 | ACC 0.9457\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0825/0938 | LOSS: 0.1872 | ACC 0.9457\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0826/0938 | LOSS: 0.1872 | ACC 0.9457\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0827/0938 | LOSS: 0.1871 | ACC 0.9457\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0828/0938 | LOSS: 0.1871 | ACC 0.9457\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0829/0938 | LOSS: 0.1870 | ACC 0.9457\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0830/0938 | LOSS: 0.1870 | ACC 0.9457\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0831/0938 | LOSS: 0.1872 | ACC 0.9457\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0832/0938 | LOSS: 0.1873 | ACC 0.9456\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0833/0938 | LOSS: 0.1871 | ACC 0.9457\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0834/0938 | LOSS: 0.1871 | ACC 0.9457\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: EPOCH 0005/0010 | BATCH 0835/0938 | LOSS: 0.1871 | ACC 0.9457\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0836/0938 | LOSS: 0.1871 | ACC 0.9457\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0837/0938 | LOSS: 0.1872 | ACC 0.9457\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0838/0938 | LOSS: 0.1872 | ACC 0.9457\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0839/0938 | LOSS: 0.1871 | ACC 0.9457\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0840/0938 | LOSS: 0.1872 | ACC 0.9457\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0841/0938 | LOSS: 0.1874 | ACC 0.9457\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0842/0938 | LOSS: 0.1874 | ACC 0.9457\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0843/0938 | LOSS: 0.1876 | ACC 0.9456\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0844/0938 | LOSS: 0.1876 | ACC 0.9457\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0845/0938 | LOSS: 0.1876 | ACC 0.9457\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0846/0938 | LOSS: 0.1876 | ACC 0.9457\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0847/0938 | LOSS: 0.1875 | ACC 0.9456\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0848/0938 | LOSS: 0.1875 | ACC 0.9457\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0849/0938 | LOSS: 0.1874 | ACC 0.9457\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0850/0938 | LOSS: 0.1874 | ACC 0.9457\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0851/0938 | LOSS: 0.1874 | ACC 0.9457\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0852/0938 | LOSS: 0.1873 | ACC 0.9457\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0853/0938 | LOSS: 0.1872 | ACC 0.9457\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0854/0938 | LOSS: 0.1872 | ACC 0.9457\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0855/0938 | LOSS: 0.1872 | ACC 0.9457\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0856/0938 | LOSS: 0.1873 | ACC 0.9457\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0857/0938 | LOSS: 0.1873 | ACC 0.9457\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0858/0938 | LOSS: 0.1872 | ACC 0.9457\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0859/0938 | LOSS: 0.1873 | ACC 0.9456\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0860/0938 | LOSS: 0.1872 | ACC 0.9456\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0861/0938 | LOSS: 0.1876 | ACC 0.9456\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0862/0938 | LOSS: 0.1874 | ACC 0.9456\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0863/0938 | LOSS: 0.1874 | ACC 0.9456\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0864/0938 | LOSS: 0.1875 | ACC 0.9456\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0865/0938 | LOSS: 0.1873 | ACC 0.9457\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0866/0938 | LOSS: 0.1874 | ACC 0.9456\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0867/0938 | LOSS: 0.1875 | ACC 0.9456\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0868/0938 | LOSS: 0.1876 | ACC 0.9455\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0869/0938 | LOSS: 0.1877 | ACC 0.9455\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0870/0938 | LOSS: 0.1877 | ACC 0.9455\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0871/0938 | LOSS: 0.1876 | ACC 0.9455\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0872/0938 | LOSS: 0.1878 | ACC 0.9454\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0873/0938 | LOSS: 0.1877 | ACC 0.9454\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0874/0938 | LOSS: 0.1877 | ACC 0.9455\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0875/0938 | LOSS: 0.1877 | ACC 0.9454\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0876/0938 | LOSS: 0.1878 | ACC 0.9454\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0877/0938 | LOSS: 0.1877 | ACC 0.9454\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0878/0938 | LOSS: 0.1877 | ACC 0.9455\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0879/0938 | LOSS: 0.1877 | ACC 0.9455\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0880/0938 | LOSS: 0.1876 | ACC 0.9455\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0881/0938 | LOSS: 0.1875 | ACC 0.9455\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0882/0938 | LOSS: 0.1875 | ACC 0.9455\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0883/0938 | LOSS: 0.1877 | ACC 0.9454\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0884/0938 | LOSS: 0.1876 | ACC 0.9454\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0885/0938 | LOSS: 0.1877 | ACC 0.9454\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0886/0938 | LOSS: 0.1877 | ACC 0.9454\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0887/0938 | LOSS: 0.1876 | ACC 0.9454\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0888/0938 | LOSS: 0.1876 | ACC 0.9454\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0889/0938 | LOSS: 0.1876 | ACC 0.9454\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0890/0938 | LOSS: 0.1878 | ACC 0.9454\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0891/0938 | LOSS: 0.1877 | ACC 0.9454\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0892/0938 | LOSS: 0.1879 | ACC 0.9454\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0893/0938 | LOSS: 0.1878 | ACC 0.9454\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0894/0938 | LOSS: 0.1878 | ACC 0.9453\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0895/0938 | LOSS: 0.1878 | ACC 0.9453\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0896/0938 | LOSS: 0.1877 | ACC 0.9453\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0897/0938 | LOSS: 0.1876 | ACC 0.9454\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0898/0938 | LOSS: 0.1876 | ACC 0.9454\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0899/0938 | LOSS: 0.1876 | ACC 0.9454\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0900/0938 | LOSS: 0.1878 | ACC 0.9454\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0901/0938 | LOSS: 0.1877 | ACC 0.9454\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0902/0938 | LOSS: 0.1878 | ACC 0.9454\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0903/0938 | LOSS: 0.1879 | ACC 0.9453\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0904/0938 | LOSS: 0.1878 | ACC 0.9453\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0905/0938 | LOSS: 0.1878 | ACC 0.9453\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0906/0938 | LOSS: 0.1877 | ACC 0.9453\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0907/0938 | LOSS: 0.1875 | ACC 0.9454\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0908/0938 | LOSS: 0.1876 | ACC 0.9453\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0909/0938 | LOSS: 0.1876 | ACC 0.9453\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0910/0938 | LOSS: 0.1877 | ACC 0.9453\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0911/0938 | LOSS: 0.1876 | ACC 0.9453\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0912/0938 | LOSS: 0.1875 | ACC 0.9453\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0913/0938 | LOSS: 0.1876 | ACC 0.9453\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0914/0938 | LOSS: 0.1877 | ACC 0.9453\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0915/0938 | LOSS: 0.1877 | ACC 0.9453\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0916/0938 | LOSS: 0.1876 | ACC 0.9453\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0917/0938 | LOSS: 0.1875 | ACC 0.9453\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0918/0938 | LOSS: 0.1876 | ACC 0.9453\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0919/0938 | LOSS: 0.1876 | ACC 0.9453\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0920/0938 | LOSS: 0.1878 | ACC 0.9453\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0921/0938 | LOSS: 0.1879 | ACC 0.9453\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0922/0938 | LOSS: 0.1880 | ACC 0.9452\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0923/0938 | LOSS: 0.1879 | ACC 0.9453\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0924/0938 | LOSS: 0.1878 | ACC 0.9453\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0925/0938 | LOSS: 0.1880 | ACC 0.9453\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0926/0938 | LOSS: 0.1881 | ACC 0.9453\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0927/0938 | LOSS: 0.1880 | ACC 0.9452\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0928/0938 | LOSS: 0.1881 | ACC 0.9452\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0929/0938 | LOSS: 0.1880 | ACC 0.9452\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0930/0938 | LOSS: 0.1880 | ACC 0.9452\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0931/0938 | LOSS: 0.1879 | ACC 0.9453\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0932/0938 | LOSS: 0.1878 | ACC 0.9453\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0933/0938 | LOSS: 0.1877 | ACC 0.9453\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0934/0938 | LOSS: 0.1877 | ACC 0.9453\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0935/0938 | LOSS: 0.1878 | ACC 0.9453\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0936/0938 | LOSS: 0.1879 | ACC 0.9453\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0937/0938 | LOSS: 0.1877 | ACC 0.9453\n",
      "TRAIN: EPOCH 0005/0010 | BATCH 0938/0938 | LOSS: 0.1878 | ACC 0.9453\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0001/0938 | LOSS: 0.1219 | ACC 0.9688\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0002/0938 | LOSS: 0.1137 | ACC 0.9609\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0003/0938 | LOSS: 0.1316 | ACC 0.9583\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0004/0938 | LOSS: 0.1453 | ACC 0.9609\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0005/0938 | LOSS: 0.1368 | ACC 0.9625\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0006/0938 | LOSS: 0.1291 | ACC 0.9635\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0007/0938 | LOSS: 0.1518 | ACC 0.9554\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0008/0938 | LOSS: 0.1533 | ACC 0.9551\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0009/0938 | LOSS: 0.1471 | ACC 0.9549\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0010/0938 | LOSS: 0.1467 | ACC 0.9531\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0011/0938 | LOSS: 0.1490 | ACC 0.9503\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0012/0938 | LOSS: 0.1623 | ACC 0.9479\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0013/0938 | LOSS: 0.1618 | ACC 0.9483\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0014/0938 | LOSS: 0.1678 | ACC 0.9453\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0015/0938 | LOSS: 0.1672 | ACC 0.9458\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0016/0938 | LOSS: 0.1657 | ACC 0.9453\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0017/0938 | LOSS: 0.1640 | ACC 0.9467\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0018/0938 | LOSS: 0.1628 | ACC 0.9479\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0019/0938 | LOSS: 0.1869 | ACC 0.9449\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0020/0938 | LOSS: 0.1996 | ACC 0.9414\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0021/0938 | LOSS: 0.2022 | ACC 0.9412\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0022/0938 | LOSS: 0.2012 | ACC 0.9418\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: EPOCH 0006/0010 | BATCH 0023/0938 | LOSS: 0.2055 | ACC 0.9409\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0024/0938 | LOSS: 0.2018 | ACC 0.9421\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0025/0938 | LOSS: 0.2017 | ACC 0.9400\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0026/0938 | LOSS: 0.1985 | ACC 0.9405\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0027/0938 | LOSS: 0.1975 | ACC 0.9410\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0028/0938 | LOSS: 0.2014 | ACC 0.9397\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0029/0938 | LOSS: 0.2032 | ACC 0.9407\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0030/0938 | LOSS: 0.2031 | ACC 0.9401\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0031/0938 | LOSS: 0.2017 | ACC 0.9395\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0032/0938 | LOSS: 0.2063 | ACC 0.9395\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0033/0938 | LOSS: 0.2107 | ACC 0.9394\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0034/0938 | LOSS: 0.2092 | ACC 0.9393\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0035/0938 | LOSS: 0.2069 | ACC 0.9406\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0036/0938 | LOSS: 0.2116 | ACC 0.9397\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0037/0938 | LOSS: 0.2087 | ACC 0.9396\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0038/0938 | LOSS: 0.2072 | ACC 0.9400\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0039/0938 | LOSS: 0.2049 | ACC 0.9407\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0040/0938 | LOSS: 0.2057 | ACC 0.9406\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0041/0938 | LOSS: 0.2040 | ACC 0.9409\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0042/0938 | LOSS: 0.2029 | ACC 0.9412\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0043/0938 | LOSS: 0.2037 | ACC 0.9411\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0044/0938 | LOSS: 0.2012 | ACC 0.9421\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0045/0938 | LOSS: 0.2031 | ACC 0.9420\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0046/0938 | LOSS: 0.2002 | ACC 0.9433\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0047/0938 | LOSS: 0.1976 | ACC 0.9445\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0048/0938 | LOSS: 0.1983 | ACC 0.9434\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0049/0938 | LOSS: 0.1984 | ACC 0.9436\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0050/0938 | LOSS: 0.1972 | ACC 0.9441\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0051/0938 | LOSS: 0.1947 | ACC 0.9449\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0052/0938 | LOSS: 0.1976 | ACC 0.9432\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0053/0938 | LOSS: 0.1990 | ACC 0.9437\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0054/0938 | LOSS: 0.1963 | ACC 0.9447\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0055/0938 | LOSS: 0.1961 | ACC 0.9443\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0056/0938 | LOSS: 0.1961 | ACC 0.9445\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0057/0938 | LOSS: 0.1939 | ACC 0.9452\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0058/0938 | LOSS: 0.1945 | ACC 0.9445\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0059/0938 | LOSS: 0.1926 | ACC 0.9452\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0060/0938 | LOSS: 0.1936 | ACC 0.9443\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0061/0938 | LOSS: 0.1926 | ACC 0.9442\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0062/0938 | LOSS: 0.1917 | ACC 0.9441\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0063/0938 | LOSS: 0.1909 | ACC 0.9447\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0064/0938 | LOSS: 0.1896 | ACC 0.9451\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0065/0938 | LOSS: 0.1873 | ACC 0.9457\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0066/0938 | LOSS: 0.1875 | ACC 0.9458\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0067/0938 | LOSS: 0.1865 | ACC 0.9461\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0068/0938 | LOSS: 0.1859 | ACC 0.9465\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0069/0938 | LOSS: 0.1850 | ACC 0.9466\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0070/0938 | LOSS: 0.1878 | ACC 0.9460\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0071/0938 | LOSS: 0.1882 | ACC 0.9456\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0072/0938 | LOSS: 0.1867 | ACC 0.9464\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0073/0938 | LOSS: 0.1858 | ACC 0.9467\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0074/0938 | LOSS: 0.1843 | ACC 0.9474\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0075/0938 | LOSS: 0.1829 | ACC 0.9479\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0076/0938 | LOSS: 0.1832 | ACC 0.9476\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0077/0938 | LOSS: 0.1836 | ACC 0.9474\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0078/0938 | LOSS: 0.1831 | ACC 0.9471\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0079/0938 | LOSS: 0.1830 | ACC 0.9468\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0080/0938 | LOSS: 0.1823 | ACC 0.9473\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0081/0938 | LOSS: 0.1815 | ACC 0.9475\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0082/0938 | LOSS: 0.1819 | ACC 0.9472\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0083/0938 | LOSS: 0.1812 | ACC 0.9475\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0084/0938 | LOSS: 0.1821 | ACC 0.9474\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0085/0938 | LOSS: 0.1812 | ACC 0.9476\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0086/0938 | LOSS: 0.1813 | ACC 0.9475\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0087/0938 | LOSS: 0.1810 | ACC 0.9479\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0088/0938 | LOSS: 0.1803 | ACC 0.9480\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0089/0938 | LOSS: 0.1803 | ACC 0.9480\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0090/0938 | LOSS: 0.1812 | ACC 0.9479\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0091/0938 | LOSS: 0.1806 | ACC 0.9478\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0092/0938 | LOSS: 0.1795 | ACC 0.9482\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0093/0938 | LOSS: 0.1790 | ACC 0.9481\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0094/0938 | LOSS: 0.1803 | ACC 0.9475\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0095/0938 | LOSS: 0.1805 | ACC 0.9475\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0096/0938 | LOSS: 0.1808 | ACC 0.9476\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0097/0938 | LOSS: 0.1817 | ACC 0.9473\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0098/0938 | LOSS: 0.1809 | ACC 0.9475\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0099/0938 | LOSS: 0.1802 | ACC 0.9478\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0100/0938 | LOSS: 0.1796 | ACC 0.9478\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0101/0938 | LOSS: 0.1791 | ACC 0.9477\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0102/0938 | LOSS: 0.1811 | ACC 0.9472\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0103/0938 | LOSS: 0.1812 | ACC 0.9472\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0104/0938 | LOSS: 0.1806 | ACC 0.9471\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0105/0938 | LOSS: 0.1805 | ACC 0.9472\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0106/0938 | LOSS: 0.1802 | ACC 0.9472\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0107/0938 | LOSS: 0.1795 | ACC 0.9473\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0108/0938 | LOSS: 0.1787 | ACC 0.9476\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0109/0938 | LOSS: 0.1781 | ACC 0.9480\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0110/0938 | LOSS: 0.1794 | ACC 0.9477\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0111/0938 | LOSS: 0.1802 | ACC 0.9478\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0112/0938 | LOSS: 0.1806 | ACC 0.9478\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0113/0938 | LOSS: 0.1799 | ACC 0.9480\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0114/0938 | LOSS: 0.1800 | ACC 0.9481\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0115/0938 | LOSS: 0.1798 | ACC 0.9482\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0116/0938 | LOSS: 0.1803 | ACC 0.9480\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0117/0938 | LOSS: 0.1800 | ACC 0.9479\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0118/0938 | LOSS: 0.1803 | ACC 0.9480\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0119/0938 | LOSS: 0.1803 | ACC 0.9480\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0120/0938 | LOSS: 0.1825 | ACC 0.9480\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0121/0938 | LOSS: 0.1829 | ACC 0.9478\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0122/0938 | LOSS: 0.1822 | ACC 0.9479\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0123/0938 | LOSS: 0.1815 | ACC 0.9479\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0124/0938 | LOSS: 0.1815 | ACC 0.9480\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0125/0938 | LOSS: 0.1820 | ACC 0.9477\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0126/0938 | LOSS: 0.1814 | ACC 0.9479\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0127/0938 | LOSS: 0.1808 | ACC 0.9480\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0128/0938 | LOSS: 0.1811 | ACC 0.9476\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0129/0938 | LOSS: 0.1801 | ACC 0.9479\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0130/0938 | LOSS: 0.1797 | ACC 0.9482\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0131/0938 | LOSS: 0.1797 | ACC 0.9479\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0132/0938 | LOSS: 0.1805 | ACC 0.9478\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0133/0938 | LOSS: 0.1797 | ACC 0.9481\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0134/0938 | LOSS: 0.1806 | ACC 0.9476\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0135/0938 | LOSS: 0.1806 | ACC 0.9478\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0136/0938 | LOSS: 0.1797 | ACC 0.9480\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0137/0938 | LOSS: 0.1794 | ACC 0.9480\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0138/0938 | LOSS: 0.1793 | ACC 0.9480\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0139/0938 | LOSS: 0.1795 | ACC 0.9478\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0140/0938 | LOSS: 0.1793 | ACC 0.9478\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0141/0938 | LOSS: 0.1794 | ACC 0.9477\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0142/0938 | LOSS: 0.1789 | ACC 0.9477\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0143/0938 | LOSS: 0.1781 | ACC 0.9479\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0144/0938 | LOSS: 0.1787 | ACC 0.9479\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0145/0938 | LOSS: 0.1784 | ACC 0.9480\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0146/0938 | LOSS: 0.1795 | ACC 0.9481\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0147/0938 | LOSS: 0.1793 | ACC 0.9481\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0148/0938 | LOSS: 0.1802 | ACC 0.9481\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0149/0938 | LOSS: 0.1795 | ACC 0.9483\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0150/0938 | LOSS: 0.1794 | ACC 0.9482\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: EPOCH 0006/0010 | BATCH 0151/0938 | LOSS: 0.1796 | ACC 0.9483\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0152/0938 | LOSS: 0.1798 | ACC 0.9483\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0153/0938 | LOSS: 0.1792 | ACC 0.9483\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0154/0938 | LOSS: 0.1799 | ACC 0.9485\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0155/0938 | LOSS: 0.1791 | ACC 0.9488\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0156/0938 | LOSS: 0.1796 | ACC 0.9487\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0157/0938 | LOSS: 0.1796 | ACC 0.9486\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0158/0938 | LOSS: 0.1797 | ACC 0.9487\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0159/0938 | LOSS: 0.1812 | ACC 0.9486\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0160/0938 | LOSS: 0.1811 | ACC 0.9484\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0161/0938 | LOSS: 0.1810 | ACC 0.9484\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0162/0938 | LOSS: 0.1819 | ACC 0.9483\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0163/0938 | LOSS: 0.1822 | ACC 0.9483\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0164/0938 | LOSS: 0.1833 | ACC 0.9479\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0165/0938 | LOSS: 0.1834 | ACC 0.9478\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0166/0938 | LOSS: 0.1834 | ACC 0.9478\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0167/0938 | LOSS: 0.1834 | ACC 0.9478\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0168/0938 | LOSS: 0.1837 | ACC 0.9475\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0169/0938 | LOSS: 0.1837 | ACC 0.9475\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0170/0938 | LOSS: 0.1838 | ACC 0.9476\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0171/0938 | LOSS: 0.1838 | ACC 0.9476\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0172/0938 | LOSS: 0.1836 | ACC 0.9477\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0173/0938 | LOSS: 0.1838 | ACC 0.9477\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0174/0938 | LOSS: 0.1831 | ACC 0.9480\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0175/0938 | LOSS: 0.1831 | ACC 0.9480\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0176/0938 | LOSS: 0.1825 | ACC 0.9482\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0177/0938 | LOSS: 0.1817 | ACC 0.9484\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0178/0938 | LOSS: 0.1818 | ACC 0.9484\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0179/0938 | LOSS: 0.1816 | ACC 0.9485\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0180/0938 | LOSS: 0.1814 | ACC 0.9485\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0181/0938 | LOSS: 0.1820 | ACC 0.9485\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0182/0938 | LOSS: 0.1822 | ACC 0.9482\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0183/0938 | LOSS: 0.1816 | ACC 0.9483\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0184/0938 | LOSS: 0.1818 | ACC 0.9483\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0185/0938 | LOSS: 0.1818 | ACC 0.9483\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0186/0938 | LOSS: 0.1814 | ACC 0.9483\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0187/0938 | LOSS: 0.1813 | ACC 0.9484\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0188/0938 | LOSS: 0.1811 | ACC 0.9484\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0189/0938 | LOSS: 0.1811 | ACC 0.9485\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0190/0938 | LOSS: 0.1809 | ACC 0.9485\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0191/0938 | LOSS: 0.1811 | ACC 0.9484\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0192/0938 | LOSS: 0.1823 | ACC 0.9482\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0193/0938 | LOSS: 0.1823 | ACC 0.9481\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0194/0938 | LOSS: 0.1834 | ACC 0.9477\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0195/0938 | LOSS: 0.1831 | ACC 0.9478\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0196/0938 | LOSS: 0.1831 | ACC 0.9479\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0197/0938 | LOSS: 0.1834 | ACC 0.9477\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0198/0938 | LOSS: 0.1833 | ACC 0.9478\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0199/0938 | LOSS: 0.1830 | ACC 0.9479\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0200/0938 | LOSS: 0.1829 | ACC 0.9479\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0201/0938 | LOSS: 0.1836 | ACC 0.9478\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0202/0938 | LOSS: 0.1832 | ACC 0.9479\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0203/0938 | LOSS: 0.1833 | ACC 0.9478\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0204/0938 | LOSS: 0.1829 | ACC 0.9479\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0205/0938 | LOSS: 0.1833 | ACC 0.9479\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0206/0938 | LOSS: 0.1831 | ACC 0.9480\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0207/0938 | LOSS: 0.1839 | ACC 0.9478\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0208/0938 | LOSS: 0.1833 | ACC 0.9479\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0209/0938 | LOSS: 0.1828 | ACC 0.9480\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0210/0938 | LOSS: 0.1835 | ACC 0.9478\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0211/0938 | LOSS: 0.1843 | ACC 0.9476\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0212/0938 | LOSS: 0.1838 | ACC 0.9479\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0213/0938 | LOSS: 0.1834 | ACC 0.9479\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0214/0938 | LOSS: 0.1831 | ACC 0.9480\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0215/0938 | LOSS: 0.1836 | ACC 0.9480\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0216/0938 | LOSS: 0.1831 | ACC 0.9482\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0217/0938 | LOSS: 0.1828 | ACC 0.9484\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0218/0938 | LOSS: 0.1825 | ACC 0.9485\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0219/0938 | LOSS: 0.1832 | ACC 0.9482\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0220/0938 | LOSS: 0.1835 | ACC 0.9480\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0221/0938 | LOSS: 0.1834 | ACC 0.9480\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0222/0938 | LOSS: 0.1833 | ACC 0.9480\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0223/0938 | LOSS: 0.1831 | ACC 0.9480\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0224/0938 | LOSS: 0.1835 | ACC 0.9480\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0225/0938 | LOSS: 0.1836 | ACC 0.9481\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0226/0938 | LOSS: 0.1839 | ACC 0.9479\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0227/0938 | LOSS: 0.1834 | ACC 0.9481\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0228/0938 | LOSS: 0.1835 | ACC 0.9480\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0229/0938 | LOSS: 0.1833 | ACC 0.9481\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0230/0938 | LOSS: 0.1835 | ACC 0.9479\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0231/0938 | LOSS: 0.1830 | ACC 0.9481\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0232/0938 | LOSS: 0.1829 | ACC 0.9481\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0233/0938 | LOSS: 0.1827 | ACC 0.9480\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0234/0938 | LOSS: 0.1828 | ACC 0.9480\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0235/0938 | LOSS: 0.1835 | ACC 0.9479\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0236/0938 | LOSS: 0.1833 | ACC 0.9479\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0237/0938 | LOSS: 0.1831 | ACC 0.9480\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0238/0938 | LOSS: 0.1827 | ACC 0.9481\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0239/0938 | LOSS: 0.1823 | ACC 0.9483\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0240/0938 | LOSS: 0.1824 | ACC 0.9483\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0241/0938 | LOSS: 0.1824 | ACC 0.9483\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0242/0938 | LOSS: 0.1831 | ACC 0.9482\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0243/0938 | LOSS: 0.1833 | ACC 0.9481\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0244/0938 | LOSS: 0.1831 | ACC 0.9482\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0245/0938 | LOSS: 0.1828 | ACC 0.9482\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0246/0938 | LOSS: 0.1824 | ACC 0.9483\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0247/0938 | LOSS: 0.1829 | ACC 0.9483\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0248/0938 | LOSS: 0.1829 | ACC 0.9484\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0249/0938 | LOSS: 0.1828 | ACC 0.9485\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0250/0938 | LOSS: 0.1827 | ACC 0.9486\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0251/0938 | LOSS: 0.1824 | ACC 0.9486\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0252/0938 | LOSS: 0.1821 | ACC 0.9488\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0253/0938 | LOSS: 0.1820 | ACC 0.9488\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0254/0938 | LOSS: 0.1819 | ACC 0.9488\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0255/0938 | LOSS: 0.1820 | ACC 0.9487\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0256/0938 | LOSS: 0.1827 | ACC 0.9486\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0257/0938 | LOSS: 0.1825 | ACC 0.9486\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0258/0938 | LOSS: 0.1827 | ACC 0.9485\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0259/0938 | LOSS: 0.1823 | ACC 0.9486\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0260/0938 | LOSS: 0.1820 | ACC 0.9487\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0261/0938 | LOSS: 0.1817 | ACC 0.9488\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0262/0938 | LOSS: 0.1817 | ACC 0.9488\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0263/0938 | LOSS: 0.1814 | ACC 0.9488\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0264/0938 | LOSS: 0.1812 | ACC 0.9489\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0265/0938 | LOSS: 0.1807 | ACC 0.9491\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0266/0938 | LOSS: 0.1806 | ACC 0.9490\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0267/0938 | LOSS: 0.1802 | ACC 0.9491\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0268/0938 | LOSS: 0.1799 | ACC 0.9492\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0269/0938 | LOSS: 0.1805 | ACC 0.9489\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0270/0938 | LOSS: 0.1801 | ACC 0.9490\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0271/0938 | LOSS: 0.1799 | ACC 0.9490\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0272/0938 | LOSS: 0.1796 | ACC 0.9492\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0273/0938 | LOSS: 0.1794 | ACC 0.9492\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0274/0938 | LOSS: 0.1794 | ACC 0.9492\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0275/0938 | LOSS: 0.1803 | ACC 0.9493\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0276/0938 | LOSS: 0.1803 | ACC 0.9492\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0277/0938 | LOSS: 0.1800 | ACC 0.9493\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0278/0938 | LOSS: 0.1798 | ACC 0.9493\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0279/0938 | LOSS: 0.1798 | ACC 0.9493\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: EPOCH 0006/0010 | BATCH 0280/0938 | LOSS: 0.1800 | ACC 0.9491\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0281/0938 | LOSS: 0.1798 | ACC 0.9491\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0282/0938 | LOSS: 0.1796 | ACC 0.9491\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0283/0938 | LOSS: 0.1794 | ACC 0.9490\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0284/0938 | LOSS: 0.1800 | ACC 0.9490\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0285/0938 | LOSS: 0.1800 | ACC 0.9489\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0286/0938 | LOSS: 0.1796 | ACC 0.9491\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0287/0938 | LOSS: 0.1798 | ACC 0.9490\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0288/0938 | LOSS: 0.1794 | ACC 0.9491\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0289/0938 | LOSS: 0.1791 | ACC 0.9491\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0290/0938 | LOSS: 0.1793 | ACC 0.9489\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0291/0938 | LOSS: 0.1794 | ACC 0.9489\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0292/0938 | LOSS: 0.1791 | ACC 0.9490\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0293/0938 | LOSS: 0.1792 | ACC 0.9488\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0294/0938 | LOSS: 0.1792 | ACC 0.9486\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0295/0938 | LOSS: 0.1789 | ACC 0.9487\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0296/0938 | LOSS: 0.1788 | ACC 0.9486\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0297/0938 | LOSS: 0.1786 | ACC 0.9487\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0298/0938 | LOSS: 0.1785 | ACC 0.9487\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0299/0938 | LOSS: 0.1791 | ACC 0.9486\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0300/0938 | LOSS: 0.1789 | ACC 0.9487\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0301/0938 | LOSS: 0.1794 | ACC 0.9486\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0302/0938 | LOSS: 0.1794 | ACC 0.9486\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0303/0938 | LOSS: 0.1796 | ACC 0.9486\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0304/0938 | LOSS: 0.1799 | ACC 0.9486\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0305/0938 | LOSS: 0.1805 | ACC 0.9484\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0306/0938 | LOSS: 0.1806 | ACC 0.9483\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0307/0938 | LOSS: 0.1811 | ACC 0.9480\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0308/0938 | LOSS: 0.1808 | ACC 0.9481\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0309/0938 | LOSS: 0.1808 | ACC 0.9481\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0310/0938 | LOSS: 0.1808 | ACC 0.9480\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0311/0938 | LOSS: 0.1808 | ACC 0.9480\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0312/0938 | LOSS: 0.1811 | ACC 0.9479\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0313/0938 | LOSS: 0.1809 | ACC 0.9479\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0314/0938 | LOSS: 0.1810 | ACC 0.9479\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0315/0938 | LOSS: 0.1814 | ACC 0.9480\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0316/0938 | LOSS: 0.1811 | ACC 0.9481\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0317/0938 | LOSS: 0.1815 | ACC 0.9479\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0318/0938 | LOSS: 0.1811 | ACC 0.9480\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0319/0938 | LOSS: 0.1809 | ACC 0.9479\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0320/0938 | LOSS: 0.1809 | ACC 0.9479\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0321/0938 | LOSS: 0.1806 | ACC 0.9480\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0322/0938 | LOSS: 0.1804 | ACC 0.9480\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0323/0938 | LOSS: 0.1806 | ACC 0.9478\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0324/0938 | LOSS: 0.1808 | ACC 0.9477\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0325/0938 | LOSS: 0.1804 | ACC 0.9478\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0326/0938 | LOSS: 0.1803 | ACC 0.9478\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0327/0938 | LOSS: 0.1802 | ACC 0.9478\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0328/0938 | LOSS: 0.1800 | ACC 0.9478\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0329/0938 | LOSS: 0.1801 | ACC 0.9479\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0330/0938 | LOSS: 0.1799 | ACC 0.9479\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0331/0938 | LOSS: 0.1799 | ACC 0.9479\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0332/0938 | LOSS: 0.1801 | ACC 0.9479\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0333/0938 | LOSS: 0.1800 | ACC 0.9479\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0334/0938 | LOSS: 0.1799 | ACC 0.9479\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0335/0938 | LOSS: 0.1806 | ACC 0.9479\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0336/0938 | LOSS: 0.1803 | ACC 0.9480\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0337/0938 | LOSS: 0.1802 | ACC 0.9479\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0338/0938 | LOSS: 0.1802 | ACC 0.9479\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0339/0938 | LOSS: 0.1800 | ACC 0.9479\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0340/0938 | LOSS: 0.1797 | ACC 0.9479\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0341/0938 | LOSS: 0.1795 | ACC 0.9480\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0342/0938 | LOSS: 0.1796 | ACC 0.9481\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0343/0938 | LOSS: 0.1803 | ACC 0.9481\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0344/0938 | LOSS: 0.1801 | ACC 0.9482\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0345/0938 | LOSS: 0.1800 | ACC 0.9482\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0346/0938 | LOSS: 0.1797 | ACC 0.9483\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0347/0938 | LOSS: 0.1798 | ACC 0.9483\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0348/0938 | LOSS: 0.1798 | ACC 0.9483\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0349/0938 | LOSS: 0.1801 | ACC 0.9482\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0350/0938 | LOSS: 0.1799 | ACC 0.9483\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0351/0938 | LOSS: 0.1799 | ACC 0.9483\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0352/0938 | LOSS: 0.1801 | ACC 0.9483\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0353/0938 | LOSS: 0.1801 | ACC 0.9483\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0354/0938 | LOSS: 0.1800 | ACC 0.9483\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0355/0938 | LOSS: 0.1802 | ACC 0.9483\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0356/0938 | LOSS: 0.1802 | ACC 0.9483\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0357/0938 | LOSS: 0.1799 | ACC 0.9484\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0358/0938 | LOSS: 0.1799 | ACC 0.9484\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0359/0938 | LOSS: 0.1797 | ACC 0.9484\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0360/0938 | LOSS: 0.1796 | ACC 0.9484\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0361/0938 | LOSS: 0.1795 | ACC 0.9485\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0362/0938 | LOSS: 0.1795 | ACC 0.9484\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0363/0938 | LOSS: 0.1795 | ACC 0.9483\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0364/0938 | LOSS: 0.1796 | ACC 0.9483\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0365/0938 | LOSS: 0.1796 | ACC 0.9483\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0366/0938 | LOSS: 0.1796 | ACC 0.9483\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0367/0938 | LOSS: 0.1797 | ACC 0.9484\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0368/0938 | LOSS: 0.1802 | ACC 0.9482\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0369/0938 | LOSS: 0.1800 | ACC 0.9483\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0370/0938 | LOSS: 0.1799 | ACC 0.9484\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0371/0938 | LOSS: 0.1799 | ACC 0.9483\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0372/0938 | LOSS: 0.1800 | ACC 0.9483\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0373/0938 | LOSS: 0.1799 | ACC 0.9483\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0374/0938 | LOSS: 0.1799 | ACC 0.9483\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0375/0938 | LOSS: 0.1800 | ACC 0.9483\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0376/0938 | LOSS: 0.1803 | ACC 0.9482\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0377/0938 | LOSS: 0.1802 | ACC 0.9482\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0378/0938 | LOSS: 0.1804 | ACC 0.9483\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0379/0938 | LOSS: 0.1801 | ACC 0.9484\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0380/0938 | LOSS: 0.1799 | ACC 0.9484\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0381/0938 | LOSS: 0.1796 | ACC 0.9485\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0382/0938 | LOSS: 0.1794 | ACC 0.9485\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0383/0938 | LOSS: 0.1790 | ACC 0.9487\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0384/0938 | LOSS: 0.1787 | ACC 0.9487\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0385/0938 | LOSS: 0.1788 | ACC 0.9486\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0386/0938 | LOSS: 0.1790 | ACC 0.9486\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0387/0938 | LOSS: 0.1787 | ACC 0.9486\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0388/0938 | LOSS: 0.1788 | ACC 0.9486\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0389/0938 | LOSS: 0.1790 | ACC 0.9486\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0390/0938 | LOSS: 0.1787 | ACC 0.9487\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0391/0938 | LOSS: 0.1788 | ACC 0.9486\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0392/0938 | LOSS: 0.1787 | ACC 0.9487\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0393/0938 | LOSS: 0.1788 | ACC 0.9487\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0394/0938 | LOSS: 0.1786 | ACC 0.9488\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0395/0938 | LOSS: 0.1784 | ACC 0.9489\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0396/0938 | LOSS: 0.1784 | ACC 0.9488\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0397/0938 | LOSS: 0.1788 | ACC 0.9486\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0398/0938 | LOSS: 0.1786 | ACC 0.9487\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0399/0938 | LOSS: 0.1785 | ACC 0.9487\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0400/0938 | LOSS: 0.1786 | ACC 0.9486\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0401/0938 | LOSS: 0.1786 | ACC 0.9486\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0402/0938 | LOSS: 0.1784 | ACC 0.9486\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0403/0938 | LOSS: 0.1789 | ACC 0.9485\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0404/0938 | LOSS: 0.1790 | ACC 0.9486\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0405/0938 | LOSS: 0.1788 | ACC 0.9485\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0406/0938 | LOSS: 0.1789 | ACC 0.9485\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0407/0938 | LOSS: 0.1789 | ACC 0.9485\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0408/0938 | LOSS: 0.1789 | ACC 0.9485\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0409/0938 | LOSS: 0.1788 | ACC 0.9485\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: EPOCH 0006/0010 | BATCH 0410/0938 | LOSS: 0.1791 | ACC 0.9485\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0411/0938 | LOSS: 0.1793 | ACC 0.9484\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0412/0938 | LOSS: 0.1790 | ACC 0.9485\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0413/0938 | LOSS: 0.1789 | ACC 0.9485\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0414/0938 | LOSS: 0.1790 | ACC 0.9485\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0415/0938 | LOSS: 0.1790 | ACC 0.9486\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0416/0938 | LOSS: 0.1788 | ACC 0.9486\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0417/0938 | LOSS: 0.1786 | ACC 0.9486\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0418/0938 | LOSS: 0.1786 | ACC 0.9485\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0419/0938 | LOSS: 0.1789 | ACC 0.9484\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0420/0938 | LOSS: 0.1788 | ACC 0.9484\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0421/0938 | LOSS: 0.1787 | ACC 0.9484\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0422/0938 | LOSS: 0.1787 | ACC 0.9484\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0423/0938 | LOSS: 0.1785 | ACC 0.9485\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0424/0938 | LOSS: 0.1788 | ACC 0.9485\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0425/0938 | LOSS: 0.1790 | ACC 0.9485\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0426/0938 | LOSS: 0.1789 | ACC 0.9485\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0427/0938 | LOSS: 0.1786 | ACC 0.9486\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0428/0938 | LOSS: 0.1784 | ACC 0.9486\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0429/0938 | LOSS: 0.1787 | ACC 0.9485\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0430/0938 | LOSS: 0.1787 | ACC 0.9485\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0431/0938 | LOSS: 0.1786 | ACC 0.9486\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0432/0938 | LOSS: 0.1785 | ACC 0.9485\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0433/0938 | LOSS: 0.1785 | ACC 0.9485\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0434/0938 | LOSS: 0.1784 | ACC 0.9485\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0435/0938 | LOSS: 0.1783 | ACC 0.9485\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0436/0938 | LOSS: 0.1780 | ACC 0.9486\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0437/0938 | LOSS: 0.1779 | ACC 0.9487\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0438/0938 | LOSS: 0.1777 | ACC 0.9488\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0439/0938 | LOSS: 0.1785 | ACC 0.9487\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0440/0938 | LOSS: 0.1784 | ACC 0.9488\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0441/0938 | LOSS: 0.1784 | ACC 0.9487\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0442/0938 | LOSS: 0.1784 | ACC 0.9487\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0443/0938 | LOSS: 0.1788 | ACC 0.9487\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0444/0938 | LOSS: 0.1788 | ACC 0.9486\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0445/0938 | LOSS: 0.1786 | ACC 0.9487\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0446/0938 | LOSS: 0.1788 | ACC 0.9486\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0447/0938 | LOSS: 0.1785 | ACC 0.9487\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0448/0938 | LOSS: 0.1783 | ACC 0.9488\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0449/0938 | LOSS: 0.1783 | ACC 0.9488\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0450/0938 | LOSS: 0.1783 | ACC 0.9488\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0451/0938 | LOSS: 0.1781 | ACC 0.9489\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0452/0938 | LOSS: 0.1779 | ACC 0.9489\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0453/0938 | LOSS: 0.1779 | ACC 0.9490\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0454/0938 | LOSS: 0.1780 | ACC 0.9489\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0455/0938 | LOSS: 0.1790 | ACC 0.9487\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0456/0938 | LOSS: 0.1790 | ACC 0.9486\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0457/0938 | LOSS: 0.1790 | ACC 0.9486\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0458/0938 | LOSS: 0.1789 | ACC 0.9485\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0459/0938 | LOSS: 0.1792 | ACC 0.9485\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0460/0938 | LOSS: 0.1791 | ACC 0.9485\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0461/0938 | LOSS: 0.1791 | ACC 0.9485\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0462/0938 | LOSS: 0.1790 | ACC 0.9486\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0463/0938 | LOSS: 0.1791 | ACC 0.9485\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0464/0938 | LOSS: 0.1789 | ACC 0.9486\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0465/0938 | LOSS: 0.1790 | ACC 0.9485\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0466/0938 | LOSS: 0.1788 | ACC 0.9486\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0467/0938 | LOSS: 0.1786 | ACC 0.9487\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0468/0938 | LOSS: 0.1784 | ACC 0.9488\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0469/0938 | LOSS: 0.1785 | ACC 0.9487\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0470/0938 | LOSS: 0.1784 | ACC 0.9487\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0471/0938 | LOSS: 0.1785 | ACC 0.9487\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0472/0938 | LOSS: 0.1784 | ACC 0.9487\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0473/0938 | LOSS: 0.1782 | ACC 0.9487\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0474/0938 | LOSS: 0.1781 | ACC 0.9488\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0475/0938 | LOSS: 0.1783 | ACC 0.9487\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0476/0938 | LOSS: 0.1784 | ACC 0.9487\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0477/0938 | LOSS: 0.1783 | ACC 0.9487\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0478/0938 | LOSS: 0.1782 | ACC 0.9487\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0479/0938 | LOSS: 0.1781 | ACC 0.9488\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0480/0938 | LOSS: 0.1781 | ACC 0.9487\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0481/0938 | LOSS: 0.1782 | ACC 0.9486\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0482/0938 | LOSS: 0.1781 | ACC 0.9486\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0483/0938 | LOSS: 0.1780 | ACC 0.9486\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0484/0938 | LOSS: 0.1780 | ACC 0.9486\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0485/0938 | LOSS: 0.1782 | ACC 0.9485\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0486/0938 | LOSS: 0.1781 | ACC 0.9486\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0487/0938 | LOSS: 0.1782 | ACC 0.9485\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0488/0938 | LOSS: 0.1782 | ACC 0.9485\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0489/0938 | LOSS: 0.1783 | ACC 0.9485\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0490/0938 | LOSS: 0.1781 | ACC 0.9486\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0491/0938 | LOSS: 0.1782 | ACC 0.9485\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0492/0938 | LOSS: 0.1784 | ACC 0.9484\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0493/0938 | LOSS: 0.1785 | ACC 0.9483\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0494/0938 | LOSS: 0.1786 | ACC 0.9483\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0495/0938 | LOSS: 0.1784 | ACC 0.9483\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0496/0938 | LOSS: 0.1784 | ACC 0.9483\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0497/0938 | LOSS: 0.1782 | ACC 0.9483\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0498/0938 | LOSS: 0.1780 | ACC 0.9484\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0499/0938 | LOSS: 0.1778 | ACC 0.9485\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0500/0938 | LOSS: 0.1781 | ACC 0.9485\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0501/0938 | LOSS: 0.1782 | ACC 0.9484\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0502/0938 | LOSS: 0.1782 | ACC 0.9484\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0503/0938 | LOSS: 0.1780 | ACC 0.9485\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0504/0938 | LOSS: 0.1782 | ACC 0.9484\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0505/0938 | LOSS: 0.1780 | ACC 0.9484\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0506/0938 | LOSS: 0.1783 | ACC 0.9484\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0507/0938 | LOSS: 0.1782 | ACC 0.9484\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0508/0938 | LOSS: 0.1783 | ACC 0.9484\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0509/0938 | LOSS: 0.1783 | ACC 0.9483\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0510/0938 | LOSS: 0.1782 | ACC 0.9483\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0511/0938 | LOSS: 0.1785 | ACC 0.9483\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0512/0938 | LOSS: 0.1784 | ACC 0.9483\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0513/0938 | LOSS: 0.1791 | ACC 0.9483\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0514/0938 | LOSS: 0.1790 | ACC 0.9483\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0515/0938 | LOSS: 0.1791 | ACC 0.9483\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0516/0938 | LOSS: 0.1790 | ACC 0.9482\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0517/0938 | LOSS: 0.1789 | ACC 0.9483\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0518/0938 | LOSS: 0.1789 | ACC 0.9482\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0519/0938 | LOSS: 0.1789 | ACC 0.9482\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0520/0938 | LOSS: 0.1791 | ACC 0.9481\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0521/0938 | LOSS: 0.1790 | ACC 0.9481\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0522/0938 | LOSS: 0.1794 | ACC 0.9480\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0523/0938 | LOSS: 0.1792 | ACC 0.9481\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0524/0938 | LOSS: 0.1792 | ACC 0.9481\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0525/0938 | LOSS: 0.1794 | ACC 0.9481\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0526/0938 | LOSS: 0.1793 | ACC 0.9482\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0527/0938 | LOSS: 0.1792 | ACC 0.9481\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0528/0938 | LOSS: 0.1791 | ACC 0.9482\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0529/0938 | LOSS: 0.1790 | ACC 0.9482\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0530/0938 | LOSS: 0.1792 | ACC 0.9482\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0531/0938 | LOSS: 0.1793 | ACC 0.9482\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0532/0938 | LOSS: 0.1794 | ACC 0.9481\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0533/0938 | LOSS: 0.1793 | ACC 0.9482\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0534/0938 | LOSS: 0.1791 | ACC 0.9483\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0535/0938 | LOSS: 0.1791 | ACC 0.9482\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0536/0938 | LOSS: 0.1790 | ACC 0.9483\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0537/0938 | LOSS: 0.1792 | ACC 0.9483\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0538/0938 | LOSS: 0.1794 | ACC 0.9482\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: EPOCH 0006/0010 | BATCH 0539/0938 | LOSS: 0.1793 | ACC 0.9483\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0540/0938 | LOSS: 0.1794 | ACC 0.9482\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0541/0938 | LOSS: 0.1793 | ACC 0.9482\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0542/0938 | LOSS: 0.1794 | ACC 0.9482\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0543/0938 | LOSS: 0.1792 | ACC 0.9482\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0544/0938 | LOSS: 0.1790 | ACC 0.9483\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0545/0938 | LOSS: 0.1790 | ACC 0.9483\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0546/0938 | LOSS: 0.1788 | ACC 0.9484\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0547/0938 | LOSS: 0.1786 | ACC 0.9484\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0548/0938 | LOSS: 0.1786 | ACC 0.9485\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0549/0938 | LOSS: 0.1785 | ACC 0.9485\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0550/0938 | LOSS: 0.1784 | ACC 0.9486\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0551/0938 | LOSS: 0.1784 | ACC 0.9486\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0552/0938 | LOSS: 0.1784 | ACC 0.9486\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0553/0938 | LOSS: 0.1782 | ACC 0.9486\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0554/0938 | LOSS: 0.1781 | ACC 0.9487\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0555/0938 | LOSS: 0.1783 | ACC 0.9487\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0556/0938 | LOSS: 0.1782 | ACC 0.9487\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0557/0938 | LOSS: 0.1781 | ACC 0.9487\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0558/0938 | LOSS: 0.1785 | ACC 0.9486\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0559/0938 | LOSS: 0.1786 | ACC 0.9485\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0560/0938 | LOSS: 0.1787 | ACC 0.9485\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0561/0938 | LOSS: 0.1786 | ACC 0.9486\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0562/0938 | LOSS: 0.1785 | ACC 0.9486\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0563/0938 | LOSS: 0.1785 | ACC 0.9486\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0564/0938 | LOSS: 0.1782 | ACC 0.9487\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0565/0938 | LOSS: 0.1784 | ACC 0.9486\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0566/0938 | LOSS: 0.1783 | ACC 0.9487\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0567/0938 | LOSS: 0.1786 | ACC 0.9487\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0568/0938 | LOSS: 0.1789 | ACC 0.9487\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0569/0938 | LOSS: 0.1788 | ACC 0.9486\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0570/0938 | LOSS: 0.1788 | ACC 0.9487\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0571/0938 | LOSS: 0.1787 | ACC 0.9487\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0572/0938 | LOSS: 0.1786 | ACC 0.9487\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0573/0938 | LOSS: 0.1786 | ACC 0.9487\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0574/0938 | LOSS: 0.1785 | ACC 0.9487\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0575/0938 | LOSS: 0.1784 | ACC 0.9487\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0576/0938 | LOSS: 0.1783 | ACC 0.9487\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0577/0938 | LOSS: 0.1781 | ACC 0.9488\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0578/0938 | LOSS: 0.1782 | ACC 0.9488\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0579/0938 | LOSS: 0.1783 | ACC 0.9488\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0580/0938 | LOSS: 0.1785 | ACC 0.9487\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0581/0938 | LOSS: 0.1783 | ACC 0.9488\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0582/0938 | LOSS: 0.1782 | ACC 0.9488\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0583/0938 | LOSS: 0.1783 | ACC 0.9488\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0584/0938 | LOSS: 0.1784 | ACC 0.9487\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0585/0938 | LOSS: 0.1783 | ACC 0.9488\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0586/0938 | LOSS: 0.1783 | ACC 0.9487\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0587/0938 | LOSS: 0.1784 | ACC 0.9487\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0588/0938 | LOSS: 0.1787 | ACC 0.9486\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0589/0938 | LOSS: 0.1790 | ACC 0.9485\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0590/0938 | LOSS: 0.1790 | ACC 0.9485\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0591/0938 | LOSS: 0.1789 | ACC 0.9485\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0592/0938 | LOSS: 0.1790 | ACC 0.9485\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0593/0938 | LOSS: 0.1789 | ACC 0.9485\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0594/0938 | LOSS: 0.1788 | ACC 0.9485\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0595/0938 | LOSS: 0.1791 | ACC 0.9484\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0596/0938 | LOSS: 0.1790 | ACC 0.9484\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0597/0938 | LOSS: 0.1791 | ACC 0.9484\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0598/0938 | LOSS: 0.1793 | ACC 0.9483\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0599/0938 | LOSS: 0.1795 | ACC 0.9483\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0600/0938 | LOSS: 0.1794 | ACC 0.9483\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0601/0938 | LOSS: 0.1794 | ACC 0.9483\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0602/0938 | LOSS: 0.1794 | ACC 0.9483\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0603/0938 | LOSS: 0.1794 | ACC 0.9482\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0604/0938 | LOSS: 0.1794 | ACC 0.9482\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0605/0938 | LOSS: 0.1792 | ACC 0.9482\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0606/0938 | LOSS: 0.1792 | ACC 0.9482\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0607/0938 | LOSS: 0.1791 | ACC 0.9482\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0608/0938 | LOSS: 0.1790 | ACC 0.9482\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0609/0938 | LOSS: 0.1790 | ACC 0.9482\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0610/0938 | LOSS: 0.1788 | ACC 0.9482\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0611/0938 | LOSS: 0.1788 | ACC 0.9482\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0612/0938 | LOSS: 0.1786 | ACC 0.9483\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0613/0938 | LOSS: 0.1786 | ACC 0.9483\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0614/0938 | LOSS: 0.1787 | ACC 0.9482\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0615/0938 | LOSS: 0.1786 | ACC 0.9482\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0616/0938 | LOSS: 0.1785 | ACC 0.9483\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0617/0938 | LOSS: 0.1783 | ACC 0.9483\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0618/0938 | LOSS: 0.1784 | ACC 0.9482\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0619/0938 | LOSS: 0.1783 | ACC 0.9483\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0620/0938 | LOSS: 0.1783 | ACC 0.9483\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0621/0938 | LOSS: 0.1783 | ACC 0.9483\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0622/0938 | LOSS: 0.1781 | ACC 0.9483\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0623/0938 | LOSS: 0.1780 | ACC 0.9483\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0624/0938 | LOSS: 0.1779 | ACC 0.9483\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0625/0938 | LOSS: 0.1777 | ACC 0.9484\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0626/0938 | LOSS: 0.1779 | ACC 0.9484\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0627/0938 | LOSS: 0.1779 | ACC 0.9483\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0628/0938 | LOSS: 0.1780 | ACC 0.9483\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0629/0938 | LOSS: 0.1781 | ACC 0.9483\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0630/0938 | LOSS: 0.1781 | ACC 0.9483\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0631/0938 | LOSS: 0.1783 | ACC 0.9483\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0632/0938 | LOSS: 0.1782 | ACC 0.9483\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0633/0938 | LOSS: 0.1781 | ACC 0.9483\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0634/0938 | LOSS: 0.1782 | ACC 0.9483\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0635/0938 | LOSS: 0.1782 | ACC 0.9483\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0636/0938 | LOSS: 0.1781 | ACC 0.9483\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0637/0938 | LOSS: 0.1782 | ACC 0.9483\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0638/0938 | LOSS: 0.1783 | ACC 0.9482\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0639/0938 | LOSS: 0.1786 | ACC 0.9482\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0640/0938 | LOSS: 0.1788 | ACC 0.9482\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0641/0938 | LOSS: 0.1788 | ACC 0.9482\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0642/0938 | LOSS: 0.1786 | ACC 0.9482\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0643/0938 | LOSS: 0.1786 | ACC 0.9482\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0644/0938 | LOSS: 0.1788 | ACC 0.9482\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0645/0938 | LOSS: 0.1786 | ACC 0.9483\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0646/0938 | LOSS: 0.1785 | ACC 0.9483\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0647/0938 | LOSS: 0.1786 | ACC 0.9482\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0648/0938 | LOSS: 0.1788 | ACC 0.9482\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0649/0938 | LOSS: 0.1788 | ACC 0.9482\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0650/0938 | LOSS: 0.1788 | ACC 0.9482\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0651/0938 | LOSS: 0.1788 | ACC 0.9482\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0652/0938 | LOSS: 0.1786 | ACC 0.9483\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0653/0938 | LOSS: 0.1784 | ACC 0.9483\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0654/0938 | LOSS: 0.1783 | ACC 0.9483\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0655/0938 | LOSS: 0.1786 | ACC 0.9483\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0656/0938 | LOSS: 0.1786 | ACC 0.9482\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0657/0938 | LOSS: 0.1785 | ACC 0.9483\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0658/0938 | LOSS: 0.1784 | ACC 0.9484\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0659/0938 | LOSS: 0.1784 | ACC 0.9483\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0660/0938 | LOSS: 0.1785 | ACC 0.9483\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0661/0938 | LOSS: 0.1785 | ACC 0.9483\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0662/0938 | LOSS: 0.1783 | ACC 0.9484\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0663/0938 | LOSS: 0.1781 | ACC 0.9485\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0664/0938 | LOSS: 0.1782 | ACC 0.9484\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0665/0938 | LOSS: 0.1782 | ACC 0.9484\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0666/0938 | LOSS: 0.1783 | ACC 0.9484\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0667/0938 | LOSS: 0.1782 | ACC 0.9484\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: EPOCH 0006/0010 | BATCH 0668/0938 | LOSS: 0.1782 | ACC 0.9484\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0669/0938 | LOSS: 0.1781 | ACC 0.9485\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0670/0938 | LOSS: 0.1780 | ACC 0.9486\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0671/0938 | LOSS: 0.1778 | ACC 0.9486\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0672/0938 | LOSS: 0.1778 | ACC 0.9486\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0673/0938 | LOSS: 0.1781 | ACC 0.9485\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0674/0938 | LOSS: 0.1779 | ACC 0.9486\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0675/0938 | LOSS: 0.1780 | ACC 0.9485\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0676/0938 | LOSS: 0.1778 | ACC 0.9486\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0677/0938 | LOSS: 0.1776 | ACC 0.9486\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0678/0938 | LOSS: 0.1775 | ACC 0.9487\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0679/0938 | LOSS: 0.1775 | ACC 0.9487\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0680/0938 | LOSS: 0.1773 | ACC 0.9487\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0681/0938 | LOSS: 0.1772 | ACC 0.9488\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0682/0938 | LOSS: 0.1770 | ACC 0.9488\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0683/0938 | LOSS: 0.1770 | ACC 0.9489\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0684/0938 | LOSS: 0.1768 | ACC 0.9489\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0685/0938 | LOSS: 0.1767 | ACC 0.9490\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0686/0938 | LOSS: 0.1766 | ACC 0.9490\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0687/0938 | LOSS: 0.1764 | ACC 0.9491\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0688/0938 | LOSS: 0.1764 | ACC 0.9491\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0689/0938 | LOSS: 0.1765 | ACC 0.9491\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0690/0938 | LOSS: 0.1764 | ACC 0.9491\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0691/0938 | LOSS: 0.1764 | ACC 0.9491\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0692/0938 | LOSS: 0.1764 | ACC 0.9492\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0693/0938 | LOSS: 0.1763 | ACC 0.9492\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0694/0938 | LOSS: 0.1761 | ACC 0.9492\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0695/0938 | LOSS: 0.1759 | ACC 0.9493\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0696/0938 | LOSS: 0.1759 | ACC 0.9493\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0697/0938 | LOSS: 0.1757 | ACC 0.9493\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0698/0938 | LOSS: 0.1755 | ACC 0.9494\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0699/0938 | LOSS: 0.1754 | ACC 0.9494\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0700/0938 | LOSS: 0.1754 | ACC 0.9494\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0701/0938 | LOSS: 0.1753 | ACC 0.9494\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0702/0938 | LOSS: 0.1752 | ACC 0.9495\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0703/0938 | LOSS: 0.1752 | ACC 0.9495\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0704/0938 | LOSS: 0.1751 | ACC 0.9495\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0705/0938 | LOSS: 0.1751 | ACC 0.9494\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0706/0938 | LOSS: 0.1751 | ACC 0.9494\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0707/0938 | LOSS: 0.1751 | ACC 0.9493\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0708/0938 | LOSS: 0.1751 | ACC 0.9494\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0709/0938 | LOSS: 0.1754 | ACC 0.9493\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0710/0938 | LOSS: 0.1756 | ACC 0.9492\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0711/0938 | LOSS: 0.1757 | ACC 0.9492\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0712/0938 | LOSS: 0.1756 | ACC 0.9492\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0713/0938 | LOSS: 0.1755 | ACC 0.9492\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0714/0938 | LOSS: 0.1755 | ACC 0.9492\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0715/0938 | LOSS: 0.1756 | ACC 0.9491\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0716/0938 | LOSS: 0.1754 | ACC 0.9492\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0717/0938 | LOSS: 0.1754 | ACC 0.9491\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0718/0938 | LOSS: 0.1753 | ACC 0.9491\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0719/0938 | LOSS: 0.1753 | ACC 0.9491\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0720/0938 | LOSS: 0.1753 | ACC 0.9492\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0721/0938 | LOSS: 0.1753 | ACC 0.9491\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0722/0938 | LOSS: 0.1751 | ACC 0.9492\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0723/0938 | LOSS: 0.1751 | ACC 0.9492\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0724/0938 | LOSS: 0.1753 | ACC 0.9491\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0725/0938 | LOSS: 0.1752 | ACC 0.9491\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0726/0938 | LOSS: 0.1752 | ACC 0.9490\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0727/0938 | LOSS: 0.1751 | ACC 0.9491\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0728/0938 | LOSS: 0.1750 | ACC 0.9491\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0729/0938 | LOSS: 0.1750 | ACC 0.9491\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0730/0938 | LOSS: 0.1750 | ACC 0.9491\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0731/0938 | LOSS: 0.1753 | ACC 0.9490\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0732/0938 | LOSS: 0.1751 | ACC 0.9490\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0733/0938 | LOSS: 0.1752 | ACC 0.9491\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0734/0938 | LOSS: 0.1751 | ACC 0.9491\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0735/0938 | LOSS: 0.1751 | ACC 0.9491\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0736/0938 | LOSS: 0.1750 | ACC 0.9492\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0737/0938 | LOSS: 0.1750 | ACC 0.9492\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0738/0938 | LOSS: 0.1750 | ACC 0.9491\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0739/0938 | LOSS: 0.1750 | ACC 0.9492\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0740/0938 | LOSS: 0.1750 | ACC 0.9491\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0741/0938 | LOSS: 0.1749 | ACC 0.9492\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0742/0938 | LOSS: 0.1749 | ACC 0.9491\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0743/0938 | LOSS: 0.1751 | ACC 0.9491\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0744/0938 | LOSS: 0.1752 | ACC 0.9491\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0745/0938 | LOSS: 0.1752 | ACC 0.9491\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0746/0938 | LOSS: 0.1751 | ACC 0.9491\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0747/0938 | LOSS: 0.1752 | ACC 0.9491\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0748/0938 | LOSS: 0.1752 | ACC 0.9491\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0749/0938 | LOSS: 0.1753 | ACC 0.9491\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0750/0938 | LOSS: 0.1754 | ACC 0.9491\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0751/0938 | LOSS: 0.1753 | ACC 0.9491\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0752/0938 | LOSS: 0.1754 | ACC 0.9490\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0753/0938 | LOSS: 0.1753 | ACC 0.9491\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0754/0938 | LOSS: 0.1752 | ACC 0.9491\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0755/0938 | LOSS: 0.1752 | ACC 0.9491\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0756/0938 | LOSS: 0.1753 | ACC 0.9491\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0757/0938 | LOSS: 0.1753 | ACC 0.9491\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0758/0938 | LOSS: 0.1753 | ACC 0.9490\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0759/0938 | LOSS: 0.1751 | ACC 0.9491\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0760/0938 | LOSS: 0.1752 | ACC 0.9491\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0761/0938 | LOSS: 0.1750 | ACC 0.9492\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0762/0938 | LOSS: 0.1749 | ACC 0.9492\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0763/0938 | LOSS: 0.1750 | ACC 0.9492\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0764/0938 | LOSS: 0.1750 | ACC 0.9491\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0765/0938 | LOSS: 0.1752 | ACC 0.9491\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0766/0938 | LOSS: 0.1751 | ACC 0.9491\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0767/0938 | LOSS: 0.1752 | ACC 0.9491\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0768/0938 | LOSS: 0.1751 | ACC 0.9491\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0769/0938 | LOSS: 0.1750 | ACC 0.9491\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0770/0938 | LOSS: 0.1750 | ACC 0.9491\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0771/0938 | LOSS: 0.1754 | ACC 0.9491\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0772/0938 | LOSS: 0.1758 | ACC 0.9490\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0773/0938 | LOSS: 0.1757 | ACC 0.9490\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0774/0938 | LOSS: 0.1758 | ACC 0.9490\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0775/0938 | LOSS: 0.1757 | ACC 0.9491\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0776/0938 | LOSS: 0.1757 | ACC 0.9491\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0777/0938 | LOSS: 0.1757 | ACC 0.9491\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0778/0938 | LOSS: 0.1758 | ACC 0.9490\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0779/0938 | LOSS: 0.1758 | ACC 0.9490\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0780/0938 | LOSS: 0.1758 | ACC 0.9491\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0781/0938 | LOSS: 0.1757 | ACC 0.9491\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0782/0938 | LOSS: 0.1756 | ACC 0.9491\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0783/0938 | LOSS: 0.1754 | ACC 0.9492\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0784/0938 | LOSS: 0.1753 | ACC 0.9492\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0785/0938 | LOSS: 0.1754 | ACC 0.9492\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0786/0938 | LOSS: 0.1755 | ACC 0.9491\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0787/0938 | LOSS: 0.1755 | ACC 0.9491\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0788/0938 | LOSS: 0.1755 | ACC 0.9491\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0789/0938 | LOSS: 0.1756 | ACC 0.9491\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0790/0938 | LOSS: 0.1754 | ACC 0.9491\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0791/0938 | LOSS: 0.1755 | ACC 0.9491\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0792/0938 | LOSS: 0.1754 | ACC 0.9491\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0793/0938 | LOSS: 0.1754 | ACC 0.9492\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0794/0938 | LOSS: 0.1755 | ACC 0.9491\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0795/0938 | LOSS: 0.1755 | ACC 0.9491\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: EPOCH 0006/0010 | BATCH 0796/0938 | LOSS: 0.1755 | ACC 0.9491\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0797/0938 | LOSS: 0.1755 | ACC 0.9491\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0798/0938 | LOSS: 0.1755 | ACC 0.9492\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0799/0938 | LOSS: 0.1753 | ACC 0.9492\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0800/0938 | LOSS: 0.1752 | ACC 0.9492\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0801/0938 | LOSS: 0.1752 | ACC 0.9492\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0802/0938 | LOSS: 0.1752 | ACC 0.9492\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0803/0938 | LOSS: 0.1751 | ACC 0.9492\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0804/0938 | LOSS: 0.1751 | ACC 0.9491\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0805/0938 | LOSS: 0.1751 | ACC 0.9491\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0806/0938 | LOSS: 0.1750 | ACC 0.9492\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0807/0938 | LOSS: 0.1750 | ACC 0.9492\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0808/0938 | LOSS: 0.1750 | ACC 0.9492\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0809/0938 | LOSS: 0.1750 | ACC 0.9492\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0810/0938 | LOSS: 0.1750 | ACC 0.9492\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0811/0938 | LOSS: 0.1749 | ACC 0.9492\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0812/0938 | LOSS: 0.1748 | ACC 0.9492\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0813/0938 | LOSS: 0.1748 | ACC 0.9493\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0814/0938 | LOSS: 0.1751 | ACC 0.9491\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0815/0938 | LOSS: 0.1754 | ACC 0.9490\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0816/0938 | LOSS: 0.1753 | ACC 0.9491\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0817/0938 | LOSS: 0.1753 | ACC 0.9491\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0818/0938 | LOSS: 0.1754 | ACC 0.9491\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0819/0938 | LOSS: 0.1757 | ACC 0.9490\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0820/0938 | LOSS: 0.1757 | ACC 0.9490\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0821/0938 | LOSS: 0.1756 | ACC 0.9490\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0822/0938 | LOSS: 0.1756 | ACC 0.9489\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0823/0938 | LOSS: 0.1757 | ACC 0.9489\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0824/0938 | LOSS: 0.1758 | ACC 0.9488\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0825/0938 | LOSS: 0.1757 | ACC 0.9488\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0826/0938 | LOSS: 0.1757 | ACC 0.9488\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0827/0938 | LOSS: 0.1757 | ACC 0.9488\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0828/0938 | LOSS: 0.1756 | ACC 0.9488\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0829/0938 | LOSS: 0.1754 | ACC 0.9489\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0830/0938 | LOSS: 0.1755 | ACC 0.9489\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0831/0938 | LOSS: 0.1754 | ACC 0.9489\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0832/0938 | LOSS: 0.1753 | ACC 0.9489\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0833/0938 | LOSS: 0.1754 | ACC 0.9489\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0834/0938 | LOSS: 0.1753 | ACC 0.9489\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0835/0938 | LOSS: 0.1752 | ACC 0.9490\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0836/0938 | LOSS: 0.1753 | ACC 0.9489\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0837/0938 | LOSS: 0.1753 | ACC 0.9489\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0838/0938 | LOSS: 0.1754 | ACC 0.9488\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0839/0938 | LOSS: 0.1754 | ACC 0.9488\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0840/0938 | LOSS: 0.1754 | ACC 0.9488\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0841/0938 | LOSS: 0.1754 | ACC 0.9488\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0842/0938 | LOSS: 0.1753 | ACC 0.9488\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0843/0938 | LOSS: 0.1753 | ACC 0.9488\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0844/0938 | LOSS: 0.1753 | ACC 0.9488\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0845/0938 | LOSS: 0.1757 | ACC 0.9488\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0846/0938 | LOSS: 0.1755 | ACC 0.9488\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0847/0938 | LOSS: 0.1754 | ACC 0.9488\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0848/0938 | LOSS: 0.1756 | ACC 0.9488\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0849/0938 | LOSS: 0.1758 | ACC 0.9487\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0850/0938 | LOSS: 0.1759 | ACC 0.9487\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0851/0938 | LOSS: 0.1759 | ACC 0.9487\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0852/0938 | LOSS: 0.1759 | ACC 0.9487\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0853/0938 | LOSS: 0.1757 | ACC 0.9488\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0854/0938 | LOSS: 0.1757 | ACC 0.9488\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0855/0938 | LOSS: 0.1757 | ACC 0.9488\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0856/0938 | LOSS: 0.1757 | ACC 0.9488\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0857/0938 | LOSS: 0.1756 | ACC 0.9488\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0858/0938 | LOSS: 0.1756 | ACC 0.9488\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0859/0938 | LOSS: 0.1755 | ACC 0.9488\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0860/0938 | LOSS: 0.1756 | ACC 0.9488\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0861/0938 | LOSS: 0.1756 | ACC 0.9488\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0862/0938 | LOSS: 0.1754 | ACC 0.9488\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0863/0938 | LOSS: 0.1754 | ACC 0.9489\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0864/0938 | LOSS: 0.1753 | ACC 0.9489\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0865/0938 | LOSS: 0.1752 | ACC 0.9490\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0866/0938 | LOSS: 0.1751 | ACC 0.9490\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0867/0938 | LOSS: 0.1752 | ACC 0.9489\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0868/0938 | LOSS: 0.1753 | ACC 0.9489\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0869/0938 | LOSS: 0.1753 | ACC 0.9489\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0870/0938 | LOSS: 0.1753 | ACC 0.9489\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0871/0938 | LOSS: 0.1754 | ACC 0.9489\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0872/0938 | LOSS: 0.1753 | ACC 0.9489\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0873/0938 | LOSS: 0.1755 | ACC 0.9489\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0874/0938 | LOSS: 0.1758 | ACC 0.9488\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0875/0938 | LOSS: 0.1760 | ACC 0.9488\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0876/0938 | LOSS: 0.1760 | ACC 0.9488\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0877/0938 | LOSS: 0.1759 | ACC 0.9488\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0878/0938 | LOSS: 0.1758 | ACC 0.9489\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0879/0938 | LOSS: 0.1758 | ACC 0.9489\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0880/0938 | LOSS: 0.1757 | ACC 0.9489\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0881/0938 | LOSS: 0.1759 | ACC 0.9489\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0882/0938 | LOSS: 0.1759 | ACC 0.9488\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0883/0938 | LOSS: 0.1758 | ACC 0.9489\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0884/0938 | LOSS: 0.1757 | ACC 0.9489\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0885/0938 | LOSS: 0.1757 | ACC 0.9489\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0886/0938 | LOSS: 0.1758 | ACC 0.9489\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0887/0938 | LOSS: 0.1758 | ACC 0.9489\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0888/0938 | LOSS: 0.1758 | ACC 0.9489\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0889/0938 | LOSS: 0.1758 | ACC 0.9489\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0890/0938 | LOSS: 0.1758 | ACC 0.9489\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0891/0938 | LOSS: 0.1758 | ACC 0.9489\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0892/0938 | LOSS: 0.1758 | ACC 0.9489\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0893/0938 | LOSS: 0.1759 | ACC 0.9489\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0894/0938 | LOSS: 0.1761 | ACC 0.9489\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0895/0938 | LOSS: 0.1760 | ACC 0.9489\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0896/0938 | LOSS: 0.1761 | ACC 0.9489\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0897/0938 | LOSS: 0.1762 | ACC 0.9489\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0898/0938 | LOSS: 0.1764 | ACC 0.9489\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0899/0938 | LOSS: 0.1765 | ACC 0.9488\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0900/0938 | LOSS: 0.1764 | ACC 0.9488\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0901/0938 | LOSS: 0.1763 | ACC 0.9489\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0902/0938 | LOSS: 0.1763 | ACC 0.9489\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0903/0938 | LOSS: 0.1763 | ACC 0.9489\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0904/0938 | LOSS: 0.1765 | ACC 0.9488\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0905/0938 | LOSS: 0.1766 | ACC 0.9487\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0906/0938 | LOSS: 0.1767 | ACC 0.9487\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0907/0938 | LOSS: 0.1768 | ACC 0.9487\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0908/0938 | LOSS: 0.1767 | ACC 0.9487\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0909/0938 | LOSS: 0.1769 | ACC 0.9487\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0910/0938 | LOSS: 0.1770 | ACC 0.9486\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0911/0938 | LOSS: 0.1770 | ACC 0.9486\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0912/0938 | LOSS: 0.1772 | ACC 0.9486\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0913/0938 | LOSS: 0.1771 | ACC 0.9486\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0914/0938 | LOSS: 0.1771 | ACC 0.9486\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0915/0938 | LOSS: 0.1772 | ACC 0.9486\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0916/0938 | LOSS: 0.1771 | ACC 0.9486\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0917/0938 | LOSS: 0.1771 | ACC 0.9486\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0918/0938 | LOSS: 0.1771 | ACC 0.9485\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0919/0938 | LOSS: 0.1769 | ACC 0.9486\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0920/0938 | LOSS: 0.1768 | ACC 0.9486\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0921/0938 | LOSS: 0.1768 | ACC 0.9486\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0922/0938 | LOSS: 0.1768 | ACC 0.9485\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0923/0938 | LOSS: 0.1768 | ACC 0.9485\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: EPOCH 0006/0010 | BATCH 0924/0938 | LOSS: 0.1769 | ACC 0.9486\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0925/0938 | LOSS: 0.1770 | ACC 0.9486\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0926/0938 | LOSS: 0.1771 | ACC 0.9486\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0927/0938 | LOSS: 0.1772 | ACC 0.9486\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0928/0938 | LOSS: 0.1772 | ACC 0.9485\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0929/0938 | LOSS: 0.1772 | ACC 0.9485\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0930/0938 | LOSS: 0.1771 | ACC 0.9485\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0931/0938 | LOSS: 0.1772 | ACC 0.9485\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0932/0938 | LOSS: 0.1774 | ACC 0.9485\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0933/0938 | LOSS: 0.1772 | ACC 0.9485\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0934/0938 | LOSS: 0.1774 | ACC 0.9485\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0935/0938 | LOSS: 0.1776 | ACC 0.9484\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0936/0938 | LOSS: 0.1775 | ACC 0.9484\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0937/0938 | LOSS: 0.1775 | ACC 0.9485\n",
      "TRAIN: EPOCH 0006/0010 | BATCH 0938/0938 | LOSS: 0.1775 | ACC 0.9485\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0001/0938 | LOSS: 0.0761 | ACC 0.9844\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0002/0938 | LOSS: 0.1180 | ACC 0.9688\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0003/0938 | LOSS: 0.1440 | ACC 0.9531\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0004/0938 | LOSS: 0.1807 | ACC 0.9531\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0005/0938 | LOSS: 0.1795 | ACC 0.9500\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0006/0938 | LOSS: 0.1846 | ACC 0.9531\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0007/0938 | LOSS: 0.1816 | ACC 0.9531\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0008/0938 | LOSS: 0.1832 | ACC 0.9512\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0009/0938 | LOSS: 0.1879 | ACC 0.9479\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0010/0938 | LOSS: 0.2032 | ACC 0.9437\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0011/0938 | LOSS: 0.1931 | ACC 0.9460\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0012/0938 | LOSS: 0.1925 | ACC 0.9466\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0013/0938 | LOSS: 0.1853 | ACC 0.9495\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0014/0938 | LOSS: 0.1820 | ACC 0.9509\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0015/0938 | LOSS: 0.1821 | ACC 0.9500\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0016/0938 | LOSS: 0.1810 | ACC 0.9473\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0017/0938 | LOSS: 0.1835 | ACC 0.9485\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0018/0938 | LOSS: 0.1794 | ACC 0.9497\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0019/0938 | LOSS: 0.1803 | ACC 0.9490\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0020/0938 | LOSS: 0.1793 | ACC 0.9492\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0021/0938 | LOSS: 0.1789 | ACC 0.9487\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0022/0938 | LOSS: 0.1823 | ACC 0.9482\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0023/0938 | LOSS: 0.1854 | ACC 0.9477\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0024/0938 | LOSS: 0.1863 | ACC 0.9466\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0025/0938 | LOSS: 0.1850 | ACC 0.9475\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0026/0938 | LOSS: 0.1842 | ACC 0.9471\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0027/0938 | LOSS: 0.1818 | ACC 0.9479\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0028/0938 | LOSS: 0.1798 | ACC 0.9487\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0029/0938 | LOSS: 0.1818 | ACC 0.9488\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0030/0938 | LOSS: 0.1793 | ACC 0.9495\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0031/0938 | LOSS: 0.1752 | ACC 0.9511\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0032/0938 | LOSS: 0.1752 | ACC 0.9512\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0033/0938 | LOSS: 0.1739 | ACC 0.9512\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0034/0938 | LOSS: 0.1734 | ACC 0.9508\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0035/0938 | LOSS: 0.1857 | ACC 0.9509\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0036/0938 | LOSS: 0.1864 | ACC 0.9510\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0037/0938 | LOSS: 0.1826 | ACC 0.9523\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0038/0938 | LOSS: 0.1818 | ACC 0.9527\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0039/0938 | LOSS: 0.1831 | ACC 0.9515\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0040/0938 | LOSS: 0.1807 | ACC 0.9523\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0041/0938 | LOSS: 0.1819 | ACC 0.9520\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0042/0938 | LOSS: 0.1841 | ACC 0.9513\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0043/0938 | LOSS: 0.1830 | ACC 0.9506\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0044/0938 | LOSS: 0.1835 | ACC 0.9506\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0045/0938 | LOSS: 0.1801 | ACC 0.9517\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0046/0938 | LOSS: 0.1795 | ACC 0.9514\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0047/0938 | LOSS: 0.1769 | ACC 0.9525\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0048/0938 | LOSS: 0.1787 | ACC 0.9505\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0049/0938 | LOSS: 0.1767 | ACC 0.9509\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0050/0938 | LOSS: 0.1769 | ACC 0.9503\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0051/0938 | LOSS: 0.1756 | ACC 0.9504\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0052/0938 | LOSS: 0.1749 | ACC 0.9501\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0053/0938 | LOSS: 0.1759 | ACC 0.9502\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0054/0938 | LOSS: 0.1779 | ACC 0.9499\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0055/0938 | LOSS: 0.1785 | ACC 0.9497\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0056/0938 | LOSS: 0.1793 | ACC 0.9498\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0057/0938 | LOSS: 0.1804 | ACC 0.9496\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0058/0938 | LOSS: 0.1821 | ACC 0.9496\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0059/0938 | LOSS: 0.1816 | ACC 0.9492\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0060/0938 | LOSS: 0.1800 | ACC 0.9497\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0061/0938 | LOSS: 0.1823 | ACC 0.9488\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0062/0938 | LOSS: 0.1811 | ACC 0.9488\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0063/0938 | LOSS: 0.1815 | ACC 0.9492\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0064/0938 | LOSS: 0.1799 | ACC 0.9495\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0065/0938 | LOSS: 0.1813 | ACC 0.9498\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0066/0938 | LOSS: 0.1795 | ACC 0.9503\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0067/0938 | LOSS: 0.1782 | ACC 0.9506\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0068/0938 | LOSS: 0.1780 | ACC 0.9506\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0069/0938 | LOSS: 0.1775 | ACC 0.9504\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0070/0938 | LOSS: 0.1804 | ACC 0.9498\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0071/0938 | LOSS: 0.1798 | ACC 0.9498\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0072/0938 | LOSS: 0.1800 | ACC 0.9497\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0073/0938 | LOSS: 0.1791 | ACC 0.9495\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0074/0938 | LOSS: 0.1803 | ACC 0.9495\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0075/0938 | LOSS: 0.1823 | ACC 0.9494\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0076/0938 | LOSS: 0.1814 | ACC 0.9492\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0077/0938 | LOSS: 0.1804 | ACC 0.9493\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0078/0938 | LOSS: 0.1799 | ACC 0.9495\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0079/0938 | LOSS: 0.1796 | ACC 0.9494\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0080/0938 | LOSS: 0.1782 | ACC 0.9498\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0081/0938 | LOSS: 0.1787 | ACC 0.9498\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0082/0938 | LOSS: 0.1794 | ACC 0.9497\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0083/0938 | LOSS: 0.1782 | ACC 0.9501\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0084/0938 | LOSS: 0.1780 | ACC 0.9501\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0085/0938 | LOSS: 0.1776 | ACC 0.9502\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0086/0938 | LOSS: 0.1765 | ACC 0.9502\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0087/0938 | LOSS: 0.1809 | ACC 0.9495\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0088/0938 | LOSS: 0.1818 | ACC 0.9494\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0089/0938 | LOSS: 0.1838 | ACC 0.9486\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0090/0938 | LOSS: 0.1828 | ACC 0.9488\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0091/0938 | LOSS: 0.1836 | ACC 0.9485\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0092/0938 | LOSS: 0.1830 | ACC 0.9484\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0093/0938 | LOSS: 0.1830 | ACC 0.9481\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0094/0938 | LOSS: 0.1822 | ACC 0.9485\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0095/0938 | LOSS: 0.1823 | ACC 0.9482\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0096/0938 | LOSS: 0.1818 | ACC 0.9482\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0097/0938 | LOSS: 0.1812 | ACC 0.9483\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0098/0938 | LOSS: 0.1812 | ACC 0.9482\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0099/0938 | LOSS: 0.1814 | ACC 0.9479\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0100/0938 | LOSS: 0.1803 | ACC 0.9483\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0101/0938 | LOSS: 0.1808 | ACC 0.9480\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0102/0938 | LOSS: 0.1830 | ACC 0.9478\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0103/0938 | LOSS: 0.1822 | ACC 0.9481\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0104/0938 | LOSS: 0.1815 | ACC 0.9483\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0105/0938 | LOSS: 0.1805 | ACC 0.9487\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0106/0938 | LOSS: 0.1802 | ACC 0.9489\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0107/0938 | LOSS: 0.1794 | ACC 0.9490\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0108/0938 | LOSS: 0.1789 | ACC 0.9492\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0109/0938 | LOSS: 0.1778 | ACC 0.9495\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0110/0938 | LOSS: 0.1781 | ACC 0.9494\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0111/0938 | LOSS: 0.1774 | ACC 0.9497\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0112/0938 | LOSS: 0.1769 | ACC 0.9499\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0113/0938 | LOSS: 0.1768 | ACC 0.9499\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: EPOCH 0007/0010 | BATCH 0114/0938 | LOSS: 0.1763 | ACC 0.9502\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0115/0938 | LOSS: 0.1762 | ACC 0.9504\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0116/0938 | LOSS: 0.1776 | ACC 0.9502\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0117/0938 | LOSS: 0.1775 | ACC 0.9502\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0118/0938 | LOSS: 0.1774 | ACC 0.9499\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0119/0938 | LOSS: 0.1764 | ACC 0.9504\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0120/0938 | LOSS: 0.1764 | ACC 0.9503\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0121/0938 | LOSS: 0.1756 | ACC 0.9507\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0122/0938 | LOSS: 0.1750 | ACC 0.9508\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0123/0938 | LOSS: 0.1751 | ACC 0.9508\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0124/0938 | LOSS: 0.1768 | ACC 0.9506\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0125/0938 | LOSS: 0.1774 | ACC 0.9505\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0126/0938 | LOSS: 0.1783 | ACC 0.9504\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0127/0938 | LOSS: 0.1780 | ACC 0.9504\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0128/0938 | LOSS: 0.1780 | ACC 0.9506\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0129/0938 | LOSS: 0.1779 | ACC 0.9506\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0130/0938 | LOSS: 0.1784 | ACC 0.9505\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0131/0938 | LOSS: 0.1792 | ACC 0.9503\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0132/0938 | LOSS: 0.1790 | ACC 0.9502\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0133/0938 | LOSS: 0.1781 | ACC 0.9503\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0134/0938 | LOSS: 0.1776 | ACC 0.9504\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0135/0938 | LOSS: 0.1770 | ACC 0.9506\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0136/0938 | LOSS: 0.1762 | ACC 0.9508\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0137/0938 | LOSS: 0.1753 | ACC 0.9512\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0138/0938 | LOSS: 0.1755 | ACC 0.9511\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0139/0938 | LOSS: 0.1751 | ACC 0.9511\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0140/0938 | LOSS: 0.1751 | ACC 0.9513\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0141/0938 | LOSS: 0.1748 | ACC 0.9514\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0142/0938 | LOSS: 0.1741 | ACC 0.9517\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0143/0938 | LOSS: 0.1749 | ACC 0.9517\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0144/0938 | LOSS: 0.1744 | ACC 0.9517\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0145/0938 | LOSS: 0.1743 | ACC 0.9518\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0146/0938 | LOSS: 0.1746 | ACC 0.9516\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0147/0938 | LOSS: 0.1753 | ACC 0.9514\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0148/0938 | LOSS: 0.1757 | ACC 0.9514\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0149/0938 | LOSS: 0.1756 | ACC 0.9514\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0150/0938 | LOSS: 0.1754 | ACC 0.9515\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0151/0938 | LOSS: 0.1748 | ACC 0.9517\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0152/0938 | LOSS: 0.1744 | ACC 0.9518\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0153/0938 | LOSS: 0.1744 | ACC 0.9518\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0154/0938 | LOSS: 0.1737 | ACC 0.9520\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0155/0938 | LOSS: 0.1742 | ACC 0.9517\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0156/0938 | LOSS: 0.1748 | ACC 0.9516\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0157/0938 | LOSS: 0.1753 | ACC 0.9514\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0158/0938 | LOSS: 0.1747 | ACC 0.9515\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0159/0938 | LOSS: 0.1739 | ACC 0.9517\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0160/0938 | LOSS: 0.1740 | ACC 0.9519\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0161/0938 | LOSS: 0.1734 | ACC 0.9520\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0162/0938 | LOSS: 0.1734 | ACC 0.9519\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0163/0938 | LOSS: 0.1733 | ACC 0.9516\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0164/0938 | LOSS: 0.1734 | ACC 0.9516\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0165/0938 | LOSS: 0.1733 | ACC 0.9516\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0166/0938 | LOSS: 0.1745 | ACC 0.9514\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0167/0938 | LOSS: 0.1742 | ACC 0.9513\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0168/0938 | LOSS: 0.1742 | ACC 0.9514\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0169/0938 | LOSS: 0.1747 | ACC 0.9514\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0170/0938 | LOSS: 0.1746 | ACC 0.9513\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0171/0938 | LOSS: 0.1748 | ACC 0.9512\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0172/0938 | LOSS: 0.1754 | ACC 0.9509\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0173/0938 | LOSS: 0.1749 | ACC 0.9509\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0174/0938 | LOSS: 0.1743 | ACC 0.9511\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0175/0938 | LOSS: 0.1753 | ACC 0.9509\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0176/0938 | LOSS: 0.1751 | ACC 0.9508\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0177/0938 | LOSS: 0.1750 | ACC 0.9510\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0178/0938 | LOSS: 0.1747 | ACC 0.9511\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0179/0938 | LOSS: 0.1749 | ACC 0.9509\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0180/0938 | LOSS: 0.1744 | ACC 0.9512\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0181/0938 | LOSS: 0.1744 | ACC 0.9511\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0182/0938 | LOSS: 0.1747 | ACC 0.9510\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0183/0938 | LOSS: 0.1749 | ACC 0.9512\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0184/0938 | LOSS: 0.1752 | ACC 0.9511\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0185/0938 | LOSS: 0.1756 | ACC 0.9510\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0186/0938 | LOSS: 0.1753 | ACC 0.9511\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0187/0938 | LOSS: 0.1772 | ACC 0.9508\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0188/0938 | LOSS: 0.1774 | ACC 0.9505\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0189/0938 | LOSS: 0.1772 | ACC 0.9505\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0190/0938 | LOSS: 0.1766 | ACC 0.9507\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0191/0938 | LOSS: 0.1762 | ACC 0.9507\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0192/0938 | LOSS: 0.1758 | ACC 0.9508\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0193/0938 | LOSS: 0.1766 | ACC 0.9508\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0194/0938 | LOSS: 0.1768 | ACC 0.9509\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0195/0938 | LOSS: 0.1774 | ACC 0.9506\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0196/0938 | LOSS: 0.1769 | ACC 0.9508\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0197/0938 | LOSS: 0.1763 | ACC 0.9511\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0198/0938 | LOSS: 0.1764 | ACC 0.9509\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0199/0938 | LOSS: 0.1770 | ACC 0.9509\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0200/0938 | LOSS: 0.1764 | ACC 0.9511\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0201/0938 | LOSS: 0.1771 | ACC 0.9509\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0202/0938 | LOSS: 0.1766 | ACC 0.9510\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0203/0938 | LOSS: 0.1769 | ACC 0.9508\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0204/0938 | LOSS: 0.1770 | ACC 0.9508\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0205/0938 | LOSS: 0.1768 | ACC 0.9506\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0206/0938 | LOSS: 0.1767 | ACC 0.9506\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0207/0938 | LOSS: 0.1762 | ACC 0.9508\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0208/0938 | LOSS: 0.1758 | ACC 0.9509\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0209/0938 | LOSS: 0.1757 | ACC 0.9510\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0210/0938 | LOSS: 0.1759 | ACC 0.9509\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0211/0938 | LOSS: 0.1757 | ACC 0.9510\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0212/0938 | LOSS: 0.1751 | ACC 0.9512\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0213/0938 | LOSS: 0.1758 | ACC 0.9511\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0214/0938 | LOSS: 0.1760 | ACC 0.9511\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0215/0938 | LOSS: 0.1761 | ACC 0.9511\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0216/0938 | LOSS: 0.1763 | ACC 0.9510\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0217/0938 | LOSS: 0.1761 | ACC 0.9511\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0218/0938 | LOSS: 0.1766 | ACC 0.9509\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0219/0938 | LOSS: 0.1759 | ACC 0.9511\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0220/0938 | LOSS: 0.1761 | ACC 0.9511\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0221/0938 | LOSS: 0.1763 | ACC 0.9511\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0222/0938 | LOSS: 0.1765 | ACC 0.9509\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0223/0938 | LOSS: 0.1765 | ACC 0.9510\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0224/0938 | LOSS: 0.1768 | ACC 0.9508\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0225/0938 | LOSS: 0.1764 | ACC 0.9509\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0226/0938 | LOSS: 0.1765 | ACC 0.9509\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0227/0938 | LOSS: 0.1763 | ACC 0.9509\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0228/0938 | LOSS: 0.1766 | ACC 0.9508\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0229/0938 | LOSS: 0.1769 | ACC 0.9506\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0230/0938 | LOSS: 0.1767 | ACC 0.9507\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0231/0938 | LOSS: 0.1766 | ACC 0.9507\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0232/0938 | LOSS: 0.1775 | ACC 0.9504\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0233/0938 | LOSS: 0.1771 | ACC 0.9505\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0234/0938 | LOSS: 0.1773 | ACC 0.9501\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0235/0938 | LOSS: 0.1776 | ACC 0.9501\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0236/0938 | LOSS: 0.1772 | ACC 0.9502\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0237/0938 | LOSS: 0.1771 | ACC 0.9502\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0238/0938 | LOSS: 0.1768 | ACC 0.9502\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0239/0938 | LOSS: 0.1764 | ACC 0.9504\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0240/0938 | LOSS: 0.1764 | ACC 0.9502\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0241/0938 | LOSS: 0.1761 | ACC 0.9503\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: EPOCH 0007/0010 | BATCH 0242/0938 | LOSS: 0.1758 | ACC 0.9503\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0243/0938 | LOSS: 0.1762 | ACC 0.9501\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0244/0938 | LOSS: 0.1771 | ACC 0.9500\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0245/0938 | LOSS: 0.1769 | ACC 0.9500\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0246/0938 | LOSS: 0.1769 | ACC 0.9500\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0247/0938 | LOSS: 0.1772 | ACC 0.9499\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0248/0938 | LOSS: 0.1770 | ACC 0.9499\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0249/0938 | LOSS: 0.1770 | ACC 0.9499\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0250/0938 | LOSS: 0.1766 | ACC 0.9501\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0251/0938 | LOSS: 0.1766 | ACC 0.9500\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0252/0938 | LOSS: 0.1769 | ACC 0.9500\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0253/0938 | LOSS: 0.1772 | ACC 0.9497\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0254/0938 | LOSS: 0.1767 | ACC 0.9499\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0255/0938 | LOSS: 0.1764 | ACC 0.9500\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0256/0938 | LOSS: 0.1758 | ACC 0.9502\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0257/0938 | LOSS: 0.1759 | ACC 0.9503\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0258/0938 | LOSS: 0.1763 | ACC 0.9503\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0259/0938 | LOSS: 0.1764 | ACC 0.9503\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0260/0938 | LOSS: 0.1763 | ACC 0.9504\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0261/0938 | LOSS: 0.1765 | ACC 0.9503\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0262/0938 | LOSS: 0.1768 | ACC 0.9500\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0263/0938 | LOSS: 0.1767 | ACC 0.9500\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0264/0938 | LOSS: 0.1765 | ACC 0.9500\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0265/0938 | LOSS: 0.1768 | ACC 0.9499\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0266/0938 | LOSS: 0.1769 | ACC 0.9498\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0267/0938 | LOSS: 0.1772 | ACC 0.9498\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0268/0938 | LOSS: 0.1774 | ACC 0.9497\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0269/0938 | LOSS: 0.1785 | ACC 0.9495\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0270/0938 | LOSS: 0.1787 | ACC 0.9496\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0271/0938 | LOSS: 0.1787 | ACC 0.9496\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0272/0938 | LOSS: 0.1784 | ACC 0.9497\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0273/0938 | LOSS: 0.1782 | ACC 0.9497\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0274/0938 | LOSS: 0.1777 | ACC 0.9499\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0275/0938 | LOSS: 0.1771 | ACC 0.9501\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0276/0938 | LOSS: 0.1768 | ACC 0.9501\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0277/0938 | LOSS: 0.1767 | ACC 0.9501\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0278/0938 | LOSS: 0.1762 | ACC 0.9503\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0279/0938 | LOSS: 0.1760 | ACC 0.9503\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0280/0938 | LOSS: 0.1756 | ACC 0.9504\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0281/0938 | LOSS: 0.1757 | ACC 0.9505\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0282/0938 | LOSS: 0.1755 | ACC 0.9506\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0283/0938 | LOSS: 0.1752 | ACC 0.9506\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0284/0938 | LOSS: 0.1752 | ACC 0.9506\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0285/0938 | LOSS: 0.1749 | ACC 0.9507\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0286/0938 | LOSS: 0.1747 | ACC 0.9507\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0287/0938 | LOSS: 0.1746 | ACC 0.9507\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0288/0938 | LOSS: 0.1750 | ACC 0.9506\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0289/0938 | LOSS: 0.1747 | ACC 0.9507\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0290/0938 | LOSS: 0.1747 | ACC 0.9506\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0291/0938 | LOSS: 0.1745 | ACC 0.9506\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0292/0938 | LOSS: 0.1746 | ACC 0.9506\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0293/0938 | LOSS: 0.1742 | ACC 0.9507\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0294/0938 | LOSS: 0.1742 | ACC 0.9507\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0295/0938 | LOSS: 0.1746 | ACC 0.9505\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0296/0938 | LOSS: 0.1746 | ACC 0.9505\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0297/0938 | LOSS: 0.1744 | ACC 0.9506\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0298/0938 | LOSS: 0.1742 | ACC 0.9506\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0299/0938 | LOSS: 0.1743 | ACC 0.9506\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0300/0938 | LOSS: 0.1751 | ACC 0.9506\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0301/0938 | LOSS: 0.1753 | ACC 0.9505\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0302/0938 | LOSS: 0.1754 | ACC 0.9504\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0303/0938 | LOSS: 0.1752 | ACC 0.9504\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0304/0938 | LOSS: 0.1749 | ACC 0.9505\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0305/0938 | LOSS: 0.1749 | ACC 0.9505\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0306/0938 | LOSS: 0.1754 | ACC 0.9504\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0307/0938 | LOSS: 0.1753 | ACC 0.9505\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0308/0938 | LOSS: 0.1750 | ACC 0.9505\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0309/0938 | LOSS: 0.1751 | ACC 0.9503\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0310/0938 | LOSS: 0.1750 | ACC 0.9502\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0311/0938 | LOSS: 0.1746 | ACC 0.9503\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0312/0938 | LOSS: 0.1746 | ACC 0.9503\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0313/0938 | LOSS: 0.1755 | ACC 0.9500\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0314/0938 | LOSS: 0.1755 | ACC 0.9499\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0315/0938 | LOSS: 0.1754 | ACC 0.9499\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0316/0938 | LOSS: 0.1749 | ACC 0.9501\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0317/0938 | LOSS: 0.1747 | ACC 0.9501\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0318/0938 | LOSS: 0.1748 | ACC 0.9501\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0319/0938 | LOSS: 0.1752 | ACC 0.9500\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0320/0938 | LOSS: 0.1750 | ACC 0.9500\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0321/0938 | LOSS: 0.1748 | ACC 0.9500\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0322/0938 | LOSS: 0.1746 | ACC 0.9501\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0323/0938 | LOSS: 0.1747 | ACC 0.9500\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0324/0938 | LOSS: 0.1749 | ACC 0.9500\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0325/0938 | LOSS: 0.1749 | ACC 0.9500\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0326/0938 | LOSS: 0.1750 | ACC 0.9499\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0327/0938 | LOSS: 0.1750 | ACC 0.9498\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0328/0938 | LOSS: 0.1750 | ACC 0.9499\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0329/0938 | LOSS: 0.1756 | ACC 0.9497\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0330/0938 | LOSS: 0.1757 | ACC 0.9496\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0331/0938 | LOSS: 0.1756 | ACC 0.9496\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0332/0938 | LOSS: 0.1755 | ACC 0.9496\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0333/0938 | LOSS: 0.1760 | ACC 0.9494\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0334/0938 | LOSS: 0.1762 | ACC 0.9493\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0335/0938 | LOSS: 0.1759 | ACC 0.9493\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0336/0938 | LOSS: 0.1757 | ACC 0.9494\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0337/0938 | LOSS: 0.1756 | ACC 0.9494\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0338/0938 | LOSS: 0.1758 | ACC 0.9493\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0339/0938 | LOSS: 0.1756 | ACC 0.9494\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0340/0938 | LOSS: 0.1752 | ACC 0.9494\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0341/0938 | LOSS: 0.1751 | ACC 0.9495\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0342/0938 | LOSS: 0.1749 | ACC 0.9496\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0343/0938 | LOSS: 0.1750 | ACC 0.9495\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0344/0938 | LOSS: 0.1749 | ACC 0.9496\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0345/0938 | LOSS: 0.1746 | ACC 0.9497\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0346/0938 | LOSS: 0.1743 | ACC 0.9498\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0347/0938 | LOSS: 0.1740 | ACC 0.9499\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0348/0938 | LOSS: 0.1742 | ACC 0.9498\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0349/0938 | LOSS: 0.1742 | ACC 0.9499\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0350/0938 | LOSS: 0.1741 | ACC 0.9499\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0351/0938 | LOSS: 0.1741 | ACC 0.9499\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0352/0938 | LOSS: 0.1738 | ACC 0.9500\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0353/0938 | LOSS: 0.1743 | ACC 0.9498\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0354/0938 | LOSS: 0.1745 | ACC 0.9498\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0355/0938 | LOSS: 0.1745 | ACC 0.9499\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0356/0938 | LOSS: 0.1745 | ACC 0.9498\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0357/0938 | LOSS: 0.1746 | ACC 0.9497\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0358/0938 | LOSS: 0.1748 | ACC 0.9496\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0359/0938 | LOSS: 0.1745 | ACC 0.9497\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0360/0938 | LOSS: 0.1745 | ACC 0.9497\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0361/0938 | LOSS: 0.1743 | ACC 0.9498\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0362/0938 | LOSS: 0.1744 | ACC 0.9499\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0363/0938 | LOSS: 0.1744 | ACC 0.9499\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0364/0938 | LOSS: 0.1742 | ACC 0.9499\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0365/0938 | LOSS: 0.1741 | ACC 0.9499\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0366/0938 | LOSS: 0.1741 | ACC 0.9499\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0367/0938 | LOSS: 0.1741 | ACC 0.9499\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0368/0938 | LOSS: 0.1739 | ACC 0.9499\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0369/0938 | LOSS: 0.1742 | ACC 0.9499\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0370/0938 | LOSS: 0.1739 | ACC 0.9500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: EPOCH 0007/0010 | BATCH 0371/0938 | LOSS: 0.1740 | ACC 0.9500\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0372/0938 | LOSS: 0.1738 | ACC 0.9501\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0373/0938 | LOSS: 0.1736 | ACC 0.9501\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0374/0938 | LOSS: 0.1734 | ACC 0.9502\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0375/0938 | LOSS: 0.1735 | ACC 0.9501\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0376/0938 | LOSS: 0.1738 | ACC 0.9501\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0377/0938 | LOSS: 0.1735 | ACC 0.9502\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0378/0938 | LOSS: 0.1737 | ACC 0.9501\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0379/0938 | LOSS: 0.1740 | ACC 0.9500\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0380/0938 | LOSS: 0.1744 | ACC 0.9500\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0381/0938 | LOSS: 0.1749 | ACC 0.9499\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0382/0938 | LOSS: 0.1748 | ACC 0.9499\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0383/0938 | LOSS: 0.1750 | ACC 0.9499\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0384/0938 | LOSS: 0.1749 | ACC 0.9499\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0385/0938 | LOSS: 0.1747 | ACC 0.9499\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0386/0938 | LOSS: 0.1750 | ACC 0.9499\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0387/0938 | LOSS: 0.1751 | ACC 0.9499\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0388/0938 | LOSS: 0.1750 | ACC 0.9499\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0389/0938 | LOSS: 0.1747 | ACC 0.9500\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0390/0938 | LOSS: 0.1748 | ACC 0.9500\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0391/0938 | LOSS: 0.1747 | ACC 0.9500\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0392/0938 | LOSS: 0.1746 | ACC 0.9499\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0393/0938 | LOSS: 0.1744 | ACC 0.9499\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0394/0938 | LOSS: 0.1742 | ACC 0.9500\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0395/0938 | LOSS: 0.1739 | ACC 0.9501\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0396/0938 | LOSS: 0.1739 | ACC 0.9501\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0397/0938 | LOSS: 0.1741 | ACC 0.9500\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0398/0938 | LOSS: 0.1738 | ACC 0.9501\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0399/0938 | LOSS: 0.1743 | ACC 0.9500\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0400/0938 | LOSS: 0.1742 | ACC 0.9500\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0401/0938 | LOSS: 0.1742 | ACC 0.9500\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0402/0938 | LOSS: 0.1742 | ACC 0.9500\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0403/0938 | LOSS: 0.1746 | ACC 0.9499\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0404/0938 | LOSS: 0.1747 | ACC 0.9499\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0405/0938 | LOSS: 0.1746 | ACC 0.9499\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0406/0938 | LOSS: 0.1747 | ACC 0.9499\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0407/0938 | LOSS: 0.1746 | ACC 0.9500\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0408/0938 | LOSS: 0.1745 | ACC 0.9500\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0409/0938 | LOSS: 0.1742 | ACC 0.9501\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0410/0938 | LOSS: 0.1745 | ACC 0.9499\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0411/0938 | LOSS: 0.1744 | ACC 0.9499\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0412/0938 | LOSS: 0.1743 | ACC 0.9500\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0413/0938 | LOSS: 0.1750 | ACC 0.9498\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0414/0938 | LOSS: 0.1750 | ACC 0.9498\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0415/0938 | LOSS: 0.1750 | ACC 0.9498\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0416/0938 | LOSS: 0.1749 | ACC 0.9498\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0417/0938 | LOSS: 0.1752 | ACC 0.9497\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0418/0938 | LOSS: 0.1750 | ACC 0.9497\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0419/0938 | LOSS: 0.1750 | ACC 0.9498\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0420/0938 | LOSS: 0.1747 | ACC 0.9499\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0421/0938 | LOSS: 0.1746 | ACC 0.9499\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0422/0938 | LOSS: 0.1747 | ACC 0.9499\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0423/0938 | LOSS: 0.1744 | ACC 0.9499\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0424/0938 | LOSS: 0.1743 | ACC 0.9499\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0425/0938 | LOSS: 0.1742 | ACC 0.9500\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0426/0938 | LOSS: 0.1744 | ACC 0.9500\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0427/0938 | LOSS: 0.1745 | ACC 0.9500\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0428/0938 | LOSS: 0.1743 | ACC 0.9501\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0429/0938 | LOSS: 0.1742 | ACC 0.9501\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0430/0938 | LOSS: 0.1740 | ACC 0.9502\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0431/0938 | LOSS: 0.1740 | ACC 0.9501\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0432/0938 | LOSS: 0.1741 | ACC 0.9501\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0433/0938 | LOSS: 0.1739 | ACC 0.9501\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0434/0938 | LOSS: 0.1739 | ACC 0.9501\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0435/0938 | LOSS: 0.1738 | ACC 0.9501\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0436/0938 | LOSS: 0.1736 | ACC 0.9501\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0437/0938 | LOSS: 0.1734 | ACC 0.9502\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0438/0938 | LOSS: 0.1732 | ACC 0.9503\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0439/0938 | LOSS: 0.1732 | ACC 0.9502\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0440/0938 | LOSS: 0.1729 | ACC 0.9503\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0441/0938 | LOSS: 0.1728 | ACC 0.9503\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0442/0938 | LOSS: 0.1726 | ACC 0.9504\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0443/0938 | LOSS: 0.1725 | ACC 0.9505\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0444/0938 | LOSS: 0.1727 | ACC 0.9504\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0445/0938 | LOSS: 0.1727 | ACC 0.9504\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0446/0938 | LOSS: 0.1733 | ACC 0.9503\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0447/0938 | LOSS: 0.1733 | ACC 0.9503\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0448/0938 | LOSS: 0.1733 | ACC 0.9503\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0449/0938 | LOSS: 0.1732 | ACC 0.9502\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0450/0938 | LOSS: 0.1733 | ACC 0.9502\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0451/0938 | LOSS: 0.1733 | ACC 0.9502\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0452/0938 | LOSS: 0.1731 | ACC 0.9502\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0453/0938 | LOSS: 0.1731 | ACC 0.9502\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0454/0938 | LOSS: 0.1733 | ACC 0.9501\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0455/0938 | LOSS: 0.1733 | ACC 0.9501\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0456/0938 | LOSS: 0.1733 | ACC 0.9500\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0457/0938 | LOSS: 0.1736 | ACC 0.9499\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0458/0938 | LOSS: 0.1735 | ACC 0.9499\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0459/0938 | LOSS: 0.1733 | ACC 0.9500\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0460/0938 | LOSS: 0.1733 | ACC 0.9500\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0461/0938 | LOSS: 0.1732 | ACC 0.9500\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0462/0938 | LOSS: 0.1731 | ACC 0.9499\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0463/0938 | LOSS: 0.1733 | ACC 0.9500\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0464/0938 | LOSS: 0.1731 | ACC 0.9500\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0465/0938 | LOSS: 0.1734 | ACC 0.9500\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0466/0938 | LOSS: 0.1734 | ACC 0.9499\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0467/0938 | LOSS: 0.1740 | ACC 0.9499\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0468/0938 | LOSS: 0.1739 | ACC 0.9499\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0469/0938 | LOSS: 0.1738 | ACC 0.9499\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0470/0938 | LOSS: 0.1738 | ACC 0.9499\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0471/0938 | LOSS: 0.1739 | ACC 0.9499\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0472/0938 | LOSS: 0.1741 | ACC 0.9497\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0473/0938 | LOSS: 0.1739 | ACC 0.9498\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0474/0938 | LOSS: 0.1736 | ACC 0.9499\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0475/0938 | LOSS: 0.1739 | ACC 0.9497\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0476/0938 | LOSS: 0.1738 | ACC 0.9498\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0477/0938 | LOSS: 0.1737 | ACC 0.9498\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0478/0938 | LOSS: 0.1739 | ACC 0.9498\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0479/0938 | LOSS: 0.1740 | ACC 0.9497\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0480/0938 | LOSS: 0.1739 | ACC 0.9497\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0481/0938 | LOSS: 0.1741 | ACC 0.9497\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0482/0938 | LOSS: 0.1740 | ACC 0.9498\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0483/0938 | LOSS: 0.1740 | ACC 0.9498\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0484/0938 | LOSS: 0.1744 | ACC 0.9496\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0485/0938 | LOSS: 0.1742 | ACC 0.9497\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0486/0938 | LOSS: 0.1742 | ACC 0.9497\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0487/0938 | LOSS: 0.1743 | ACC 0.9497\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0488/0938 | LOSS: 0.1742 | ACC 0.9497\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0489/0938 | LOSS: 0.1742 | ACC 0.9496\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0490/0938 | LOSS: 0.1744 | ACC 0.9496\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0491/0938 | LOSS: 0.1743 | ACC 0.9496\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0492/0938 | LOSS: 0.1746 | ACC 0.9495\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0493/0938 | LOSS: 0.1748 | ACC 0.9495\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0494/0938 | LOSS: 0.1749 | ACC 0.9494\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0495/0938 | LOSS: 0.1749 | ACC 0.9494\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0496/0938 | LOSS: 0.1749 | ACC 0.9494\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0497/0938 | LOSS: 0.1750 | ACC 0.9494\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0498/0938 | LOSS: 0.1753 | ACC 0.9494\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0499/0938 | LOSS: 0.1756 | ACC 0.9493\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: EPOCH 0007/0010 | BATCH 0500/0938 | LOSS: 0.1755 | ACC 0.9493\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0501/0938 | LOSS: 0.1756 | ACC 0.9493\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0502/0938 | LOSS: 0.1754 | ACC 0.9494\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0503/0938 | LOSS: 0.1753 | ACC 0.9494\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0504/0938 | LOSS: 0.1752 | ACC 0.9494\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0505/0938 | LOSS: 0.1754 | ACC 0.9495\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0506/0938 | LOSS: 0.1755 | ACC 0.9495\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0507/0938 | LOSS: 0.1756 | ACC 0.9494\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0508/0938 | LOSS: 0.1760 | ACC 0.9492\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0509/0938 | LOSS: 0.1766 | ACC 0.9491\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0510/0938 | LOSS: 0.1768 | ACC 0.9491\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0511/0938 | LOSS: 0.1768 | ACC 0.9490\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0512/0938 | LOSS: 0.1768 | ACC 0.9490\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0513/0938 | LOSS: 0.1773 | ACC 0.9489\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0514/0938 | LOSS: 0.1774 | ACC 0.9489\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0515/0938 | LOSS: 0.1774 | ACC 0.9489\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0516/0938 | LOSS: 0.1775 | ACC 0.9489\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0517/0938 | LOSS: 0.1775 | ACC 0.9489\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0518/0938 | LOSS: 0.1774 | ACC 0.9489\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0519/0938 | LOSS: 0.1772 | ACC 0.9489\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0520/0938 | LOSS: 0.1770 | ACC 0.9489\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0521/0938 | LOSS: 0.1770 | ACC 0.9490\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0522/0938 | LOSS: 0.1772 | ACC 0.9489\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0523/0938 | LOSS: 0.1772 | ACC 0.9489\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0524/0938 | LOSS: 0.1777 | ACC 0.9488\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0525/0938 | LOSS: 0.1779 | ACC 0.9487\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0526/0938 | LOSS: 0.1780 | ACC 0.9487\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0527/0938 | LOSS: 0.1780 | ACC 0.9487\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0528/0938 | LOSS: 0.1778 | ACC 0.9488\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0529/0938 | LOSS: 0.1779 | ACC 0.9488\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0530/0938 | LOSS: 0.1777 | ACC 0.9489\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0531/0938 | LOSS: 0.1776 | ACC 0.9489\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0532/0938 | LOSS: 0.1777 | ACC 0.9489\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0533/0938 | LOSS: 0.1777 | ACC 0.9489\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0534/0938 | LOSS: 0.1774 | ACC 0.9490\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0535/0938 | LOSS: 0.1774 | ACC 0.9490\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0536/0938 | LOSS: 0.1772 | ACC 0.9490\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0537/0938 | LOSS: 0.1777 | ACC 0.9491\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0538/0938 | LOSS: 0.1775 | ACC 0.9491\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0539/0938 | LOSS: 0.1773 | ACC 0.9492\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0540/0938 | LOSS: 0.1771 | ACC 0.9493\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0541/0938 | LOSS: 0.1773 | ACC 0.9493\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0542/0938 | LOSS: 0.1771 | ACC 0.9493\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0543/0938 | LOSS: 0.1771 | ACC 0.9492\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0544/0938 | LOSS: 0.1773 | ACC 0.9492\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0545/0938 | LOSS: 0.1773 | ACC 0.9492\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0546/0938 | LOSS: 0.1772 | ACC 0.9493\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0547/0938 | LOSS: 0.1773 | ACC 0.9492\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0548/0938 | LOSS: 0.1772 | ACC 0.9492\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0549/0938 | LOSS: 0.1772 | ACC 0.9493\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0550/0938 | LOSS: 0.1771 | ACC 0.9493\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0551/0938 | LOSS: 0.1771 | ACC 0.9493\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0552/0938 | LOSS: 0.1771 | ACC 0.9492\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0553/0938 | LOSS: 0.1771 | ACC 0.9493\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0554/0938 | LOSS: 0.1771 | ACC 0.9493\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0555/0938 | LOSS: 0.1769 | ACC 0.9493\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0556/0938 | LOSS: 0.1772 | ACC 0.9492\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0557/0938 | LOSS: 0.1772 | ACC 0.9492\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0558/0938 | LOSS: 0.1771 | ACC 0.9492\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0559/0938 | LOSS: 0.1771 | ACC 0.9492\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0560/0938 | LOSS: 0.1768 | ACC 0.9493\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0561/0938 | LOSS: 0.1769 | ACC 0.9493\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0562/0938 | LOSS: 0.1768 | ACC 0.9493\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0563/0938 | LOSS: 0.1768 | ACC 0.9493\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0564/0938 | LOSS: 0.1767 | ACC 0.9493\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0565/0938 | LOSS: 0.1766 | ACC 0.9493\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0566/0938 | LOSS: 0.1769 | ACC 0.9492\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0567/0938 | LOSS: 0.1767 | ACC 0.9493\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0568/0938 | LOSS: 0.1765 | ACC 0.9493\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0569/0938 | LOSS: 0.1763 | ACC 0.9494\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0570/0938 | LOSS: 0.1763 | ACC 0.9494\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0571/0938 | LOSS: 0.1764 | ACC 0.9493\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0572/0938 | LOSS: 0.1769 | ACC 0.9492\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0573/0938 | LOSS: 0.1771 | ACC 0.9493\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0574/0938 | LOSS: 0.1769 | ACC 0.9493\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0575/0938 | LOSS: 0.1768 | ACC 0.9493\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0576/0938 | LOSS: 0.1769 | ACC 0.9493\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0577/0938 | LOSS: 0.1770 | ACC 0.9493\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0578/0938 | LOSS: 0.1770 | ACC 0.9493\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0579/0938 | LOSS: 0.1773 | ACC 0.9492\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0580/0938 | LOSS: 0.1772 | ACC 0.9492\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0581/0938 | LOSS: 0.1772 | ACC 0.9492\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0582/0938 | LOSS: 0.1775 | ACC 0.9492\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0583/0938 | LOSS: 0.1776 | ACC 0.9492\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0584/0938 | LOSS: 0.1775 | ACC 0.9492\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0585/0938 | LOSS: 0.1773 | ACC 0.9492\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0586/0938 | LOSS: 0.1773 | ACC 0.9492\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0587/0938 | LOSS: 0.1776 | ACC 0.9492\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0588/0938 | LOSS: 0.1775 | ACC 0.9492\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0589/0938 | LOSS: 0.1773 | ACC 0.9493\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0590/0938 | LOSS: 0.1775 | ACC 0.9493\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0591/0938 | LOSS: 0.1774 | ACC 0.9493\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0592/0938 | LOSS: 0.1774 | ACC 0.9493\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0593/0938 | LOSS: 0.1775 | ACC 0.9492\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0594/0938 | LOSS: 0.1777 | ACC 0.9492\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0595/0938 | LOSS: 0.1776 | ACC 0.9492\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0596/0938 | LOSS: 0.1779 | ACC 0.9491\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0597/0938 | LOSS: 0.1780 | ACC 0.9490\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0598/0938 | LOSS: 0.1778 | ACC 0.9491\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0599/0938 | LOSS: 0.1777 | ACC 0.9491\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0600/0938 | LOSS: 0.1777 | ACC 0.9491\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0601/0938 | LOSS: 0.1775 | ACC 0.9492\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0602/0938 | LOSS: 0.1775 | ACC 0.9492\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0603/0938 | LOSS: 0.1775 | ACC 0.9492\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0604/0938 | LOSS: 0.1774 | ACC 0.9492\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0605/0938 | LOSS: 0.1774 | ACC 0.9492\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0606/0938 | LOSS: 0.1773 | ACC 0.9492\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0607/0938 | LOSS: 0.1771 | ACC 0.9493\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0608/0938 | LOSS: 0.1771 | ACC 0.9493\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0609/0938 | LOSS: 0.1774 | ACC 0.9493\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0610/0938 | LOSS: 0.1776 | ACC 0.9492\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0611/0938 | LOSS: 0.1776 | ACC 0.9492\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0612/0938 | LOSS: 0.1775 | ACC 0.9492\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0613/0938 | LOSS: 0.1775 | ACC 0.9492\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0614/0938 | LOSS: 0.1776 | ACC 0.9492\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0615/0938 | LOSS: 0.1774 | ACC 0.9492\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0616/0938 | LOSS: 0.1773 | ACC 0.9492\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0617/0938 | LOSS: 0.1773 | ACC 0.9491\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0618/0938 | LOSS: 0.1773 | ACC 0.9492\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0619/0938 | LOSS: 0.1771 | ACC 0.9492\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0620/0938 | LOSS: 0.1773 | ACC 0.9492\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0621/0938 | LOSS: 0.1772 | ACC 0.9492\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0622/0938 | LOSS: 0.1772 | ACC 0.9492\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0623/0938 | LOSS: 0.1772 | ACC 0.9493\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0624/0938 | LOSS: 0.1771 | ACC 0.9493\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0625/0938 | LOSS: 0.1770 | ACC 0.9493\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: EPOCH 0007/0010 | BATCH 0626/0938 | LOSS: 0.1771 | ACC 0.9492\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0627/0938 | LOSS: 0.1769 | ACC 0.9493\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0628/0938 | LOSS: 0.1768 | ACC 0.9493\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0629/0938 | LOSS: 0.1768 | ACC 0.9493\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0630/0938 | LOSS: 0.1767 | ACC 0.9493\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0631/0938 | LOSS: 0.1766 | ACC 0.9493\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0632/0938 | LOSS: 0.1765 | ACC 0.9493\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0633/0938 | LOSS: 0.1765 | ACC 0.9493\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0634/0938 | LOSS: 0.1765 | ACC 0.9493\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0635/0938 | LOSS: 0.1765 | ACC 0.9494\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0636/0938 | LOSS: 0.1763 | ACC 0.9494\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0637/0938 | LOSS: 0.1762 | ACC 0.9494\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0638/0938 | LOSS: 0.1762 | ACC 0.9494\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0639/0938 | LOSS: 0.1761 | ACC 0.9495\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0640/0938 | LOSS: 0.1760 | ACC 0.9495\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0641/0938 | LOSS: 0.1760 | ACC 0.9495\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0642/0938 | LOSS: 0.1762 | ACC 0.9494\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0643/0938 | LOSS: 0.1762 | ACC 0.9494\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0644/0938 | LOSS: 0.1762 | ACC 0.9494\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0645/0938 | LOSS: 0.1763 | ACC 0.9493\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0646/0938 | LOSS: 0.1762 | ACC 0.9494\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0647/0938 | LOSS: 0.1761 | ACC 0.9494\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0648/0938 | LOSS: 0.1760 | ACC 0.9494\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0649/0938 | LOSS: 0.1763 | ACC 0.9493\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0650/0938 | LOSS: 0.1762 | ACC 0.9494\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0651/0938 | LOSS: 0.1761 | ACC 0.9494\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0652/0938 | LOSS: 0.1759 | ACC 0.9495\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0653/0938 | LOSS: 0.1761 | ACC 0.9495\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0654/0938 | LOSS: 0.1760 | ACC 0.9495\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0655/0938 | LOSS: 0.1758 | ACC 0.9495\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0656/0938 | LOSS: 0.1757 | ACC 0.9496\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0657/0938 | LOSS: 0.1757 | ACC 0.9496\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0658/0938 | LOSS: 0.1756 | ACC 0.9496\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0659/0938 | LOSS: 0.1755 | ACC 0.9496\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0660/0938 | LOSS: 0.1753 | ACC 0.9497\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0661/0938 | LOSS: 0.1752 | ACC 0.9497\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0662/0938 | LOSS: 0.1754 | ACC 0.9497\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0663/0938 | LOSS: 0.1756 | ACC 0.9496\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0664/0938 | LOSS: 0.1756 | ACC 0.9496\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0665/0938 | LOSS: 0.1754 | ACC 0.9496\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0666/0938 | LOSS: 0.1753 | ACC 0.9496\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0667/0938 | LOSS: 0.1755 | ACC 0.9496\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0668/0938 | LOSS: 0.1757 | ACC 0.9495\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0669/0938 | LOSS: 0.1757 | ACC 0.9495\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0670/0938 | LOSS: 0.1757 | ACC 0.9495\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0671/0938 | LOSS: 0.1757 | ACC 0.9495\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0672/0938 | LOSS: 0.1755 | ACC 0.9495\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0673/0938 | LOSS: 0.1756 | ACC 0.9495\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0674/0938 | LOSS: 0.1757 | ACC 0.9495\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0675/0938 | LOSS: 0.1757 | ACC 0.9494\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0676/0938 | LOSS: 0.1756 | ACC 0.9495\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0677/0938 | LOSS: 0.1754 | ACC 0.9495\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0678/0938 | LOSS: 0.1753 | ACC 0.9495\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0679/0938 | LOSS: 0.1752 | ACC 0.9496\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0680/0938 | LOSS: 0.1751 | ACC 0.9496\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0681/0938 | LOSS: 0.1751 | ACC 0.9496\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0682/0938 | LOSS: 0.1751 | ACC 0.9496\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0683/0938 | LOSS: 0.1750 | ACC 0.9496\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0684/0938 | LOSS: 0.1749 | ACC 0.9496\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0685/0938 | LOSS: 0.1750 | ACC 0.9496\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0686/0938 | LOSS: 0.1751 | ACC 0.9496\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0687/0938 | LOSS: 0.1751 | ACC 0.9496\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0688/0938 | LOSS: 0.1752 | ACC 0.9496\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0689/0938 | LOSS: 0.1751 | ACC 0.9496\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0690/0938 | LOSS: 0.1751 | ACC 0.9496\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0691/0938 | LOSS: 0.1750 | ACC 0.9496\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0692/0938 | LOSS: 0.1749 | ACC 0.9496\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0693/0938 | LOSS: 0.1747 | ACC 0.9497\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0694/0938 | LOSS: 0.1751 | ACC 0.9496\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0695/0938 | LOSS: 0.1750 | ACC 0.9497\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0696/0938 | LOSS: 0.1752 | ACC 0.9496\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0697/0938 | LOSS: 0.1751 | ACC 0.9496\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0698/0938 | LOSS: 0.1750 | ACC 0.9497\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0699/0938 | LOSS: 0.1751 | ACC 0.9497\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0700/0938 | LOSS: 0.1751 | ACC 0.9497\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0701/0938 | LOSS: 0.1750 | ACC 0.9498\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0702/0938 | LOSS: 0.1752 | ACC 0.9497\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0703/0938 | LOSS: 0.1752 | ACC 0.9497\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0704/0938 | LOSS: 0.1752 | ACC 0.9497\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0705/0938 | LOSS: 0.1750 | ACC 0.9498\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0706/0938 | LOSS: 0.1749 | ACC 0.9498\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0707/0938 | LOSS: 0.1751 | ACC 0.9498\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0708/0938 | LOSS: 0.1750 | ACC 0.9498\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0709/0938 | LOSS: 0.1750 | ACC 0.9498\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0710/0938 | LOSS: 0.1751 | ACC 0.9498\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0711/0938 | LOSS: 0.1750 | ACC 0.9499\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0712/0938 | LOSS: 0.1748 | ACC 0.9499\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0713/0938 | LOSS: 0.1747 | ACC 0.9499\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0714/0938 | LOSS: 0.1747 | ACC 0.9499\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0715/0938 | LOSS: 0.1747 | ACC 0.9498\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0716/0938 | LOSS: 0.1751 | ACC 0.9497\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0717/0938 | LOSS: 0.1752 | ACC 0.9497\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0718/0938 | LOSS: 0.1753 | ACC 0.9497\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0719/0938 | LOSS: 0.1752 | ACC 0.9497\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0720/0938 | LOSS: 0.1752 | ACC 0.9497\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0721/0938 | LOSS: 0.1752 | ACC 0.9497\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0722/0938 | LOSS: 0.1753 | ACC 0.9497\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0723/0938 | LOSS: 0.1754 | ACC 0.9497\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0724/0938 | LOSS: 0.1753 | ACC 0.9497\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0725/0938 | LOSS: 0.1751 | ACC 0.9498\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0726/0938 | LOSS: 0.1751 | ACC 0.9498\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0727/0938 | LOSS: 0.1751 | ACC 0.9498\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0728/0938 | LOSS: 0.1750 | ACC 0.9497\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0729/0938 | LOSS: 0.1751 | ACC 0.9497\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0730/0938 | LOSS: 0.1752 | ACC 0.9497\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0731/0938 | LOSS: 0.1751 | ACC 0.9497\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0732/0938 | LOSS: 0.1749 | ACC 0.9497\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0733/0938 | LOSS: 0.1748 | ACC 0.9498\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0734/0938 | LOSS: 0.1747 | ACC 0.9498\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0735/0938 | LOSS: 0.1746 | ACC 0.9498\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0736/0938 | LOSS: 0.1746 | ACC 0.9498\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0737/0938 | LOSS: 0.1747 | ACC 0.9497\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0738/0938 | LOSS: 0.1746 | ACC 0.9498\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0739/0938 | LOSS: 0.1747 | ACC 0.9497\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0740/0938 | LOSS: 0.1747 | ACC 0.9497\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0741/0938 | LOSS: 0.1749 | ACC 0.9497\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0742/0938 | LOSS: 0.1749 | ACC 0.9497\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0743/0938 | LOSS: 0.1748 | ACC 0.9497\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0744/0938 | LOSS: 0.1748 | ACC 0.9497\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0745/0938 | LOSS: 0.1749 | ACC 0.9496\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0746/0938 | LOSS: 0.1747 | ACC 0.9497\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0747/0938 | LOSS: 0.1746 | ACC 0.9497\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0748/0938 | LOSS: 0.1745 | ACC 0.9498\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0749/0938 | LOSS: 0.1746 | ACC 0.9497\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0750/0938 | LOSS: 0.1746 | ACC 0.9497\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0751/0938 | LOSS: 0.1744 | ACC 0.9498\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0752/0938 | LOSS: 0.1744 | ACC 0.9498\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: EPOCH 0007/0010 | BATCH 0753/0938 | LOSS: 0.1744 | ACC 0.9498\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0754/0938 | LOSS: 0.1743 | ACC 0.9498\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0755/0938 | LOSS: 0.1741 | ACC 0.9498\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0756/0938 | LOSS: 0.1741 | ACC 0.9498\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0757/0938 | LOSS: 0.1743 | ACC 0.9498\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0758/0938 | LOSS: 0.1744 | ACC 0.9498\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0759/0938 | LOSS: 0.1744 | ACC 0.9498\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0760/0938 | LOSS: 0.1742 | ACC 0.9498\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0761/0938 | LOSS: 0.1743 | ACC 0.9498\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0762/0938 | LOSS: 0.1745 | ACC 0.9497\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0763/0938 | LOSS: 0.1744 | ACC 0.9497\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0764/0938 | LOSS: 0.1743 | ACC 0.9497\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0765/0938 | LOSS: 0.1745 | ACC 0.9497\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0766/0938 | LOSS: 0.1744 | ACC 0.9497\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0767/0938 | LOSS: 0.1742 | ACC 0.9497\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0768/0938 | LOSS: 0.1741 | ACC 0.9497\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0769/0938 | LOSS: 0.1741 | ACC 0.9498\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0770/0938 | LOSS: 0.1743 | ACC 0.9497\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0771/0938 | LOSS: 0.1742 | ACC 0.9497\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0772/0938 | LOSS: 0.1743 | ACC 0.9497\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0773/0938 | LOSS: 0.1743 | ACC 0.9497\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0774/0938 | LOSS: 0.1742 | ACC 0.9498\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0775/0938 | LOSS: 0.1742 | ACC 0.9497\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0776/0938 | LOSS: 0.1741 | ACC 0.9498\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0777/0938 | LOSS: 0.1743 | ACC 0.9497\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0778/0938 | LOSS: 0.1742 | ACC 0.9498\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0779/0938 | LOSS: 0.1742 | ACC 0.9498\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0780/0938 | LOSS: 0.1743 | ACC 0.9497\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0781/0938 | LOSS: 0.1746 | ACC 0.9497\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0782/0938 | LOSS: 0.1744 | ACC 0.9497\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0783/0938 | LOSS: 0.1748 | ACC 0.9497\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0784/0938 | LOSS: 0.1748 | ACC 0.9497\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0785/0938 | LOSS: 0.1749 | ACC 0.9497\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0786/0938 | LOSS: 0.1752 | ACC 0.9496\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0787/0938 | LOSS: 0.1755 | ACC 0.9496\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0788/0938 | LOSS: 0.1754 | ACC 0.9496\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0789/0938 | LOSS: 0.1755 | ACC 0.9496\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0790/0938 | LOSS: 0.1754 | ACC 0.9496\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0791/0938 | LOSS: 0.1754 | ACC 0.9496\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0792/0938 | LOSS: 0.1754 | ACC 0.9496\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0793/0938 | LOSS: 0.1755 | ACC 0.9496\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0794/0938 | LOSS: 0.1756 | ACC 0.9495\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0795/0938 | LOSS: 0.1755 | ACC 0.9495\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0796/0938 | LOSS: 0.1754 | ACC 0.9496\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0797/0938 | LOSS: 0.1753 | ACC 0.9496\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0798/0938 | LOSS: 0.1752 | ACC 0.9496\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0799/0938 | LOSS: 0.1751 | ACC 0.9496\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0800/0938 | LOSS: 0.1751 | ACC 0.9496\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0801/0938 | LOSS: 0.1752 | ACC 0.9496\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0802/0938 | LOSS: 0.1753 | ACC 0.9496\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0803/0938 | LOSS: 0.1753 | ACC 0.9495\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0804/0938 | LOSS: 0.1755 | ACC 0.9495\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0805/0938 | LOSS: 0.1754 | ACC 0.9495\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0806/0938 | LOSS: 0.1754 | ACC 0.9495\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0807/0938 | LOSS: 0.1753 | ACC 0.9496\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0808/0938 | LOSS: 0.1753 | ACC 0.9495\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0809/0938 | LOSS: 0.1752 | ACC 0.9495\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0810/0938 | LOSS: 0.1753 | ACC 0.9495\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0811/0938 | LOSS: 0.1753 | ACC 0.9494\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0812/0938 | LOSS: 0.1754 | ACC 0.9494\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0813/0938 | LOSS: 0.1753 | ACC 0.9494\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0814/0938 | LOSS: 0.1752 | ACC 0.9495\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0815/0938 | LOSS: 0.1753 | ACC 0.9494\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0816/0938 | LOSS: 0.1752 | ACC 0.9495\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0817/0938 | LOSS: 0.1752 | ACC 0.9495\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0818/0938 | LOSS: 0.1750 | ACC 0.9496\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0819/0938 | LOSS: 0.1749 | ACC 0.9496\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0820/0938 | LOSS: 0.1748 | ACC 0.9496\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0821/0938 | LOSS: 0.1747 | ACC 0.9497\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0822/0938 | LOSS: 0.1746 | ACC 0.9497\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0823/0938 | LOSS: 0.1745 | ACC 0.9497\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0824/0938 | LOSS: 0.1744 | ACC 0.9497\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0825/0938 | LOSS: 0.1743 | ACC 0.9497\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0826/0938 | LOSS: 0.1744 | ACC 0.9497\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0827/0938 | LOSS: 0.1744 | ACC 0.9497\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0828/0938 | LOSS: 0.1744 | ACC 0.9497\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0829/0938 | LOSS: 0.1744 | ACC 0.9497\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0830/0938 | LOSS: 0.1744 | ACC 0.9497\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0831/0938 | LOSS: 0.1744 | ACC 0.9497\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0832/0938 | LOSS: 0.1744 | ACC 0.9496\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0833/0938 | LOSS: 0.1745 | ACC 0.9497\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0834/0938 | LOSS: 0.1743 | ACC 0.9497\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0835/0938 | LOSS: 0.1743 | ACC 0.9497\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0836/0938 | LOSS: 0.1743 | ACC 0.9496\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0837/0938 | LOSS: 0.1742 | ACC 0.9497\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0838/0938 | LOSS: 0.1741 | ACC 0.9497\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0839/0938 | LOSS: 0.1740 | ACC 0.9497\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0840/0938 | LOSS: 0.1739 | ACC 0.9498\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0841/0938 | LOSS: 0.1739 | ACC 0.9497\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0842/0938 | LOSS: 0.1739 | ACC 0.9498\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0843/0938 | LOSS: 0.1739 | ACC 0.9498\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0844/0938 | LOSS: 0.1739 | ACC 0.9498\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0845/0938 | LOSS: 0.1739 | ACC 0.9497\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0846/0938 | LOSS: 0.1738 | ACC 0.9498\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0847/0938 | LOSS: 0.1738 | ACC 0.9498\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0848/0938 | LOSS: 0.1738 | ACC 0.9497\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0849/0938 | LOSS: 0.1737 | ACC 0.9497\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0850/0938 | LOSS: 0.1736 | ACC 0.9498\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0851/0938 | LOSS: 0.1737 | ACC 0.9497\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0852/0938 | LOSS: 0.1738 | ACC 0.9497\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0853/0938 | LOSS: 0.1740 | ACC 0.9497\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0854/0938 | LOSS: 0.1742 | ACC 0.9496\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0855/0938 | LOSS: 0.1742 | ACC 0.9496\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0856/0938 | LOSS: 0.1744 | ACC 0.9496\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0857/0938 | LOSS: 0.1742 | ACC 0.9496\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0858/0938 | LOSS: 0.1743 | ACC 0.9496\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0859/0938 | LOSS: 0.1742 | ACC 0.9496\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0860/0938 | LOSS: 0.1742 | ACC 0.9496\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0861/0938 | LOSS: 0.1742 | ACC 0.9496\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0862/0938 | LOSS: 0.1741 | ACC 0.9496\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0863/0938 | LOSS: 0.1743 | ACC 0.9495\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0864/0938 | LOSS: 0.1742 | ACC 0.9496\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0865/0938 | LOSS: 0.1743 | ACC 0.9495\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0866/0938 | LOSS: 0.1743 | ACC 0.9496\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0867/0938 | LOSS: 0.1741 | ACC 0.9496\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0868/0938 | LOSS: 0.1741 | ACC 0.9496\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0869/0938 | LOSS: 0.1742 | ACC 0.9496\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0870/0938 | LOSS: 0.1741 | ACC 0.9496\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0871/0938 | LOSS: 0.1742 | ACC 0.9496\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0872/0938 | LOSS: 0.1741 | ACC 0.9496\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0873/0938 | LOSS: 0.1740 | ACC 0.9497\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0874/0938 | LOSS: 0.1739 | ACC 0.9497\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0875/0938 | LOSS: 0.1739 | ACC 0.9497\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0876/0938 | LOSS: 0.1739 | ACC 0.9497\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0877/0938 | LOSS: 0.1738 | ACC 0.9497\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0878/0938 | LOSS: 0.1738 | ACC 0.9497\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0879/0938 | LOSS: 0.1737 | ACC 0.9497\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0880/0938 | LOSS: 0.1737 | ACC 0.9496\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0881/0938 | LOSS: 0.1736 | ACC 0.9497\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: EPOCH 0007/0010 | BATCH 0882/0938 | LOSS: 0.1735 | ACC 0.9497\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0883/0938 | LOSS: 0.1734 | ACC 0.9498\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0884/0938 | LOSS: 0.1734 | ACC 0.9497\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0885/0938 | LOSS: 0.1733 | ACC 0.9498\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0886/0938 | LOSS: 0.1732 | ACC 0.9498\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0887/0938 | LOSS: 0.1733 | ACC 0.9498\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0888/0938 | LOSS: 0.1735 | ACC 0.9498\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0889/0938 | LOSS: 0.1734 | ACC 0.9498\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0890/0938 | LOSS: 0.1734 | ACC 0.9498\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0891/0938 | LOSS: 0.1734 | ACC 0.9498\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0892/0938 | LOSS: 0.1733 | ACC 0.9498\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0893/0938 | LOSS: 0.1731 | ACC 0.9499\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0894/0938 | LOSS: 0.1731 | ACC 0.9498\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0895/0938 | LOSS: 0.1732 | ACC 0.9498\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0896/0938 | LOSS: 0.1732 | ACC 0.9499\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0897/0938 | LOSS: 0.1732 | ACC 0.9499\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0898/0938 | LOSS: 0.1731 | ACC 0.9499\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0899/0938 | LOSS: 0.1729 | ACC 0.9499\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0900/0938 | LOSS: 0.1729 | ACC 0.9500\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0901/0938 | LOSS: 0.1728 | ACC 0.9500\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0902/0938 | LOSS: 0.1727 | ACC 0.9500\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0903/0938 | LOSS: 0.1728 | ACC 0.9500\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0904/0938 | LOSS: 0.1727 | ACC 0.9501\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0905/0938 | LOSS: 0.1727 | ACC 0.9501\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0906/0938 | LOSS: 0.1726 | ACC 0.9501\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0907/0938 | LOSS: 0.1727 | ACC 0.9501\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0908/0938 | LOSS: 0.1726 | ACC 0.9502\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0909/0938 | LOSS: 0.1726 | ACC 0.9502\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0910/0938 | LOSS: 0.1725 | ACC 0.9502\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0911/0938 | LOSS: 0.1724 | ACC 0.9502\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0912/0938 | LOSS: 0.1724 | ACC 0.9502\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0913/0938 | LOSS: 0.1725 | ACC 0.9503\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0914/0938 | LOSS: 0.1725 | ACC 0.9503\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0915/0938 | LOSS: 0.1725 | ACC 0.9503\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0916/0938 | LOSS: 0.1725 | ACC 0.9503\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0917/0938 | LOSS: 0.1724 | ACC 0.9503\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0918/0938 | LOSS: 0.1725 | ACC 0.9502\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0919/0938 | LOSS: 0.1724 | ACC 0.9503\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0920/0938 | LOSS: 0.1725 | ACC 0.9503\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0921/0938 | LOSS: 0.1724 | ACC 0.9503\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0922/0938 | LOSS: 0.1723 | ACC 0.9503\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0923/0938 | LOSS: 0.1724 | ACC 0.9503\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0924/0938 | LOSS: 0.1723 | ACC 0.9503\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0925/0938 | LOSS: 0.1723 | ACC 0.9503\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0926/0938 | LOSS: 0.1722 | ACC 0.9503\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0927/0938 | LOSS: 0.1722 | ACC 0.9502\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0928/0938 | LOSS: 0.1723 | ACC 0.9502\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0929/0938 | LOSS: 0.1722 | ACC 0.9503\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0930/0938 | LOSS: 0.1723 | ACC 0.9503\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0931/0938 | LOSS: 0.1722 | ACC 0.9503\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0932/0938 | LOSS: 0.1721 | ACC 0.9504\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0933/0938 | LOSS: 0.1720 | ACC 0.9503\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0934/0938 | LOSS: 0.1721 | ACC 0.9503\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0935/0938 | LOSS: 0.1719 | ACC 0.9504\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0936/0938 | LOSS: 0.1719 | ACC 0.9504\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0937/0938 | LOSS: 0.1719 | ACC 0.9503\n",
      "TRAIN: EPOCH 0007/0010 | BATCH 0938/0938 | LOSS: 0.1719 | ACC 0.9503\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0001/0938 | LOSS: 0.1233 | ACC 0.9375\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0002/0938 | LOSS: 0.1903 | ACC 0.9219\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0003/0938 | LOSS: 0.2019 | ACC 0.9375\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0004/0938 | LOSS: 0.1905 | ACC 0.9453\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0005/0938 | LOSS: 0.1752 | ACC 0.9500\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0006/0938 | LOSS: 0.1804 | ACC 0.9479\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0007/0938 | LOSS: 0.1838 | ACC 0.9464\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0008/0938 | LOSS: 0.1748 | ACC 0.9473\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0009/0938 | LOSS: 0.1739 | ACC 0.9479\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0010/0938 | LOSS: 0.1753 | ACC 0.9484\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0011/0938 | LOSS: 0.1744 | ACC 0.9503\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0012/0938 | LOSS: 0.1790 | ACC 0.9492\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0013/0938 | LOSS: 0.1759 | ACC 0.9495\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0014/0938 | LOSS: 0.1779 | ACC 0.9487\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0015/0938 | LOSS: 0.1712 | ACC 0.9510\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0016/0938 | LOSS: 0.1697 | ACC 0.9512\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0017/0938 | LOSS: 0.1750 | ACC 0.9494\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0018/0938 | LOSS: 0.1718 | ACC 0.9514\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0019/0938 | LOSS: 0.1728 | ACC 0.9523\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0020/0938 | LOSS: 0.1694 | ACC 0.9508\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0021/0938 | LOSS: 0.1737 | ACC 0.9509\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0022/0938 | LOSS: 0.1735 | ACC 0.9496\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0023/0938 | LOSS: 0.1677 | ACC 0.9518\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0024/0938 | LOSS: 0.1665 | ACC 0.9518\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0025/0938 | LOSS: 0.1640 | ACC 0.9519\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0026/0938 | LOSS: 0.1600 | ACC 0.9531\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0027/0938 | LOSS: 0.1595 | ACC 0.9543\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0028/0938 | LOSS: 0.1591 | ACC 0.9548\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0029/0938 | LOSS: 0.1611 | ACC 0.9553\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0030/0938 | LOSS: 0.1630 | ACC 0.9547\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0031/0938 | LOSS: 0.1604 | ACC 0.9556\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0032/0938 | LOSS: 0.1600 | ACC 0.9556\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0033/0938 | LOSS: 0.1619 | ACC 0.9541\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0034/0938 | LOSS: 0.1578 | ACC 0.9554\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0035/0938 | LOSS: 0.1625 | ACC 0.9540\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0036/0938 | LOSS: 0.1615 | ACC 0.9536\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0037/0938 | LOSS: 0.1611 | ACC 0.9535\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0038/0938 | LOSS: 0.1619 | ACC 0.9535\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0039/0938 | LOSS: 0.1586 | ACC 0.9547\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0040/0938 | LOSS: 0.1581 | ACC 0.9543\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0041/0938 | LOSS: 0.1570 | ACC 0.9543\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0042/0938 | LOSS: 0.1571 | ACC 0.9546\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0043/0938 | LOSS: 0.1623 | ACC 0.9546\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0044/0938 | LOSS: 0.1608 | ACC 0.9549\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0045/0938 | LOSS: 0.1611 | ACC 0.9549\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0046/0938 | LOSS: 0.1611 | ACC 0.9541\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0047/0938 | LOSS: 0.1595 | ACC 0.9545\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0048/0938 | LOSS: 0.1592 | ACC 0.9541\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0049/0938 | LOSS: 0.1668 | ACC 0.9531\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0050/0938 | LOSS: 0.1655 | ACC 0.9531\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0051/0938 | LOSS: 0.1664 | ACC 0.9528\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0052/0938 | LOSS: 0.1645 | ACC 0.9534\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0053/0938 | LOSS: 0.1624 | ACC 0.9537\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0054/0938 | LOSS: 0.1628 | ACC 0.9531\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0055/0938 | LOSS: 0.1629 | ACC 0.9528\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0056/0938 | LOSS: 0.1626 | ACC 0.9528\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0057/0938 | LOSS: 0.1633 | ACC 0.9520\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0058/0938 | LOSS: 0.1648 | ACC 0.9518\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0059/0938 | LOSS: 0.1627 | ACC 0.9526\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0060/0938 | LOSS: 0.1636 | ACC 0.9526\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0061/0938 | LOSS: 0.1622 | ACC 0.9529\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0062/0938 | LOSS: 0.1637 | ACC 0.9524\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0063/0938 | LOSS: 0.1629 | ACC 0.9521\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0064/0938 | LOSS: 0.1630 | ACC 0.9519\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0065/0938 | LOSS: 0.1627 | ACC 0.9519\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0066/0938 | LOSS: 0.1646 | ACC 0.9515\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0067/0938 | LOSS: 0.1683 | ACC 0.9510\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0068/0938 | LOSS: 0.1699 | ACC 0.9506\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0069/0938 | LOSS: 0.1721 | ACC 0.9488\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0070/0938 | LOSS: 0.1719 | ACC 0.9491\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0071/0938 | LOSS: 0.1714 | ACC 0.9496\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0072/0938 | LOSS: 0.1698 | ACC 0.9501\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: EPOCH 0008/0010 | BATCH 0073/0938 | LOSS: 0.1686 | ACC 0.9503\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0074/0938 | LOSS: 0.1690 | ACC 0.9504\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0075/0938 | LOSS: 0.1697 | ACC 0.9500\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0076/0938 | LOSS: 0.1701 | ACC 0.9500\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0077/0938 | LOSS: 0.1696 | ACC 0.9503\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0078/0938 | LOSS: 0.1690 | ACC 0.9503\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0079/0938 | LOSS: 0.1718 | ACC 0.9496\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0080/0938 | LOSS: 0.1707 | ACC 0.9500\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0081/0938 | LOSS: 0.1692 | ACC 0.9504\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0082/0938 | LOSS: 0.1696 | ACC 0.9506\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0083/0938 | LOSS: 0.1705 | ACC 0.9505\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0084/0938 | LOSS: 0.1693 | ACC 0.9509\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0085/0938 | LOSS: 0.1688 | ACC 0.9509\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0086/0938 | LOSS: 0.1683 | ACC 0.9509\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0087/0938 | LOSS: 0.1672 | ACC 0.9513\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0088/0938 | LOSS: 0.1709 | ACC 0.9508\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0089/0938 | LOSS: 0.1713 | ACC 0.9508\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0090/0938 | LOSS: 0.1711 | ACC 0.9510\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0091/0938 | LOSS: 0.1707 | ACC 0.9512\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0092/0938 | LOSS: 0.1707 | ACC 0.9511\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0093/0938 | LOSS: 0.1698 | ACC 0.9513\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0094/0938 | LOSS: 0.1690 | ACC 0.9515\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0095/0938 | LOSS: 0.1691 | ACC 0.9516\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0096/0938 | LOSS: 0.1683 | ACC 0.9520\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0097/0938 | LOSS: 0.1680 | ACC 0.9515\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0098/0938 | LOSS: 0.1675 | ACC 0.9517\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0099/0938 | LOSS: 0.1679 | ACC 0.9514\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0100/0938 | LOSS: 0.1686 | ACC 0.9516\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0101/0938 | LOSS: 0.1683 | ACC 0.9517\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0102/0938 | LOSS: 0.1679 | ACC 0.9519\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0103/0938 | LOSS: 0.1683 | ACC 0.9519\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0104/0938 | LOSS: 0.1698 | ACC 0.9518\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0105/0938 | LOSS: 0.1700 | ACC 0.9512\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0106/0938 | LOSS: 0.1699 | ACC 0.9514\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0107/0938 | LOSS: 0.1703 | ACC 0.9511\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0108/0938 | LOSS: 0.1702 | ACC 0.9508\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0109/0938 | LOSS: 0.1698 | ACC 0.9510\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0110/0938 | LOSS: 0.1693 | ACC 0.9509\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0111/0938 | LOSS: 0.1690 | ACC 0.9509\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0112/0938 | LOSS: 0.1688 | ACC 0.9509\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0113/0938 | LOSS: 0.1689 | ACC 0.9505\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0114/0938 | LOSS: 0.1698 | ACC 0.9502\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0115/0938 | LOSS: 0.1693 | ACC 0.9504\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0116/0938 | LOSS: 0.1692 | ACC 0.9506\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0117/0938 | LOSS: 0.1679 | ACC 0.9510\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0118/0938 | LOSS: 0.1680 | ACC 0.9506\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0119/0938 | LOSS: 0.1674 | ACC 0.9508\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0120/0938 | LOSS: 0.1669 | ACC 0.9510\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0121/0938 | LOSS: 0.1669 | ACC 0.9511\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0122/0938 | LOSS: 0.1663 | ACC 0.9511\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0123/0938 | LOSS: 0.1655 | ACC 0.9513\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0124/0938 | LOSS: 0.1646 | ACC 0.9517\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0125/0938 | LOSS: 0.1657 | ACC 0.9514\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0126/0938 | LOSS: 0.1652 | ACC 0.9514\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0127/0938 | LOSS: 0.1647 | ACC 0.9515\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0128/0938 | LOSS: 0.1660 | ACC 0.9509\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0129/0938 | LOSS: 0.1664 | ACC 0.9507\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0130/0938 | LOSS: 0.1666 | ACC 0.9506\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0131/0938 | LOSS: 0.1668 | ACC 0.9504\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0132/0938 | LOSS: 0.1658 | ACC 0.9505\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0133/0938 | LOSS: 0.1662 | ACC 0.9504\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0134/0938 | LOSS: 0.1653 | ACC 0.9507\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0135/0938 | LOSS: 0.1664 | ACC 0.9502\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0136/0938 | LOSS: 0.1667 | ACC 0.9501\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0137/0938 | LOSS: 0.1666 | ACC 0.9502\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0138/0938 | LOSS: 0.1670 | ACC 0.9501\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0139/0938 | LOSS: 0.1664 | ACC 0.9503\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0140/0938 | LOSS: 0.1662 | ACC 0.9502\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0141/0938 | LOSS: 0.1672 | ACC 0.9500\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0142/0938 | LOSS: 0.1668 | ACC 0.9502\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0143/0938 | LOSS: 0.1672 | ACC 0.9502\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0144/0938 | LOSS: 0.1690 | ACC 0.9495\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0145/0938 | LOSS: 0.1697 | ACC 0.9494\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0146/0938 | LOSS: 0.1710 | ACC 0.9491\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0147/0938 | LOSS: 0.1714 | ACC 0.9487\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0148/0938 | LOSS: 0.1718 | ACC 0.9486\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0149/0938 | LOSS: 0.1712 | ACC 0.9489\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0150/0938 | LOSS: 0.1707 | ACC 0.9491\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0151/0938 | LOSS: 0.1710 | ACC 0.9489\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0152/0938 | LOSS: 0.1704 | ACC 0.9491\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0153/0938 | LOSS: 0.1698 | ACC 0.9493\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0154/0938 | LOSS: 0.1697 | ACC 0.9495\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0155/0938 | LOSS: 0.1696 | ACC 0.9494\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0156/0938 | LOSS: 0.1696 | ACC 0.9493\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0157/0938 | LOSS: 0.1695 | ACC 0.9493\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0158/0938 | LOSS: 0.1701 | ACC 0.9491\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0159/0938 | LOSS: 0.1705 | ACC 0.9491\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0160/0938 | LOSS: 0.1707 | ACC 0.9487\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0161/0938 | LOSS: 0.1705 | ACC 0.9490\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0162/0938 | LOSS: 0.1697 | ACC 0.9492\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0163/0938 | LOSS: 0.1694 | ACC 0.9493\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0164/0938 | LOSS: 0.1691 | ACC 0.9494\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0165/0938 | LOSS: 0.1700 | ACC 0.9492\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0166/0938 | LOSS: 0.1699 | ACC 0.9493\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0167/0938 | LOSS: 0.1695 | ACC 0.9494\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0168/0938 | LOSS: 0.1695 | ACC 0.9493\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0169/0938 | LOSS: 0.1701 | ACC 0.9491\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0170/0938 | LOSS: 0.1700 | ACC 0.9490\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0171/0938 | LOSS: 0.1708 | ACC 0.9489\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0172/0938 | LOSS: 0.1704 | ACC 0.9491\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0173/0938 | LOSS: 0.1710 | ACC 0.9490\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0174/0938 | LOSS: 0.1711 | ACC 0.9487\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0175/0938 | LOSS: 0.1708 | ACC 0.9487\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0176/0938 | LOSS: 0.1708 | ACC 0.9486\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0177/0938 | LOSS: 0.1701 | ACC 0.9488\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0178/0938 | LOSS: 0.1706 | ACC 0.9486\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0179/0938 | LOSS: 0.1704 | ACC 0.9488\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0180/0938 | LOSS: 0.1704 | ACC 0.9487\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0181/0938 | LOSS: 0.1706 | ACC 0.9484\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0182/0938 | LOSS: 0.1704 | ACC 0.9485\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0183/0938 | LOSS: 0.1701 | ACC 0.9485\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0184/0938 | LOSS: 0.1693 | ACC 0.9487\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0185/0938 | LOSS: 0.1688 | ACC 0.9490\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0186/0938 | LOSS: 0.1685 | ACC 0.9491\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0187/0938 | LOSS: 0.1681 | ACC 0.9492\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0188/0938 | LOSS: 0.1683 | ACC 0.9491\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0189/0938 | LOSS: 0.1681 | ACC 0.9491\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0190/0938 | LOSS: 0.1681 | ACC 0.9489\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0191/0938 | LOSS: 0.1680 | ACC 0.9490\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0192/0938 | LOSS: 0.1677 | ACC 0.9491\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0193/0938 | LOSS: 0.1671 | ACC 0.9493\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0194/0938 | LOSS: 0.1671 | ACC 0.9492\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0195/0938 | LOSS: 0.1669 | ACC 0.9492\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0196/0938 | LOSS: 0.1669 | ACC 0.9493\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0197/0938 | LOSS: 0.1670 | ACC 0.9492\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0198/0938 | LOSS: 0.1675 | ACC 0.9493\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0199/0938 | LOSS: 0.1677 | ACC 0.9491\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0200/0938 | LOSS: 0.1675 | ACC 0.9490\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0201/0938 | LOSS: 0.1673 | ACC 0.9490\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0202/0938 | LOSS: 0.1670 | ACC 0.9490\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0203/0938 | LOSS: 0.1667 | ACC 0.9491\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: EPOCH 0008/0010 | BATCH 0204/0938 | LOSS: 0.1674 | ACC 0.9491\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0205/0938 | LOSS: 0.1669 | ACC 0.9494\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0206/0938 | LOSS: 0.1664 | ACC 0.9496\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0207/0938 | LOSS: 0.1663 | ACC 0.9494\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0208/0938 | LOSS: 0.1661 | ACC 0.9494\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0209/0938 | LOSS: 0.1662 | ACC 0.9493\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0210/0938 | LOSS: 0.1662 | ACC 0.9493\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0211/0938 | LOSS: 0.1656 | ACC 0.9496\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0212/0938 | LOSS: 0.1653 | ACC 0.9497\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0213/0938 | LOSS: 0.1658 | ACC 0.9495\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0214/0938 | LOSS: 0.1656 | ACC 0.9495\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0215/0938 | LOSS: 0.1661 | ACC 0.9495\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0216/0938 | LOSS: 0.1658 | ACC 0.9497\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0217/0938 | LOSS: 0.1664 | ACC 0.9496\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0218/0938 | LOSS: 0.1663 | ACC 0.9496\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0219/0938 | LOSS: 0.1662 | ACC 0.9497\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0220/0938 | LOSS: 0.1658 | ACC 0.9499\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0221/0938 | LOSS: 0.1656 | ACC 0.9500\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0222/0938 | LOSS: 0.1652 | ACC 0.9502\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0223/0938 | LOSS: 0.1648 | ACC 0.9503\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0224/0938 | LOSS: 0.1651 | ACC 0.9501\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0225/0938 | LOSS: 0.1652 | ACC 0.9501\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0226/0938 | LOSS: 0.1649 | ACC 0.9502\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0227/0938 | LOSS: 0.1657 | ACC 0.9502\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0228/0938 | LOSS: 0.1654 | ACC 0.9502\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0229/0938 | LOSS: 0.1656 | ACC 0.9504\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0230/0938 | LOSS: 0.1653 | ACC 0.9504\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0231/0938 | LOSS: 0.1649 | ACC 0.9505\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0232/0938 | LOSS: 0.1647 | ACC 0.9506\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0233/0938 | LOSS: 0.1651 | ACC 0.9504\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0234/0938 | LOSS: 0.1651 | ACC 0.9504\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0235/0938 | LOSS: 0.1647 | ACC 0.9505\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0236/0938 | LOSS: 0.1645 | ACC 0.9504\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0237/0938 | LOSS: 0.1643 | ACC 0.9504\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0238/0938 | LOSS: 0.1640 | ACC 0.9505\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0239/0938 | LOSS: 0.1640 | ACC 0.9504\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0240/0938 | LOSS: 0.1643 | ACC 0.9505\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0241/0938 | LOSS: 0.1640 | ACC 0.9505\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0242/0938 | LOSS: 0.1641 | ACC 0.9505\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0243/0938 | LOSS: 0.1637 | ACC 0.9504\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0244/0938 | LOSS: 0.1634 | ACC 0.9506\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0245/0938 | LOSS: 0.1630 | ACC 0.9507\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0246/0938 | LOSS: 0.1631 | ACC 0.9506\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0247/0938 | LOSS: 0.1626 | ACC 0.9508\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0248/0938 | LOSS: 0.1623 | ACC 0.9509\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0249/0938 | LOSS: 0.1627 | ACC 0.9509\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0250/0938 | LOSS: 0.1636 | ACC 0.9508\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0251/0938 | LOSS: 0.1641 | ACC 0.9506\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0252/0938 | LOSS: 0.1641 | ACC 0.9506\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0253/0938 | LOSS: 0.1637 | ACC 0.9507\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0254/0938 | LOSS: 0.1633 | ACC 0.9508\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0255/0938 | LOSS: 0.1640 | ACC 0.9506\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0256/0938 | LOSS: 0.1639 | ACC 0.9506\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0257/0938 | LOSS: 0.1636 | ACC 0.9508\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0258/0938 | LOSS: 0.1637 | ACC 0.9507\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0259/0938 | LOSS: 0.1635 | ACC 0.9508\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0260/0938 | LOSS: 0.1634 | ACC 0.9509\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0261/0938 | LOSS: 0.1634 | ACC 0.9509\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0262/0938 | LOSS: 0.1632 | ACC 0.9510\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0263/0938 | LOSS: 0.1639 | ACC 0.9509\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0264/0938 | LOSS: 0.1638 | ACC 0.9509\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0265/0938 | LOSS: 0.1638 | ACC 0.9508\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0266/0938 | LOSS: 0.1644 | ACC 0.9507\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0267/0938 | LOSS: 0.1650 | ACC 0.9505\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0268/0938 | LOSS: 0.1648 | ACC 0.9505\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0269/0938 | LOSS: 0.1654 | ACC 0.9506\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0270/0938 | LOSS: 0.1655 | ACC 0.9506\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0271/0938 | LOSS: 0.1658 | ACC 0.9505\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0272/0938 | LOSS: 0.1658 | ACC 0.9504\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0273/0938 | LOSS: 0.1667 | ACC 0.9501\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0274/0938 | LOSS: 0.1669 | ACC 0.9502\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0275/0938 | LOSS: 0.1667 | ACC 0.9502\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0276/0938 | LOSS: 0.1669 | ACC 0.9500\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0277/0938 | LOSS: 0.1675 | ACC 0.9499\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0278/0938 | LOSS: 0.1673 | ACC 0.9499\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0279/0938 | LOSS: 0.1674 | ACC 0.9499\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0280/0938 | LOSS: 0.1669 | ACC 0.9501\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0281/0938 | LOSS: 0.1668 | ACC 0.9501\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0282/0938 | LOSS: 0.1665 | ACC 0.9502\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0283/0938 | LOSS: 0.1666 | ACC 0.9501\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0284/0938 | LOSS: 0.1663 | ACC 0.9502\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0285/0938 | LOSS: 0.1664 | ACC 0.9502\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0286/0938 | LOSS: 0.1662 | ACC 0.9503\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0287/0938 | LOSS: 0.1664 | ACC 0.9503\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0288/0938 | LOSS: 0.1666 | ACC 0.9502\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0289/0938 | LOSS: 0.1663 | ACC 0.9503\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0290/0938 | LOSS: 0.1660 | ACC 0.9504\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0291/0938 | LOSS: 0.1662 | ACC 0.9503\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0292/0938 | LOSS: 0.1659 | ACC 0.9504\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0293/0938 | LOSS: 0.1660 | ACC 0.9502\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0294/0938 | LOSS: 0.1665 | ACC 0.9501\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0295/0938 | LOSS: 0.1664 | ACC 0.9502\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0296/0938 | LOSS: 0.1660 | ACC 0.9503\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0297/0938 | LOSS: 0.1660 | ACC 0.9503\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0298/0938 | LOSS: 0.1657 | ACC 0.9504\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0299/0938 | LOSS: 0.1669 | ACC 0.9504\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0300/0938 | LOSS: 0.1668 | ACC 0.9504\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0301/0938 | LOSS: 0.1672 | ACC 0.9503\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0302/0938 | LOSS: 0.1669 | ACC 0.9503\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0303/0938 | LOSS: 0.1671 | ACC 0.9503\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0304/0938 | LOSS: 0.1669 | ACC 0.9503\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0305/0938 | LOSS: 0.1668 | ACC 0.9504\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0306/0938 | LOSS: 0.1666 | ACC 0.9504\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0307/0938 | LOSS: 0.1665 | ACC 0.9504\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0308/0938 | LOSS: 0.1663 | ACC 0.9504\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0309/0938 | LOSS: 0.1663 | ACC 0.9504\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0310/0938 | LOSS: 0.1661 | ACC 0.9505\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0311/0938 | LOSS: 0.1662 | ACC 0.9505\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0312/0938 | LOSS: 0.1660 | ACC 0.9506\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0313/0938 | LOSS: 0.1661 | ACC 0.9505\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0314/0938 | LOSS: 0.1658 | ACC 0.9505\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0315/0938 | LOSS: 0.1658 | ACC 0.9504\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0316/0938 | LOSS: 0.1656 | ACC 0.9506\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0317/0938 | LOSS: 0.1658 | ACC 0.9505\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0318/0938 | LOSS: 0.1656 | ACC 0.9506\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0319/0938 | LOSS: 0.1655 | ACC 0.9505\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0320/0938 | LOSS: 0.1653 | ACC 0.9506\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0321/0938 | LOSS: 0.1652 | ACC 0.9507\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0322/0938 | LOSS: 0.1652 | ACC 0.9507\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0323/0938 | LOSS: 0.1654 | ACC 0.9508\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0324/0938 | LOSS: 0.1652 | ACC 0.9508\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0325/0938 | LOSS: 0.1650 | ACC 0.9509\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0326/0938 | LOSS: 0.1650 | ACC 0.9509\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0327/0938 | LOSS: 0.1649 | ACC 0.9509\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0328/0938 | LOSS: 0.1647 | ACC 0.9510\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0329/0938 | LOSS: 0.1649 | ACC 0.9509\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0330/0938 | LOSS: 0.1649 | ACC 0.9510\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0331/0938 | LOSS: 0.1645 | ACC 0.9512\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0332/0938 | LOSS: 0.1645 | ACC 0.9512\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0333/0938 | LOSS: 0.1642 | ACC 0.9513\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0334/0938 | LOSS: 0.1641 | ACC 0.9513\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0335/0938 | LOSS: 0.1639 | ACC 0.9514\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: EPOCH 0008/0010 | BATCH 0336/0938 | LOSS: 0.1639 | ACC 0.9514\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0337/0938 | LOSS: 0.1648 | ACC 0.9513\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0338/0938 | LOSS: 0.1646 | ACC 0.9513\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0339/0938 | LOSS: 0.1647 | ACC 0.9513\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0340/0938 | LOSS: 0.1648 | ACC 0.9513\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0341/0938 | LOSS: 0.1647 | ACC 0.9513\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0342/0938 | LOSS: 0.1644 | ACC 0.9514\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0343/0938 | LOSS: 0.1644 | ACC 0.9515\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0344/0938 | LOSS: 0.1647 | ACC 0.9515\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0345/0938 | LOSS: 0.1646 | ACC 0.9516\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0346/0938 | LOSS: 0.1643 | ACC 0.9516\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0347/0938 | LOSS: 0.1641 | ACC 0.9517\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0348/0938 | LOSS: 0.1641 | ACC 0.9517\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0349/0938 | LOSS: 0.1645 | ACC 0.9516\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0350/0938 | LOSS: 0.1646 | ACC 0.9516\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0351/0938 | LOSS: 0.1650 | ACC 0.9514\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0352/0938 | LOSS: 0.1648 | ACC 0.9515\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0353/0938 | LOSS: 0.1646 | ACC 0.9515\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0354/0938 | LOSS: 0.1646 | ACC 0.9515\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0355/0938 | LOSS: 0.1644 | ACC 0.9516\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0356/0938 | LOSS: 0.1643 | ACC 0.9516\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0357/0938 | LOSS: 0.1649 | ACC 0.9515\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0358/0938 | LOSS: 0.1649 | ACC 0.9514\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0359/0938 | LOSS: 0.1646 | ACC 0.9515\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0360/0938 | LOSS: 0.1644 | ACC 0.9515\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0361/0938 | LOSS: 0.1647 | ACC 0.9514\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0362/0938 | LOSS: 0.1646 | ACC 0.9514\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0363/0938 | LOSS: 0.1647 | ACC 0.9514\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0364/0938 | LOSS: 0.1647 | ACC 0.9513\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0365/0938 | LOSS: 0.1650 | ACC 0.9513\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0366/0938 | LOSS: 0.1647 | ACC 0.9515\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0367/0938 | LOSS: 0.1647 | ACC 0.9514\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0368/0938 | LOSS: 0.1645 | ACC 0.9515\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0369/0938 | LOSS: 0.1649 | ACC 0.9514\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0370/0938 | LOSS: 0.1646 | ACC 0.9515\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0371/0938 | LOSS: 0.1644 | ACC 0.9516\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0372/0938 | LOSS: 0.1645 | ACC 0.9515\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0373/0938 | LOSS: 0.1646 | ACC 0.9515\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0374/0938 | LOSS: 0.1645 | ACC 0.9515\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0375/0938 | LOSS: 0.1643 | ACC 0.9515\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0376/0938 | LOSS: 0.1646 | ACC 0.9515\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0377/0938 | LOSS: 0.1648 | ACC 0.9514\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0378/0938 | LOSS: 0.1648 | ACC 0.9514\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0379/0938 | LOSS: 0.1648 | ACC 0.9515\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0380/0938 | LOSS: 0.1645 | ACC 0.9516\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0381/0938 | LOSS: 0.1645 | ACC 0.9516\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0382/0938 | LOSS: 0.1642 | ACC 0.9517\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0383/0938 | LOSS: 0.1640 | ACC 0.9518\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0384/0938 | LOSS: 0.1648 | ACC 0.9517\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0385/0938 | LOSS: 0.1647 | ACC 0.9517\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0386/0938 | LOSS: 0.1648 | ACC 0.9517\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0387/0938 | LOSS: 0.1650 | ACC 0.9518\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0388/0938 | LOSS: 0.1648 | ACC 0.9518\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0389/0938 | LOSS: 0.1645 | ACC 0.9519\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0390/0938 | LOSS: 0.1648 | ACC 0.9519\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0391/0938 | LOSS: 0.1650 | ACC 0.9518\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0392/0938 | LOSS: 0.1651 | ACC 0.9518\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0393/0938 | LOSS: 0.1654 | ACC 0.9518\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0394/0938 | LOSS: 0.1656 | ACC 0.9518\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0395/0938 | LOSS: 0.1655 | ACC 0.9519\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0396/0938 | LOSS: 0.1656 | ACC 0.9518\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0397/0938 | LOSS: 0.1654 | ACC 0.9518\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0398/0938 | LOSS: 0.1656 | ACC 0.9516\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0399/0938 | LOSS: 0.1654 | ACC 0.9517\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0400/0938 | LOSS: 0.1654 | ACC 0.9516\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0401/0938 | LOSS: 0.1653 | ACC 0.9517\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0402/0938 | LOSS: 0.1650 | ACC 0.9518\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0403/0938 | LOSS: 0.1652 | ACC 0.9517\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0404/0938 | LOSS: 0.1655 | ACC 0.9517\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0405/0938 | LOSS: 0.1654 | ACC 0.9517\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0406/0938 | LOSS: 0.1658 | ACC 0.9517\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0407/0938 | LOSS: 0.1659 | ACC 0.9516\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0408/0938 | LOSS: 0.1659 | ACC 0.9516\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0409/0938 | LOSS: 0.1658 | ACC 0.9516\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0410/0938 | LOSS: 0.1658 | ACC 0.9516\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0411/0938 | LOSS: 0.1656 | ACC 0.9517\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0412/0938 | LOSS: 0.1653 | ACC 0.9518\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0413/0938 | LOSS: 0.1652 | ACC 0.9518\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0414/0938 | LOSS: 0.1652 | ACC 0.9518\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0415/0938 | LOSS: 0.1651 | ACC 0.9518\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0416/0938 | LOSS: 0.1649 | ACC 0.9519\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0417/0938 | LOSS: 0.1653 | ACC 0.9519\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0418/0938 | LOSS: 0.1652 | ACC 0.9520\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0419/0938 | LOSS: 0.1651 | ACC 0.9519\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0420/0938 | LOSS: 0.1651 | ACC 0.9519\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0421/0938 | LOSS: 0.1651 | ACC 0.9519\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0422/0938 | LOSS: 0.1655 | ACC 0.9518\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0423/0938 | LOSS: 0.1654 | ACC 0.9518\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0424/0938 | LOSS: 0.1653 | ACC 0.9518\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0425/0938 | LOSS: 0.1653 | ACC 0.9518\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0426/0938 | LOSS: 0.1655 | ACC 0.9517\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0427/0938 | LOSS: 0.1656 | ACC 0.9516\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0428/0938 | LOSS: 0.1656 | ACC 0.9516\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0429/0938 | LOSS: 0.1656 | ACC 0.9516\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0430/0938 | LOSS: 0.1658 | ACC 0.9516\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0431/0938 | LOSS: 0.1656 | ACC 0.9516\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0432/0938 | LOSS: 0.1656 | ACC 0.9516\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0433/0938 | LOSS: 0.1653 | ACC 0.9518\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0434/0938 | LOSS: 0.1650 | ACC 0.9518\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0435/0938 | LOSS: 0.1651 | ACC 0.9518\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0436/0938 | LOSS: 0.1649 | ACC 0.9518\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0437/0938 | LOSS: 0.1650 | ACC 0.9519\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0438/0938 | LOSS: 0.1649 | ACC 0.9519\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0439/0938 | LOSS: 0.1648 | ACC 0.9518\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0440/0938 | LOSS: 0.1651 | ACC 0.9518\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0441/0938 | LOSS: 0.1649 | ACC 0.9519\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0442/0938 | LOSS: 0.1652 | ACC 0.9518\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0443/0938 | LOSS: 0.1649 | ACC 0.9519\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0444/0938 | LOSS: 0.1647 | ACC 0.9520\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0445/0938 | LOSS: 0.1646 | ACC 0.9520\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0446/0938 | LOSS: 0.1647 | ACC 0.9520\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0447/0938 | LOSS: 0.1649 | ACC 0.9519\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0448/0938 | LOSS: 0.1655 | ACC 0.9518\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0449/0938 | LOSS: 0.1656 | ACC 0.9518\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0450/0938 | LOSS: 0.1656 | ACC 0.9518\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0451/0938 | LOSS: 0.1656 | ACC 0.9518\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0452/0938 | LOSS: 0.1656 | ACC 0.9518\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0453/0938 | LOSS: 0.1656 | ACC 0.9517\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0454/0938 | LOSS: 0.1654 | ACC 0.9518\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0455/0938 | LOSS: 0.1653 | ACC 0.9518\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0456/0938 | LOSS: 0.1651 | ACC 0.9519\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0457/0938 | LOSS: 0.1648 | ACC 0.9520\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0458/0938 | LOSS: 0.1650 | ACC 0.9520\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0459/0938 | LOSS: 0.1650 | ACC 0.9520\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0460/0938 | LOSS: 0.1648 | ACC 0.9521\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0461/0938 | LOSS: 0.1648 | ACC 0.9520\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0462/0938 | LOSS: 0.1647 | ACC 0.9521\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0463/0938 | LOSS: 0.1645 | ACC 0.9521\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0464/0938 | LOSS: 0.1649 | ACC 0.9520\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0465/0938 | LOSS: 0.1650 | ACC 0.9520\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0466/0938 | LOSS: 0.1652 | ACC 0.9519\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: EPOCH 0008/0010 | BATCH 0467/0938 | LOSS: 0.1653 | ACC 0.9519\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0468/0938 | LOSS: 0.1652 | ACC 0.9519\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0469/0938 | LOSS: 0.1650 | ACC 0.9519\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0470/0938 | LOSS: 0.1650 | ACC 0.9519\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0471/0938 | LOSS: 0.1650 | ACC 0.9520\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0472/0938 | LOSS: 0.1647 | ACC 0.9521\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0473/0938 | LOSS: 0.1650 | ACC 0.9520\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0474/0938 | LOSS: 0.1653 | ACC 0.9520\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0475/0938 | LOSS: 0.1655 | ACC 0.9519\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0476/0938 | LOSS: 0.1653 | ACC 0.9520\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0477/0938 | LOSS: 0.1652 | ACC 0.9520\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0478/0938 | LOSS: 0.1652 | ACC 0.9519\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0479/0938 | LOSS: 0.1651 | ACC 0.9520\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0480/0938 | LOSS: 0.1650 | ACC 0.9519\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0481/0938 | LOSS: 0.1649 | ACC 0.9519\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0482/0938 | LOSS: 0.1651 | ACC 0.9518\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0483/0938 | LOSS: 0.1650 | ACC 0.9518\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0484/0938 | LOSS: 0.1649 | ACC 0.9518\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0485/0938 | LOSS: 0.1647 | ACC 0.9518\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0486/0938 | LOSS: 0.1653 | ACC 0.9517\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0487/0938 | LOSS: 0.1655 | ACC 0.9517\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0488/0938 | LOSS: 0.1657 | ACC 0.9517\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0489/0938 | LOSS: 0.1657 | ACC 0.9517\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0490/0938 | LOSS: 0.1657 | ACC 0.9517\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0491/0938 | LOSS: 0.1655 | ACC 0.9517\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0492/0938 | LOSS: 0.1655 | ACC 0.9517\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0493/0938 | LOSS: 0.1656 | ACC 0.9517\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0494/0938 | LOSS: 0.1654 | ACC 0.9517\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0495/0938 | LOSS: 0.1654 | ACC 0.9517\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0496/0938 | LOSS: 0.1654 | ACC 0.9518\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0497/0938 | LOSS: 0.1656 | ACC 0.9517\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0498/0938 | LOSS: 0.1659 | ACC 0.9517\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0499/0938 | LOSS: 0.1656 | ACC 0.9518\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0500/0938 | LOSS: 0.1656 | ACC 0.9517\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0501/0938 | LOSS: 0.1657 | ACC 0.9517\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0502/0938 | LOSS: 0.1655 | ACC 0.9518\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0503/0938 | LOSS: 0.1655 | ACC 0.9518\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0504/0938 | LOSS: 0.1655 | ACC 0.9517\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0505/0938 | LOSS: 0.1657 | ACC 0.9517\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0506/0938 | LOSS: 0.1659 | ACC 0.9516\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0507/0938 | LOSS: 0.1659 | ACC 0.9516\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0508/0938 | LOSS: 0.1664 | ACC 0.9516\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0509/0938 | LOSS: 0.1662 | ACC 0.9517\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0510/0938 | LOSS: 0.1661 | ACC 0.9517\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0511/0938 | LOSS: 0.1661 | ACC 0.9517\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0512/0938 | LOSS: 0.1660 | ACC 0.9518\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0513/0938 | LOSS: 0.1658 | ACC 0.9518\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0514/0938 | LOSS: 0.1660 | ACC 0.9517\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0515/0938 | LOSS: 0.1659 | ACC 0.9517\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0516/0938 | LOSS: 0.1657 | ACC 0.9517\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0517/0938 | LOSS: 0.1658 | ACC 0.9517\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0518/0938 | LOSS: 0.1656 | ACC 0.9518\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0519/0938 | LOSS: 0.1658 | ACC 0.9517\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0520/0938 | LOSS: 0.1656 | ACC 0.9517\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0521/0938 | LOSS: 0.1655 | ACC 0.9518\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0522/0938 | LOSS: 0.1655 | ACC 0.9518\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0523/0938 | LOSS: 0.1656 | ACC 0.9518\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0524/0938 | LOSS: 0.1653 | ACC 0.9519\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0525/0938 | LOSS: 0.1652 | ACC 0.9519\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0526/0938 | LOSS: 0.1652 | ACC 0.9519\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0527/0938 | LOSS: 0.1651 | ACC 0.9519\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0528/0938 | LOSS: 0.1653 | ACC 0.9519\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0529/0938 | LOSS: 0.1654 | ACC 0.9519\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0530/0938 | LOSS: 0.1654 | ACC 0.9519\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0531/0938 | LOSS: 0.1653 | ACC 0.9519\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0532/0938 | LOSS: 0.1653 | ACC 0.9519\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0533/0938 | LOSS: 0.1654 | ACC 0.9520\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0534/0938 | LOSS: 0.1653 | ACC 0.9519\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0535/0938 | LOSS: 0.1655 | ACC 0.9519\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0536/0938 | LOSS: 0.1657 | ACC 0.9519\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0537/0938 | LOSS: 0.1657 | ACC 0.9519\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0538/0938 | LOSS: 0.1656 | ACC 0.9519\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0539/0938 | LOSS: 0.1658 | ACC 0.9518\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0540/0938 | LOSS: 0.1657 | ACC 0.9519\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0541/0938 | LOSS: 0.1657 | ACC 0.9519\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0542/0938 | LOSS: 0.1654 | ACC 0.9519\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0543/0938 | LOSS: 0.1657 | ACC 0.9518\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0544/0938 | LOSS: 0.1658 | ACC 0.9518\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0545/0938 | LOSS: 0.1659 | ACC 0.9518\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0546/0938 | LOSS: 0.1658 | ACC 0.9518\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0547/0938 | LOSS: 0.1657 | ACC 0.9518\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0548/0938 | LOSS: 0.1656 | ACC 0.9518\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0549/0938 | LOSS: 0.1656 | ACC 0.9518\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0550/0938 | LOSS: 0.1657 | ACC 0.9516\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0551/0938 | LOSS: 0.1656 | ACC 0.9517\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0552/0938 | LOSS: 0.1656 | ACC 0.9517\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0553/0938 | LOSS: 0.1655 | ACC 0.9517\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0554/0938 | LOSS: 0.1654 | ACC 0.9517\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0555/0938 | LOSS: 0.1655 | ACC 0.9517\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0556/0938 | LOSS: 0.1655 | ACC 0.9516\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0557/0938 | LOSS: 0.1655 | ACC 0.9517\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0558/0938 | LOSS: 0.1653 | ACC 0.9518\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0559/0938 | LOSS: 0.1655 | ACC 0.9517\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0560/0938 | LOSS: 0.1655 | ACC 0.9517\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0561/0938 | LOSS: 0.1659 | ACC 0.9516\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0562/0938 | LOSS: 0.1658 | ACC 0.9516\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0563/0938 | LOSS: 0.1656 | ACC 0.9517\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0564/0938 | LOSS: 0.1657 | ACC 0.9517\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0565/0938 | LOSS: 0.1657 | ACC 0.9517\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0566/0938 | LOSS: 0.1658 | ACC 0.9517\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0567/0938 | LOSS: 0.1658 | ACC 0.9517\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0568/0938 | LOSS: 0.1656 | ACC 0.9518\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0569/0938 | LOSS: 0.1655 | ACC 0.9518\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0570/0938 | LOSS: 0.1654 | ACC 0.9519\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0571/0938 | LOSS: 0.1653 | ACC 0.9519\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0572/0938 | LOSS: 0.1656 | ACC 0.9519\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0573/0938 | LOSS: 0.1657 | ACC 0.9518\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0574/0938 | LOSS: 0.1657 | ACC 0.9518\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0575/0938 | LOSS: 0.1657 | ACC 0.9518\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0576/0938 | LOSS: 0.1656 | ACC 0.9517\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0577/0938 | LOSS: 0.1658 | ACC 0.9517\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0578/0938 | LOSS: 0.1657 | ACC 0.9517\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0579/0938 | LOSS: 0.1656 | ACC 0.9517\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0580/0938 | LOSS: 0.1656 | ACC 0.9517\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0581/0938 | LOSS: 0.1654 | ACC 0.9518\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0582/0938 | LOSS: 0.1655 | ACC 0.9516\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0583/0938 | LOSS: 0.1653 | ACC 0.9517\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0584/0938 | LOSS: 0.1652 | ACC 0.9517\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0585/0938 | LOSS: 0.1653 | ACC 0.9517\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0586/0938 | LOSS: 0.1654 | ACC 0.9516\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0587/0938 | LOSS: 0.1652 | ACC 0.9517\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0588/0938 | LOSS: 0.1651 | ACC 0.9517\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0589/0938 | LOSS: 0.1651 | ACC 0.9516\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0590/0938 | LOSS: 0.1650 | ACC 0.9517\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0591/0938 | LOSS: 0.1650 | ACC 0.9517\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0592/0938 | LOSS: 0.1649 | ACC 0.9517\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0593/0938 | LOSS: 0.1649 | ACC 0.9517\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0594/0938 | LOSS: 0.1648 | ACC 0.9517\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0595/0938 | LOSS: 0.1647 | ACC 0.9518\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: EPOCH 0008/0010 | BATCH 0596/0938 | LOSS: 0.1646 | ACC 0.9518\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0597/0938 | LOSS: 0.1647 | ACC 0.9518\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0598/0938 | LOSS: 0.1646 | ACC 0.9518\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0599/0938 | LOSS: 0.1644 | ACC 0.9518\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0600/0938 | LOSS: 0.1645 | ACC 0.9518\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0601/0938 | LOSS: 0.1644 | ACC 0.9518\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0602/0938 | LOSS: 0.1645 | ACC 0.9518\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0603/0938 | LOSS: 0.1644 | ACC 0.9518\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0604/0938 | LOSS: 0.1643 | ACC 0.9518\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0605/0938 | LOSS: 0.1641 | ACC 0.9518\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0606/0938 | LOSS: 0.1640 | ACC 0.9519\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0607/0938 | LOSS: 0.1639 | ACC 0.9519\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0608/0938 | LOSS: 0.1637 | ACC 0.9520\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0609/0938 | LOSS: 0.1638 | ACC 0.9519\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0610/0938 | LOSS: 0.1639 | ACC 0.9520\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0611/0938 | LOSS: 0.1638 | ACC 0.9520\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0612/0938 | LOSS: 0.1637 | ACC 0.9520\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0613/0938 | LOSS: 0.1637 | ACC 0.9520\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0614/0938 | LOSS: 0.1636 | ACC 0.9520\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0615/0938 | LOSS: 0.1635 | ACC 0.9521\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0616/0938 | LOSS: 0.1634 | ACC 0.9521\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0617/0938 | LOSS: 0.1635 | ACC 0.9521\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0618/0938 | LOSS: 0.1635 | ACC 0.9520\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0619/0938 | LOSS: 0.1634 | ACC 0.9520\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0620/0938 | LOSS: 0.1634 | ACC 0.9520\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0621/0938 | LOSS: 0.1635 | ACC 0.9520\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0622/0938 | LOSS: 0.1634 | ACC 0.9520\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0623/0938 | LOSS: 0.1634 | ACC 0.9520\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0624/0938 | LOSS: 0.1633 | ACC 0.9520\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0625/0938 | LOSS: 0.1633 | ACC 0.9520\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0626/0938 | LOSS: 0.1633 | ACC 0.9520\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0627/0938 | LOSS: 0.1634 | ACC 0.9519\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0628/0938 | LOSS: 0.1634 | ACC 0.9519\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0629/0938 | LOSS: 0.1632 | ACC 0.9520\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0630/0938 | LOSS: 0.1632 | ACC 0.9520\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0631/0938 | LOSS: 0.1632 | ACC 0.9519\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0632/0938 | LOSS: 0.1631 | ACC 0.9520\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0633/0938 | LOSS: 0.1632 | ACC 0.9519\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0634/0938 | LOSS: 0.1633 | ACC 0.9519\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0635/0938 | LOSS: 0.1633 | ACC 0.9519\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0636/0938 | LOSS: 0.1632 | ACC 0.9519\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0637/0938 | LOSS: 0.1632 | ACC 0.9518\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0638/0938 | LOSS: 0.1632 | ACC 0.9518\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0639/0938 | LOSS: 0.1630 | ACC 0.9519\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0640/0938 | LOSS: 0.1628 | ACC 0.9519\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0641/0938 | LOSS: 0.1627 | ACC 0.9520\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0642/0938 | LOSS: 0.1627 | ACC 0.9520\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0643/0938 | LOSS: 0.1627 | ACC 0.9520\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0644/0938 | LOSS: 0.1628 | ACC 0.9520\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0645/0938 | LOSS: 0.1629 | ACC 0.9519\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0646/0938 | LOSS: 0.1631 | ACC 0.9518\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0647/0938 | LOSS: 0.1630 | ACC 0.9518\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0648/0938 | LOSS: 0.1629 | ACC 0.9518\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0649/0938 | LOSS: 0.1633 | ACC 0.9517\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0650/0938 | LOSS: 0.1632 | ACC 0.9517\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0651/0938 | LOSS: 0.1632 | ACC 0.9517\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0652/0938 | LOSS: 0.1633 | ACC 0.9517\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0653/0938 | LOSS: 0.1634 | ACC 0.9517\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0654/0938 | LOSS: 0.1635 | ACC 0.9517\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0655/0938 | LOSS: 0.1636 | ACC 0.9516\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0656/0938 | LOSS: 0.1636 | ACC 0.9515\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0657/0938 | LOSS: 0.1636 | ACC 0.9515\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0658/0938 | LOSS: 0.1635 | ACC 0.9516\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0659/0938 | LOSS: 0.1635 | ACC 0.9516\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0660/0938 | LOSS: 0.1635 | ACC 0.9515\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0661/0938 | LOSS: 0.1634 | ACC 0.9515\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0662/0938 | LOSS: 0.1634 | ACC 0.9515\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0663/0938 | LOSS: 0.1632 | ACC 0.9515\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0664/0938 | LOSS: 0.1631 | ACC 0.9516\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0665/0938 | LOSS: 0.1632 | ACC 0.9515\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0666/0938 | LOSS: 0.1633 | ACC 0.9515\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0667/0938 | LOSS: 0.1634 | ACC 0.9515\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0668/0938 | LOSS: 0.1633 | ACC 0.9515\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0669/0938 | LOSS: 0.1631 | ACC 0.9516\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0670/0938 | LOSS: 0.1630 | ACC 0.9516\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0671/0938 | LOSS: 0.1631 | ACC 0.9515\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0672/0938 | LOSS: 0.1632 | ACC 0.9515\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0673/0938 | LOSS: 0.1632 | ACC 0.9514\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0674/0938 | LOSS: 0.1631 | ACC 0.9515\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0675/0938 | LOSS: 0.1631 | ACC 0.9514\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0676/0938 | LOSS: 0.1631 | ACC 0.9514\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0677/0938 | LOSS: 0.1631 | ACC 0.9514\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0678/0938 | LOSS: 0.1631 | ACC 0.9514\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0679/0938 | LOSS: 0.1630 | ACC 0.9514\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0680/0938 | LOSS: 0.1628 | ACC 0.9515\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0681/0938 | LOSS: 0.1630 | ACC 0.9515\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0682/0938 | LOSS: 0.1631 | ACC 0.9515\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0683/0938 | LOSS: 0.1631 | ACC 0.9515\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0684/0938 | LOSS: 0.1635 | ACC 0.9514\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0685/0938 | LOSS: 0.1638 | ACC 0.9514\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0686/0938 | LOSS: 0.1638 | ACC 0.9514\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0687/0938 | LOSS: 0.1639 | ACC 0.9513\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0688/0938 | LOSS: 0.1639 | ACC 0.9513\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0689/0938 | LOSS: 0.1638 | ACC 0.9513\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0690/0938 | LOSS: 0.1639 | ACC 0.9513\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0691/0938 | LOSS: 0.1637 | ACC 0.9513\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0692/0938 | LOSS: 0.1637 | ACC 0.9514\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0693/0938 | LOSS: 0.1637 | ACC 0.9513\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0694/0938 | LOSS: 0.1637 | ACC 0.9514\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0695/0938 | LOSS: 0.1637 | ACC 0.9513\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0696/0938 | LOSS: 0.1637 | ACC 0.9514\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0697/0938 | LOSS: 0.1636 | ACC 0.9514\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0698/0938 | LOSS: 0.1634 | ACC 0.9514\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0699/0938 | LOSS: 0.1634 | ACC 0.9514\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0700/0938 | LOSS: 0.1633 | ACC 0.9515\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0701/0938 | LOSS: 0.1632 | ACC 0.9515\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0702/0938 | LOSS: 0.1631 | ACC 0.9515\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0703/0938 | LOSS: 0.1633 | ACC 0.9514\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0704/0938 | LOSS: 0.1634 | ACC 0.9514\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0705/0938 | LOSS: 0.1635 | ACC 0.9514\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0706/0938 | LOSS: 0.1634 | ACC 0.9514\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0707/0938 | LOSS: 0.1633 | ACC 0.9515\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0708/0938 | LOSS: 0.1634 | ACC 0.9515\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0709/0938 | LOSS: 0.1634 | ACC 0.9515\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0710/0938 | LOSS: 0.1634 | ACC 0.9515\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0711/0938 | LOSS: 0.1635 | ACC 0.9515\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0712/0938 | LOSS: 0.1633 | ACC 0.9516\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0713/0938 | LOSS: 0.1635 | ACC 0.9515\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0714/0938 | LOSS: 0.1635 | ACC 0.9515\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0715/0938 | LOSS: 0.1636 | ACC 0.9515\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0716/0938 | LOSS: 0.1635 | ACC 0.9515\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0717/0938 | LOSS: 0.1634 | ACC 0.9515\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0718/0938 | LOSS: 0.1632 | ACC 0.9516\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0719/0938 | LOSS: 0.1631 | ACC 0.9516\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0720/0938 | LOSS: 0.1630 | ACC 0.9516\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0721/0938 | LOSS: 0.1629 | ACC 0.9517\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0722/0938 | LOSS: 0.1627 | ACC 0.9517\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0723/0938 | LOSS: 0.1626 | ACC 0.9518\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0724/0938 | LOSS: 0.1627 | ACC 0.9517\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0725/0938 | LOSS: 0.1625 | ACC 0.9518\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: EPOCH 0008/0010 | BATCH 0726/0938 | LOSS: 0.1625 | ACC 0.9518\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0727/0938 | LOSS: 0.1624 | ACC 0.9518\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0728/0938 | LOSS: 0.1622 | ACC 0.9518\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0729/0938 | LOSS: 0.1621 | ACC 0.9519\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0730/0938 | LOSS: 0.1621 | ACC 0.9518\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0731/0938 | LOSS: 0.1621 | ACC 0.9518\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0732/0938 | LOSS: 0.1621 | ACC 0.9519\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0733/0938 | LOSS: 0.1620 | ACC 0.9519\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0734/0938 | LOSS: 0.1621 | ACC 0.9518\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0735/0938 | LOSS: 0.1621 | ACC 0.9518\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0736/0938 | LOSS: 0.1621 | ACC 0.9518\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0737/0938 | LOSS: 0.1622 | ACC 0.9518\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0738/0938 | LOSS: 0.1620 | ACC 0.9518\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0739/0938 | LOSS: 0.1626 | ACC 0.9518\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0740/0938 | LOSS: 0.1627 | ACC 0.9518\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0741/0938 | LOSS: 0.1626 | ACC 0.9519\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0742/0938 | LOSS: 0.1625 | ACC 0.9519\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0743/0938 | LOSS: 0.1625 | ACC 0.9519\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0744/0938 | LOSS: 0.1625 | ACC 0.9519\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0745/0938 | LOSS: 0.1625 | ACC 0.9518\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0746/0938 | LOSS: 0.1625 | ACC 0.9518\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0747/0938 | LOSS: 0.1625 | ACC 0.9517\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0748/0938 | LOSS: 0.1626 | ACC 0.9517\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0749/0938 | LOSS: 0.1626 | ACC 0.9517\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0750/0938 | LOSS: 0.1626 | ACC 0.9517\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0751/0938 | LOSS: 0.1628 | ACC 0.9517\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0752/0938 | LOSS: 0.1627 | ACC 0.9517\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0753/0938 | LOSS: 0.1627 | ACC 0.9517\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0754/0938 | LOSS: 0.1625 | ACC 0.9517\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0755/0938 | LOSS: 0.1626 | ACC 0.9517\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0756/0938 | LOSS: 0.1626 | ACC 0.9517\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0757/0938 | LOSS: 0.1628 | ACC 0.9517\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0758/0938 | LOSS: 0.1628 | ACC 0.9517\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0759/0938 | LOSS: 0.1629 | ACC 0.9517\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0760/0938 | LOSS: 0.1629 | ACC 0.9516\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0761/0938 | LOSS: 0.1628 | ACC 0.9517\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0762/0938 | LOSS: 0.1627 | ACC 0.9517\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0763/0938 | LOSS: 0.1628 | ACC 0.9517\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0764/0938 | LOSS: 0.1627 | ACC 0.9517\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0765/0938 | LOSS: 0.1628 | ACC 0.9517\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0766/0938 | LOSS: 0.1627 | ACC 0.9517\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0767/0938 | LOSS: 0.1626 | ACC 0.9517\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0768/0938 | LOSS: 0.1626 | ACC 0.9517\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0769/0938 | LOSS: 0.1626 | ACC 0.9517\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0770/0938 | LOSS: 0.1627 | ACC 0.9517\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0771/0938 | LOSS: 0.1627 | ACC 0.9516\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0772/0938 | LOSS: 0.1628 | ACC 0.9516\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0773/0938 | LOSS: 0.1629 | ACC 0.9516\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0774/0938 | LOSS: 0.1629 | ACC 0.9517\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0775/0938 | LOSS: 0.1628 | ACC 0.9517\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0776/0938 | LOSS: 0.1628 | ACC 0.9517\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0777/0938 | LOSS: 0.1627 | ACC 0.9517\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0778/0938 | LOSS: 0.1627 | ACC 0.9517\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0779/0938 | LOSS: 0.1626 | ACC 0.9518\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0780/0938 | LOSS: 0.1627 | ACC 0.9517\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0781/0938 | LOSS: 0.1627 | ACC 0.9517\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0782/0938 | LOSS: 0.1626 | ACC 0.9517\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0783/0938 | LOSS: 0.1625 | ACC 0.9517\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0784/0938 | LOSS: 0.1623 | ACC 0.9517\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0785/0938 | LOSS: 0.1622 | ACC 0.9518\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0786/0938 | LOSS: 0.1623 | ACC 0.9518\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0787/0938 | LOSS: 0.1621 | ACC 0.9518\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0788/0938 | LOSS: 0.1620 | ACC 0.9518\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0789/0938 | LOSS: 0.1622 | ACC 0.9518\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0790/0938 | LOSS: 0.1621 | ACC 0.9518\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0791/0938 | LOSS: 0.1620 | ACC 0.9519\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0792/0938 | LOSS: 0.1619 | ACC 0.9519\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0793/0938 | LOSS: 0.1618 | ACC 0.9519\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0794/0938 | LOSS: 0.1617 | ACC 0.9520\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0795/0938 | LOSS: 0.1618 | ACC 0.9519\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0796/0938 | LOSS: 0.1618 | ACC 0.9519\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0797/0938 | LOSS: 0.1617 | ACC 0.9519\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0798/0938 | LOSS: 0.1619 | ACC 0.9519\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0799/0938 | LOSS: 0.1618 | ACC 0.9518\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0800/0938 | LOSS: 0.1617 | ACC 0.9519\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0801/0938 | LOSS: 0.1617 | ACC 0.9519\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0802/0938 | LOSS: 0.1616 | ACC 0.9519\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0803/0938 | LOSS: 0.1616 | ACC 0.9519\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0804/0938 | LOSS: 0.1615 | ACC 0.9519\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0805/0938 | LOSS: 0.1617 | ACC 0.9519\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0806/0938 | LOSS: 0.1618 | ACC 0.9519\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0807/0938 | LOSS: 0.1618 | ACC 0.9519\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0808/0938 | LOSS: 0.1619 | ACC 0.9518\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0809/0938 | LOSS: 0.1621 | ACC 0.9519\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0810/0938 | LOSS: 0.1621 | ACC 0.9519\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0811/0938 | LOSS: 0.1621 | ACC 0.9519\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0812/0938 | LOSS: 0.1620 | ACC 0.9519\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0813/0938 | LOSS: 0.1619 | ACC 0.9519\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0814/0938 | LOSS: 0.1618 | ACC 0.9520\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0815/0938 | LOSS: 0.1618 | ACC 0.9519\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0816/0938 | LOSS: 0.1622 | ACC 0.9519\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0817/0938 | LOSS: 0.1622 | ACC 0.9519\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0818/0938 | LOSS: 0.1621 | ACC 0.9519\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0819/0938 | LOSS: 0.1620 | ACC 0.9520\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0820/0938 | LOSS: 0.1619 | ACC 0.9520\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0821/0938 | LOSS: 0.1619 | ACC 0.9519\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0822/0938 | LOSS: 0.1620 | ACC 0.9519\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0823/0938 | LOSS: 0.1620 | ACC 0.9519\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0824/0938 | LOSS: 0.1619 | ACC 0.9519\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0825/0938 | LOSS: 0.1618 | ACC 0.9519\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0826/0938 | LOSS: 0.1617 | ACC 0.9519\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0827/0938 | LOSS: 0.1618 | ACC 0.9520\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0828/0938 | LOSS: 0.1617 | ACC 0.9520\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0829/0938 | LOSS: 0.1617 | ACC 0.9520\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0830/0938 | LOSS: 0.1616 | ACC 0.9520\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0831/0938 | LOSS: 0.1618 | ACC 0.9520\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0832/0938 | LOSS: 0.1617 | ACC 0.9520\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0833/0938 | LOSS: 0.1617 | ACC 0.9520\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0834/0938 | LOSS: 0.1616 | ACC 0.9520\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0835/0938 | LOSS: 0.1616 | ACC 0.9520\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0836/0938 | LOSS: 0.1614 | ACC 0.9521\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0837/0938 | LOSS: 0.1615 | ACC 0.9520\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0838/0938 | LOSS: 0.1615 | ACC 0.9520\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0839/0938 | LOSS: 0.1615 | ACC 0.9520\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0840/0938 | LOSS: 0.1616 | ACC 0.9520\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0841/0938 | LOSS: 0.1616 | ACC 0.9520\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0842/0938 | LOSS: 0.1618 | ACC 0.9520\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0843/0938 | LOSS: 0.1617 | ACC 0.9520\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0844/0938 | LOSS: 0.1615 | ACC 0.9521\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0845/0938 | LOSS: 0.1615 | ACC 0.9521\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0846/0938 | LOSS: 0.1614 | ACC 0.9521\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0847/0938 | LOSS: 0.1614 | ACC 0.9520\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0848/0938 | LOSS: 0.1614 | ACC 0.9520\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0849/0938 | LOSS: 0.1613 | ACC 0.9520\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0850/0938 | LOSS: 0.1614 | ACC 0.9520\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: EPOCH 0008/0010 | BATCH 0851/0938 | LOSS: 0.1615 | ACC 0.9520\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0852/0938 | LOSS: 0.1614 | ACC 0.9520\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0853/0938 | LOSS: 0.1616 | ACC 0.9520\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0854/0938 | LOSS: 0.1616 | ACC 0.9520\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0855/0938 | LOSS: 0.1616 | ACC 0.9520\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0856/0938 | LOSS: 0.1616 | ACC 0.9520\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0857/0938 | LOSS: 0.1616 | ACC 0.9520\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0858/0938 | LOSS: 0.1616 | ACC 0.9520\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0859/0938 | LOSS: 0.1616 | ACC 0.9521\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0860/0938 | LOSS: 0.1616 | ACC 0.9520\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0861/0938 | LOSS: 0.1615 | ACC 0.9521\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0862/0938 | LOSS: 0.1615 | ACC 0.9521\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0863/0938 | LOSS: 0.1614 | ACC 0.9521\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0864/0938 | LOSS: 0.1614 | ACC 0.9521\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0865/0938 | LOSS: 0.1614 | ACC 0.9521\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0866/0938 | LOSS: 0.1614 | ACC 0.9521\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0867/0938 | LOSS: 0.1613 | ACC 0.9522\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0868/0938 | LOSS: 0.1612 | ACC 0.9522\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0869/0938 | LOSS: 0.1611 | ACC 0.9522\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0870/0938 | LOSS: 0.1610 | ACC 0.9523\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0871/0938 | LOSS: 0.1609 | ACC 0.9523\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0872/0938 | LOSS: 0.1609 | ACC 0.9523\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0873/0938 | LOSS: 0.1611 | ACC 0.9522\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0874/0938 | LOSS: 0.1610 | ACC 0.9523\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0875/0938 | LOSS: 0.1611 | ACC 0.9523\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0876/0938 | LOSS: 0.1612 | ACC 0.9523\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0877/0938 | LOSS: 0.1612 | ACC 0.9522\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0878/0938 | LOSS: 0.1614 | ACC 0.9522\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0879/0938 | LOSS: 0.1614 | ACC 0.9522\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0880/0938 | LOSS: 0.1615 | ACC 0.9522\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0881/0938 | LOSS: 0.1614 | ACC 0.9521\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0882/0938 | LOSS: 0.1613 | ACC 0.9522\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0883/0938 | LOSS: 0.1613 | ACC 0.9522\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0884/0938 | LOSS: 0.1614 | ACC 0.9521\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0885/0938 | LOSS: 0.1613 | ACC 0.9522\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0886/0938 | LOSS: 0.1614 | ACC 0.9521\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0887/0938 | LOSS: 0.1614 | ACC 0.9521\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0888/0938 | LOSS: 0.1613 | ACC 0.9521\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0889/0938 | LOSS: 0.1613 | ACC 0.9522\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0890/0938 | LOSS: 0.1612 | ACC 0.9522\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0891/0938 | LOSS: 0.1613 | ACC 0.9522\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0892/0938 | LOSS: 0.1614 | ACC 0.9522\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0893/0938 | LOSS: 0.1614 | ACC 0.9522\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0894/0938 | LOSS: 0.1613 | ACC 0.9522\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0895/0938 | LOSS: 0.1613 | ACC 0.9522\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0896/0938 | LOSS: 0.1612 | ACC 0.9522\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0897/0938 | LOSS: 0.1612 | ACC 0.9522\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0898/0938 | LOSS: 0.1611 | ACC 0.9522\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0899/0938 | LOSS: 0.1613 | ACC 0.9522\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0900/0938 | LOSS: 0.1613 | ACC 0.9522\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0901/0938 | LOSS: 0.1613 | ACC 0.9522\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0902/0938 | LOSS: 0.1615 | ACC 0.9522\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0903/0938 | LOSS: 0.1615 | ACC 0.9522\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0904/0938 | LOSS: 0.1615 | ACC 0.9521\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0905/0938 | LOSS: 0.1614 | ACC 0.9521\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0906/0938 | LOSS: 0.1613 | ACC 0.9522\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0907/0938 | LOSS: 0.1616 | ACC 0.9522\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0908/0938 | LOSS: 0.1615 | ACC 0.9522\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0909/0938 | LOSS: 0.1616 | ACC 0.9521\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0910/0938 | LOSS: 0.1615 | ACC 0.9521\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0911/0938 | LOSS: 0.1617 | ACC 0.9521\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0912/0938 | LOSS: 0.1617 | ACC 0.9521\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0913/0938 | LOSS: 0.1616 | ACC 0.9521\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0914/0938 | LOSS: 0.1615 | ACC 0.9521\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0915/0938 | LOSS: 0.1615 | ACC 0.9521\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0916/0938 | LOSS: 0.1615 | ACC 0.9521\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0917/0938 | LOSS: 0.1616 | ACC 0.9521\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0918/0938 | LOSS: 0.1616 | ACC 0.9521\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0919/0938 | LOSS: 0.1617 | ACC 0.9521\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0920/0938 | LOSS: 0.1617 | ACC 0.9521\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0921/0938 | LOSS: 0.1617 | ACC 0.9521\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0922/0938 | LOSS: 0.1616 | ACC 0.9521\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0923/0938 | LOSS: 0.1616 | ACC 0.9521\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0924/0938 | LOSS: 0.1616 | ACC 0.9521\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0925/0938 | LOSS: 0.1616 | ACC 0.9521\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0926/0938 | LOSS: 0.1616 | ACC 0.9521\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0927/0938 | LOSS: 0.1616 | ACC 0.9521\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0928/0938 | LOSS: 0.1617 | ACC 0.9521\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0929/0938 | LOSS: 0.1618 | ACC 0.9521\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0930/0938 | LOSS: 0.1619 | ACC 0.9521\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0931/0938 | LOSS: 0.1618 | ACC 0.9521\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0932/0938 | LOSS: 0.1619 | ACC 0.9521\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0933/0938 | LOSS: 0.1619 | ACC 0.9521\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0934/0938 | LOSS: 0.1617 | ACC 0.9521\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0935/0938 | LOSS: 0.1618 | ACC 0.9521\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0936/0938 | LOSS: 0.1618 | ACC 0.9521\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0937/0938 | LOSS: 0.1617 | ACC 0.9521\n",
      "TRAIN: EPOCH 0008/0010 | BATCH 0938/0938 | LOSS: 0.1618 | ACC 0.9521\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0001/0938 | LOSS: 0.1574 | ACC 0.9375\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0002/0938 | LOSS: 0.1545 | ACC 0.9453\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0003/0938 | LOSS: 0.1438 | ACC 0.9583\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0004/0938 | LOSS: 0.1559 | ACC 0.9531\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0005/0938 | LOSS: 0.1511 | ACC 0.9563\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0006/0938 | LOSS: 0.1338 | ACC 0.9609\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0007/0938 | LOSS: 0.1414 | ACC 0.9598\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0008/0938 | LOSS: 0.1473 | ACC 0.9531\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0009/0938 | LOSS: 0.1472 | ACC 0.9497\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0010/0938 | LOSS: 0.1415 | ACC 0.9516\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0011/0938 | LOSS: 0.1435 | ACC 0.9517\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0012/0938 | LOSS: 0.1445 | ACC 0.9531\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0013/0938 | LOSS: 0.1431 | ACC 0.9531\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0014/0938 | LOSS: 0.1399 | ACC 0.9542\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0015/0938 | LOSS: 0.1497 | ACC 0.9500\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0016/0938 | LOSS: 0.1584 | ACC 0.9492\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0017/0938 | LOSS: 0.1586 | ACC 0.9494\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0018/0938 | LOSS: 0.1578 | ACC 0.9497\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0019/0938 | LOSS: 0.1624 | ACC 0.9498\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0020/0938 | LOSS: 0.1685 | ACC 0.9484\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0021/0938 | LOSS: 0.1666 | ACC 0.9494\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0022/0938 | LOSS: 0.1673 | ACC 0.9496\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0023/0938 | LOSS: 0.1650 | ACC 0.9497\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0024/0938 | LOSS: 0.1614 | ACC 0.9505\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0025/0938 | LOSS: 0.1600 | ACC 0.9513\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0026/0938 | LOSS: 0.1598 | ACC 0.9513\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0027/0938 | LOSS: 0.1620 | ACC 0.9508\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0028/0938 | LOSS: 0.1586 | ACC 0.9515\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0029/0938 | LOSS: 0.1575 | ACC 0.9515\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0030/0938 | LOSS: 0.1584 | ACC 0.9516\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0031/0938 | LOSS: 0.1594 | ACC 0.9511\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0032/0938 | LOSS: 0.1569 | ACC 0.9517\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0033/0938 | LOSS: 0.1579 | ACC 0.9517\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0034/0938 | LOSS: 0.1573 | ACC 0.9522\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0035/0938 | LOSS: 0.1579 | ACC 0.9531\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0036/0938 | LOSS: 0.1568 | ACC 0.9536\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0037/0938 | LOSS: 0.1573 | ACC 0.9535\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0038/0938 | LOSS: 0.1606 | ACC 0.9519\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0039/0938 | LOSS: 0.1604 | ACC 0.9523\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0040/0938 | LOSS: 0.1634 | ACC 0.9516\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: EPOCH 0009/0010 | BATCH 0041/0938 | LOSS: 0.1606 | ACC 0.9520\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0042/0938 | LOSS: 0.1581 | ACC 0.9531\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0043/0938 | LOSS: 0.1622 | ACC 0.9531\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0044/0938 | LOSS: 0.1628 | ACC 0.9521\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0045/0938 | LOSS: 0.1606 | ACC 0.9531\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0046/0938 | LOSS: 0.1615 | ACC 0.9531\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0047/0938 | LOSS: 0.1598 | ACC 0.9535\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0048/0938 | LOSS: 0.1600 | ACC 0.9535\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0049/0938 | LOSS: 0.1603 | ACC 0.9534\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0050/0938 | LOSS: 0.1596 | ACC 0.9534\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0051/0938 | LOSS: 0.1594 | ACC 0.9531\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0052/0938 | LOSS: 0.1597 | ACC 0.9528\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0053/0938 | LOSS: 0.1610 | ACC 0.9522\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0054/0938 | LOSS: 0.1634 | ACC 0.9528\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0055/0938 | LOSS: 0.1651 | ACC 0.9526\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0056/0938 | LOSS: 0.1634 | ACC 0.9528\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0057/0938 | LOSS: 0.1633 | ACC 0.9531\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0058/0938 | LOSS: 0.1617 | ACC 0.9537\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0059/0938 | LOSS: 0.1605 | ACC 0.9539\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0060/0938 | LOSS: 0.1602 | ACC 0.9542\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0061/0938 | LOSS: 0.1591 | ACC 0.9544\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0062/0938 | LOSS: 0.1620 | ACC 0.9539\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0063/0938 | LOSS: 0.1617 | ACC 0.9536\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0064/0938 | LOSS: 0.1611 | ACC 0.9539\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0065/0938 | LOSS: 0.1605 | ACC 0.9541\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0066/0938 | LOSS: 0.1615 | ACC 0.9529\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0067/0938 | LOSS: 0.1601 | ACC 0.9534\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0068/0938 | LOSS: 0.1601 | ACC 0.9534\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0069/0938 | LOSS: 0.1600 | ACC 0.9534\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0070/0938 | LOSS: 0.1631 | ACC 0.9522\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0071/0938 | LOSS: 0.1623 | ACC 0.9522\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0072/0938 | LOSS: 0.1632 | ACC 0.9523\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0073/0938 | LOSS: 0.1617 | ACC 0.9529\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0074/0938 | LOSS: 0.1612 | ACC 0.9525\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0075/0938 | LOSS: 0.1609 | ACC 0.9527\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0076/0938 | LOSS: 0.1625 | ACC 0.9521\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0077/0938 | LOSS: 0.1632 | ACC 0.9523\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0078/0938 | LOSS: 0.1624 | ACC 0.9523\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0079/0938 | LOSS: 0.1626 | ACC 0.9517\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0080/0938 | LOSS: 0.1627 | ACC 0.9518\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0081/0938 | LOSS: 0.1619 | ACC 0.9520\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0082/0938 | LOSS: 0.1652 | ACC 0.9510\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0083/0938 | LOSS: 0.1644 | ACC 0.9512\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0084/0938 | LOSS: 0.1634 | ACC 0.9515\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0085/0938 | LOSS: 0.1644 | ACC 0.9513\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0086/0938 | LOSS: 0.1644 | ACC 0.9508\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0087/0938 | LOSS: 0.1639 | ACC 0.9510\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0088/0938 | LOSS: 0.1637 | ACC 0.9512\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0089/0938 | LOSS: 0.1630 | ACC 0.9512\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0090/0938 | LOSS: 0.1637 | ACC 0.9510\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0091/0938 | LOSS: 0.1631 | ACC 0.9511\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0092/0938 | LOSS: 0.1635 | ACC 0.9511\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0093/0938 | LOSS: 0.1626 | ACC 0.9513\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0094/0938 | LOSS: 0.1632 | ACC 0.9510\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0095/0938 | LOSS: 0.1641 | ACC 0.9508\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0096/0938 | LOSS: 0.1642 | ACC 0.9507\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0097/0938 | LOSS: 0.1650 | ACC 0.9504\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0098/0938 | LOSS: 0.1641 | ACC 0.9507\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0099/0938 | LOSS: 0.1650 | ACC 0.9504\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0100/0938 | LOSS: 0.1643 | ACC 0.9506\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0101/0938 | LOSS: 0.1647 | ACC 0.9505\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0102/0938 | LOSS: 0.1666 | ACC 0.9498\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0103/0938 | LOSS: 0.1659 | ACC 0.9498\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0104/0938 | LOSS: 0.1667 | ACC 0.9498\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0105/0938 | LOSS: 0.1671 | ACC 0.9499\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0106/0938 | LOSS: 0.1665 | ACC 0.9500\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0107/0938 | LOSS: 0.1672 | ACC 0.9501\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0108/0938 | LOSS: 0.1667 | ACC 0.9502\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0109/0938 | LOSS: 0.1670 | ACC 0.9503\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0110/0938 | LOSS: 0.1675 | ACC 0.9506\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0111/0938 | LOSS: 0.1673 | ACC 0.9503\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0112/0938 | LOSS: 0.1676 | ACC 0.9503\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0113/0938 | LOSS: 0.1672 | ACC 0.9505\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0114/0938 | LOSS: 0.1672 | ACC 0.9505\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0115/0938 | LOSS: 0.1673 | ACC 0.9503\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0116/0938 | LOSS: 0.1668 | ACC 0.9503\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0117/0938 | LOSS: 0.1669 | ACC 0.9505\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0118/0938 | LOSS: 0.1664 | ACC 0.9505\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0119/0938 | LOSS: 0.1678 | ACC 0.9496\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0120/0938 | LOSS: 0.1670 | ACC 0.9499\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0121/0938 | LOSS: 0.1665 | ACC 0.9500\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0122/0938 | LOSS: 0.1663 | ACC 0.9501\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0123/0938 | LOSS: 0.1652 | ACC 0.9505\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0124/0938 | LOSS: 0.1653 | ACC 0.9501\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0125/0938 | LOSS: 0.1644 | ACC 0.9505\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0126/0938 | LOSS: 0.1646 | ACC 0.9504\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0127/0938 | LOSS: 0.1642 | ACC 0.9504\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0128/0938 | LOSS: 0.1633 | ACC 0.9508\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0129/0938 | LOSS: 0.1623 | ACC 0.9511\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0130/0938 | LOSS: 0.1621 | ACC 0.9513\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0131/0938 | LOSS: 0.1614 | ACC 0.9516\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0132/0938 | LOSS: 0.1607 | ACC 0.9518\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0133/0938 | LOSS: 0.1611 | ACC 0.9520\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0134/0938 | LOSS: 0.1613 | ACC 0.9517\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0135/0938 | LOSS: 0.1609 | ACC 0.9519\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0136/0938 | LOSS: 0.1602 | ACC 0.9521\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0137/0938 | LOSS: 0.1601 | ACC 0.9520\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0138/0938 | LOSS: 0.1597 | ACC 0.9520\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0139/0938 | LOSS: 0.1604 | ACC 0.9519\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0140/0938 | LOSS: 0.1596 | ACC 0.9521\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0141/0938 | LOSS: 0.1593 | ACC 0.9520\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0142/0938 | LOSS: 0.1584 | ACC 0.9524\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0143/0938 | LOSS: 0.1581 | ACC 0.9524\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0144/0938 | LOSS: 0.1587 | ACC 0.9523\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0145/0938 | LOSS: 0.1592 | ACC 0.9523\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0146/0938 | LOSS: 0.1616 | ACC 0.9516\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0147/0938 | LOSS: 0.1613 | ACC 0.9517\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0148/0938 | LOSS: 0.1606 | ACC 0.9519\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0149/0938 | LOSS: 0.1603 | ACC 0.9520\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0150/0938 | LOSS: 0.1601 | ACC 0.9520\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0151/0938 | LOSS: 0.1596 | ACC 0.9521\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0152/0938 | LOSS: 0.1605 | ACC 0.9522\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0153/0938 | LOSS: 0.1599 | ACC 0.9524\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0154/0938 | LOSS: 0.1592 | ACC 0.9526\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0155/0938 | LOSS: 0.1595 | ACC 0.9524\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0156/0938 | LOSS: 0.1590 | ACC 0.9526\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0157/0938 | LOSS: 0.1583 | ACC 0.9529\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0158/0938 | LOSS: 0.1583 | ACC 0.9529\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0159/0938 | LOSS: 0.1584 | ACC 0.9530\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0160/0938 | LOSS: 0.1592 | ACC 0.9528\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0161/0938 | LOSS: 0.1588 | ACC 0.9529\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0162/0938 | LOSS: 0.1589 | ACC 0.9528\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0163/0938 | LOSS: 0.1598 | ACC 0.9525\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0164/0938 | LOSS: 0.1593 | ACC 0.9526\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0165/0938 | LOSS: 0.1595 | ACC 0.9527\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0166/0938 | LOSS: 0.1592 | ACC 0.9528\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0167/0938 | LOSS: 0.1594 | ACC 0.9528\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0168/0938 | LOSS: 0.1593 | ACC 0.9529\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: EPOCH 0009/0010 | BATCH 0169/0938 | LOSS: 0.1593 | ACC 0.9529\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0170/0938 | LOSS: 0.1589 | ACC 0.9528\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0171/0938 | LOSS: 0.1584 | ACC 0.9530\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0172/0938 | LOSS: 0.1585 | ACC 0.9530\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0173/0938 | LOSS: 0.1582 | ACC 0.9531\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0174/0938 | LOSS: 0.1583 | ACC 0.9530\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0175/0938 | LOSS: 0.1585 | ACC 0.9532\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0176/0938 | LOSS: 0.1583 | ACC 0.9533\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0177/0938 | LOSS: 0.1579 | ACC 0.9534\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0178/0938 | LOSS: 0.1577 | ACC 0.9532\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0179/0938 | LOSS: 0.1575 | ACC 0.9532\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0180/0938 | LOSS: 0.1577 | ACC 0.9532\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0181/0938 | LOSS: 0.1573 | ACC 0.9533\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0182/0938 | LOSS: 0.1566 | ACC 0.9536\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0183/0938 | LOSS: 0.1562 | ACC 0.9535\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0184/0938 | LOSS: 0.1563 | ACC 0.9535\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0185/0938 | LOSS: 0.1562 | ACC 0.9535\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0186/0938 | LOSS: 0.1559 | ACC 0.9535\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0187/0938 | LOSS: 0.1559 | ACC 0.9535\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0188/0938 | LOSS: 0.1560 | ACC 0.9536\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0189/0938 | LOSS: 0.1562 | ACC 0.9535\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0190/0938 | LOSS: 0.1565 | ACC 0.9534\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0191/0938 | LOSS: 0.1560 | ACC 0.9535\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0192/0938 | LOSS: 0.1565 | ACC 0.9535\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0193/0938 | LOSS: 0.1570 | ACC 0.9533\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0194/0938 | LOSS: 0.1575 | ACC 0.9532\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0195/0938 | LOSS: 0.1570 | ACC 0.9534\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0196/0938 | LOSS: 0.1568 | ACC 0.9534\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0197/0938 | LOSS: 0.1567 | ACC 0.9536\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0198/0938 | LOSS: 0.1573 | ACC 0.9534\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0199/0938 | LOSS: 0.1569 | ACC 0.9535\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0200/0938 | LOSS: 0.1566 | ACC 0.9537\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0201/0938 | LOSS: 0.1565 | ACC 0.9537\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0202/0938 | LOSS: 0.1566 | ACC 0.9537\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0203/0938 | LOSS: 0.1565 | ACC 0.9537\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0204/0938 | LOSS: 0.1561 | ACC 0.9539\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0205/0938 | LOSS: 0.1561 | ACC 0.9538\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0206/0938 | LOSS: 0.1572 | ACC 0.9537\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0207/0938 | LOSS: 0.1571 | ACC 0.9537\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0208/0938 | LOSS: 0.1567 | ACC 0.9538\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0209/0938 | LOSS: 0.1572 | ACC 0.9536\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0210/0938 | LOSS: 0.1578 | ACC 0.9535\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0211/0938 | LOSS: 0.1579 | ACC 0.9533\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0212/0938 | LOSS: 0.1574 | ACC 0.9535\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0213/0938 | LOSS: 0.1579 | ACC 0.9533\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0214/0938 | LOSS: 0.1586 | ACC 0.9533\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0215/0938 | LOSS: 0.1604 | ACC 0.9532\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0216/0938 | LOSS: 0.1599 | ACC 0.9534\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0217/0938 | LOSS: 0.1597 | ACC 0.9534\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0218/0938 | LOSS: 0.1595 | ACC 0.9535\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0219/0938 | LOSS: 0.1593 | ACC 0.9536\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0220/0938 | LOSS: 0.1595 | ACC 0.9536\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0221/0938 | LOSS: 0.1592 | ACC 0.9536\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0222/0938 | LOSS: 0.1589 | ACC 0.9537\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0223/0938 | LOSS: 0.1600 | ACC 0.9536\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0224/0938 | LOSS: 0.1600 | ACC 0.9536\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0225/0938 | LOSS: 0.1597 | ACC 0.9537\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0226/0938 | LOSS: 0.1599 | ACC 0.9538\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0227/0938 | LOSS: 0.1605 | ACC 0.9536\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0228/0938 | LOSS: 0.1600 | ACC 0.9538\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0229/0938 | LOSS: 0.1596 | ACC 0.9539\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0230/0938 | LOSS: 0.1597 | ACC 0.9538\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0231/0938 | LOSS: 0.1598 | ACC 0.9538\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0232/0938 | LOSS: 0.1594 | ACC 0.9539\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0233/0938 | LOSS: 0.1593 | ACC 0.9539\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0234/0938 | LOSS: 0.1591 | ACC 0.9539\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0235/0938 | LOSS: 0.1589 | ACC 0.9540\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0236/0938 | LOSS: 0.1589 | ACC 0.9539\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0237/0938 | LOSS: 0.1593 | ACC 0.9537\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0238/0938 | LOSS: 0.1607 | ACC 0.9537\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0239/0938 | LOSS: 0.1608 | ACC 0.9536\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0240/0938 | LOSS: 0.1605 | ACC 0.9536\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0241/0938 | LOSS: 0.1616 | ACC 0.9533\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0242/0938 | LOSS: 0.1611 | ACC 0.9534\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0243/0938 | LOSS: 0.1611 | ACC 0.9534\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0244/0938 | LOSS: 0.1619 | ACC 0.9531\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0245/0938 | LOSS: 0.1615 | ACC 0.9533\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0246/0938 | LOSS: 0.1616 | ACC 0.9531\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0247/0938 | LOSS: 0.1619 | ACC 0.9529\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0248/0938 | LOSS: 0.1618 | ACC 0.9530\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0249/0938 | LOSS: 0.1619 | ACC 0.9531\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0250/0938 | LOSS: 0.1620 | ACC 0.9532\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0251/0938 | LOSS: 0.1624 | ACC 0.9529\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0252/0938 | LOSS: 0.1622 | ACC 0.9529\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0253/0938 | LOSS: 0.1620 | ACC 0.9531\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0254/0938 | LOSS: 0.1622 | ACC 0.9531\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0255/0938 | LOSS: 0.1628 | ACC 0.9530\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0256/0938 | LOSS: 0.1629 | ACC 0.9529\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0257/0938 | LOSS: 0.1627 | ACC 0.9530\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0258/0938 | LOSS: 0.1632 | ACC 0.9529\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0259/0938 | LOSS: 0.1635 | ACC 0.9529\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0260/0938 | LOSS: 0.1634 | ACC 0.9528\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0261/0938 | LOSS: 0.1635 | ACC 0.9526\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0262/0938 | LOSS: 0.1632 | ACC 0.9526\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0263/0938 | LOSS: 0.1627 | ACC 0.9528\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0264/0938 | LOSS: 0.1631 | ACC 0.9528\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0265/0938 | LOSS: 0.1630 | ACC 0.9528\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0266/0938 | LOSS: 0.1626 | ACC 0.9529\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0267/0938 | LOSS: 0.1627 | ACC 0.9529\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0268/0938 | LOSS: 0.1627 | ACC 0.9530\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0269/0938 | LOSS: 0.1626 | ACC 0.9530\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0270/0938 | LOSS: 0.1623 | ACC 0.9531\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0271/0938 | LOSS: 0.1622 | ACC 0.9532\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0272/0938 | LOSS: 0.1624 | ACC 0.9533\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0273/0938 | LOSS: 0.1623 | ACC 0.9533\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0274/0938 | LOSS: 0.1624 | ACC 0.9532\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0275/0938 | LOSS: 0.1624 | ACC 0.9534\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0276/0938 | LOSS: 0.1627 | ACC 0.9533\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0277/0938 | LOSS: 0.1624 | ACC 0.9534\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0278/0938 | LOSS: 0.1622 | ACC 0.9534\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0279/0938 | LOSS: 0.1619 | ACC 0.9536\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0280/0938 | LOSS: 0.1619 | ACC 0.9536\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0281/0938 | LOSS: 0.1619 | ACC 0.9536\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0282/0938 | LOSS: 0.1618 | ACC 0.9537\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0283/0938 | LOSS: 0.1614 | ACC 0.9538\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0284/0938 | LOSS: 0.1615 | ACC 0.9537\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0285/0938 | LOSS: 0.1614 | ACC 0.9538\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0286/0938 | LOSS: 0.1617 | ACC 0.9537\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0287/0938 | LOSS: 0.1618 | ACC 0.9537\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0288/0938 | LOSS: 0.1618 | ACC 0.9537\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0289/0938 | LOSS: 0.1616 | ACC 0.9537\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0290/0938 | LOSS: 0.1616 | ACC 0.9538\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0291/0938 | LOSS: 0.1619 | ACC 0.9537\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0292/0938 | LOSS: 0.1618 | ACC 0.9538\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0293/0938 | LOSS: 0.1618 | ACC 0.9537\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0294/0938 | LOSS: 0.1616 | ACC 0.9538\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0295/0938 | LOSS: 0.1617 | ACC 0.9537\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0296/0938 | LOSS: 0.1613 | ACC 0.9538\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0297/0938 | LOSS: 0.1615 | ACC 0.9537\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0298/0938 | LOSS: 0.1616 | ACC 0.9536\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: EPOCH 0009/0010 | BATCH 0299/0938 | LOSS: 0.1614 | ACC 0.9538\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0300/0938 | LOSS: 0.1613 | ACC 0.9538\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0301/0938 | LOSS: 0.1614 | ACC 0.9539\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0302/0938 | LOSS: 0.1611 | ACC 0.9540\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0303/0938 | LOSS: 0.1612 | ACC 0.9538\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0304/0938 | LOSS: 0.1609 | ACC 0.9539\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0305/0938 | LOSS: 0.1613 | ACC 0.9538\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0306/0938 | LOSS: 0.1610 | ACC 0.9539\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0307/0938 | LOSS: 0.1609 | ACC 0.9539\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0308/0938 | LOSS: 0.1606 | ACC 0.9539\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0309/0938 | LOSS: 0.1612 | ACC 0.9538\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0310/0938 | LOSS: 0.1609 | ACC 0.9539\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0311/0938 | LOSS: 0.1609 | ACC 0.9539\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0312/0938 | LOSS: 0.1607 | ACC 0.9540\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0313/0938 | LOSS: 0.1608 | ACC 0.9539\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0314/0938 | LOSS: 0.1612 | ACC 0.9539\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0315/0938 | LOSS: 0.1608 | ACC 0.9540\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0316/0938 | LOSS: 0.1610 | ACC 0.9540\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0317/0938 | LOSS: 0.1610 | ACC 0.9539\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0318/0938 | LOSS: 0.1607 | ACC 0.9539\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0319/0938 | LOSS: 0.1607 | ACC 0.9539\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0320/0938 | LOSS: 0.1611 | ACC 0.9537\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0321/0938 | LOSS: 0.1610 | ACC 0.9538\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0322/0938 | LOSS: 0.1610 | ACC 0.9537\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0323/0938 | LOSS: 0.1610 | ACC 0.9537\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0324/0938 | LOSS: 0.1610 | ACC 0.9537\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0325/0938 | LOSS: 0.1610 | ACC 0.9537\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0326/0938 | LOSS: 0.1612 | ACC 0.9537\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0327/0938 | LOSS: 0.1609 | ACC 0.9538\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0328/0938 | LOSS: 0.1607 | ACC 0.9539\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0329/0938 | LOSS: 0.1607 | ACC 0.9539\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0330/0938 | LOSS: 0.1605 | ACC 0.9540\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0331/0938 | LOSS: 0.1604 | ACC 0.9541\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0332/0938 | LOSS: 0.1602 | ACC 0.9541\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0333/0938 | LOSS: 0.1603 | ACC 0.9540\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0334/0938 | LOSS: 0.1602 | ACC 0.9540\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0335/0938 | LOSS: 0.1600 | ACC 0.9540\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0336/0938 | LOSS: 0.1601 | ACC 0.9539\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0337/0938 | LOSS: 0.1601 | ACC 0.9539\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0338/0938 | LOSS: 0.1598 | ACC 0.9540\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0339/0938 | LOSS: 0.1598 | ACC 0.9540\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0340/0938 | LOSS: 0.1607 | ACC 0.9540\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0341/0938 | LOSS: 0.1607 | ACC 0.9539\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0342/0938 | LOSS: 0.1609 | ACC 0.9539\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0343/0938 | LOSS: 0.1605 | ACC 0.9540\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0344/0938 | LOSS: 0.1608 | ACC 0.9540\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0345/0938 | LOSS: 0.1604 | ACC 0.9541\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0346/0938 | LOSS: 0.1602 | ACC 0.9542\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0347/0938 | LOSS: 0.1599 | ACC 0.9543\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0348/0938 | LOSS: 0.1598 | ACC 0.9543\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0349/0938 | LOSS: 0.1600 | ACC 0.9542\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0350/0938 | LOSS: 0.1602 | ACC 0.9542\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0351/0938 | LOSS: 0.1599 | ACC 0.9542\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0352/0938 | LOSS: 0.1598 | ACC 0.9543\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0353/0938 | LOSS: 0.1600 | ACC 0.9543\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0354/0938 | LOSS: 0.1598 | ACC 0.9543\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0355/0938 | LOSS: 0.1599 | ACC 0.9543\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0356/0938 | LOSS: 0.1597 | ACC 0.9544\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0357/0938 | LOSS: 0.1606 | ACC 0.9543\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0358/0938 | LOSS: 0.1608 | ACC 0.9543\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0359/0938 | LOSS: 0.1607 | ACC 0.9544\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0360/0938 | LOSS: 0.1609 | ACC 0.9544\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0361/0938 | LOSS: 0.1606 | ACC 0.9545\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0362/0938 | LOSS: 0.1606 | ACC 0.9545\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0363/0938 | LOSS: 0.1606 | ACC 0.9544\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0364/0938 | LOSS: 0.1606 | ACC 0.9544\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0365/0938 | LOSS: 0.1604 | ACC 0.9545\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0366/0938 | LOSS: 0.1602 | ACC 0.9546\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0367/0938 | LOSS: 0.1604 | ACC 0.9545\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0368/0938 | LOSS: 0.1612 | ACC 0.9544\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0369/0938 | LOSS: 0.1616 | ACC 0.9543\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0370/0938 | LOSS: 0.1616 | ACC 0.9543\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0371/0938 | LOSS: 0.1614 | ACC 0.9543\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0372/0938 | LOSS: 0.1613 | ACC 0.9544\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0373/0938 | LOSS: 0.1612 | ACC 0.9543\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0374/0938 | LOSS: 0.1612 | ACC 0.9544\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0375/0938 | LOSS: 0.1610 | ACC 0.9545\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0376/0938 | LOSS: 0.1608 | ACC 0.9545\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0377/0938 | LOSS: 0.1608 | ACC 0.9546\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0378/0938 | LOSS: 0.1606 | ACC 0.9547\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0379/0938 | LOSS: 0.1605 | ACC 0.9547\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0380/0938 | LOSS: 0.1603 | ACC 0.9547\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0381/0938 | LOSS: 0.1602 | ACC 0.9548\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0382/0938 | LOSS: 0.1601 | ACC 0.9548\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0383/0938 | LOSS: 0.1601 | ACC 0.9548\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0384/0938 | LOSS: 0.1601 | ACC 0.9548\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0385/0938 | LOSS: 0.1603 | ACC 0.9548\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0386/0938 | LOSS: 0.1605 | ACC 0.9547\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0387/0938 | LOSS: 0.1610 | ACC 0.9546\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0388/0938 | LOSS: 0.1611 | ACC 0.9546\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0389/0938 | LOSS: 0.1608 | ACC 0.9547\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0390/0938 | LOSS: 0.1610 | ACC 0.9547\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0391/0938 | LOSS: 0.1619 | ACC 0.9546\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0392/0938 | LOSS: 0.1619 | ACC 0.9545\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0393/0938 | LOSS: 0.1619 | ACC 0.9545\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0394/0938 | LOSS: 0.1616 | ACC 0.9546\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0395/0938 | LOSS: 0.1618 | ACC 0.9545\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0396/0938 | LOSS: 0.1619 | ACC 0.9544\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0397/0938 | LOSS: 0.1617 | ACC 0.9545\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0398/0938 | LOSS: 0.1615 | ACC 0.9546\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0399/0938 | LOSS: 0.1612 | ACC 0.9547\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0400/0938 | LOSS: 0.1609 | ACC 0.9548\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0401/0938 | LOSS: 0.1610 | ACC 0.9547\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0402/0938 | LOSS: 0.1609 | ACC 0.9547\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0403/0938 | LOSS: 0.1611 | ACC 0.9546\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0404/0938 | LOSS: 0.1616 | ACC 0.9547\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0405/0938 | LOSS: 0.1614 | ACC 0.9547\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0406/0938 | LOSS: 0.1616 | ACC 0.9546\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0407/0938 | LOSS: 0.1613 | ACC 0.9547\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0408/0938 | LOSS: 0.1611 | ACC 0.9547\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0409/0938 | LOSS: 0.1609 | ACC 0.9547\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0410/0938 | LOSS: 0.1608 | ACC 0.9548\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0411/0938 | LOSS: 0.1607 | ACC 0.9548\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0412/0938 | LOSS: 0.1606 | ACC 0.9548\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0413/0938 | LOSS: 0.1607 | ACC 0.9548\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0414/0938 | LOSS: 0.1607 | ACC 0.9548\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0415/0938 | LOSS: 0.1605 | ACC 0.9548\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0416/0938 | LOSS: 0.1606 | ACC 0.9549\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0417/0938 | LOSS: 0.1606 | ACC 0.9548\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0418/0938 | LOSS: 0.1605 | ACC 0.9548\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0419/0938 | LOSS: 0.1604 | ACC 0.9549\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0420/0938 | LOSS: 0.1602 | ACC 0.9549\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0421/0938 | LOSS: 0.1604 | ACC 0.9547\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0422/0938 | LOSS: 0.1602 | ACC 0.9548\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0423/0938 | LOSS: 0.1604 | ACC 0.9548\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0424/0938 | LOSS: 0.1606 | ACC 0.9547\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0425/0938 | LOSS: 0.1604 | ACC 0.9547\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0426/0938 | LOSS: 0.1604 | ACC 0.9548\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0427/0938 | LOSS: 0.1602 | ACC 0.9548\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: EPOCH 0009/0010 | BATCH 0428/0938 | LOSS: 0.1601 | ACC 0.9548\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0429/0938 | LOSS: 0.1603 | ACC 0.9547\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0430/0938 | LOSS: 0.1605 | ACC 0.9547\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0431/0938 | LOSS: 0.1603 | ACC 0.9548\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0432/0938 | LOSS: 0.1604 | ACC 0.9548\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0433/0938 | LOSS: 0.1603 | ACC 0.9547\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0434/0938 | LOSS: 0.1601 | ACC 0.9548\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0435/0938 | LOSS: 0.1600 | ACC 0.9548\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0436/0938 | LOSS: 0.1598 | ACC 0.9549\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0437/0938 | LOSS: 0.1603 | ACC 0.9549\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0438/0938 | LOSS: 0.1602 | ACC 0.9549\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0439/0938 | LOSS: 0.1601 | ACC 0.9549\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0440/0938 | LOSS: 0.1600 | ACC 0.9549\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0441/0938 | LOSS: 0.1601 | ACC 0.9549\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0442/0938 | LOSS: 0.1600 | ACC 0.9549\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0443/0938 | LOSS: 0.1601 | ACC 0.9548\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0444/0938 | LOSS: 0.1601 | ACC 0.9548\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0445/0938 | LOSS: 0.1599 | ACC 0.9549\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0446/0938 | LOSS: 0.1597 | ACC 0.9549\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0447/0938 | LOSS: 0.1598 | ACC 0.9549\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0448/0938 | LOSS: 0.1598 | ACC 0.9549\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0449/0938 | LOSS: 0.1598 | ACC 0.9549\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0450/0938 | LOSS: 0.1597 | ACC 0.9549\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0451/0938 | LOSS: 0.1594 | ACC 0.9550\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0452/0938 | LOSS: 0.1600 | ACC 0.9549\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0453/0938 | LOSS: 0.1603 | ACC 0.9549\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0454/0938 | LOSS: 0.1604 | ACC 0.9548\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0455/0938 | LOSS: 0.1602 | ACC 0.9549\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0456/0938 | LOSS: 0.1601 | ACC 0.9549\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0457/0938 | LOSS: 0.1601 | ACC 0.9549\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0458/0938 | LOSS: 0.1601 | ACC 0.9549\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0459/0938 | LOSS: 0.1599 | ACC 0.9549\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0460/0938 | LOSS: 0.1598 | ACC 0.9549\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0461/0938 | LOSS: 0.1599 | ACC 0.9549\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0462/0938 | LOSS: 0.1599 | ACC 0.9549\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0463/0938 | LOSS: 0.1600 | ACC 0.9548\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0464/0938 | LOSS: 0.1602 | ACC 0.9548\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0465/0938 | LOSS: 0.1603 | ACC 0.9548\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0466/0938 | LOSS: 0.1602 | ACC 0.9547\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0467/0938 | LOSS: 0.1600 | ACC 0.9547\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0468/0938 | LOSS: 0.1599 | ACC 0.9547\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0469/0938 | LOSS: 0.1599 | ACC 0.9546\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0470/0938 | LOSS: 0.1599 | ACC 0.9546\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0471/0938 | LOSS: 0.1597 | ACC 0.9546\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0472/0938 | LOSS: 0.1598 | ACC 0.9545\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0473/0938 | LOSS: 0.1597 | ACC 0.9545\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0474/0938 | LOSS: 0.1597 | ACC 0.9545\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0475/0938 | LOSS: 0.1596 | ACC 0.9545\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0476/0938 | LOSS: 0.1594 | ACC 0.9546\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0477/0938 | LOSS: 0.1595 | ACC 0.9545\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0478/0938 | LOSS: 0.1596 | ACC 0.9545\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0479/0938 | LOSS: 0.1594 | ACC 0.9546\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0480/0938 | LOSS: 0.1600 | ACC 0.9544\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0481/0938 | LOSS: 0.1600 | ACC 0.9544\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0482/0938 | LOSS: 0.1601 | ACC 0.9543\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0483/0938 | LOSS: 0.1602 | ACC 0.9543\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0484/0938 | LOSS: 0.1600 | ACC 0.9544\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0485/0938 | LOSS: 0.1599 | ACC 0.9543\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0486/0938 | LOSS: 0.1600 | ACC 0.9543\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0487/0938 | LOSS: 0.1599 | ACC 0.9543\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0488/0938 | LOSS: 0.1600 | ACC 0.9544\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0489/0938 | LOSS: 0.1602 | ACC 0.9543\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0490/0938 | LOSS: 0.1599 | ACC 0.9544\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0491/0938 | LOSS: 0.1602 | ACC 0.9543\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0492/0938 | LOSS: 0.1605 | ACC 0.9542\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0493/0938 | LOSS: 0.1604 | ACC 0.9542\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0494/0938 | LOSS: 0.1603 | ACC 0.9542\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0495/0938 | LOSS: 0.1602 | ACC 0.9543\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0496/0938 | LOSS: 0.1601 | ACC 0.9543\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0497/0938 | LOSS: 0.1602 | ACC 0.9543\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0498/0938 | LOSS: 0.1601 | ACC 0.9543\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0499/0938 | LOSS: 0.1601 | ACC 0.9543\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0500/0938 | LOSS: 0.1600 | ACC 0.9544\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0501/0938 | LOSS: 0.1602 | ACC 0.9545\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0502/0938 | LOSS: 0.1600 | ACC 0.9545\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0503/0938 | LOSS: 0.1599 | ACC 0.9545\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0504/0938 | LOSS: 0.1599 | ACC 0.9545\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0505/0938 | LOSS: 0.1598 | ACC 0.9545\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0506/0938 | LOSS: 0.1598 | ACC 0.9545\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0507/0938 | LOSS: 0.1598 | ACC 0.9545\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0508/0938 | LOSS: 0.1602 | ACC 0.9544\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0509/0938 | LOSS: 0.1600 | ACC 0.9544\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0510/0938 | LOSS: 0.1600 | ACC 0.9545\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0511/0938 | LOSS: 0.1599 | ACC 0.9545\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0512/0938 | LOSS: 0.1597 | ACC 0.9545\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0513/0938 | LOSS: 0.1599 | ACC 0.9544\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0514/0938 | LOSS: 0.1598 | ACC 0.9545\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0515/0938 | LOSS: 0.1596 | ACC 0.9545\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0516/0938 | LOSS: 0.1597 | ACC 0.9545\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0517/0938 | LOSS: 0.1601 | ACC 0.9544\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0518/0938 | LOSS: 0.1603 | ACC 0.9544\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0519/0938 | LOSS: 0.1602 | ACC 0.9544\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0520/0938 | LOSS: 0.1604 | ACC 0.9544\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0521/0938 | LOSS: 0.1602 | ACC 0.9545\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0522/0938 | LOSS: 0.1601 | ACC 0.9545\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0523/0938 | LOSS: 0.1601 | ACC 0.9545\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0524/0938 | LOSS: 0.1601 | ACC 0.9544\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0525/0938 | LOSS: 0.1601 | ACC 0.9544\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0526/0938 | LOSS: 0.1599 | ACC 0.9545\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0527/0938 | LOSS: 0.1598 | ACC 0.9545\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0528/0938 | LOSS: 0.1598 | ACC 0.9544\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0529/0938 | LOSS: 0.1598 | ACC 0.9544\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0530/0938 | LOSS: 0.1597 | ACC 0.9544\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0531/0938 | LOSS: 0.1596 | ACC 0.9544\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0532/0938 | LOSS: 0.1594 | ACC 0.9544\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0533/0938 | LOSS: 0.1592 | ACC 0.9545\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0534/0938 | LOSS: 0.1592 | ACC 0.9545\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0535/0938 | LOSS: 0.1597 | ACC 0.9544\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0536/0938 | LOSS: 0.1597 | ACC 0.9544\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0537/0938 | LOSS: 0.1596 | ACC 0.9544\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0538/0938 | LOSS: 0.1597 | ACC 0.9544\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0539/0938 | LOSS: 0.1599 | ACC 0.9544\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0540/0938 | LOSS: 0.1597 | ACC 0.9545\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0541/0938 | LOSS: 0.1596 | ACC 0.9545\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0542/0938 | LOSS: 0.1596 | ACC 0.9545\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0543/0938 | LOSS: 0.1595 | ACC 0.9545\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0544/0938 | LOSS: 0.1595 | ACC 0.9544\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0545/0938 | LOSS: 0.1595 | ACC 0.9544\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0546/0938 | LOSS: 0.1594 | ACC 0.9544\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0547/0938 | LOSS: 0.1593 | ACC 0.9545\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0548/0938 | LOSS: 0.1593 | ACC 0.9545\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0549/0938 | LOSS: 0.1593 | ACC 0.9544\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0550/0938 | LOSS: 0.1591 | ACC 0.9545\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0551/0938 | LOSS: 0.1591 | ACC 0.9545\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0552/0938 | LOSS: 0.1591 | ACC 0.9545\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0553/0938 | LOSS: 0.1592 | ACC 0.9544\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0554/0938 | LOSS: 0.1591 | ACC 0.9545\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0555/0938 | LOSS: 0.1593 | ACC 0.9544\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: EPOCH 0009/0010 | BATCH 0556/0938 | LOSS: 0.1592 | ACC 0.9544\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0557/0938 | LOSS: 0.1592 | ACC 0.9544\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0558/0938 | LOSS: 0.1593 | ACC 0.9543\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0559/0938 | LOSS: 0.1592 | ACC 0.9543\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0560/0938 | LOSS: 0.1595 | ACC 0.9543\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0561/0938 | LOSS: 0.1597 | ACC 0.9542\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0562/0938 | LOSS: 0.1597 | ACC 0.9542\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0563/0938 | LOSS: 0.1596 | ACC 0.9542\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0564/0938 | LOSS: 0.1595 | ACC 0.9543\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0565/0938 | LOSS: 0.1595 | ACC 0.9543\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0566/0938 | LOSS: 0.1594 | ACC 0.9543\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0567/0938 | LOSS: 0.1594 | ACC 0.9543\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0568/0938 | LOSS: 0.1596 | ACC 0.9542\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0569/0938 | LOSS: 0.1595 | ACC 0.9542\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0570/0938 | LOSS: 0.1594 | ACC 0.9542\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0571/0938 | LOSS: 0.1594 | ACC 0.9542\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0572/0938 | LOSS: 0.1594 | ACC 0.9542\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0573/0938 | LOSS: 0.1593 | ACC 0.9542\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0574/0938 | LOSS: 0.1597 | ACC 0.9541\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0575/0938 | LOSS: 0.1598 | ACC 0.9541\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0576/0938 | LOSS: 0.1598 | ACC 0.9542\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0577/0938 | LOSS: 0.1597 | ACC 0.9542\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0578/0938 | LOSS: 0.1599 | ACC 0.9542\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0579/0938 | LOSS: 0.1598 | ACC 0.9542\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0580/0938 | LOSS: 0.1597 | ACC 0.9542\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0581/0938 | LOSS: 0.1597 | ACC 0.9542\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0582/0938 | LOSS: 0.1597 | ACC 0.9542\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0583/0938 | LOSS: 0.1600 | ACC 0.9541\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0584/0938 | LOSS: 0.1600 | ACC 0.9541\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0585/0938 | LOSS: 0.1600 | ACC 0.9541\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0586/0938 | LOSS: 0.1599 | ACC 0.9542\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0587/0938 | LOSS: 0.1598 | ACC 0.9542\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0588/0938 | LOSS: 0.1598 | ACC 0.9542\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0589/0938 | LOSS: 0.1597 | ACC 0.9543\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0590/0938 | LOSS: 0.1598 | ACC 0.9543\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0591/0938 | LOSS: 0.1596 | ACC 0.9543\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0592/0938 | LOSS: 0.1595 | ACC 0.9544\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0593/0938 | LOSS: 0.1594 | ACC 0.9544\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0594/0938 | LOSS: 0.1594 | ACC 0.9544\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0595/0938 | LOSS: 0.1596 | ACC 0.9543\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0596/0938 | LOSS: 0.1597 | ACC 0.9543\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0597/0938 | LOSS: 0.1597 | ACC 0.9543\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0598/0938 | LOSS: 0.1596 | ACC 0.9544\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0599/0938 | LOSS: 0.1598 | ACC 0.9543\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0600/0938 | LOSS: 0.1597 | ACC 0.9543\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0601/0938 | LOSS: 0.1596 | ACC 0.9543\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0602/0938 | LOSS: 0.1596 | ACC 0.9543\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0603/0938 | LOSS: 0.1596 | ACC 0.9543\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0604/0938 | LOSS: 0.1596 | ACC 0.9544\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0605/0938 | LOSS: 0.1596 | ACC 0.9543\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0606/0938 | LOSS: 0.1597 | ACC 0.9543\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0607/0938 | LOSS: 0.1596 | ACC 0.9544\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0608/0938 | LOSS: 0.1595 | ACC 0.9543\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0609/0938 | LOSS: 0.1593 | ACC 0.9544\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0610/0938 | LOSS: 0.1592 | ACC 0.9545\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0611/0938 | LOSS: 0.1590 | ACC 0.9545\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0612/0938 | LOSS: 0.1590 | ACC 0.9545\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0613/0938 | LOSS: 0.1589 | ACC 0.9545\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0614/0938 | LOSS: 0.1587 | ACC 0.9546\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0615/0938 | LOSS: 0.1589 | ACC 0.9546\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0616/0938 | LOSS: 0.1588 | ACC 0.9546\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0617/0938 | LOSS: 0.1586 | ACC 0.9547\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0618/0938 | LOSS: 0.1585 | ACC 0.9547\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0619/0938 | LOSS: 0.1585 | ACC 0.9547\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0620/0938 | LOSS: 0.1587 | ACC 0.9546\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0621/0938 | LOSS: 0.1589 | ACC 0.9545\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0622/0938 | LOSS: 0.1592 | ACC 0.9545\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0623/0938 | LOSS: 0.1597 | ACC 0.9545\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0624/0938 | LOSS: 0.1596 | ACC 0.9545\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0625/0938 | LOSS: 0.1597 | ACC 0.9545\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0626/0938 | LOSS: 0.1598 | ACC 0.9544\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0627/0938 | LOSS: 0.1598 | ACC 0.9544\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0628/0938 | LOSS: 0.1601 | ACC 0.9544\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0629/0938 | LOSS: 0.1599 | ACC 0.9544\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0630/0938 | LOSS: 0.1598 | ACC 0.9544\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0631/0938 | LOSS: 0.1598 | ACC 0.9544\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0632/0938 | LOSS: 0.1598 | ACC 0.9544\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0633/0938 | LOSS: 0.1599 | ACC 0.9544\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0634/0938 | LOSS: 0.1600 | ACC 0.9543\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0635/0938 | LOSS: 0.1601 | ACC 0.9543\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0636/0938 | LOSS: 0.1601 | ACC 0.9544\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0637/0938 | LOSS: 0.1600 | ACC 0.9544\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0638/0938 | LOSS: 0.1602 | ACC 0.9543\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0639/0938 | LOSS: 0.1603 | ACC 0.9543\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0640/0938 | LOSS: 0.1602 | ACC 0.9544\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0641/0938 | LOSS: 0.1601 | ACC 0.9544\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0642/0938 | LOSS: 0.1602 | ACC 0.9544\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0643/0938 | LOSS: 0.1605 | ACC 0.9543\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0644/0938 | LOSS: 0.1606 | ACC 0.9543\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0645/0938 | LOSS: 0.1607 | ACC 0.9543\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0646/0938 | LOSS: 0.1607 | ACC 0.9543\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0647/0938 | LOSS: 0.1606 | ACC 0.9543\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0648/0938 | LOSS: 0.1606 | ACC 0.9543\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0649/0938 | LOSS: 0.1606 | ACC 0.9543\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0650/0938 | LOSS: 0.1607 | ACC 0.9543\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0651/0938 | LOSS: 0.1607 | ACC 0.9543\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0652/0938 | LOSS: 0.1607 | ACC 0.9543\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0653/0938 | LOSS: 0.1606 | ACC 0.9542\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0654/0938 | LOSS: 0.1607 | ACC 0.9542\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0655/0938 | LOSS: 0.1606 | ACC 0.9542\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0656/0938 | LOSS: 0.1605 | ACC 0.9542\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0657/0938 | LOSS: 0.1604 | ACC 0.9543\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0658/0938 | LOSS: 0.1606 | ACC 0.9542\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0659/0938 | LOSS: 0.1606 | ACC 0.9542\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0660/0938 | LOSS: 0.1606 | ACC 0.9541\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0661/0938 | LOSS: 0.1607 | ACC 0.9542\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0662/0938 | LOSS: 0.1605 | ACC 0.9542\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0663/0938 | LOSS: 0.1604 | ACC 0.9543\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0664/0938 | LOSS: 0.1603 | ACC 0.9543\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0665/0938 | LOSS: 0.1606 | ACC 0.9543\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0666/0938 | LOSS: 0.1606 | ACC 0.9543\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0667/0938 | LOSS: 0.1606 | ACC 0.9542\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0668/0938 | LOSS: 0.1606 | ACC 0.9542\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0669/0938 | LOSS: 0.1605 | ACC 0.9542\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0670/0938 | LOSS: 0.1605 | ACC 0.9542\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0671/0938 | LOSS: 0.1605 | ACC 0.9542\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0672/0938 | LOSS: 0.1607 | ACC 0.9541\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0673/0938 | LOSS: 0.1607 | ACC 0.9542\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0674/0938 | LOSS: 0.1608 | ACC 0.9542\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0675/0938 | LOSS: 0.1606 | ACC 0.9542\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0676/0938 | LOSS: 0.1605 | ACC 0.9542\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0677/0938 | LOSS: 0.1604 | ACC 0.9542\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0678/0938 | LOSS: 0.1605 | ACC 0.9542\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0679/0938 | LOSS: 0.1603 | ACC 0.9543\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0680/0938 | LOSS: 0.1603 | ACC 0.9543\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0681/0938 | LOSS: 0.1604 | ACC 0.9543\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0682/0938 | LOSS: 0.1603 | ACC 0.9543\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0683/0938 | LOSS: 0.1604 | ACC 0.9543\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0684/0938 | LOSS: 0.1602 | ACC 0.9544\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: EPOCH 0009/0010 | BATCH 0685/0938 | LOSS: 0.1601 | ACC 0.9543\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0686/0938 | LOSS: 0.1601 | ACC 0.9543\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0687/0938 | LOSS: 0.1602 | ACC 0.9543\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0688/0938 | LOSS: 0.1601 | ACC 0.9543\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0689/0938 | LOSS: 0.1602 | ACC 0.9543\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0690/0938 | LOSS: 0.1602 | ACC 0.9543\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0691/0938 | LOSS: 0.1601 | ACC 0.9543\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0692/0938 | LOSS: 0.1600 | ACC 0.9543\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0693/0938 | LOSS: 0.1600 | ACC 0.9543\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0694/0938 | LOSS: 0.1600 | ACC 0.9543\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0695/0938 | LOSS: 0.1599 | ACC 0.9543\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0696/0938 | LOSS: 0.1598 | ACC 0.9544\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0697/0938 | LOSS: 0.1599 | ACC 0.9544\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0698/0938 | LOSS: 0.1599 | ACC 0.9543\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0699/0938 | LOSS: 0.1600 | ACC 0.9543\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0700/0938 | LOSS: 0.1600 | ACC 0.9543\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0701/0938 | LOSS: 0.1601 | ACC 0.9543\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0702/0938 | LOSS: 0.1600 | ACC 0.9543\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0703/0938 | LOSS: 0.1602 | ACC 0.9543\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0704/0938 | LOSS: 0.1601 | ACC 0.9543\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0705/0938 | LOSS: 0.1599 | ACC 0.9543\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0706/0938 | LOSS: 0.1600 | ACC 0.9543\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0707/0938 | LOSS: 0.1599 | ACC 0.9543\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0708/0938 | LOSS: 0.1601 | ACC 0.9543\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0709/0938 | LOSS: 0.1599 | ACC 0.9544\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0710/0938 | LOSS: 0.1598 | ACC 0.9544\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0711/0938 | LOSS: 0.1598 | ACC 0.9544\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0712/0938 | LOSS: 0.1596 | ACC 0.9544\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0713/0938 | LOSS: 0.1596 | ACC 0.9544\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0714/0938 | LOSS: 0.1595 | ACC 0.9545\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0715/0938 | LOSS: 0.1597 | ACC 0.9544\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0716/0938 | LOSS: 0.1595 | ACC 0.9544\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0717/0938 | LOSS: 0.1594 | ACC 0.9544\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0718/0938 | LOSS: 0.1594 | ACC 0.9544\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0719/0938 | LOSS: 0.1595 | ACC 0.9544\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0720/0938 | LOSS: 0.1596 | ACC 0.9544\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0721/0938 | LOSS: 0.1598 | ACC 0.9543\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0722/0938 | LOSS: 0.1599 | ACC 0.9543\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0723/0938 | LOSS: 0.1604 | ACC 0.9543\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0724/0938 | LOSS: 0.1605 | ACC 0.9542\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0725/0938 | LOSS: 0.1606 | ACC 0.9542\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0726/0938 | LOSS: 0.1610 | ACC 0.9541\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0727/0938 | LOSS: 0.1609 | ACC 0.9541\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0728/0938 | LOSS: 0.1608 | ACC 0.9541\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0729/0938 | LOSS: 0.1607 | ACC 0.9542\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0730/0938 | LOSS: 0.1607 | ACC 0.9542\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0731/0938 | LOSS: 0.1607 | ACC 0.9542\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0732/0938 | LOSS: 0.1609 | ACC 0.9542\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0733/0938 | LOSS: 0.1609 | ACC 0.9542\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0734/0938 | LOSS: 0.1611 | ACC 0.9541\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0735/0938 | LOSS: 0.1612 | ACC 0.9541\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0736/0938 | LOSS: 0.1611 | ACC 0.9541\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0737/0938 | LOSS: 0.1610 | ACC 0.9541\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0738/0938 | LOSS: 0.1611 | ACC 0.9541\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0739/0938 | LOSS: 0.1610 | ACC 0.9541\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0740/0938 | LOSS: 0.1611 | ACC 0.9540\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0741/0938 | LOSS: 0.1610 | ACC 0.9541\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0742/0938 | LOSS: 0.1611 | ACC 0.9541\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0743/0938 | LOSS: 0.1611 | ACC 0.9540\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0744/0938 | LOSS: 0.1610 | ACC 0.9540\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0745/0938 | LOSS: 0.1610 | ACC 0.9540\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0746/0938 | LOSS: 0.1609 | ACC 0.9540\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0747/0938 | LOSS: 0.1610 | ACC 0.9540\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0748/0938 | LOSS: 0.1608 | ACC 0.9541\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0749/0938 | LOSS: 0.1607 | ACC 0.9541\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0750/0938 | LOSS: 0.1607 | ACC 0.9540\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0751/0938 | LOSS: 0.1606 | ACC 0.9540\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0752/0938 | LOSS: 0.1607 | ACC 0.9540\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0753/0938 | LOSS: 0.1608 | ACC 0.9540\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0754/0938 | LOSS: 0.1610 | ACC 0.9539\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0755/0938 | LOSS: 0.1609 | ACC 0.9539\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0756/0938 | LOSS: 0.1607 | ACC 0.9540\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0757/0938 | LOSS: 0.1607 | ACC 0.9540\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0758/0938 | LOSS: 0.1606 | ACC 0.9540\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0759/0938 | LOSS: 0.1608 | ACC 0.9539\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0760/0938 | LOSS: 0.1608 | ACC 0.9539\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0761/0938 | LOSS: 0.1608 | ACC 0.9540\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0762/0938 | LOSS: 0.1607 | ACC 0.9540\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0763/0938 | LOSS: 0.1610 | ACC 0.9539\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0764/0938 | LOSS: 0.1609 | ACC 0.9539\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0765/0938 | LOSS: 0.1609 | ACC 0.9539\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0766/0938 | LOSS: 0.1609 | ACC 0.9539\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0767/0938 | LOSS: 0.1610 | ACC 0.9539\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0768/0938 | LOSS: 0.1610 | ACC 0.9539\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0769/0938 | LOSS: 0.1610 | ACC 0.9539\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0770/0938 | LOSS: 0.1611 | ACC 0.9539\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0771/0938 | LOSS: 0.1611 | ACC 0.9538\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0772/0938 | LOSS: 0.1611 | ACC 0.9538\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0773/0938 | LOSS: 0.1611 | ACC 0.9538\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0774/0938 | LOSS: 0.1609 | ACC 0.9539\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0775/0938 | LOSS: 0.1609 | ACC 0.9539\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0776/0938 | LOSS: 0.1607 | ACC 0.9540\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0777/0938 | LOSS: 0.1609 | ACC 0.9539\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0778/0938 | LOSS: 0.1611 | ACC 0.9539\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0779/0938 | LOSS: 0.1610 | ACC 0.9539\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0780/0938 | LOSS: 0.1610 | ACC 0.9539\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0781/0938 | LOSS: 0.1611 | ACC 0.9538\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0782/0938 | LOSS: 0.1611 | ACC 0.9539\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0783/0938 | LOSS: 0.1612 | ACC 0.9539\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0784/0938 | LOSS: 0.1612 | ACC 0.9539\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0785/0938 | LOSS: 0.1611 | ACC 0.9539\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0786/0938 | LOSS: 0.1612 | ACC 0.9538\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0787/0938 | LOSS: 0.1612 | ACC 0.9538\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0788/0938 | LOSS: 0.1612 | ACC 0.9537\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0789/0938 | LOSS: 0.1611 | ACC 0.9538\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0790/0938 | LOSS: 0.1610 | ACC 0.9538\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0791/0938 | LOSS: 0.1610 | ACC 0.9538\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0792/0938 | LOSS: 0.1610 | ACC 0.9538\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0793/0938 | LOSS: 0.1611 | ACC 0.9538\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0794/0938 | LOSS: 0.1611 | ACC 0.9538\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0795/0938 | LOSS: 0.1612 | ACC 0.9538\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0796/0938 | LOSS: 0.1610 | ACC 0.9539\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0797/0938 | LOSS: 0.1612 | ACC 0.9538\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0798/0938 | LOSS: 0.1612 | ACC 0.9538\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0799/0938 | LOSS: 0.1611 | ACC 0.9538\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0800/0938 | LOSS: 0.1612 | ACC 0.9539\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0801/0938 | LOSS: 0.1611 | ACC 0.9539\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0802/0938 | LOSS: 0.1612 | ACC 0.9539\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0803/0938 | LOSS: 0.1611 | ACC 0.9539\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0804/0938 | LOSS: 0.1611 | ACC 0.9539\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0805/0938 | LOSS: 0.1612 | ACC 0.9539\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0806/0938 | LOSS: 0.1612 | ACC 0.9539\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0807/0938 | LOSS: 0.1612 | ACC 0.9539\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0808/0938 | LOSS: 0.1611 | ACC 0.9539\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0809/0938 | LOSS: 0.1611 | ACC 0.9539\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0810/0938 | LOSS: 0.1612 | ACC 0.9539\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0811/0938 | LOSS: 0.1611 | ACC 0.9539\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: EPOCH 0009/0010 | BATCH 0812/0938 | LOSS: 0.1611 | ACC 0.9538\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0813/0938 | LOSS: 0.1610 | ACC 0.9539\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0814/0938 | LOSS: 0.1609 | ACC 0.9539\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0815/0938 | LOSS: 0.1608 | ACC 0.9539\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0816/0938 | LOSS: 0.1607 | ACC 0.9540\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0817/0938 | LOSS: 0.1606 | ACC 0.9540\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0818/0938 | LOSS: 0.1606 | ACC 0.9540\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0819/0938 | LOSS: 0.1607 | ACC 0.9540\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0820/0938 | LOSS: 0.1606 | ACC 0.9540\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0821/0938 | LOSS: 0.1605 | ACC 0.9541\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0822/0938 | LOSS: 0.1605 | ACC 0.9541\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0823/0938 | LOSS: 0.1604 | ACC 0.9541\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0824/0938 | LOSS: 0.1604 | ACC 0.9541\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0825/0938 | LOSS: 0.1606 | ACC 0.9540\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0826/0938 | LOSS: 0.1605 | ACC 0.9541\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0827/0938 | LOSS: 0.1605 | ACC 0.9541\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0828/0938 | LOSS: 0.1606 | ACC 0.9540\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0829/0938 | LOSS: 0.1606 | ACC 0.9540\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0830/0938 | LOSS: 0.1605 | ACC 0.9540\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0831/0938 | LOSS: 0.1605 | ACC 0.9540\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0832/0938 | LOSS: 0.1604 | ACC 0.9540\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0833/0938 | LOSS: 0.1605 | ACC 0.9540\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0834/0938 | LOSS: 0.1605 | ACC 0.9540\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0835/0938 | LOSS: 0.1604 | ACC 0.9540\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0836/0938 | LOSS: 0.1603 | ACC 0.9541\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0837/0938 | LOSS: 0.1602 | ACC 0.9541\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0838/0938 | LOSS: 0.1601 | ACC 0.9541\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0839/0938 | LOSS: 0.1600 | ACC 0.9541\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0840/0938 | LOSS: 0.1599 | ACC 0.9541\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0841/0938 | LOSS: 0.1598 | ACC 0.9542\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0842/0938 | LOSS: 0.1597 | ACC 0.9542\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0843/0938 | LOSS: 0.1597 | ACC 0.9542\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0844/0938 | LOSS: 0.1598 | ACC 0.9541\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0845/0938 | LOSS: 0.1599 | ACC 0.9541\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0846/0938 | LOSS: 0.1601 | ACC 0.9541\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0847/0938 | LOSS: 0.1601 | ACC 0.9541\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0848/0938 | LOSS: 0.1602 | ACC 0.9540\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0849/0938 | LOSS: 0.1602 | ACC 0.9540\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0850/0938 | LOSS: 0.1601 | ACC 0.9541\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0851/0938 | LOSS: 0.1601 | ACC 0.9541\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0852/0938 | LOSS: 0.1601 | ACC 0.9541\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0853/0938 | LOSS: 0.1601 | ACC 0.9541\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0854/0938 | LOSS: 0.1600 | ACC 0.9541\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0855/0938 | LOSS: 0.1599 | ACC 0.9541\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0856/0938 | LOSS: 0.1600 | ACC 0.9540\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0857/0938 | LOSS: 0.1600 | ACC 0.9540\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0858/0938 | LOSS: 0.1599 | ACC 0.9540\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0859/0938 | LOSS: 0.1598 | ACC 0.9540\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0860/0938 | LOSS: 0.1599 | ACC 0.9540\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0861/0938 | LOSS: 0.1597 | ACC 0.9541\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0862/0938 | LOSS: 0.1597 | ACC 0.9541\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0863/0938 | LOSS: 0.1598 | ACC 0.9541\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0864/0938 | LOSS: 0.1596 | ACC 0.9541\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0865/0938 | LOSS: 0.1598 | ACC 0.9541\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0866/0938 | LOSS: 0.1597 | ACC 0.9541\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0867/0938 | LOSS: 0.1597 | ACC 0.9541\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0868/0938 | LOSS: 0.1597 | ACC 0.9541\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0869/0938 | LOSS: 0.1596 | ACC 0.9541\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0870/0938 | LOSS: 0.1598 | ACC 0.9541\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0871/0938 | LOSS: 0.1598 | ACC 0.9541\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0872/0938 | LOSS: 0.1600 | ACC 0.9541\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0873/0938 | LOSS: 0.1604 | ACC 0.9540\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0874/0938 | LOSS: 0.1603 | ACC 0.9540\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0875/0938 | LOSS: 0.1602 | ACC 0.9540\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0876/0938 | LOSS: 0.1601 | ACC 0.9541\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0877/0938 | LOSS: 0.1599 | ACC 0.9541\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0878/0938 | LOSS: 0.1602 | ACC 0.9541\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0879/0938 | LOSS: 0.1602 | ACC 0.9541\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0880/0938 | LOSS: 0.1601 | ACC 0.9542\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0881/0938 | LOSS: 0.1601 | ACC 0.9541\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0882/0938 | LOSS: 0.1600 | ACC 0.9542\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0883/0938 | LOSS: 0.1599 | ACC 0.9542\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0884/0938 | LOSS: 0.1599 | ACC 0.9542\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0885/0938 | LOSS: 0.1600 | ACC 0.9541\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0886/0938 | LOSS: 0.1599 | ACC 0.9541\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0887/0938 | LOSS: 0.1601 | ACC 0.9541\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0888/0938 | LOSS: 0.1600 | ACC 0.9541\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0889/0938 | LOSS: 0.1600 | ACC 0.9541\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0890/0938 | LOSS: 0.1599 | ACC 0.9542\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0891/0938 | LOSS: 0.1598 | ACC 0.9542\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0892/0938 | LOSS: 0.1602 | ACC 0.9541\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0893/0938 | LOSS: 0.1601 | ACC 0.9541\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0894/0938 | LOSS: 0.1602 | ACC 0.9541\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0895/0938 | LOSS: 0.1601 | ACC 0.9541\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0896/0938 | LOSS: 0.1601 | ACC 0.9542\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0897/0938 | LOSS: 0.1600 | ACC 0.9541\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0898/0938 | LOSS: 0.1600 | ACC 0.9541\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0899/0938 | LOSS: 0.1599 | ACC 0.9542\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0900/0938 | LOSS: 0.1601 | ACC 0.9541\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0901/0938 | LOSS: 0.1600 | ACC 0.9541\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0902/0938 | LOSS: 0.1599 | ACC 0.9541\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0903/0938 | LOSS: 0.1598 | ACC 0.9541\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0904/0938 | LOSS: 0.1598 | ACC 0.9541\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0905/0938 | LOSS: 0.1598 | ACC 0.9541\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0906/0938 | LOSS: 0.1597 | ACC 0.9541\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0907/0938 | LOSS: 0.1596 | ACC 0.9541\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0908/0938 | LOSS: 0.1596 | ACC 0.9541\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0909/0938 | LOSS: 0.1596 | ACC 0.9541\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0910/0938 | LOSS: 0.1598 | ACC 0.9541\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0911/0938 | LOSS: 0.1598 | ACC 0.9541\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0912/0938 | LOSS: 0.1598 | ACC 0.9541\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0913/0938 | LOSS: 0.1597 | ACC 0.9541\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0914/0938 | LOSS: 0.1596 | ACC 0.9541\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0915/0938 | LOSS: 0.1597 | ACC 0.9541\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0916/0938 | LOSS: 0.1597 | ACC 0.9541\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0917/0938 | LOSS: 0.1597 | ACC 0.9541\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0918/0938 | LOSS: 0.1597 | ACC 0.9541\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0919/0938 | LOSS: 0.1596 | ACC 0.9541\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0920/0938 | LOSS: 0.1598 | ACC 0.9541\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0921/0938 | LOSS: 0.1598 | ACC 0.9541\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0922/0938 | LOSS: 0.1598 | ACC 0.9541\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0923/0938 | LOSS: 0.1598 | ACC 0.9541\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0924/0938 | LOSS: 0.1599 | ACC 0.9541\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0925/0938 | LOSS: 0.1598 | ACC 0.9541\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0926/0938 | LOSS: 0.1598 | ACC 0.9541\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0927/0938 | LOSS: 0.1597 | ACC 0.9541\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0928/0938 | LOSS: 0.1599 | ACC 0.9540\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0929/0938 | LOSS: 0.1599 | ACC 0.9540\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0930/0938 | LOSS: 0.1601 | ACC 0.9539\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0931/0938 | LOSS: 0.1600 | ACC 0.9540\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0932/0938 | LOSS: 0.1600 | ACC 0.9540\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0933/0938 | LOSS: 0.1598 | ACC 0.9540\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0934/0938 | LOSS: 0.1598 | ACC 0.9540\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0935/0938 | LOSS: 0.1598 | ACC 0.9540\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0936/0938 | LOSS: 0.1597 | ACC 0.9540\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0937/0938 | LOSS: 0.1596 | ACC 0.9540\n",
      "TRAIN: EPOCH 0009/0010 | BATCH 0938/0938 | LOSS: 0.1596 | ACC 0.9540\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: EPOCH 0010/0010 | BATCH 0001/0938 | LOSS: 0.1106 | ACC 0.9688\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0002/0938 | LOSS: 0.1065 | ACC 0.9688\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0003/0938 | LOSS: 0.1358 | ACC 0.9583\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0004/0938 | LOSS: 0.1147 | ACC 0.9648\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0005/0938 | LOSS: 0.1232 | ACC 0.9625\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0006/0938 | LOSS: 0.1322 | ACC 0.9583\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0007/0938 | LOSS: 0.1281 | ACC 0.9576\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0008/0938 | LOSS: 0.1242 | ACC 0.9590\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0009/0938 | LOSS: 0.1218 | ACC 0.9618\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0010/0938 | LOSS: 0.1292 | ACC 0.9578\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0011/0938 | LOSS: 0.1269 | ACC 0.9574\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0012/0938 | LOSS: 0.1220 | ACC 0.9583\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0013/0938 | LOSS: 0.1229 | ACC 0.9567\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0014/0938 | LOSS: 0.1302 | ACC 0.9531\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0015/0938 | LOSS: 0.1345 | ACC 0.9521\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0016/0938 | LOSS: 0.1338 | ACC 0.9531\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0017/0938 | LOSS: 0.1274 | ACC 0.9559\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0018/0938 | LOSS: 0.1281 | ACC 0.9575\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0019/0938 | LOSS: 0.1337 | ACC 0.9572\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0020/0938 | LOSS: 0.1366 | ACC 0.9563\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0021/0938 | LOSS: 0.1367 | ACC 0.9568\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0022/0938 | LOSS: 0.1352 | ACC 0.9567\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0023/0938 | LOSS: 0.1338 | ACC 0.9572\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0024/0938 | LOSS: 0.1343 | ACC 0.9577\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0025/0938 | LOSS: 0.1401 | ACC 0.9556\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0026/0938 | LOSS: 0.1476 | ACC 0.9531\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0027/0938 | LOSS: 0.1466 | ACC 0.9525\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0028/0938 | LOSS: 0.1436 | ACC 0.9537\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0029/0938 | LOSS: 0.1432 | ACC 0.9531\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0030/0938 | LOSS: 0.1423 | ACC 0.9531\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0031/0938 | LOSS: 0.1412 | ACC 0.9536\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0032/0938 | LOSS: 0.1386 | ACC 0.9551\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0033/0938 | LOSS: 0.1440 | ACC 0.9541\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0034/0938 | LOSS: 0.1450 | ACC 0.9540\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0035/0938 | LOSS: 0.1436 | ACC 0.9545\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0036/0938 | LOSS: 0.1447 | ACC 0.9540\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0037/0938 | LOSS: 0.1441 | ACC 0.9540\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0038/0938 | LOSS: 0.1470 | ACC 0.9527\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0039/0938 | LOSS: 0.1469 | ACC 0.9531\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0040/0938 | LOSS: 0.1477 | ACC 0.9531\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0041/0938 | LOSS: 0.1512 | ACC 0.9512\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0042/0938 | LOSS: 0.1499 | ACC 0.9513\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0043/0938 | LOSS: 0.1486 | ACC 0.9517\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0044/0938 | LOSS: 0.1471 | ACC 0.9524\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0045/0938 | LOSS: 0.1478 | ACC 0.9521\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0046/0938 | LOSS: 0.1493 | ACC 0.9514\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0047/0938 | LOSS: 0.1505 | ACC 0.9511\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0048/0938 | LOSS: 0.1499 | ACC 0.9515\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0049/0938 | LOSS: 0.1475 | ACC 0.9522\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0050/0938 | LOSS: 0.1478 | ACC 0.9522\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0051/0938 | LOSS: 0.1455 | ACC 0.9531\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0052/0938 | LOSS: 0.1440 | ACC 0.9537\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0053/0938 | LOSS: 0.1434 | ACC 0.9537\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0054/0938 | LOSS: 0.1446 | ACC 0.9537\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0055/0938 | LOSS: 0.1463 | ACC 0.9534\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0056/0938 | LOSS: 0.1466 | ACC 0.9534\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0057/0938 | LOSS: 0.1459 | ACC 0.9531\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0058/0938 | LOSS: 0.1449 | ACC 0.9534\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0059/0938 | LOSS: 0.1438 | ACC 0.9537\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0060/0938 | LOSS: 0.1425 | ACC 0.9542\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0061/0938 | LOSS: 0.1441 | ACC 0.9539\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0062/0938 | LOSS: 0.1435 | ACC 0.9539\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0063/0938 | LOSS: 0.1420 | ACC 0.9546\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0064/0938 | LOSS: 0.1440 | ACC 0.9543\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0065/0938 | LOSS: 0.1424 | ACC 0.9550\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0066/0938 | LOSS: 0.1428 | ACC 0.9553\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0067/0938 | LOSS: 0.1414 | ACC 0.9559\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0068/0938 | LOSS: 0.1426 | ACC 0.9557\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0069/0938 | LOSS: 0.1434 | ACC 0.9554\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0070/0938 | LOSS: 0.1436 | ACC 0.9549\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0071/0938 | LOSS: 0.1440 | ACC 0.9544\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0072/0938 | LOSS: 0.1437 | ACC 0.9542\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0073/0938 | LOSS: 0.1422 | ACC 0.9546\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0074/0938 | LOSS: 0.1445 | ACC 0.9544\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0075/0938 | LOSS: 0.1438 | ACC 0.9546\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0076/0938 | LOSS: 0.1442 | ACC 0.9546\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0077/0938 | LOSS: 0.1440 | ACC 0.9545\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0078/0938 | LOSS: 0.1479 | ACC 0.9535\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0079/0938 | LOSS: 0.1473 | ACC 0.9535\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0080/0938 | LOSS: 0.1502 | ACC 0.9535\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0081/0938 | LOSS: 0.1509 | ACC 0.9533\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0082/0938 | LOSS: 0.1514 | ACC 0.9537\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0083/0938 | LOSS: 0.1513 | ACC 0.9535\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0084/0938 | LOSS: 0.1506 | ACC 0.9533\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0085/0938 | LOSS: 0.1508 | ACC 0.9531\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0086/0938 | LOSS: 0.1510 | ACC 0.9526\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0087/0938 | LOSS: 0.1501 | ACC 0.9528\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0088/0938 | LOSS: 0.1502 | ACC 0.9528\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0089/0938 | LOSS: 0.1513 | ACC 0.9522\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0090/0938 | LOSS: 0.1519 | ACC 0.9523\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0091/0938 | LOSS: 0.1513 | ACC 0.9524\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0092/0938 | LOSS: 0.1507 | ACC 0.9524\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0093/0938 | LOSS: 0.1510 | ACC 0.9526\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0094/0938 | LOSS: 0.1502 | ACC 0.9528\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0095/0938 | LOSS: 0.1499 | ACC 0.9531\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0096/0938 | LOSS: 0.1500 | ACC 0.9531\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0097/0938 | LOSS: 0.1499 | ACC 0.9534\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0098/0938 | LOSS: 0.1497 | ACC 0.9533\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0099/0938 | LOSS: 0.1494 | ACC 0.9534\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0100/0938 | LOSS: 0.1502 | ACC 0.9534\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0101/0938 | LOSS: 0.1498 | ACC 0.9534\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0102/0938 | LOSS: 0.1502 | ACC 0.9537\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0103/0938 | LOSS: 0.1500 | ACC 0.9536\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0104/0938 | LOSS: 0.1491 | ACC 0.9539\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0105/0938 | LOSS: 0.1498 | ACC 0.9537\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0106/0938 | LOSS: 0.1490 | ACC 0.9542\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0107/0938 | LOSS: 0.1496 | ACC 0.9537\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0108/0938 | LOSS: 0.1497 | ACC 0.9537\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0109/0938 | LOSS: 0.1505 | ACC 0.9537\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0110/0938 | LOSS: 0.1515 | ACC 0.9536\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0111/0938 | LOSS: 0.1509 | ACC 0.9537\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0112/0938 | LOSS: 0.1519 | ACC 0.9534\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0113/0938 | LOSS: 0.1514 | ACC 0.9535\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0114/0938 | LOSS: 0.1526 | ACC 0.9534\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0115/0938 | LOSS: 0.1540 | ACC 0.9530\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0116/0938 | LOSS: 0.1540 | ACC 0.9530\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0117/0938 | LOSS: 0.1543 | ACC 0.9527\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0118/0938 | LOSS: 0.1547 | ACC 0.9526\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0119/0938 | LOSS: 0.1549 | ACC 0.9523\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0120/0938 | LOSS: 0.1539 | ACC 0.9526\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0121/0938 | LOSS: 0.1540 | ACC 0.9525\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0122/0938 | LOSS: 0.1535 | ACC 0.9526\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0123/0938 | LOSS: 0.1526 | ACC 0.9529\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0124/0938 | LOSS: 0.1518 | ACC 0.9531\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0125/0938 | LOSS: 0.1520 | ACC 0.9527\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0126/0938 | LOSS: 0.1513 | ACC 0.9530\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0127/0938 | LOSS: 0.1509 | ACC 0.9532\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: EPOCH 0010/0010 | BATCH 0128/0938 | LOSS: 0.1509 | ACC 0.9532\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0129/0938 | LOSS: 0.1504 | ACC 0.9534\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0130/0938 | LOSS: 0.1504 | ACC 0.9534\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0131/0938 | LOSS: 0.1500 | ACC 0.9535\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0132/0938 | LOSS: 0.1500 | ACC 0.9536\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0133/0938 | LOSS: 0.1500 | ACC 0.9536\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0134/0938 | LOSS: 0.1491 | ACC 0.9539\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0135/0938 | LOSS: 0.1492 | ACC 0.9539\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0136/0938 | LOSS: 0.1495 | ACC 0.9539\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0137/0938 | LOSS: 0.1498 | ACC 0.9539\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0138/0938 | LOSS: 0.1493 | ACC 0.9540\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0139/0938 | LOSS: 0.1493 | ACC 0.9541\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0140/0938 | LOSS: 0.1494 | ACC 0.9540\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0141/0938 | LOSS: 0.1485 | ACC 0.9543\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0142/0938 | LOSS: 0.1479 | ACC 0.9546\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0143/0938 | LOSS: 0.1482 | ACC 0.9545\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0144/0938 | LOSS: 0.1482 | ACC 0.9545\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0145/0938 | LOSS: 0.1480 | ACC 0.9545\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0146/0938 | LOSS: 0.1475 | ACC 0.9546\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0147/0938 | LOSS: 0.1477 | ACC 0.9547\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0148/0938 | LOSS: 0.1470 | ACC 0.9549\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0149/0938 | LOSS: 0.1465 | ACC 0.9551\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0150/0938 | LOSS: 0.1459 | ACC 0.9553\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0151/0938 | LOSS: 0.1453 | ACC 0.9556\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0152/0938 | LOSS: 0.1462 | ACC 0.9556\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0153/0938 | LOSS: 0.1458 | ACC 0.9557\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0154/0938 | LOSS: 0.1460 | ACC 0.9556\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0155/0938 | LOSS: 0.1453 | ACC 0.9557\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0156/0938 | LOSS: 0.1446 | ACC 0.9559\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0157/0938 | LOSS: 0.1452 | ACC 0.9557\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0158/0938 | LOSS: 0.1459 | ACC 0.9554\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0159/0938 | LOSS: 0.1456 | ACC 0.9555\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0160/0938 | LOSS: 0.1455 | ACC 0.9557\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0161/0938 | LOSS: 0.1450 | ACC 0.9558\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0162/0938 | LOSS: 0.1446 | ACC 0.9559\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0163/0938 | LOSS: 0.1442 | ACC 0.9561\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0164/0938 | LOSS: 0.1441 | ACC 0.9561\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0165/0938 | LOSS: 0.1436 | ACC 0.9563\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0166/0938 | LOSS: 0.1440 | ACC 0.9561\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0167/0938 | LOSS: 0.1439 | ACC 0.9562\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0168/0938 | LOSS: 0.1441 | ACC 0.9560\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0169/0938 | LOSS: 0.1442 | ACC 0.9559\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0170/0938 | LOSS: 0.1442 | ACC 0.9559\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0171/0938 | LOSS: 0.1444 | ACC 0.9560\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0172/0938 | LOSS: 0.1442 | ACC 0.9559\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0173/0938 | LOSS: 0.1445 | ACC 0.9559\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0174/0938 | LOSS: 0.1441 | ACC 0.9561\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0175/0938 | LOSS: 0.1440 | ACC 0.9561\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0176/0938 | LOSS: 0.1443 | ACC 0.9561\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0177/0938 | LOSS: 0.1445 | ACC 0.9560\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0178/0938 | LOSS: 0.1444 | ACC 0.9560\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0179/0938 | LOSS: 0.1439 | ACC 0.9562\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0180/0938 | LOSS: 0.1435 | ACC 0.9563\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0181/0938 | LOSS: 0.1433 | ACC 0.9563\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0182/0938 | LOSS: 0.1430 | ACC 0.9564\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0183/0938 | LOSS: 0.1439 | ACC 0.9563\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0184/0938 | LOSS: 0.1436 | ACC 0.9564\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0185/0938 | LOSS: 0.1436 | ACC 0.9563\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0186/0938 | LOSS: 0.1432 | ACC 0.9563\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0187/0938 | LOSS: 0.1435 | ACC 0.9562\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0188/0938 | LOSS: 0.1438 | ACC 0.9560\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0189/0938 | LOSS: 0.1433 | ACC 0.9562\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0190/0938 | LOSS: 0.1432 | ACC 0.9563\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0191/0938 | LOSS: 0.1433 | ACC 0.9563\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0192/0938 | LOSS: 0.1452 | ACC 0.9563\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0193/0938 | LOSS: 0.1450 | ACC 0.9564\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0194/0938 | LOSS: 0.1450 | ACC 0.9563\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0195/0938 | LOSS: 0.1448 | ACC 0.9565\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0196/0938 | LOSS: 0.1445 | ACC 0.9566\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0197/0938 | LOSS: 0.1443 | ACC 0.9565\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0198/0938 | LOSS: 0.1444 | ACC 0.9566\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0199/0938 | LOSS: 0.1447 | ACC 0.9567\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0200/0938 | LOSS: 0.1447 | ACC 0.9566\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0201/0938 | LOSS: 0.1441 | ACC 0.9569\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0202/0938 | LOSS: 0.1440 | ACC 0.9567\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0203/0938 | LOSS: 0.1441 | ACC 0.9567\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0204/0938 | LOSS: 0.1443 | ACC 0.9566\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0205/0938 | LOSS: 0.1443 | ACC 0.9566\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0206/0938 | LOSS: 0.1440 | ACC 0.9565\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0207/0938 | LOSS: 0.1439 | ACC 0.9566\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0208/0938 | LOSS: 0.1443 | ACC 0.9565\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0209/0938 | LOSS: 0.1441 | ACC 0.9566\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0210/0938 | LOSS: 0.1440 | ACC 0.9566\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0211/0938 | LOSS: 0.1438 | ACC 0.9567\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0212/0938 | LOSS: 0.1437 | ACC 0.9567\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0213/0938 | LOSS: 0.1439 | ACC 0.9566\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0214/0938 | LOSS: 0.1437 | ACC 0.9567\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0215/0938 | LOSS: 0.1434 | ACC 0.9568\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0216/0938 | LOSS: 0.1434 | ACC 0.9567\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0217/0938 | LOSS: 0.1430 | ACC 0.9568\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0218/0938 | LOSS: 0.1427 | ACC 0.9569\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0219/0938 | LOSS: 0.1429 | ACC 0.9568\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0220/0938 | LOSS: 0.1437 | ACC 0.9565\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0221/0938 | LOSS: 0.1436 | ACC 0.9563\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0222/0938 | LOSS: 0.1433 | ACC 0.9564\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0223/0938 | LOSS: 0.1433 | ACC 0.9563\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0224/0938 | LOSS: 0.1437 | ACC 0.9562\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0225/0938 | LOSS: 0.1437 | ACC 0.9563\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0226/0938 | LOSS: 0.1435 | ACC 0.9564\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0227/0938 | LOSS: 0.1432 | ACC 0.9564\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0228/0938 | LOSS: 0.1432 | ACC 0.9564\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0229/0938 | LOSS: 0.1431 | ACC 0.9564\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0230/0938 | LOSS: 0.1430 | ACC 0.9563\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0231/0938 | LOSS: 0.1428 | ACC 0.9562\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0232/0938 | LOSS: 0.1425 | ACC 0.9563\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0233/0938 | LOSS: 0.1431 | ACC 0.9561\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0234/0938 | LOSS: 0.1436 | ACC 0.9560\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0235/0938 | LOSS: 0.1438 | ACC 0.9559\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0236/0938 | LOSS: 0.1440 | ACC 0.9558\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0237/0938 | LOSS: 0.1443 | ACC 0.9556\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0238/0938 | LOSS: 0.1445 | ACC 0.9555\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0239/0938 | LOSS: 0.1445 | ACC 0.9555\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0240/0938 | LOSS: 0.1443 | ACC 0.9555\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0241/0938 | LOSS: 0.1444 | ACC 0.9554\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0242/0938 | LOSS: 0.1443 | ACC 0.9553\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0243/0938 | LOSS: 0.1446 | ACC 0.9551\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0244/0938 | LOSS: 0.1443 | ACC 0.9551\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0245/0938 | LOSS: 0.1442 | ACC 0.9552\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0246/0938 | LOSS: 0.1450 | ACC 0.9550\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0247/0938 | LOSS: 0.1454 | ACC 0.9548\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0248/0938 | LOSS: 0.1458 | ACC 0.9547\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0249/0938 | LOSS: 0.1457 | ACC 0.9546\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0250/0938 | LOSS: 0.1458 | ACC 0.9546\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0251/0938 | LOSS: 0.1458 | ACC 0.9546\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0252/0938 | LOSS: 0.1457 | ACC 0.9546\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0253/0938 | LOSS: 0.1460 | ACC 0.9545\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0254/0938 | LOSS: 0.1461 | ACC 0.9544\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: EPOCH 0010/0010 | BATCH 0255/0938 | LOSS: 0.1456 | ACC 0.9546\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0256/0938 | LOSS: 0.1453 | ACC 0.9547\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0257/0938 | LOSS: 0.1452 | ACC 0.9547\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0258/0938 | LOSS: 0.1452 | ACC 0.9548\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0259/0938 | LOSS: 0.1452 | ACC 0.9547\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0260/0938 | LOSS: 0.1454 | ACC 0.9547\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0261/0938 | LOSS: 0.1454 | ACC 0.9547\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0262/0938 | LOSS: 0.1450 | ACC 0.9549\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0263/0938 | LOSS: 0.1449 | ACC 0.9550\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0264/0938 | LOSS: 0.1445 | ACC 0.9551\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0265/0938 | LOSS: 0.1447 | ACC 0.9550\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0266/0938 | LOSS: 0.1447 | ACC 0.9550\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0267/0938 | LOSS: 0.1443 | ACC 0.9551\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0268/0938 | LOSS: 0.1442 | ACC 0.9551\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0269/0938 | LOSS: 0.1448 | ACC 0.9552\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0270/0938 | LOSS: 0.1455 | ACC 0.9549\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0271/0938 | LOSS: 0.1457 | ACC 0.9549\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0272/0938 | LOSS: 0.1455 | ACC 0.9549\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0273/0938 | LOSS: 0.1461 | ACC 0.9548\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0274/0938 | LOSS: 0.1459 | ACC 0.9549\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0275/0938 | LOSS: 0.1454 | ACC 0.9551\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0276/0938 | LOSS: 0.1452 | ACC 0.9552\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0277/0938 | LOSS: 0.1455 | ACC 0.9552\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0278/0938 | LOSS: 0.1453 | ACC 0.9553\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0279/0938 | LOSS: 0.1454 | ACC 0.9553\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0280/0938 | LOSS: 0.1455 | ACC 0.9552\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0281/0938 | LOSS: 0.1462 | ACC 0.9550\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0282/0938 | LOSS: 0.1469 | ACC 0.9548\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0283/0938 | LOSS: 0.1468 | ACC 0.9549\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0284/0938 | LOSS: 0.1475 | ACC 0.9547\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0285/0938 | LOSS: 0.1477 | ACC 0.9547\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0286/0938 | LOSS: 0.1478 | ACC 0.9545\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0287/0938 | LOSS: 0.1476 | ACC 0.9546\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0288/0938 | LOSS: 0.1473 | ACC 0.9547\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0289/0938 | LOSS: 0.1474 | ACC 0.9546\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0290/0938 | LOSS: 0.1472 | ACC 0.9547\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0291/0938 | LOSS: 0.1471 | ACC 0.9547\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0292/0938 | LOSS: 0.1475 | ACC 0.9546\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0293/0938 | LOSS: 0.1475 | ACC 0.9547\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0294/0938 | LOSS: 0.1472 | ACC 0.9547\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0295/0938 | LOSS: 0.1474 | ACC 0.9546\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0296/0938 | LOSS: 0.1471 | ACC 0.9547\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0297/0938 | LOSS: 0.1468 | ACC 0.9549\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0298/0938 | LOSS: 0.1472 | ACC 0.9548\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0299/0938 | LOSS: 0.1474 | ACC 0.9547\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0300/0938 | LOSS: 0.1472 | ACC 0.9548\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0301/0938 | LOSS: 0.1470 | ACC 0.9548\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0302/0938 | LOSS: 0.1472 | ACC 0.9547\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0303/0938 | LOSS: 0.1470 | ACC 0.9548\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0304/0938 | LOSS: 0.1468 | ACC 0.9548\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0305/0938 | LOSS: 0.1472 | ACC 0.9548\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0306/0938 | LOSS: 0.1471 | ACC 0.9548\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0307/0938 | LOSS: 0.1474 | ACC 0.9548\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0308/0938 | LOSS: 0.1472 | ACC 0.9548\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0309/0938 | LOSS: 0.1471 | ACC 0.9548\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0310/0938 | LOSS: 0.1470 | ACC 0.9549\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0311/0938 | LOSS: 0.1470 | ACC 0.9548\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0312/0938 | LOSS: 0.1472 | ACC 0.9548\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0313/0938 | LOSS: 0.1471 | ACC 0.9548\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0314/0938 | LOSS: 0.1469 | ACC 0.9549\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0315/0938 | LOSS: 0.1469 | ACC 0.9549\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0316/0938 | LOSS: 0.1472 | ACC 0.9548\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0317/0938 | LOSS: 0.1472 | ACC 0.9548\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0318/0938 | LOSS: 0.1471 | ACC 0.9548\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0319/0938 | LOSS: 0.1472 | ACC 0.9549\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0320/0938 | LOSS: 0.1477 | ACC 0.9548\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0321/0938 | LOSS: 0.1476 | ACC 0.9549\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0322/0938 | LOSS: 0.1478 | ACC 0.9548\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0323/0938 | LOSS: 0.1480 | ACC 0.9548\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0324/0938 | LOSS: 0.1486 | ACC 0.9546\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0325/0938 | LOSS: 0.1485 | ACC 0.9546\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0326/0938 | LOSS: 0.1485 | ACC 0.9546\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0327/0938 | LOSS: 0.1483 | ACC 0.9547\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0328/0938 | LOSS: 0.1480 | ACC 0.9547\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0329/0938 | LOSS: 0.1481 | ACC 0.9546\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0330/0938 | LOSS: 0.1479 | ACC 0.9547\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0331/0938 | LOSS: 0.1480 | ACC 0.9548\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0332/0938 | LOSS: 0.1477 | ACC 0.9548\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0333/0938 | LOSS: 0.1474 | ACC 0.9550\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0334/0938 | LOSS: 0.1475 | ACC 0.9548\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0335/0938 | LOSS: 0.1474 | ACC 0.9549\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0336/0938 | LOSS: 0.1473 | ACC 0.9548\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0337/0938 | LOSS: 0.1471 | ACC 0.9548\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0338/0938 | LOSS: 0.1471 | ACC 0.9549\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0339/0938 | LOSS: 0.1469 | ACC 0.9549\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0340/0938 | LOSS: 0.1476 | ACC 0.9547\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0341/0938 | LOSS: 0.1476 | ACC 0.9546\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0342/0938 | LOSS: 0.1475 | ACC 0.9546\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0343/0938 | LOSS: 0.1477 | ACC 0.9546\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0344/0938 | LOSS: 0.1477 | ACC 0.9546\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0345/0938 | LOSS: 0.1476 | ACC 0.9547\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0346/0938 | LOSS: 0.1473 | ACC 0.9548\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0347/0938 | LOSS: 0.1471 | ACC 0.9548\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0348/0938 | LOSS: 0.1469 | ACC 0.9549\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0349/0938 | LOSS: 0.1466 | ACC 0.9550\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0350/0938 | LOSS: 0.1469 | ACC 0.9550\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0351/0938 | LOSS: 0.1471 | ACC 0.9550\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0352/0938 | LOSS: 0.1471 | ACC 0.9550\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0353/0938 | LOSS: 0.1473 | ACC 0.9549\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0354/0938 | LOSS: 0.1474 | ACC 0.9548\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0355/0938 | LOSS: 0.1476 | ACC 0.9547\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0356/0938 | LOSS: 0.1477 | ACC 0.9547\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0357/0938 | LOSS: 0.1477 | ACC 0.9547\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0358/0938 | LOSS: 0.1476 | ACC 0.9547\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0359/0938 | LOSS: 0.1473 | ACC 0.9547\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0360/0938 | LOSS: 0.1471 | ACC 0.9548\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0361/0938 | LOSS: 0.1472 | ACC 0.9546\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0362/0938 | LOSS: 0.1472 | ACC 0.9546\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0363/0938 | LOSS: 0.1474 | ACC 0.9546\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0364/0938 | LOSS: 0.1472 | ACC 0.9547\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0365/0938 | LOSS: 0.1472 | ACC 0.9547\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0366/0938 | LOSS: 0.1473 | ACC 0.9546\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0367/0938 | LOSS: 0.1473 | ACC 0.9545\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0368/0938 | LOSS: 0.1475 | ACC 0.9545\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0369/0938 | LOSS: 0.1473 | ACC 0.9546\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0370/0938 | LOSS: 0.1472 | ACC 0.9546\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0371/0938 | LOSS: 0.1473 | ACC 0.9546\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0372/0938 | LOSS: 0.1472 | ACC 0.9546\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0373/0938 | LOSS: 0.1476 | ACC 0.9546\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0374/0938 | LOSS: 0.1474 | ACC 0.9546\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0375/0938 | LOSS: 0.1477 | ACC 0.9545\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0376/0938 | LOSS: 0.1480 | ACC 0.9545\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0377/0938 | LOSS: 0.1482 | ACC 0.9545\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0378/0938 | LOSS: 0.1483 | ACC 0.9544\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0379/0938 | LOSS: 0.1480 | ACC 0.9545\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0380/0938 | LOSS: 0.1482 | ACC 0.9545\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0381/0938 | LOSS: 0.1480 | ACC 0.9546\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0382/0938 | LOSS: 0.1481 | ACC 0.9546\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0383/0938 | LOSS: 0.1479 | ACC 0.9547\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: EPOCH 0010/0010 | BATCH 0384/0938 | LOSS: 0.1479 | ACC 0.9547\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0385/0938 | LOSS: 0.1479 | ACC 0.9546\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0386/0938 | LOSS: 0.1479 | ACC 0.9546\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0387/0938 | LOSS: 0.1479 | ACC 0.9545\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0388/0938 | LOSS: 0.1480 | ACC 0.9546\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0389/0938 | LOSS: 0.1480 | ACC 0.9545\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0390/0938 | LOSS: 0.1482 | ACC 0.9543\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0391/0938 | LOSS: 0.1480 | ACC 0.9544\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0392/0938 | LOSS: 0.1482 | ACC 0.9544\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0393/0938 | LOSS: 0.1484 | ACC 0.9542\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0394/0938 | LOSS: 0.1485 | ACC 0.9542\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0395/0938 | LOSS: 0.1486 | ACC 0.9542\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0396/0938 | LOSS: 0.1484 | ACC 0.9542\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0397/0938 | LOSS: 0.1483 | ACC 0.9543\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0398/0938 | LOSS: 0.1483 | ACC 0.9543\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0399/0938 | LOSS: 0.1483 | ACC 0.9542\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0400/0938 | LOSS: 0.1488 | ACC 0.9541\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0401/0938 | LOSS: 0.1486 | ACC 0.9541\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0402/0938 | LOSS: 0.1486 | ACC 0.9541\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0403/0938 | LOSS: 0.1484 | ACC 0.9542\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0404/0938 | LOSS: 0.1486 | ACC 0.9541\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0405/0938 | LOSS: 0.1484 | ACC 0.9541\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0406/0938 | LOSS: 0.1484 | ACC 0.9540\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0407/0938 | LOSS: 0.1483 | ACC 0.9540\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0408/0938 | LOSS: 0.1482 | ACC 0.9540\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0409/0938 | LOSS: 0.1484 | ACC 0.9540\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0410/0938 | LOSS: 0.1481 | ACC 0.9541\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0411/0938 | LOSS: 0.1480 | ACC 0.9542\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0412/0938 | LOSS: 0.1484 | ACC 0.9541\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0413/0938 | LOSS: 0.1482 | ACC 0.9541\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0414/0938 | LOSS: 0.1480 | ACC 0.9542\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0415/0938 | LOSS: 0.1482 | ACC 0.9542\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0416/0938 | LOSS: 0.1481 | ACC 0.9542\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0417/0938 | LOSS: 0.1479 | ACC 0.9543\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0418/0938 | LOSS: 0.1479 | ACC 0.9543\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0419/0938 | LOSS: 0.1479 | ACC 0.9543\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0420/0938 | LOSS: 0.1479 | ACC 0.9542\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0421/0938 | LOSS: 0.1480 | ACC 0.9542\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0422/0938 | LOSS: 0.1479 | ACC 0.9543\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0423/0938 | LOSS: 0.1483 | ACC 0.9542\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0424/0938 | LOSS: 0.1484 | ACC 0.9542\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0425/0938 | LOSS: 0.1489 | ACC 0.9541\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0426/0938 | LOSS: 0.1489 | ACC 0.9541\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0427/0938 | LOSS: 0.1489 | ACC 0.9541\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0428/0938 | LOSS: 0.1493 | ACC 0.9540\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0429/0938 | LOSS: 0.1491 | ACC 0.9541\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0430/0938 | LOSS: 0.1488 | ACC 0.9541\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0431/0938 | LOSS: 0.1488 | ACC 0.9541\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0432/0938 | LOSS: 0.1491 | ACC 0.9541\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0433/0938 | LOSS: 0.1489 | ACC 0.9541\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0434/0938 | LOSS: 0.1491 | ACC 0.9540\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0435/0938 | LOSS: 0.1490 | ACC 0.9540\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0436/0938 | LOSS: 0.1489 | ACC 0.9541\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0437/0938 | LOSS: 0.1488 | ACC 0.9541\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0438/0938 | LOSS: 0.1487 | ACC 0.9541\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0439/0938 | LOSS: 0.1489 | ACC 0.9541\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0440/0938 | LOSS: 0.1488 | ACC 0.9541\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0441/0938 | LOSS: 0.1490 | ACC 0.9541\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0442/0938 | LOSS: 0.1490 | ACC 0.9541\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0443/0938 | LOSS: 0.1493 | ACC 0.9540\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0444/0938 | LOSS: 0.1492 | ACC 0.9541\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0445/0938 | LOSS: 0.1489 | ACC 0.9542\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0446/0938 | LOSS: 0.1490 | ACC 0.9541\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0447/0938 | LOSS: 0.1492 | ACC 0.9540\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0448/0938 | LOSS: 0.1491 | ACC 0.9541\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0449/0938 | LOSS: 0.1492 | ACC 0.9541\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0450/0938 | LOSS: 0.1495 | ACC 0.9541\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0451/0938 | LOSS: 0.1497 | ACC 0.9541\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0452/0938 | LOSS: 0.1498 | ACC 0.9541\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0453/0938 | LOSS: 0.1500 | ACC 0.9540\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0454/0938 | LOSS: 0.1500 | ACC 0.9540\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0455/0938 | LOSS: 0.1500 | ACC 0.9540\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0456/0938 | LOSS: 0.1501 | ACC 0.9539\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0457/0938 | LOSS: 0.1500 | ACC 0.9540\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0458/0938 | LOSS: 0.1502 | ACC 0.9539\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0459/0938 | LOSS: 0.1502 | ACC 0.9539\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0460/0938 | LOSS: 0.1502 | ACC 0.9539\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0461/0938 | LOSS: 0.1501 | ACC 0.9539\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0462/0938 | LOSS: 0.1500 | ACC 0.9540\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0463/0938 | LOSS: 0.1499 | ACC 0.9540\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0464/0938 | LOSS: 0.1497 | ACC 0.9541\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0465/0938 | LOSS: 0.1495 | ACC 0.9542\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0466/0938 | LOSS: 0.1497 | ACC 0.9541\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0467/0938 | LOSS: 0.1496 | ACC 0.9542\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0468/0938 | LOSS: 0.1494 | ACC 0.9543\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0469/0938 | LOSS: 0.1493 | ACC 0.9543\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0470/0938 | LOSS: 0.1492 | ACC 0.9544\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0471/0938 | LOSS: 0.1493 | ACC 0.9544\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0472/0938 | LOSS: 0.1491 | ACC 0.9544\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0473/0938 | LOSS: 0.1491 | ACC 0.9544\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0474/0938 | LOSS: 0.1491 | ACC 0.9545\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0475/0938 | LOSS: 0.1489 | ACC 0.9545\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0476/0938 | LOSS: 0.1488 | ACC 0.9546\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0477/0938 | LOSS: 0.1487 | ACC 0.9546\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0478/0938 | LOSS: 0.1489 | ACC 0.9545\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0479/0938 | LOSS: 0.1492 | ACC 0.9544\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0480/0938 | LOSS: 0.1492 | ACC 0.9543\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0481/0938 | LOSS: 0.1494 | ACC 0.9543\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0482/0938 | LOSS: 0.1493 | ACC 0.9543\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0483/0938 | LOSS: 0.1492 | ACC 0.9543\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0484/0938 | LOSS: 0.1491 | ACC 0.9544\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0485/0938 | LOSS: 0.1490 | ACC 0.9544\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0486/0938 | LOSS: 0.1487 | ACC 0.9545\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0487/0938 | LOSS: 0.1486 | ACC 0.9545\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0488/0938 | LOSS: 0.1484 | ACC 0.9546\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0489/0938 | LOSS: 0.1483 | ACC 0.9546\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0490/0938 | LOSS: 0.1483 | ACC 0.9546\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0491/0938 | LOSS: 0.1488 | ACC 0.9547\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0492/0938 | LOSS: 0.1489 | ACC 0.9546\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0493/0938 | LOSS: 0.1488 | ACC 0.9546\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0494/0938 | LOSS: 0.1488 | ACC 0.9546\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0495/0938 | LOSS: 0.1487 | ACC 0.9547\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0496/0938 | LOSS: 0.1486 | ACC 0.9547\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0497/0938 | LOSS: 0.1485 | ACC 0.9548\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0498/0938 | LOSS: 0.1486 | ACC 0.9548\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0499/0938 | LOSS: 0.1484 | ACC 0.9548\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0500/0938 | LOSS: 0.1486 | ACC 0.9548\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0501/0938 | LOSS: 0.1484 | ACC 0.9548\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0502/0938 | LOSS: 0.1484 | ACC 0.9548\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0503/0938 | LOSS: 0.1482 | ACC 0.9549\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0504/0938 | LOSS: 0.1481 | ACC 0.9549\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0505/0938 | LOSS: 0.1481 | ACC 0.9549\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0506/0938 | LOSS: 0.1479 | ACC 0.9549\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0507/0938 | LOSS: 0.1485 | ACC 0.9548\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0508/0938 | LOSS: 0.1485 | ACC 0.9548\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0509/0938 | LOSS: 0.1484 | ACC 0.9548\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0510/0938 | LOSS: 0.1483 | ACC 0.9548\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0511/0938 | LOSS: 0.1483 | ACC 0.9548\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: EPOCH 0010/0010 | BATCH 0512/0938 | LOSS: 0.1485 | ACC 0.9548\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0513/0938 | LOSS: 0.1484 | ACC 0.9548\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0514/0938 | LOSS: 0.1483 | ACC 0.9548\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0515/0938 | LOSS: 0.1485 | ACC 0.9547\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0516/0938 | LOSS: 0.1486 | ACC 0.9546\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0517/0938 | LOSS: 0.1486 | ACC 0.9546\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0518/0938 | LOSS: 0.1487 | ACC 0.9546\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0519/0938 | LOSS: 0.1486 | ACC 0.9546\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0520/0938 | LOSS: 0.1485 | ACC 0.9547\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0521/0938 | LOSS: 0.1486 | ACC 0.9547\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0522/0938 | LOSS: 0.1483 | ACC 0.9547\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0523/0938 | LOSS: 0.1484 | ACC 0.9547\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0524/0938 | LOSS: 0.1484 | ACC 0.9547\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0525/0938 | LOSS: 0.1482 | ACC 0.9547\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0526/0938 | LOSS: 0.1483 | ACC 0.9547\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0527/0938 | LOSS: 0.1481 | ACC 0.9547\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0528/0938 | LOSS: 0.1484 | ACC 0.9546\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0529/0938 | LOSS: 0.1482 | ACC 0.9547\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0530/0938 | LOSS: 0.1484 | ACC 0.9546\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0531/0938 | LOSS: 0.1488 | ACC 0.9546\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0532/0938 | LOSS: 0.1486 | ACC 0.9546\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0533/0938 | LOSS: 0.1485 | ACC 0.9546\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0534/0938 | LOSS: 0.1485 | ACC 0.9546\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0535/0938 | LOSS: 0.1487 | ACC 0.9545\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0536/0938 | LOSS: 0.1487 | ACC 0.9545\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0537/0938 | LOSS: 0.1486 | ACC 0.9546\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0538/0938 | LOSS: 0.1485 | ACC 0.9546\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0539/0938 | LOSS: 0.1484 | ACC 0.9546\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0540/0938 | LOSS: 0.1485 | ACC 0.9546\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0541/0938 | LOSS: 0.1485 | ACC 0.9546\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0542/0938 | LOSS: 0.1485 | ACC 0.9546\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0543/0938 | LOSS: 0.1487 | ACC 0.9546\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0544/0938 | LOSS: 0.1489 | ACC 0.9545\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0545/0938 | LOSS: 0.1492 | ACC 0.9544\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0546/0938 | LOSS: 0.1491 | ACC 0.9545\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0547/0938 | LOSS: 0.1489 | ACC 0.9545\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0548/0938 | LOSS: 0.1488 | ACC 0.9546\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0549/0938 | LOSS: 0.1487 | ACC 0.9546\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0550/0938 | LOSS: 0.1486 | ACC 0.9546\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0551/0938 | LOSS: 0.1485 | ACC 0.9547\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0552/0938 | LOSS: 0.1485 | ACC 0.9547\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0553/0938 | LOSS: 0.1487 | ACC 0.9546\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0554/0938 | LOSS: 0.1485 | ACC 0.9546\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0555/0938 | LOSS: 0.1488 | ACC 0.9546\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0556/0938 | LOSS: 0.1487 | ACC 0.9546\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0557/0938 | LOSS: 0.1485 | ACC 0.9547\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0558/0938 | LOSS: 0.1484 | ACC 0.9548\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0559/0938 | LOSS: 0.1483 | ACC 0.9548\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0560/0938 | LOSS: 0.1481 | ACC 0.9549\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0561/0938 | LOSS: 0.1480 | ACC 0.9549\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0562/0938 | LOSS: 0.1481 | ACC 0.9548\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0563/0938 | LOSS: 0.1484 | ACC 0.9548\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0564/0938 | LOSS: 0.1484 | ACC 0.9548\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0565/0938 | LOSS: 0.1485 | ACC 0.9547\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0566/0938 | LOSS: 0.1485 | ACC 0.9548\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0567/0938 | LOSS: 0.1484 | ACC 0.9548\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0568/0938 | LOSS: 0.1485 | ACC 0.9547\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0569/0938 | LOSS: 0.1486 | ACC 0.9547\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0570/0938 | LOSS: 0.1485 | ACC 0.9548\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0571/0938 | LOSS: 0.1485 | ACC 0.9548\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0572/0938 | LOSS: 0.1485 | ACC 0.9548\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0573/0938 | LOSS: 0.1484 | ACC 0.9548\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0574/0938 | LOSS: 0.1486 | ACC 0.9548\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0575/0938 | LOSS: 0.1485 | ACC 0.9548\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0576/0938 | LOSS: 0.1485 | ACC 0.9548\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0577/0938 | LOSS: 0.1484 | ACC 0.9548\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0578/0938 | LOSS: 0.1484 | ACC 0.9548\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0579/0938 | LOSS: 0.1491 | ACC 0.9546\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0580/0938 | LOSS: 0.1491 | ACC 0.9546\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0581/0938 | LOSS: 0.1493 | ACC 0.9546\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0582/0938 | LOSS: 0.1491 | ACC 0.9547\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0583/0938 | LOSS: 0.1491 | ACC 0.9547\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0584/0938 | LOSS: 0.1489 | ACC 0.9548\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0585/0938 | LOSS: 0.1490 | ACC 0.9548\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0586/0938 | LOSS: 0.1489 | ACC 0.9548\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0587/0938 | LOSS: 0.1488 | ACC 0.9548\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0588/0938 | LOSS: 0.1487 | ACC 0.9548\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0589/0938 | LOSS: 0.1486 | ACC 0.9548\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0590/0938 | LOSS: 0.1487 | ACC 0.9547\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0591/0938 | LOSS: 0.1487 | ACC 0.9548\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0592/0938 | LOSS: 0.1487 | ACC 0.9547\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0593/0938 | LOSS: 0.1487 | ACC 0.9548\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0594/0938 | LOSS: 0.1486 | ACC 0.9548\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0595/0938 | LOSS: 0.1486 | ACC 0.9548\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0596/0938 | LOSS: 0.1485 | ACC 0.9548\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0597/0938 | LOSS: 0.1486 | ACC 0.9548\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0598/0938 | LOSS: 0.1489 | ACC 0.9548\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0599/0938 | LOSS: 0.1488 | ACC 0.9549\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0600/0938 | LOSS: 0.1487 | ACC 0.9549\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0601/0938 | LOSS: 0.1485 | ACC 0.9550\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0602/0938 | LOSS: 0.1485 | ACC 0.9550\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0603/0938 | LOSS: 0.1484 | ACC 0.9550\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0604/0938 | LOSS: 0.1483 | ACC 0.9550\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0605/0938 | LOSS: 0.1482 | ACC 0.9551\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0606/0938 | LOSS: 0.1483 | ACC 0.9551\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0607/0938 | LOSS: 0.1485 | ACC 0.9551\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0608/0938 | LOSS: 0.1484 | ACC 0.9551\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0609/0938 | LOSS: 0.1486 | ACC 0.9550\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0610/0938 | LOSS: 0.1485 | ACC 0.9550\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0611/0938 | LOSS: 0.1486 | ACC 0.9550\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0612/0938 | LOSS: 0.1485 | ACC 0.9551\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0613/0938 | LOSS: 0.1485 | ACC 0.9550\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0614/0938 | LOSS: 0.1483 | ACC 0.9551\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0615/0938 | LOSS: 0.1485 | ACC 0.9550\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0616/0938 | LOSS: 0.1483 | ACC 0.9551\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0617/0938 | LOSS: 0.1486 | ACC 0.9550\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0618/0938 | LOSS: 0.1487 | ACC 0.9551\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0619/0938 | LOSS: 0.1488 | ACC 0.9550\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0620/0938 | LOSS: 0.1486 | ACC 0.9551\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0621/0938 | LOSS: 0.1487 | ACC 0.9551\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0622/0938 | LOSS: 0.1486 | ACC 0.9551\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0623/0938 | LOSS: 0.1487 | ACC 0.9551\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0624/0938 | LOSS: 0.1488 | ACC 0.9551\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0625/0938 | LOSS: 0.1486 | ACC 0.9551\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0626/0938 | LOSS: 0.1486 | ACC 0.9551\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0627/0938 | LOSS: 0.1488 | ACC 0.9551\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0628/0938 | LOSS: 0.1490 | ACC 0.9551\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0629/0938 | LOSS: 0.1490 | ACC 0.9551\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0630/0938 | LOSS: 0.1488 | ACC 0.9551\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0631/0938 | LOSS: 0.1486 | ACC 0.9552\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0632/0938 | LOSS: 0.1489 | ACC 0.9552\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0633/0938 | LOSS: 0.1490 | ACC 0.9551\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0634/0938 | LOSS: 0.1489 | ACC 0.9551\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0635/0938 | LOSS: 0.1488 | ACC 0.9551\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0636/0938 | LOSS: 0.1487 | ACC 0.9552\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0637/0938 | LOSS: 0.1491 | ACC 0.9552\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0638/0938 | LOSS: 0.1489 | ACC 0.9552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: EPOCH 0010/0010 | BATCH 0639/0938 | LOSS: 0.1489 | ACC 0.9552\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0640/0938 | LOSS: 0.1489 | ACC 0.9552\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0641/0938 | LOSS: 0.1488 | ACC 0.9552\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0642/0938 | LOSS: 0.1488 | ACC 0.9552\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0643/0938 | LOSS: 0.1488 | ACC 0.9552\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0644/0938 | LOSS: 0.1490 | ACC 0.9551\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0645/0938 | LOSS: 0.1493 | ACC 0.9551\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0646/0938 | LOSS: 0.1491 | ACC 0.9552\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0647/0938 | LOSS: 0.1492 | ACC 0.9551\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0648/0938 | LOSS: 0.1492 | ACC 0.9552\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0649/0938 | LOSS: 0.1493 | ACC 0.9551\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0650/0938 | LOSS: 0.1492 | ACC 0.9551\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0651/0938 | LOSS: 0.1493 | ACC 0.9550\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0652/0938 | LOSS: 0.1493 | ACC 0.9550\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0653/0938 | LOSS: 0.1492 | ACC 0.9550\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0654/0938 | LOSS: 0.1492 | ACC 0.9550\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0655/0938 | LOSS: 0.1492 | ACC 0.9550\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0656/0938 | LOSS: 0.1492 | ACC 0.9551\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0657/0938 | LOSS: 0.1491 | ACC 0.9551\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0658/0938 | LOSS: 0.1490 | ACC 0.9551\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0659/0938 | LOSS: 0.1490 | ACC 0.9551\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0660/0938 | LOSS: 0.1490 | ACC 0.9551\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0661/0938 | LOSS: 0.1492 | ACC 0.9551\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0662/0938 | LOSS: 0.1493 | ACC 0.9550\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0663/0938 | LOSS: 0.1492 | ACC 0.9551\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0664/0938 | LOSS: 0.1492 | ACC 0.9551\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0665/0938 | LOSS: 0.1493 | ACC 0.9550\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0666/0938 | LOSS: 0.1492 | ACC 0.9550\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0667/0938 | LOSS: 0.1492 | ACC 0.9550\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0668/0938 | LOSS: 0.1491 | ACC 0.9550\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0669/0938 | LOSS: 0.1490 | ACC 0.9551\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0670/0938 | LOSS: 0.1489 | ACC 0.9551\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0671/0938 | LOSS: 0.1488 | ACC 0.9552\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0672/0938 | LOSS: 0.1487 | ACC 0.9551\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0673/0938 | LOSS: 0.1490 | ACC 0.9551\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0674/0938 | LOSS: 0.1490 | ACC 0.9551\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0675/0938 | LOSS: 0.1492 | ACC 0.9550\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0676/0938 | LOSS: 0.1492 | ACC 0.9551\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0677/0938 | LOSS: 0.1491 | ACC 0.9551\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0678/0938 | LOSS: 0.1491 | ACC 0.9551\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0679/0938 | LOSS: 0.1489 | ACC 0.9552\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0680/0938 | LOSS: 0.1488 | ACC 0.9552\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0681/0938 | LOSS: 0.1487 | ACC 0.9552\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0682/0938 | LOSS: 0.1488 | ACC 0.9553\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0683/0938 | LOSS: 0.1488 | ACC 0.9553\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0684/0938 | LOSS: 0.1489 | ACC 0.9552\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0685/0938 | LOSS: 0.1488 | ACC 0.9552\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0686/0938 | LOSS: 0.1491 | ACC 0.9551\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0687/0938 | LOSS: 0.1490 | ACC 0.9552\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0688/0938 | LOSS: 0.1492 | ACC 0.9551\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0689/0938 | LOSS: 0.1493 | ACC 0.9551\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0690/0938 | LOSS: 0.1492 | ACC 0.9551\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0691/0938 | LOSS: 0.1491 | ACC 0.9551\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0692/0938 | LOSS: 0.1491 | ACC 0.9551\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0693/0938 | LOSS: 0.1493 | ACC 0.9550\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0694/0938 | LOSS: 0.1495 | ACC 0.9549\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0695/0938 | LOSS: 0.1494 | ACC 0.9550\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0696/0938 | LOSS: 0.1494 | ACC 0.9550\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0697/0938 | LOSS: 0.1495 | ACC 0.9550\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0698/0938 | LOSS: 0.1494 | ACC 0.9550\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0699/0938 | LOSS: 0.1495 | ACC 0.9550\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0700/0938 | LOSS: 0.1495 | ACC 0.9550\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0701/0938 | LOSS: 0.1495 | ACC 0.9550\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0702/0938 | LOSS: 0.1494 | ACC 0.9550\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0703/0938 | LOSS: 0.1493 | ACC 0.9550\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0704/0938 | LOSS: 0.1496 | ACC 0.9549\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0705/0938 | LOSS: 0.1497 | ACC 0.9550\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0706/0938 | LOSS: 0.1500 | ACC 0.9549\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0707/0938 | LOSS: 0.1501 | ACC 0.9549\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0708/0938 | LOSS: 0.1501 | ACC 0.9548\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0709/0938 | LOSS: 0.1500 | ACC 0.9548\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0710/0938 | LOSS: 0.1500 | ACC 0.9548\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0711/0938 | LOSS: 0.1499 | ACC 0.9549\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0712/0938 | LOSS: 0.1499 | ACC 0.9549\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0713/0938 | LOSS: 0.1500 | ACC 0.9549\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0714/0938 | LOSS: 0.1499 | ACC 0.9549\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0715/0938 | LOSS: 0.1499 | ACC 0.9549\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0716/0938 | LOSS: 0.1499 | ACC 0.9550\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0717/0938 | LOSS: 0.1500 | ACC 0.9549\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0718/0938 | LOSS: 0.1500 | ACC 0.9549\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0719/0938 | LOSS: 0.1503 | ACC 0.9549\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0720/0938 | LOSS: 0.1502 | ACC 0.9549\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0721/0938 | LOSS: 0.1502 | ACC 0.9550\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0722/0938 | LOSS: 0.1501 | ACC 0.9549\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0723/0938 | LOSS: 0.1502 | ACC 0.9549\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0724/0938 | LOSS: 0.1503 | ACC 0.9550\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0725/0938 | LOSS: 0.1502 | ACC 0.9550\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0726/0938 | LOSS: 0.1502 | ACC 0.9550\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0727/0938 | LOSS: 0.1502 | ACC 0.9550\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0728/0938 | LOSS: 0.1506 | ACC 0.9549\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0729/0938 | LOSS: 0.1507 | ACC 0.9548\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0730/0938 | LOSS: 0.1507 | ACC 0.9548\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0731/0938 | LOSS: 0.1506 | ACC 0.9548\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0732/0938 | LOSS: 0.1505 | ACC 0.9548\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0733/0938 | LOSS: 0.1504 | ACC 0.9549\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0734/0938 | LOSS: 0.1503 | ACC 0.9549\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0735/0938 | LOSS: 0.1502 | ACC 0.9549\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0736/0938 | LOSS: 0.1501 | ACC 0.9549\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0737/0938 | LOSS: 0.1503 | ACC 0.9549\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0738/0938 | LOSS: 0.1502 | ACC 0.9549\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0739/0938 | LOSS: 0.1506 | ACC 0.9549\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0740/0938 | LOSS: 0.1506 | ACC 0.9549\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0741/0938 | LOSS: 0.1508 | ACC 0.9548\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0742/0938 | LOSS: 0.1507 | ACC 0.9549\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0743/0938 | LOSS: 0.1508 | ACC 0.9548\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0744/0938 | LOSS: 0.1506 | ACC 0.9549\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0745/0938 | LOSS: 0.1506 | ACC 0.9549\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0746/0938 | LOSS: 0.1505 | ACC 0.9549\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0747/0938 | LOSS: 0.1505 | ACC 0.9549\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0748/0938 | LOSS: 0.1505 | ACC 0.9549\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0749/0938 | LOSS: 0.1505 | ACC 0.9549\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0750/0938 | LOSS: 0.1505 | ACC 0.9549\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0751/0938 | LOSS: 0.1505 | ACC 0.9549\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0752/0938 | LOSS: 0.1504 | ACC 0.9549\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0753/0938 | LOSS: 0.1504 | ACC 0.9549\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0754/0938 | LOSS: 0.1504 | ACC 0.9549\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0755/0938 | LOSS: 0.1504 | ACC 0.9548\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0756/0938 | LOSS: 0.1504 | ACC 0.9549\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0757/0938 | LOSS: 0.1504 | ACC 0.9548\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0758/0938 | LOSS: 0.1503 | ACC 0.9548\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0759/0938 | LOSS: 0.1503 | ACC 0.9548\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0760/0938 | LOSS: 0.1503 | ACC 0.9549\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0761/0938 | LOSS: 0.1502 | ACC 0.9549\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0762/0938 | LOSS: 0.1501 | ACC 0.9549\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0763/0938 | LOSS: 0.1500 | ACC 0.9549\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0764/0938 | LOSS: 0.1499 | ACC 0.9549\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0765/0938 | LOSS: 0.1499 | ACC 0.9549\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0766/0938 | LOSS: 0.1498 | ACC 0.9549\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: EPOCH 0010/0010 | BATCH 0767/0938 | LOSS: 0.1499 | ACC 0.9549\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0768/0938 | LOSS: 0.1499 | ACC 0.9549\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0769/0938 | LOSS: 0.1499 | ACC 0.9549\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0770/0938 | LOSS: 0.1499 | ACC 0.9548\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0771/0938 | LOSS: 0.1499 | ACC 0.9548\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0772/0938 | LOSS: 0.1498 | ACC 0.9549\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0773/0938 | LOSS: 0.1502 | ACC 0.9548\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0774/0938 | LOSS: 0.1503 | ACC 0.9548\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0775/0938 | LOSS: 0.1502 | ACC 0.9549\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0776/0938 | LOSS: 0.1500 | ACC 0.9549\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0777/0938 | LOSS: 0.1501 | ACC 0.9549\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0778/0938 | LOSS: 0.1501 | ACC 0.9549\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0779/0938 | LOSS: 0.1501 | ACC 0.9550\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0780/0938 | LOSS: 0.1501 | ACC 0.9549\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0781/0938 | LOSS: 0.1501 | ACC 0.9549\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0782/0938 | LOSS: 0.1500 | ACC 0.9549\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0783/0938 | LOSS: 0.1499 | ACC 0.9550\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0784/0938 | LOSS: 0.1499 | ACC 0.9550\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0785/0938 | LOSS: 0.1499 | ACC 0.9550\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0786/0938 | LOSS: 0.1499 | ACC 0.9550\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0787/0938 | LOSS: 0.1497 | ACC 0.9551\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0788/0938 | LOSS: 0.1499 | ACC 0.9551\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0789/0938 | LOSS: 0.1498 | ACC 0.9551\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0790/0938 | LOSS: 0.1499 | ACC 0.9550\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0791/0938 | LOSS: 0.1499 | ACC 0.9550\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0792/0938 | LOSS: 0.1499 | ACC 0.9550\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0793/0938 | LOSS: 0.1498 | ACC 0.9551\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0794/0938 | LOSS: 0.1498 | ACC 0.9551\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0795/0938 | LOSS: 0.1498 | ACC 0.9551\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0796/0938 | LOSS: 0.1497 | ACC 0.9551\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0797/0938 | LOSS: 0.1496 | ACC 0.9551\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0798/0938 | LOSS: 0.1497 | ACC 0.9551\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0799/0938 | LOSS: 0.1496 | ACC 0.9551\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0800/0938 | LOSS: 0.1497 | ACC 0.9551\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0801/0938 | LOSS: 0.1498 | ACC 0.9550\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0802/0938 | LOSS: 0.1499 | ACC 0.9550\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0803/0938 | LOSS: 0.1500 | ACC 0.9550\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0804/0938 | LOSS: 0.1499 | ACC 0.9550\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0805/0938 | LOSS: 0.1498 | ACC 0.9550\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0806/0938 | LOSS: 0.1498 | ACC 0.9550\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0807/0938 | LOSS: 0.1500 | ACC 0.9550\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0808/0938 | LOSS: 0.1500 | ACC 0.9550\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0809/0938 | LOSS: 0.1499 | ACC 0.9550\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0810/0938 | LOSS: 0.1498 | ACC 0.9551\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0811/0938 | LOSS: 0.1497 | ACC 0.9551\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0812/0938 | LOSS: 0.1498 | ACC 0.9551\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0813/0938 | LOSS: 0.1496 | ACC 0.9551\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0814/0938 | LOSS: 0.1495 | ACC 0.9552\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0815/0938 | LOSS: 0.1495 | ACC 0.9552\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0816/0938 | LOSS: 0.1495 | ACC 0.9552\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0817/0938 | LOSS: 0.1494 | ACC 0.9552\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0818/0938 | LOSS: 0.1496 | ACC 0.9552\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0819/0938 | LOSS: 0.1495 | ACC 0.9552\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0820/0938 | LOSS: 0.1496 | ACC 0.9553\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0821/0938 | LOSS: 0.1495 | ACC 0.9553\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0822/0938 | LOSS: 0.1496 | ACC 0.9553\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0823/0938 | LOSS: 0.1497 | ACC 0.9552\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0824/0938 | LOSS: 0.1497 | ACC 0.9552\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0825/0938 | LOSS: 0.1498 | ACC 0.9552\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0826/0938 | LOSS: 0.1498 | ACC 0.9551\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0827/0938 | LOSS: 0.1499 | ACC 0.9551\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0828/0938 | LOSS: 0.1499 | ACC 0.9551\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0829/0938 | LOSS: 0.1499 | ACC 0.9551\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0830/0938 | LOSS: 0.1499 | ACC 0.9551\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0831/0938 | LOSS: 0.1498 | ACC 0.9551\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0832/0938 | LOSS: 0.1497 | ACC 0.9552\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0833/0938 | LOSS: 0.1497 | ACC 0.9552\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0834/0938 | LOSS: 0.1496 | ACC 0.9552\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0835/0938 | LOSS: 0.1496 | ACC 0.9551\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0836/0938 | LOSS: 0.1495 | ACC 0.9552\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0837/0938 | LOSS: 0.1495 | ACC 0.9552\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0838/0938 | LOSS: 0.1494 | ACC 0.9552\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0839/0938 | LOSS: 0.1494 | ACC 0.9552\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0840/0938 | LOSS: 0.1493 | ACC 0.9553\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0841/0938 | LOSS: 0.1492 | ACC 0.9553\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0842/0938 | LOSS: 0.1494 | ACC 0.9553\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0843/0938 | LOSS: 0.1493 | ACC 0.9553\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0844/0938 | LOSS: 0.1494 | ACC 0.9553\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0845/0938 | LOSS: 0.1494 | ACC 0.9553\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0846/0938 | LOSS: 0.1493 | ACC 0.9553\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0847/0938 | LOSS: 0.1493 | ACC 0.9553\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0848/0938 | LOSS: 0.1491 | ACC 0.9553\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0849/0938 | LOSS: 0.1491 | ACC 0.9554\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0850/0938 | LOSS: 0.1490 | ACC 0.9554\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0851/0938 | LOSS: 0.1490 | ACC 0.9553\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0852/0938 | LOSS: 0.1490 | ACC 0.9553\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0853/0938 | LOSS: 0.1490 | ACC 0.9553\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0854/0938 | LOSS: 0.1489 | ACC 0.9553\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0855/0938 | LOSS: 0.1489 | ACC 0.9553\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0856/0938 | LOSS: 0.1488 | ACC 0.9554\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0857/0938 | LOSS: 0.1488 | ACC 0.9554\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0858/0938 | LOSS: 0.1487 | ACC 0.9554\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0859/0938 | LOSS: 0.1486 | ACC 0.9554\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0860/0938 | LOSS: 0.1488 | ACC 0.9553\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0861/0938 | LOSS: 0.1488 | ACC 0.9553\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0862/0938 | LOSS: 0.1489 | ACC 0.9553\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0863/0938 | LOSS: 0.1489 | ACC 0.9553\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0864/0938 | LOSS: 0.1488 | ACC 0.9553\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0865/0938 | LOSS: 0.1488 | ACC 0.9553\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0866/0938 | LOSS: 0.1488 | ACC 0.9553\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0867/0938 | LOSS: 0.1488 | ACC 0.9553\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0868/0938 | LOSS: 0.1487 | ACC 0.9553\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0869/0938 | LOSS: 0.1488 | ACC 0.9553\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0870/0938 | LOSS: 0.1489 | ACC 0.9554\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0871/0938 | LOSS: 0.1490 | ACC 0.9553\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0872/0938 | LOSS: 0.1490 | ACC 0.9553\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0873/0938 | LOSS: 0.1493 | ACC 0.9553\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0874/0938 | LOSS: 0.1492 | ACC 0.9553\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0875/0938 | LOSS: 0.1492 | ACC 0.9553\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0876/0938 | LOSS: 0.1491 | ACC 0.9553\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0877/0938 | LOSS: 0.1491 | ACC 0.9553\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0878/0938 | LOSS: 0.1491 | ACC 0.9553\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0879/0938 | LOSS: 0.1490 | ACC 0.9553\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0880/0938 | LOSS: 0.1489 | ACC 0.9554\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0881/0938 | LOSS: 0.1491 | ACC 0.9553\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0882/0938 | LOSS: 0.1493 | ACC 0.9554\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0883/0938 | LOSS: 0.1493 | ACC 0.9553\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0884/0938 | LOSS: 0.1492 | ACC 0.9554\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0885/0938 | LOSS: 0.1492 | ACC 0.9554\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0886/0938 | LOSS: 0.1492 | ACC 0.9553\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0887/0938 | LOSS: 0.1494 | ACC 0.9553\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0888/0938 | LOSS: 0.1494 | ACC 0.9553\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0889/0938 | LOSS: 0.1494 | ACC 0.9553\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0890/0938 | LOSS: 0.1493 | ACC 0.9553\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0891/0938 | LOSS: 0.1494 | ACC 0.9554\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0892/0938 | LOSS: 0.1494 | ACC 0.9553\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0893/0938 | LOSS: 0.1495 | ACC 0.9554\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0894/0938 | LOSS: 0.1495 | ACC 0.9553\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0895/0938 | LOSS: 0.1494 | ACC 0.9554\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: EPOCH 0010/0010 | BATCH 0896/0938 | LOSS: 0.1493 | ACC 0.9554\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0897/0938 | LOSS: 0.1493 | ACC 0.9554\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0898/0938 | LOSS: 0.1493 | ACC 0.9554\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0899/0938 | LOSS: 0.1495 | ACC 0.9554\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0900/0938 | LOSS: 0.1494 | ACC 0.9554\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0901/0938 | LOSS: 0.1494 | ACC 0.9554\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0902/0938 | LOSS: 0.1497 | ACC 0.9554\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0903/0938 | LOSS: 0.1497 | ACC 0.9554\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0904/0938 | LOSS: 0.1496 | ACC 0.9554\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0905/0938 | LOSS: 0.1497 | ACC 0.9554\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0906/0938 | LOSS: 0.1496 | ACC 0.9554\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0907/0938 | LOSS: 0.1496 | ACC 0.9554\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0908/0938 | LOSS: 0.1496 | ACC 0.9554\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0909/0938 | LOSS: 0.1497 | ACC 0.9554\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0910/0938 | LOSS: 0.1496 | ACC 0.9554\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0911/0938 | LOSS: 0.1498 | ACC 0.9554\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0912/0938 | LOSS: 0.1497 | ACC 0.9554\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0913/0938 | LOSS: 0.1497 | ACC 0.9554\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0914/0938 | LOSS: 0.1496 | ACC 0.9554\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0915/0938 | LOSS: 0.1497 | ACC 0.9554\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0916/0938 | LOSS: 0.1497 | ACC 0.9554\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0917/0938 | LOSS: 0.1496 | ACC 0.9554\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0918/0938 | LOSS: 0.1497 | ACC 0.9554\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0919/0938 | LOSS: 0.1499 | ACC 0.9554\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0920/0938 | LOSS: 0.1498 | ACC 0.9554\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0921/0938 | LOSS: 0.1498 | ACC 0.9554\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0922/0938 | LOSS: 0.1498 | ACC 0.9554\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0923/0938 | LOSS: 0.1498 | ACC 0.9554\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0924/0938 | LOSS: 0.1498 | ACC 0.9554\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0925/0938 | LOSS: 0.1497 | ACC 0.9554\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0926/0938 | LOSS: 0.1499 | ACC 0.9554\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0927/0938 | LOSS: 0.1498 | ACC 0.9554\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0928/0938 | LOSS: 0.1498 | ACC 0.9554\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0929/0938 | LOSS: 0.1499 | ACC 0.9553\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0930/0938 | LOSS: 0.1500 | ACC 0.9553\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0931/0938 | LOSS: 0.1501 | ACC 0.9552\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0932/0938 | LOSS: 0.1502 | ACC 0.9552\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0933/0938 | LOSS: 0.1502 | ACC 0.9552\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0934/0938 | LOSS: 0.1501 | ACC 0.9552\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0935/0938 | LOSS: 0.1502 | ACC 0.9551\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0936/0938 | LOSS: 0.1502 | ACC 0.9552\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0937/0938 | LOSS: 0.1503 | ACC 0.9551\n",
      "TRAIN: EPOCH 0010/0010 | BATCH 0938/0938 | LOSS: 0.1503 | ACC 0.9551\n"
     ]
    }
   ],
   "source": [
    "## 라이브러리 추가하기\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from torchvision import transforms, datasets\n",
    "\n",
    "## 트레이닝 필요한 파라메터를 설정하기\n",
    "lr = 1e-3\n",
    "batch_size = 64\n",
    "num_epoch = 10\n",
    "\n",
    "ckpt_dir = './checkpoint'\n",
    "log_dir = './log'\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "## 네트워크 구축하기\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=10, kernel_size=5, stride=1, padding=0, bias=True)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2)\n",
    "        self.relu1 = nn.ReLU()\n",
    "\n",
    "        self.conv2 = nn.Conv2d(in_channels=10, out_channels=20, kernel_size=5, stride=1, padding=0, bias=True)\n",
    "        self.drop2 = nn.Dropout2d(p=0.5)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2)\n",
    "        self.relu2 = nn.ReLU()\n",
    "\n",
    "        self.fc1 = nn.Linear(in_features=320, out_features=50, bias=True)\n",
    "        self.relu1_fc1 = nn.ReLU()\n",
    "        self.drop1_fc1 = nn.Dropout2d(p=0.5)\n",
    "\n",
    "        self.fc2 = nn.Linear(in_features=50, out_features=10, bias=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.relu1(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.drop2(x)\n",
    "        x = self.pool2(x)\n",
    "        x = self.relu2(x)\n",
    "\n",
    "        x = x.view(-1, 320)\n",
    "\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu1_fc1(x)\n",
    "        x = self.drop1_fc1(x)\n",
    "\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "## 네트워크를 저장하거나 불러오는 함수 작성하기\n",
    "def save(ckpt_dir, net, optim, epoch):\n",
    "    if not os.path.exists(ckpt_dir):\n",
    "        os.makedirs(ckpt_dir)\n",
    "\n",
    "    torch.save({'net': net.state_dict(), 'optim': optim.state_dict()},\n",
    "               './%s/model_epoch%d.pth' % (ckpt_dir, epoch))\n",
    "\n",
    "def load(ckpt_dir, net, optim):\n",
    "    ckpt_lst = os.listdir(ckpt_dir)\n",
    "    ckpt_lst.sort()\n",
    "\n",
    "    dict_model = torch.load('./%s/%s' % (ckpt_dir, ckpt_lst[-1]))\n",
    "\n",
    "    net.load_state_dict(dict_model['net'])\n",
    "    optim.load_state_dict(dict_model['optim'])\n",
    "\n",
    "    return net, optim\n",
    "\n",
    "## MNIST 데이터 불러오기\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize(mean=(0.5,), std=(0.5,))])\n",
    "\n",
    "dataset = datasets.MNIST(download=True, root='./', train=True, transform=transform)\n",
    "loader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "\n",
    "num_data = len(loader.dataset)\n",
    "num_batch = np.ceil(num_data / batch_size)\n",
    "\n",
    "## 네트워크 설정 및 필요한 손실함수 구현하기\n",
    "net = Net().to(device)\n",
    "params = net.parameters()\n",
    "\n",
    "fn_loss = nn.CrossEntropyLoss().to(device)\n",
    "fn_pred = lambda output: torch.softmax(output, dim=1)\n",
    "fn_acc = lambda pred, label: ((pred.max(dim=1)[1] == label).type(torch.float)).mean()\n",
    "\n",
    "optim = torch.optim.Adam(params, lr=lr)\n",
    "\n",
    "writer = SummaryWriter(log_dir=log_dir)\n",
    "\n",
    "## 트레이닝 시작하기\n",
    "for epoch in range(1, num_epoch + 1):\n",
    "    net.train()\n",
    "\n",
    "    loss_arr = []\n",
    "    acc_arr = []\n",
    "\n",
    "    for batch, (input, label) in enumerate(loader, 1):\n",
    "        input = input.to(device)\n",
    "        label = label.to(device)\n",
    "\n",
    "        output = net(input)\n",
    "        pred = fn_pred(output)\n",
    "\n",
    "\n",
    "        optim.zero_grad()\n",
    "\n",
    "        loss = fn_loss(output, label)\n",
    "        acc = fn_acc(pred, label)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optim.step()\n",
    "\n",
    "        loss_arr += [loss.item()]\n",
    "        acc_arr += [acc.item()]\n",
    "\n",
    "        print('TRAIN: EPOCH %04d/%04d | BATCH %04d/%04d | LOSS: %.4f | ACC %.4f' %\n",
    "              (epoch, num_epoch, batch, num_batch, np.mean(loss_arr), np.mean(acc_arr)))\n",
    "\n",
    "    writer.add_scalar('loss', np.mean(loss_arr), epoch)\n",
    "    writer.add_scalar('acc', np.mean(acc_arr), epoch)\n",
    "\n",
    "    save(ckpt_dir=ckpt_dir, net=net, optim=optim, epoch=epoch)\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST: BATCH 0001/0157 | LOSS: 0.0037 | ACC 1.0000\n",
      "TEST: BATCH 0002/0157 | LOSS: 0.0056 | ACC 1.0000\n",
      "TEST: BATCH 0003/0157 | LOSS: 0.0054 | ACC 1.0000\n",
      "TEST: BATCH 0004/0157 | LOSS: 0.0098 | ACC 0.9961\n",
      "TEST: BATCH 0005/0157 | LOSS: 0.0201 | ACC 0.9938\n",
      "TEST: BATCH 0006/0157 | LOSS: 0.0269 | ACC 0.9896\n",
      "TEST: BATCH 0007/0157 | LOSS: 0.0287 | ACC 0.9888\n",
      "TEST: BATCH 0008/0157 | LOSS: 0.0388 | ACC 0.9863\n",
      "TEST: BATCH 0009/0157 | LOSS: 0.0359 | ACC 0.9878\n",
      "TEST: BATCH 0010/0157 | LOSS: 0.0366 | ACC 0.9875\n",
      "TEST: BATCH 0011/0157 | LOSS: 0.0355 | ACC 0.9886\n",
      "TEST: BATCH 0012/0157 | LOSS: 0.0355 | ACC 0.9896\n",
      "TEST: BATCH 0013/0157 | LOSS: 0.0333 | ACC 0.9904\n",
      "TEST: BATCH 0014/0157 | LOSS: 0.0321 | ACC 0.9911\n",
      "TEST: BATCH 0015/0157 | LOSS: 0.0384 | ACC 0.9896\n",
      "TEST: BATCH 0016/0157 | LOSS: 0.0427 | ACC 0.9883\n",
      "TEST: BATCH 0017/0157 | LOSS: 0.0443 | ACC 0.9871\n",
      "TEST: BATCH 0018/0157 | LOSS: 0.0452 | ACC 0.9861\n",
      "TEST: BATCH 0019/0157 | LOSS: 0.0453 | ACC 0.9860\n",
      "TEST: BATCH 0020/0157 | LOSS: 0.0486 | ACC 0.9844\n",
      "TEST: BATCH 0021/0157 | LOSS: 0.0496 | ACC 0.9844\n",
      "TEST: BATCH 0022/0157 | LOSS: 0.0505 | ACC 0.9844\n",
      "TEST: BATCH 0023/0157 | LOSS: 0.0505 | ACC 0.9844\n",
      "TEST: BATCH 0024/0157 | LOSS: 0.0546 | ACC 0.9831\n",
      "TEST: BATCH 0025/0157 | LOSS: 0.0532 | ACC 0.9838\n",
      "TEST: BATCH 0026/0157 | LOSS: 0.0528 | ACC 0.9838\n",
      "TEST: BATCH 0027/0157 | LOSS: 0.0584 | ACC 0.9826\n",
      "TEST: BATCH 0028/0157 | LOSS: 0.0584 | ACC 0.9827\n",
      "TEST: BATCH 0029/0157 | LOSS: 0.0567 | ACC 0.9833\n",
      "TEST: BATCH 0030/0157 | LOSS: 0.0574 | ACC 0.9823\n",
      "TEST: BATCH 0031/0157 | LOSS: 0.0562 | ACC 0.9829\n",
      "TEST: BATCH 0032/0157 | LOSS: 0.0580 | ACC 0.9824\n",
      "TEST: BATCH 0033/0157 | LOSS: 0.0584 | ACC 0.9820\n",
      "TEST: BATCH 0034/0157 | LOSS: 0.0595 | ACC 0.9812\n",
      "TEST: BATCH 0035/0157 | LOSS: 0.0593 | ACC 0.9808\n",
      "TEST: BATCH 0036/0157 | LOSS: 0.0603 | ACC 0.9800\n",
      "TEST: BATCH 0037/0157 | LOSS: 0.0594 | ACC 0.9806\n",
      "TEST: BATCH 0038/0157 | LOSS: 0.0590 | ACC 0.9807\n",
      "TEST: BATCH 0039/0157 | LOSS: 0.0588 | ACC 0.9808\n",
      "TEST: BATCH 0040/0157 | LOSS: 0.0575 | ACC 0.9812\n",
      "TEST: BATCH 0041/0157 | LOSS: 0.0579 | ACC 0.9813\n",
      "TEST: BATCH 0042/0157 | LOSS: 0.0585 | ACC 0.9814\n",
      "TEST: BATCH 0043/0157 | LOSS: 0.0574 | ACC 0.9818\n",
      "TEST: BATCH 0044/0157 | LOSS: 0.0564 | ACC 0.9822\n",
      "TEST: BATCH 0045/0157 | LOSS: 0.0554 | ACC 0.9826\n",
      "TEST: BATCH 0046/0157 | LOSS: 0.0574 | ACC 0.9823\n",
      "TEST: BATCH 0047/0157 | LOSS: 0.0583 | ACC 0.9820\n",
      "TEST: BATCH 0048/0157 | LOSS: 0.0583 | ACC 0.9821\n",
      "TEST: BATCH 0049/0157 | LOSS: 0.0575 | ACC 0.9825\n",
      "TEST: BATCH 0050/0157 | LOSS: 0.0566 | ACC 0.9828\n",
      "TEST: BATCH 0051/0157 | LOSS: 0.0557 | ACC 0.9831\n",
      "TEST: BATCH 0052/0157 | LOSS: 0.0556 | ACC 0.9829\n",
      "TEST: BATCH 0053/0157 | LOSS: 0.0552 | ACC 0.9832\n",
      "TEST: BATCH 0054/0157 | LOSS: 0.0549 | ACC 0.9832\n",
      "TEST: BATCH 0055/0157 | LOSS: 0.0548 | ACC 0.9832\n",
      "TEST: BATCH 0056/0157 | LOSS: 0.0579 | ACC 0.9830\n",
      "TEST: BATCH 0057/0157 | LOSS: 0.0574 | ACC 0.9830\n",
      "TEST: BATCH 0058/0157 | LOSS: 0.0570 | ACC 0.9830\n",
      "TEST: BATCH 0059/0157 | LOSS: 0.0590 | ACC 0.9825\n",
      "TEST: BATCH 0060/0157 | LOSS: 0.0616 | ACC 0.9820\n",
      "TEST: BATCH 0061/0157 | LOSS: 0.0616 | ACC 0.9818\n",
      "TEST: BATCH 0062/0157 | LOSS: 0.0618 | ACC 0.9819\n",
      "TEST: BATCH 0063/0157 | LOSS: 0.0618 | ACC 0.9816\n",
      "TEST: BATCH 0064/0157 | LOSS: 0.0619 | ACC 0.9817\n",
      "TEST: BATCH 0065/0157 | LOSS: 0.0611 | ACC 0.9820\n",
      "TEST: BATCH 0066/0157 | LOSS: 0.0618 | ACC 0.9815\n",
      "TEST: BATCH 0067/0157 | LOSS: 0.0631 | ACC 0.9809\n",
      "TEST: BATCH 0068/0157 | LOSS: 0.0633 | ACC 0.9807\n",
      "TEST: BATCH 0069/0157 | LOSS: 0.0629 | ACC 0.9808\n",
      "TEST: BATCH 0070/0157 | LOSS: 0.0623 | ACC 0.9810\n",
      "TEST: BATCH 0071/0157 | LOSS: 0.0625 | ACC 0.9811\n",
      "TEST: BATCH 0072/0157 | LOSS: 0.0623 | ACC 0.9809\n",
      "TEST: BATCH 0073/0157 | LOSS: 0.0625 | ACC 0.9810\n",
      "TEST: BATCH 0074/0157 | LOSS: 0.0619 | ACC 0.9812\n",
      "TEST: BATCH 0075/0157 | LOSS: 0.0618 | ACC 0.9812\n",
      "TEST: BATCH 0076/0157 | LOSS: 0.0623 | ACC 0.9811\n",
      "TEST: BATCH 0077/0157 | LOSS: 0.0618 | ACC 0.9811\n",
      "TEST: BATCH 0078/0157 | LOSS: 0.0619 | ACC 0.9812\n",
      "TEST: BATCH 0079/0157 | LOSS: 0.0611 | ACC 0.9814\n",
      "TEST: BATCH 0080/0157 | LOSS: 0.0604 | ACC 0.9816\n",
      "TEST: BATCH 0081/0157 | LOSS: 0.0598 | ACC 0.9819\n",
      "TEST: BATCH 0082/0157 | LOSS: 0.0591 | ACC 0.9821\n",
      "TEST: BATCH 0083/0157 | LOSS: 0.0584 | ACC 0.9823\n",
      "TEST: BATCH 0084/0157 | LOSS: 0.0577 | ACC 0.9825\n",
      "TEST: BATCH 0085/0157 | LOSS: 0.0570 | ACC 0.9827\n",
      "TEST: BATCH 0086/0157 | LOSS: 0.0564 | ACC 0.9829\n",
      "TEST: BATCH 0087/0157 | LOSS: 0.0558 | ACC 0.9831\n",
      "TEST: BATCH 0088/0157 | LOSS: 0.0552 | ACC 0.9833\n",
      "TEST: BATCH 0089/0157 | LOSS: 0.0546 | ACC 0.9835\n",
      "TEST: BATCH 0090/0157 | LOSS: 0.0542 | ACC 0.9835\n",
      "TEST: BATCH 0091/0157 | LOSS: 0.0536 | ACC 0.9837\n",
      "TEST: BATCH 0092/0157 | LOSS: 0.0533 | ACC 0.9839\n",
      "TEST: BATCH 0093/0157 | LOSS: 0.0532 | ACC 0.9837\n",
      "TEST: BATCH 0094/0157 | LOSS: 0.0534 | ACC 0.9837\n",
      "TEST: BATCH 0095/0157 | LOSS: 0.0530 | ACC 0.9839\n",
      "TEST: BATCH 0096/0157 | LOSS: 0.0528 | ACC 0.9839\n",
      "TEST: BATCH 0097/0157 | LOSS: 0.0525 | ACC 0.9839\n",
      "TEST: BATCH 0098/0157 | LOSS: 0.0520 | ACC 0.9841\n",
      "TEST: BATCH 0099/0157 | LOSS: 0.0515 | ACC 0.9842\n",
      "TEST: BATCH 0100/0157 | LOSS: 0.0509 | ACC 0.9844\n",
      "TEST: BATCH 0101/0157 | LOSS: 0.0505 | ACC 0.9845\n",
      "TEST: BATCH 0102/0157 | LOSS: 0.0504 | ACC 0.9845\n",
      "TEST: BATCH 0103/0157 | LOSS: 0.0515 | ACC 0.9841\n",
      "TEST: BATCH 0104/0157 | LOSS: 0.0537 | ACC 0.9835\n",
      "TEST: BATCH 0105/0157 | LOSS: 0.0533 | ACC 0.9836\n",
      "TEST: BATCH 0106/0157 | LOSS: 0.0533 | ACC 0.9836\n",
      "TEST: BATCH 0107/0157 | LOSS: 0.0529 | ACC 0.9836\n",
      "TEST: BATCH 0108/0157 | LOSS: 0.0527 | ACC 0.9837\n",
      "TEST: BATCH 0109/0157 | LOSS: 0.0523 | ACC 0.9838\n",
      "TEST: BATCH 0110/0157 | LOSS: 0.0518 | ACC 0.9839\n",
      "TEST: BATCH 0111/0157 | LOSS: 0.0514 | ACC 0.9841\n",
      "TEST: BATCH 0112/0157 | LOSS: 0.0511 | ACC 0.9841\n",
      "TEST: BATCH 0113/0157 | LOSS: 0.0507 | ACC 0.9842\n",
      "TEST: BATCH 0114/0157 | LOSS: 0.0503 | ACC 0.9844\n",
      "TEST: BATCH 0115/0157 | LOSS: 0.0499 | ACC 0.9845\n",
      "TEST: BATCH 0116/0157 | LOSS: 0.0495 | ACC 0.9846\n",
      "TEST: BATCH 0117/0157 | LOSS: 0.0493 | ACC 0.9848\n",
      "TEST: BATCH 0118/0157 | LOSS: 0.0490 | ACC 0.9849\n",
      "TEST: BATCH 0119/0157 | LOSS: 0.0486 | ACC 0.9850\n",
      "TEST: BATCH 0120/0157 | LOSS: 0.0482 | ACC 0.9852\n",
      "TEST: BATCH 0121/0157 | LOSS: 0.0478 | ACC 0.9853\n",
      "TEST: BATCH 0122/0157 | LOSS: 0.0474 | ACC 0.9854\n",
      "TEST: BATCH 0123/0157 | LOSS: 0.0474 | ACC 0.9854\n",
      "TEST: BATCH 0124/0157 | LOSS: 0.0478 | ACC 0.9851\n",
      "TEST: BATCH 0125/0157 | LOSS: 0.0474 | ACC 0.9852\n",
      "TEST: BATCH 0126/0157 | LOSS: 0.0471 | ACC 0.9852\n",
      "TEST: BATCH 0127/0157 | LOSS: 0.0473 | ACC 0.9852\n",
      "TEST: BATCH 0128/0157 | LOSS: 0.0469 | ACC 0.9854\n",
      "TEST: BATCH 0129/0157 | LOSS: 0.0467 | ACC 0.9855\n",
      "TEST: BATCH 0130/0157 | LOSS: 0.0466 | ACC 0.9855\n",
      "TEST: BATCH 0131/0157 | LOSS: 0.0464 | ACC 0.9856\n",
      "TEST: BATCH 0132/0157 | LOSS: 0.0461 | ACC 0.9857\n",
      "TEST: BATCH 0133/0157 | LOSS: 0.0457 | ACC 0.9858\n",
      "TEST: BATCH 0134/0157 | LOSS: 0.0455 | ACC 0.9859\n",
      "TEST: BATCH 0135/0157 | LOSS: 0.0451 | ACC 0.9860\n",
      "TEST: BATCH 0136/0157 | LOSS: 0.0448 | ACC 0.9861\n",
      "TEST: BATCH 0137/0157 | LOSS: 0.0445 | ACC 0.9862\n",
      "TEST: BATCH 0138/0157 | LOSS: 0.0442 | ACC 0.9863\n",
      "TEST: BATCH 0139/0157 | LOSS: 0.0438 | ACC 0.9864\n",
      "TEST: BATCH 0140/0157 | LOSS: 0.0435 | ACC 0.9865\n",
      "TEST: BATCH 0141/0157 | LOSS: 0.0441 | ACC 0.9864\n",
      "TEST: BATCH 0142/0157 | LOSS: 0.0441 | ACC 0.9864\n",
      "TEST: BATCH 0143/0157 | LOSS: 0.0438 | ACC 0.9865\n",
      "TEST: BATCH 0144/0157 | LOSS: 0.0435 | ACC 0.9865\n",
      "TEST: BATCH 0145/0157 | LOSS: 0.0432 | ACC 0.9866\n",
      "TEST: BATCH 0146/0157 | LOSS: 0.0429 | ACC 0.9867\n",
      "TEST: BATCH 0147/0157 | LOSS: 0.0426 | ACC 0.9868\n",
      "TEST: BATCH 0148/0157 | LOSS: 0.0424 | ACC 0.9869\n",
      "TEST: BATCH 0149/0157 | LOSS: 0.0421 | ACC 0.9870\n",
      "TEST: BATCH 0150/0157 | LOSS: 0.0419 | ACC 0.9871\n",
      "TEST: BATCH 0151/0157 | LOSS: 0.0419 | ACC 0.9871\n",
      "TEST: BATCH 0152/0157 | LOSS: 0.0420 | ACC 0.9869\n",
      "TEST: BATCH 0153/0157 | LOSS: 0.0430 | ACC 0.9868\n",
      "TEST: BATCH 0154/0157 | LOSS: 0.0430 | ACC 0.9867\n",
      "TEST: BATCH 0155/0157 | LOSS: 0.0432 | ACC 0.9866\n",
      "TEST: BATCH 0156/0157 | LOSS: 0.0431 | ACC 0.9867\n",
      "TEST: BATCH 0157/0157 | LOSS: 0.0428 | ACC 0.9868\n"
     ]
    }
   ],
   "source": [
    "## 라이브러리 추가하기\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from torchvision import transforms, datasets\n",
    "\n",
    "## 트레이닝 필요한 파라메터를 설정하기\n",
    "lr = 1e-3\n",
    "batch_size = 64\n",
    "num_epoch = 10\n",
    "\n",
    "ckpt_dir = './checkpoint'\n",
    "log_dir = './log'\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "## 네트워크 구축하기\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=10, kernel_size=5, stride=1, padding=0, bias=True)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2)\n",
    "        self.relu1 = nn.ReLU()\n",
    "\n",
    "        self.conv2 = nn.Conv2d(in_channels=10, out_channels=20, kernel_size=5, stride=1, padding=0, bias=True)\n",
    "        self.drop2 = nn.Dropout2d(p=0.5)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2)\n",
    "        self.relu2 = nn.ReLU()\n",
    "\n",
    "        self.fc1 = nn.Linear(in_features=320, out_features=50, bias=True)\n",
    "        self.relu1_fc1 = nn.ReLU()\n",
    "        self.drop1_fc1 = nn.Dropout2d(p=0.5)\n",
    "\n",
    "        self.fc2 = nn.Linear(in_features=50, out_features=10, bias=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.relu1(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.drop2(x)\n",
    "        x = self.pool2(x)\n",
    "        x = self.relu2(x)\n",
    "\n",
    "        x = x.view(-1, 320)\n",
    "\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu1_fc1(x)\n",
    "        x = self.drop1_fc1(x)\n",
    "\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "## 네트워크를 저장하거나 불러오는 함수 작성하기\n",
    "def save(ckpt_dir, net, optim, epoch):\n",
    "    if not os.path.exists(ckpt_dir):\n",
    "        os.makedirs(ckpt_dir)\n",
    "\n",
    "    torch.save({'net': net.state_dict(), 'optim': optim.state_dict()},\n",
    "               './%s/model_epoch%d.pth' % (ckpt_dir, epoch))\n",
    "\n",
    "\n",
    "def load(ckpt_dir, net, optim):\n",
    "    ckpt_lst = os.listdir(ckpt_dir)\n",
    "    ckpt_lst.sort()\n",
    "\n",
    "    dict_model = torch.load('./%s/%s' % (ckpt_dir, ckpt_lst[-1]))\n",
    "\n",
    "    net.load_state_dict(dict_model['net'])\n",
    "    optim.load_state_dict(dict_model['optim'])\n",
    "\n",
    "    return net, optim\n",
    "\n",
    "\n",
    "## MNIST 데이터 불러오기\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize(mean=(0.5,), std=(0.5,))])\n",
    "\n",
    "dataset = datasets.MNIST(download=True, root='./', train=False, transform=transform)\n",
    "loader = DataLoader(dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "num_data = len(loader.dataset)\n",
    "num_batch = np.ceil(num_data / batch_size)\n",
    "\n",
    "## 네트워크 설정 및 필요한 손실함수 구현하기\n",
    "net = Net().to(device)\n",
    "params = net.parameters()\n",
    "\n",
    "fn_loss = nn.CrossEntropyLoss().to(device)\n",
    "fn_pred = lambda output: torch.softmax(output, dim=1)\n",
    "fn_acc = lambda pred, label: ((pred.max(dim=1)[1] == label).type(torch.float)).mean()\n",
    "\n",
    "optim = torch.optim.Adam(params, lr=lr)\n",
    "\n",
    "writer = SummaryWriter(log_dir=log_dir)\n",
    "\n",
    "net, optim = load(ckpt_dir=ckpt_dir, net=net, optim=optim)\n",
    "\n",
    "## 트레이닝 시작하기\n",
    "with torch.no_grad():\n",
    "    # net.train()\n",
    "    net.eval()\n",
    "\n",
    "    loss_arr = []\n",
    "    acc_arr = []\n",
    "\n",
    "    for batch, (input, label) in enumerate(loader, 1):\n",
    "        input = input.to(device)\n",
    "        label = label.to(device)\n",
    "\n",
    "        output = net(input)\n",
    "        pred = fn_pred(output)\n",
    "\n",
    "        loss = fn_loss(output, label)\n",
    "        acc = fn_acc(pred, label)\n",
    "\n",
    "        loss_arr += [loss.item()]\n",
    "        acc_arr += [acc.item()]\n",
    "\n",
    "        print('TEST: BATCH %04d/%04d | LOSS: %.4f | ACC %.4f' %\n",
    "              (batch, num_batch, np.mean(loss_arr), np.mean(acc_arr)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for UNet:\n\tMissing key(s) in state_dict: \"enc1_1.0.weight\", \"enc1_1.0.bias\", \"enc1_1.1.weight\", \"enc1_1.1.bias\", \"enc1_1.1.running_mean\", \"enc1_1.1.running_var\", \"enc1_2.0.weight\", \"enc1_2.0.bias\", \"enc1_2.1.weight\", \"enc1_2.1.bias\", \"enc1_2.1.running_mean\", \"enc1_2.1.running_var\", \"enc2_1.0.weight\", \"enc2_1.0.bias\", \"enc2_1.1.weight\", \"enc2_1.1.bias\", \"enc2_1.1.running_mean\", \"enc2_1.1.running_var\", \"enc2_2.0.weight\", \"enc2_2.0.bias\", \"enc2_2.1.weight\", \"enc2_2.1.bias\", \"enc2_2.1.running_mean\", \"enc2_2.1.running_var\", \"enc3_1.0.weight\", \"enc3_1.0.bias\", \"enc3_1.1.weight\", \"enc3_1.1.bias\", \"enc3_1.1.running_mean\", \"enc3_1.1.running_var\", \"enc3_2.0.weight\", \"enc3_2.0.bias\", \"enc3_2.1.weight\", \"enc3_2.1.bias\", \"enc3_2.1.running_mean\", \"enc3_2.1.running_var\", \"enc4_1.0.weight\", \"enc4_1.0.bias\", \"enc4_1.1.weight\", \"enc4_1.1.bias\", \"enc4_1.1.running_mean\", \"enc4_1.1.running_var\", \"enc4_2.0.weight\", \"enc4_2.0.bias\", \"enc4_2.1.weight\", \"enc4_2.1.bias\", \"enc4_2.1.running_mean\", \"enc4_2.1.running_var\", \"enc5_1.0.weight\", \"enc5_1.0.bias\", \"enc5_1.1.weight\", \"enc5_1.1.bias\", \"enc5_1.1.running_mean\", \"enc5_1.1.running_var\", \"dec5_1.0.weight\", \"dec5_1.0.bias\", \"dec5_1.1.weight\", \"dec5_1.1.bias\", \"dec5_1.1.running_mean\", \"dec5_1.1.running_var\", \"unpool4.weight\", \"unpool4.bias\", \"dec4_2.0.weight\", \"dec4_2.0.bias\", \"dec4_2.1.weight\", \"dec4_2.1.bias\", \"dec4_2.1.running_mean\", \"dec4_2.1.running_var\", \"dec4_1.0.weight\", \"dec4_1.0.bias\", \"dec4_1.1.weight\", \"dec4_1.1.bias\", \"dec4_1.1.running_mean\", \"dec4_1.1.running_var\", \"unpool3.weight\", \"unpool3.bias\", \"dec3_2.0.weight\", \"dec3_2.0.bias\", \"dec3_2.1.weight\", \"dec3_2.1.bias\", \"dec3_2.1.running_mean\", \"dec3_2.1.running_var\", \"dec3_1.0.weight\", \"dec3_1.0.bias\", \"dec3_1.1.weight\", \"dec3_1.1.bias\", \"dec3_1.1.running_mean\", \"dec3_1.1.running_var\", \"unpool2.weight\", \"unpool2.bias\", \"dec2_2.0.weight\", \"dec2_2.0.bias\", \"dec2_2.1.weight\", \"dec2_2.1.bias\", \"dec2_2.1.running_mean\", \"dec2_2.1.running_var\", \"dec2_1.0.weight\", \"dec2_1.0.bias\", \"dec2_1.1.weight\", \"dec2_1.1.bias\", \"dec2_1.1.running_mean\", \"dec2_1.1.running_var\", \"unpool1.weight\", \"unpool1.bias\", \"dec1_2.0.weight\", \"dec1_2.0.bias\", \"dec1_2.1.weight\", \"dec1_2.1.bias\", \"dec1_2.1.running_mean\", \"dec1_2.1.running_var\", \"dec1_1.0.weight\", \"dec1_1.0.bias\", \"dec1_1.1.weight\", \"dec1_1.1.bias\", \"dec1_1.1.running_mean\", \"dec1_1.1.running_var\", \"fc.weight\", \"fc.bias\". \n\tUnexpected key(s) in state_dict: \"conv1.weight\", \"conv1.bias\", \"conv2.weight\", \"conv2.bias\", \"fc1.weight\", \"fc1.bias\", \"fc2.weight\", \"fc2.bias\". ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-cc8ce851d4e5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    299\u001b[0m \u001b[1;31m## 네트워크 학습시키기\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    300\u001b[0m \u001b[0mst_epoch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 301\u001b[1;33m \u001b[0mnet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mst_epoch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mckpt_dir\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mckpt_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    302\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    303\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mst_epoch\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_epoch\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-cc8ce851d4e5>\u001b[0m in \u001b[0;36mload\u001b[1;34m(ckpt_dir, net, optim)\u001b[0m\n\u001b[0;32m    291\u001b[0m     \u001b[0mdict_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./%s/%s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mckpt_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mckpt_lst\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    292\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 293\u001b[1;33m     \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdict_model\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'net'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    294\u001b[0m     \u001b[0moptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdict_model\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'optim'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    295\u001b[0m     \u001b[0mepoch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mckpt_lst\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'epoch'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'pth'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[1;34m(self, state_dict, strict)\u001b[0m\n\u001b[0;32m   1043\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1044\u001b[0m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[1;32m-> 1045\u001b[1;33m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[0m\u001b[0;32m   1046\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1047\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for UNet:\n\tMissing key(s) in state_dict: \"enc1_1.0.weight\", \"enc1_1.0.bias\", \"enc1_1.1.weight\", \"enc1_1.1.bias\", \"enc1_1.1.running_mean\", \"enc1_1.1.running_var\", \"enc1_2.0.weight\", \"enc1_2.0.bias\", \"enc1_2.1.weight\", \"enc1_2.1.bias\", \"enc1_2.1.running_mean\", \"enc1_2.1.running_var\", \"enc2_1.0.weight\", \"enc2_1.0.bias\", \"enc2_1.1.weight\", \"enc2_1.1.bias\", \"enc2_1.1.running_mean\", \"enc2_1.1.running_var\", \"enc2_2.0.weight\", \"enc2_2.0.bias\", \"enc2_2.1.weight\", \"enc2_2.1.bias\", \"enc2_2.1.running_mean\", \"enc2_2.1.running_var\", \"enc3_1.0.weight\", \"enc3_1.0.bias\", \"enc3_1.1.weight\", \"enc3_1.1.bias\", \"enc3_1.1.running_mean\", \"enc3_1.1.running_var\", \"enc3_2.0.weight\", \"enc3_2.0.bias\", \"enc3_2.1.weight\", \"enc3_2.1.bias\", \"enc3_2.1.running_mean\", \"enc3_2.1.running_var\", \"enc4_1.0.weight\", \"enc4_1.0.bias\", \"enc4_1.1.weight\", \"enc4_1.1.bias\", \"enc4_1.1.running_mean\", \"enc4_1.1.running_var\", \"enc4_2.0.weight\", \"enc4_2.0.bias\", \"enc4_2.1.weight\", \"enc4_2.1.bias\", \"enc4_2.1.running_mean\", \"enc4_2.1.running_var\", \"enc5_1.0.weight\", \"enc5_1.0.bias\", \"enc5_1.1.weight\", \"enc5_1.1.bias\", \"enc5_1.1.running_mean\", \"enc5_1.1.running_var\", \"dec5_1.0.weight\", \"dec5_1.0.bias\", \"dec5_1.1.weight\", \"dec5_1.1.bias\", \"dec5_1.1.running_mean\", \"dec5_1.1.running_var\", \"unpool4.weight\", \"unpool4.bias\", \"dec4_2.0.weight\", \"dec4_2.0.bias\", \"dec4_2.1.weight\", \"dec4_2.1.bias\", \"dec4_2.1.running_mean\", \"dec4_2.1.running_var\", \"dec4_1.0.weight\", \"dec4_1.0.bias\", \"dec4_1.1.weight\", \"dec4_1.1.bias\", \"dec4_1.1.running_mean\", \"dec4_1.1.running_var\", \"unpool3.weight\", \"unpool3.bias\", \"dec3_2.0.weight\", \"dec3_2.0.bias\", \"dec3_2.1.weight\", \"dec3_2.1.bias\", \"dec3_2.1.running_mean\", \"dec3_2.1.running_var\", \"dec3_1.0.weight\", \"dec3_1.0.bias\", \"dec3_1.1.weight\", \"dec3_1.1.bias\", \"dec3_1.1.running_mean\", \"dec3_1.1.running_var\", \"unpool2.weight\", \"unpool2.bias\", \"dec2_2.0.weight\", \"dec2_2.0.bias\", \"dec2_2.1.weight\", \"dec2_2.1.bias\", \"dec2_2.1.running_mean\", \"dec2_2.1.running_var\", \"dec2_1.0.weight\", \"dec2_1.0.bias\", \"dec2_1.1.weight\", \"dec2_1.1.bias\", \"dec2_1.1.running_mean\", \"dec2_1.1.running_var\", \"unpool1.weight\", \"unpool1.bias\", \"dec1_2.0.weight\", \"dec1_2.0.bias\", \"dec1_2.1.weight\", \"dec1_2.1.bias\", \"dec1_2.1.running_mean\", \"dec1_2.1.running_var\", \"dec1_1.0.weight\", \"dec1_1.0.bias\", \"dec1_1.1.weight\", \"dec1_1.1.bias\", \"dec1_1.1.running_mean\", \"dec1_1.1.running_var\", \"fc.weight\", \"fc.bias\". \n\tUnexpected key(s) in state_dict: \"conv1.weight\", \"conv1.bias\", \"conv2.weight\", \"conv2.bias\", \"fc1.weight\", \"fc1.bias\", \"fc2.weight\", \"fc2.bias\". "
     ]
    }
   ],
   "source": [
    "## 라이브러리 추가하기\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torchvision import transforms, datasets\n",
    "\n",
    "## 트레이닝 파라메터 설정하기\n",
    "lr = 1e-3\n",
    "batch_size = 4\n",
    "num_epoch = 100\n",
    "\n",
    "data_dir = './datasets'\n",
    "ckpt_dir = './checkpoint'\n",
    "log_dir = './log'\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "## 네트워크 구축하기\n",
    "class  UNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(UNet, self).__init__()\n",
    "\n",
    "        def CBR2d(in_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=True):\n",
    "            layers = []\n",
    "            layers += [nn.Conv2d(in_channels=in_channels, out_channels=out_channels,\n",
    "                                 kernel_size=kernel_size, stride=stride,\n",
    "                                 bias=bias)]\n",
    "            layers += [nn.BatchNorm2d(num_features=out_channels)]\n",
    "            layers += [nn.ReLU()]\n",
    "\n",
    "            cbr = nn.Sequential(*layers)\n",
    "\n",
    "            return cbr\n",
    "\n",
    "        # Contracting path\n",
    "        self.enc1_1 = CBR2d(in_channels=1, out_channels=64)\n",
    "        self.enc1_2 = CBR2d(in_channels=64, out_channels=64)\n",
    "\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2)\n",
    "\n",
    "        self.enc2_1 = CBR2d(in_channels=64, out_channels=128)\n",
    "        self.enc2_2 = CBR2d(in_channels=128, out_channels=128)\n",
    "\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2)\n",
    "\n",
    "        self.enc3_1 = CBR2d(in_channels=128, out_channels=256)\n",
    "        self.enc3_2 = CBR2d(in_channels=256, out_channels=256)\n",
    "\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2)\n",
    "\n",
    "        self.enc4_1 = CBR2d(in_channels=256, out_channels=512)\n",
    "        self.enc4_2 = CBR2d(in_channels=512, out_channels=512)\n",
    "\n",
    "        self.pool4 = nn.MaxPool2d(kernel_size=2)\n",
    "\n",
    "        self.enc5_1 = CBR2d(in_channels=512, out_channels=1024)\n",
    "\n",
    "        # Expansive path\n",
    "        self.dec5_1 = CBR2d(in_channels=1024, out_channels=512)\n",
    "\n",
    "        self.unpool4 = nn.ConvTranspose2d(in_channels=512, out_channels=512,\n",
    "                                          kernel_size=2, stride=2, padding=0, bias=True)\n",
    "\n",
    "        self.dec4_2 = CBR2d(in_channels=2 * 512, out_channels=512)\n",
    "        self.dec4_1 = CBR2d(in_channels=512, out_channels=256)\n",
    "\n",
    "        self.unpool3 = nn.ConvTranspose2d(in_channels=256, out_channels=256,\n",
    "                                          kernel_size=2, stride=2, padding=0, bias=True)\n",
    "\n",
    "        self.dec3_2 = CBR2d(in_channels=2 * 256, out_channels=256)\n",
    "        self.dec3_1 = CBR2d(in_channels=256, out_channels=128)\n",
    "\n",
    "        self.unpool2 = nn.ConvTranspose2d(in_channels=128, out_channels=128,\n",
    "                                          kernel_size=2, stride=2, padding=0, bias=True)\n",
    "\n",
    "        self.dec2_2 = CBR2d(in_channels=2 * 128, out_channels=128)\n",
    "        self.dec2_1 = CBR2d(in_channels=128, out_channels=64)\n",
    "\n",
    "        self.unpool1 = nn.ConvTranspose2d(in_channels=64, out_channels=64,\n",
    "                                          kernel_size=2, stride=2, padding=0, bias=True)\n",
    "\n",
    "        self.dec1_2 = CBR2d(in_channels=2 * 64, out_channels=64)\n",
    "        self.dec1_1 = CBR2d(in_channels=64, out_channels=64)\n",
    "\n",
    "        self.fc = nn.Conv2d(in_channels=64, out_channels=1, kernel_size=1, stride=1, padding=0, bias=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        enc1_1 = self.enc1_1(x)\n",
    "        enc1_2 = self.enc1_2(enc1_1)\n",
    "        pool1 = self.pool1(enc1_2)\n",
    "\n",
    "        enc2_1 = self.enc2_1(pool1)\n",
    "        enc2_2 = self.enc2_2(enc2_1)\n",
    "        pool2 = self.pool2(enc2_2)\n",
    "\n",
    "        enc3_1 = self.enc3_1(pool2)\n",
    "        enc3_2 = self.enc3_2(enc3_1)\n",
    "        pool3 = self.pool3(enc3_2)\n",
    "\n",
    "        enc4_1 = self.enc4_1(pool3)\n",
    "        enc4_2 = self.enc4_2(enc4_1)\n",
    "        pool4 = self.pool4(enc4_2)\n",
    "\n",
    "        enc5_1 = self.enc5_1(pool4)\n",
    "\n",
    "\n",
    "        dec5_1 = self.dec5_1(enc5_1)\n",
    "\n",
    "        unpool4 = self.unpool4(dec5_1)\n",
    "        cat4 = torch.cat((unpool4, enc4_2), dim=1)\n",
    "        dec4_2 = self.dec4_2(cat4)\n",
    "        dec4_1 = self.dec4_1(dec4_2)\n",
    "\n",
    "        unpool3 = self.unpool3(dec4_1)\n",
    "        cat3 = torch.cat((unpool3, enc3_2), dim=1)\n",
    "        dec3_2 = self.dec3_2(cat3)\n",
    "        dec3_1 = self.dec3_1(dec3_2)\n",
    "\n",
    "        unpool2 = self.unpool2(dec3_1)\n",
    "        cat2 = torch.cat((unpool2, enc2_2), dim=1)\n",
    "        dec2_2 = self.dec2_2(cat2)\n",
    "        dec2_1 = self.dec2_1(dec2_2)\n",
    "\n",
    "        unpool1 = self.unpool1(dec2_1)\n",
    "        cat1 = torch.cat((unpool1, enc1_1), dim=1)\n",
    "        dec1_2 = self.dec1_2(cat1)\n",
    "        dec1_1 = self.dec1_1(dec1_2)\n",
    "\n",
    "        x = self.fc(dec1_1)\n",
    "\n",
    "        return x\n",
    "\n",
    "## 데이터 로더를 구현하기\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data_dir, transform=None):\n",
    "        self.data_dir = data_dir\n",
    "        self.transform =transform\n",
    "\n",
    "        lst_data = os.listdir(self.data_dir)\n",
    "\n",
    "        lst_label = [f for f in lst_data if f.startswith('label')]\n",
    "        lst_input = [f for f in lst_data if f.startswith('input')]\n",
    "\n",
    "        lst_label.sort()\n",
    "        lst_input.sort()\n",
    "\n",
    "        self.lst_label = lst_label\n",
    "        self.lst_input = lst_input\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.lst_label)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        label = np.load(os.path.join(self.data_dir, self.lst_label[index]))\n",
    "        input = np.load(os.path.join(self.data_dir, self.lst_input[index]))\n",
    "\n",
    "        label = label/255.0\n",
    "        input = input/255.0\n",
    "\n",
    "        if label.ndim == 2:\n",
    "            label = label[:, :, np.newaxis]\n",
    "        if label.ndim == 2:\n",
    "            input = input[:, :, np.newaxis]\n",
    "\n",
    "        data = {'input': input, 'label': label}\n",
    "\n",
    "        if self.transform:\n",
    "            data = self.transform(data)\n",
    "\n",
    "        return data\n",
    "\n",
    "\n",
    "# ##\n",
    "# dataset_train = Dataset(data_dir=os.path.join(data_dir, 'train'))\n",
    "#\n",
    "# ##\n",
    "# data = dataset_train.__getitem__(0)\n",
    "#\n",
    "# input = data['input']\n",
    "# label = data['label']\n",
    "#\n",
    "# ##\n",
    "# plt.subplot(121)\n",
    "# plt.imshow(input.squeeze())\n",
    "#\n",
    "# plt.subplot(122)\n",
    "# plt.imshow(label.squeeze())\n",
    "#\n",
    "# plt.show()\n",
    "\n",
    "## 트랜스폼 구현하기\n",
    "\n",
    "class ToTensor(object):\n",
    "    def __call__(self, data):\n",
    "        label, input = data['label'], data['input']\n",
    "\n",
    "        label = label.transpose((2, 0, 1)).astype(np.float32)\n",
    "        input = label.transpose((2, 0, 1)).astype(np.float32)\n",
    "\n",
    "        data = {'label': torch.from_numpy(label), 'input': torch.from_numpy(input)}\n",
    "\n",
    "        return data\n",
    "class Nomalization(object):\n",
    "    def __init__(self, mean=0.5, std=0.5):\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "\n",
    "    def __call__(self, data):\n",
    "        label, input = data['label'], data['input']\n",
    "\n",
    "        input = (input - self.mean) / self.std\n",
    "\n",
    "        data = {'label': label, 'input': input}\n",
    "\n",
    "        return data\n",
    "\n",
    "class RandomFlip(object):\n",
    "    def __call__(self, data):\n",
    "        label, input = data['label'], data['input']\n",
    "\n",
    "        if np.random.rand() > 0.5:\n",
    "            label = np.fliplr(label)\n",
    "            input = np.fliplr(input)\n",
    "\n",
    "        if np.random.rand() > 0.5:\n",
    "            label = np.flipud(label)\n",
    "            input = np.flipud(input)\n",
    "\n",
    "        data = {'label': label, 'input': input}\n",
    "\n",
    "        return data\n",
    "\n",
    "## 네트워크 학습하기\n",
    "transform = transforms.Compose([Nomalization(mean=0.5, std=0.5), RandomFlip(), ToTensor()])\n",
    "\n",
    "dataset_train = Dataset(data_dir=os.path.join(data_dir, 'train'), transform=transform)\n",
    "loader_train = DataLoader(dataset_train, batch_size=batch_size, shuffle=True, num_workers=8)\n",
    "\n",
    "dataset_val = Dataset(data_dir=os.path.join(data_dir, 'val'), transform=transform)\n",
    "loader_val = DataLoader(dataset_val, batch_size=batch_size, shuffle=False, num_workers=8)\n",
    "\n",
    "## 네트워크 생성하기\n",
    "net = UNet().to(device)\n",
    "\n",
    "## 손실함수 정의하기\n",
    "fn_loss = nn.BCEWithLogitsLoss().to(device)\n",
    "\n",
    "## Optimizer 설정하기\n",
    "optim = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "\n",
    "## 그밖에 부수적인 variables 설정하기\n",
    "num_data_train = len(dataset_train)\n",
    "num_data_val = len(dataset_val)\n",
    "\n",
    "num_batch_train = np.ceil(num_data_train / batch_size)\n",
    "num_batch_val = np.ceil(num_data_val / batch_size)\n",
    "\n",
    "## 그밖에 부수적인 functions 설정하기\n",
    "fn_tonumpy = lambda x: x.to('cpu').detach().numpy().transpose(0, 2, 3, 1)\n",
    "fn_denorm = lambda x, mean, std: (x * std) + mean\n",
    "fn_class = lambda x: 1.0 * (x > 0.5)\n",
    "\n",
    "## Tensorboard 를 사용하기 위한 SummaryWriter 설정\n",
    "writer_train = SummaryWriter(log_dir=os.path.join(log_dir, 'train'))\n",
    "writer_val = SummaryWriter(log_dir=os.path.join(log_dir, 'val'))\n",
    "\n",
    "## 네트워크 저장하기\n",
    "def save(ckpt_dir, net, optim, epoch):\n",
    "    if not os.path.exists(ckpt_dir):\n",
    "        os.makedirs(ckpt_dir)\n",
    "\n",
    "    torch.save({'net': net.state_dict(), 'optim': optim.state_dict()},\n",
    "               \"./%s/model_epoch%d.pth\" % (ckpt_dir, epoch))\n",
    "\n",
    "## 네트워크 불러오기\n",
    "def load(ckpt_dir, net, optim):\n",
    "    if not os.path.exists(ckpt_dir):\n",
    "        epoch = 0\n",
    "        return net, optim, epoch\n",
    "\n",
    "    ckpt_lst = os.listdir(ckpt_dir)\n",
    "    ckpt_lst.sort(key=lambda f: int(''.join(filter(str.isdigit, f))))\n",
    "\n",
    "    dict_model = torch.load('./%s/%s' % (ckpt_dir, ckpt_lst[-1]))\n",
    "\n",
    "    net.load_state_dict(dict_model['net'])\n",
    "    optim.load_state_dict(dict_model['optim'])\n",
    "    epoch = int(ckpt_lst[-1].split('epoch')[1].split('pth')[0])\n",
    "\n",
    "    return net, optim, epoch\n",
    "\n",
    "## 네트워크 학습시키기\n",
    "st_epoch = 0\n",
    "net, optim, st_epoch = load(ckpt_dir=ckpt_dir, net=net, optim=optim)\n",
    "\n",
    "for epoch in range(st_epoch + 1, num_epoch + 1):\n",
    "    net.train()\n",
    "    loss_arr = []\n",
    "\n",
    "    for batch, data in enumerate(loader_train, 1):\n",
    "        label = data['label'].to(device)\n",
    "        input = data['input'].to(device)\n",
    "\n",
    "        output = net(input)\n",
    "\n",
    "        # backward pass\n",
    "        optim.zero_grad()\n",
    "\n",
    "        loss = fn_loss(output, label)\n",
    "        loss.backward()\n",
    "\n",
    "        optim.step()\n",
    "\n",
    "        # 손실함수 계산\n",
    "        loss_arr += [loss.item()]\n",
    "\n",
    "        print(\"TRAIN: EPOCH %04d / %04d | BATCH %04d / %04d | LOSS %.4f\" %\n",
    "              (epoch, num_epoch, batch, num_batch_train, np.mean(loss_arr)))\n",
    "\n",
    "        # Tensorboard 저장하기\n",
    "        label = fn_tonumpy(label)\n",
    "        input = fn_tonumpy(fn_denorm(input, mean=0.5, std=0.5))\n",
    "        output = fn_tonumpy(fn_class(output))\n",
    "\n",
    "        writer_train.add_image('label', label, num_batch_train * (epoch - 1) + batch, dataformats='NHWC')\n",
    "        writer_train.add_image('input', input, num_batch_train * (epoch - 1) + batch, dataformats='NHWC')\n",
    "        writer_train.add_image('output', output, num_batch_train * (epoch - 1) + batch, dataformats='NHWC')\n",
    "\n",
    "    writer_train.add_scalar('loss', np.mean(loss_arr), epoch)\n",
    "\n",
    "\n",
    "    with torch.no_grad():\n",
    "        net.eval()\n",
    "        loss_arr = []\n",
    "\n",
    "        for batch, data in enumerate(loader_val, 1):\n",
    "            # forward pass\n",
    "            label = data['label'].to(device)\n",
    "            input = data['input'].to(device)\n",
    "\n",
    "            output = net(input)\n",
    "\n",
    "            #손실함수 계산하기\n",
    "            loss = fn_loss(output, label)\n",
    "\n",
    "            loss_arr += [loss.item()]\n",
    "\n",
    "            print(\"VALID: EPOCH %04d / %04d | BATCH %04d / %04d | LOSS %.4f\" %\n",
    "                  (epoch, num_epoch, batch, num_batch_val, np.mean(loss_arr)))\n",
    "\n",
    "            # Tensorboard 저장하기\n",
    "            label = fn_tonumpy(label)\n",
    "            input = fn_tonumpy(fn_denorm(input))\n",
    "            output = fn_tonumpy(fn_class(output))\n",
    "\n",
    "            writer_val.add_image('label', label, num_batch_val * (epoch - 1) + batch, dataformats='NHWC')\n",
    "            writer_val.add_image('input', input, num_batch_val * (epoch - 1) + batch, dataformats='NHWC')\n",
    "            writer_val.add_image('output', output, num_batch_val * (epoch - 1) + batch, dataformats='NHWC')\n",
    "\n",
    "    writer_val.add_scalar('loss', np.mean(loss_arr), epoch)\n",
    "\n",
    "    if epoch % 50 == 0:\n",
    "        save(ckpt_dir=ckpt_dir, net=net, optim=optim, epoch=epoch)\n",
    "\n",
    "writer_train.close()\n",
    "writer_val.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
