{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tooth_CNN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KyungRyeolBaek/study/blob/main/tooth_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7kcfNgCUt_k2"
      },
      "source": [
        "# tooth_CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VKyLcNd9hX75"
      },
      "source": [
        "# parameter\n",
        "image_num = 9                                 # 전체 이미지 개수\n",
        "train_image_num = [1, 2, 3, 4, 5, 6, 7, 8]    # 트레이닝 이미지 범위 [1, 2, 3, 4, 5, 6, 7, 8]\n",
        "test_image_num = 0                            # 테스트 이미지 숫자 [0]\n",
        "X_shape = [6, 6]                              # X 형태 [행, 열] -> 트레이닝 크기\n",
        "y_shape = 5                                   # y 형태 -> 트레이닝 결과 크기\n",
        "y_test_range = [120, 125]                     # y_test 예측 범위 [120 ~ 125]\n",
        "epoch = 1000                                  # epoch 횟수\n",
        "\n",
        "\n",
        "def tooth_CNN(image_num = image_num, train_image_num = train_image_num, test_image_num = test_image_num, X_shape = X_shape, y_shape = y_shape, y_test_range = y_test_range, epoch = epoch):\n",
        "  import tensorflow as tf\n",
        "  import pandas as pd\n",
        "  import matplotlib.pyplot as plt\n",
        "  import numpy as np\n",
        "  import math\n",
        "  from tensorflow.keras import datasets, layers, models\n",
        "  \n",
        "  for num in range(0, image_num): \n",
        "    globals()['df{}'.format(num)] = pd.read_table('./images/sino_examples/sino_{}.txt'.format(num),sep=',', header = None)\n",
        "    globals()['df{}'.format(num)] = globals()['df{}'.format(num)] / math.ceil(globals()['df{}'.format(num)].max().max())\n",
        "\n",
        "  # train셋, test셋으로 나누어 줍니다. X는 입력 변수, y는 출력 변수\n",
        "  X_train_org, X_test_org, y_train_org, y_test_org = [], [], [], []\n",
        "\n",
        "  # X 형태 (3+3, 6), y 형태 (5)\n",
        "  for num in train_image_num:\n",
        "    for i in range(360 - X_shape[1]):\n",
        "      for j in range(256 - (int(2*X_shape[0]/2) + y_shape)):\n",
        "        X_train_org.append(pd.concat([globals()['df{}'.format(num)].iloc[j:j+int(X_shape[0]/2), 0+i:X_shape[1]+i], globals()['df{}'.format(num)].iloc[j+int(X_shape[0]/2)+y_shape:j+int(X_shape[0]/2)+y_shape+int(X_shape[0]/2), 0+i:X_shape[1]+i]], axis = 0))\n",
        "        y_train_org.append(globals()['df{}'.format(num)].iloc[j+int(X_shape[0]/2):j+int(X_shape[0]/2)+y_shape, i+int(X_shape[0]/2)])\n",
        "\n",
        "  for i in range(360 - X_shape[1]):\n",
        "    X_test_org.append(pd.concat([globals()['df{}'.format(test_image_num)].iloc[y_test_range[0] - int(X_shape[0]/2):y_test_range[0], 0+i:X_shape[1]+i], globals()['df{}'.format(test_image_num)].iloc[y_test_range[1]:y_test_range[1] + int(X_shape[0]/2), 0+i:X_shape[1]+i]], axis = 0))\n",
        "    y_test_org.append(globals()['df{}'.format(test_image_num)].iloc[y_test_range[0]:y_test_range[1], i+int(X_shape[0]/2)])\n",
        "\n",
        "  X_train_org, X_test_org, y_train_org, y_test_org = np.array(X_train_org), np.array(X_test_org), np.array(y_train_org), np.array(y_test_org)\n",
        "\n",
        "  # RGB 값을 추가 합니다. 우선 흑백으로 설정 하였습니다.\n",
        "  # train 형태 : ((8*354*245, 6, 6, 1)), test 형태 : ((354, 6, 6, 1))\n",
        "  # tensorflow는 3차원만 지원하므로 3차원 형태로 reshape 해줘야 합니다.\n",
        "  X_train = X_train_org.reshape((len(train_image_num)*(360-X_shape[1])*(256-X_shape[0]-y_shape), X_shape[0], X_shape[1], 1))\n",
        "  X_test = X_test_org.reshape(((360-X_shape[1]), X_shape[0], X_shape[1], 1))\n",
        "  y_train = y_train_org\n",
        "  y_test = y_test_org\n",
        "\n",
        "  model = models.Sequential()\n",
        "  model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(X_shape[0], X_shape[1], 1)))\n",
        "  # MaxPooling2D(filter)\n",
        "  # model.add(layers.MaxPooling2D((2, 2)))\n",
        "  model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "  # model.add(layers.MaxPooling2D((2, 2)))\n",
        "  # model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "\n",
        "  model.add(layers.Flatten())\n",
        "  model.add(layers.Dense(64, activation='relu'))\n",
        "  model.add(layers.Dense(5))\n",
        "  model.summary()\n",
        "\n",
        "  # model 구성\n",
        "  model.compile(optimizer='adam',\n",
        "                loss='mse',\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "  model.fit(X_test, y_test, epochs=epoch, verbose = 0)\n",
        "\n",
        "  test_loss, test_acc = model.evaluate(X_test,  y_test, verbose=2)      # test 데이터를 넣었을 때의 loss, acc\n",
        "  print(test_acc)   # 정확도\n",
        "\n",
        "  # 모델 예측\n",
        "  pred = model.predict(X_test)    # 예측 데이터를 ()안에 넣으면 됩니다.\n",
        "\n",
        "  figure, axes = plt.subplots(nrows=2, ncols=2, figsize = (35, 15))\n",
        "  axes[0][0].set_title('Test Image')\n",
        "  axes[0][0].imshow(y_test_org.T)\n",
        "  axes[0][1].set_title('Pred Image')\n",
        "  axes[0][1].imshow(pred.T)\n",
        "  axes[1][0].set_title('Test Image')\n",
        "  axes[1][0].imshow(globals()['df{}'.format(test_image_num)])\n",
        "  df_test_img = globals()['df{}'.format(test_image_num)]\n",
        "  df_test_img.iloc[y_test_range[0]:y_test_range[1], 0+int(X_shape[1]/2):360-int(X_shape[1]/2)] = pred.T\n",
        "  axes[1][1].set_title('Pred Image')\n",
        "  axes[1][1].imshow(df_test_img)\n",
        "  figure.colorbar;\n",
        "\n",
        "  figure.tight_layout()\n",
        "  plt.show()"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        },
        "id": "wwOLoe28mOJa",
        "outputId": "2c7d574d-74a1-4c0e-bf90-6bc872f77731"
      },
      "source": [
        "# parameter\n",
        "image_num = 9                                 # 전체 이미지 개수\n",
        "train_image_num = [1, 2, 3, 4, 5, 6, 7, 8]    # 트레이닝 이미지 범위 [1, 2, 3, 4, 5, 6, 7, 8]\n",
        "test_image_num = 0                            # 테스트 이미지 숫자 [0]\n",
        "X_shape = [21, 20]                            # X 형태 [행, 열] -> 트레이닝 크기\n",
        "y_shape = 5                                   # y 형태 -> 트레이닝 결과 크기\n",
        "y_test_range = [120, 125]                     # y_test 예측 범위 [120 ~ 125]\n",
        "epoch = 1000                                  # epoch 횟수\n",
        "\n",
        "tooth_CNN(image_num = image_num, train_image_num = train_image_num, test_image_num = test_image_num, X_shape = X_shape, y_shape = y_shape, y_test_range = y_test_range, epoch = epoch)"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-66-cb18981a4aaf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1000\u001b[0m                                  \u001b[0;31m# epoch 횟수\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mtooth_CNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_num\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_image_num\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_image_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_image_num\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_image_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test_range\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_test_range\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-65-9659b5dc64b6>\u001b[0m in \u001b[0;36mtooth_CNN\u001b[0;34m(image_num, train_image_num, test_image_num, X_shape, y_shape, y_test_range, epoch)\u001b[0m\n\u001b[1;32m     40\u001b[0m   \u001b[0;31m# train 형태 : ((8*354*245, 6, 6, 1)), test 형태 : ((354, 6, 6, 1))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m   \u001b[0;31m# tensorflow는 3차원만 지원하므로 3차원 형태로 reshape 해줘야 합니다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m   \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train_org\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_image_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m360\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mX_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mX_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0my_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m   \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_test_org\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m360\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mX_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m   \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_train_org\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 250240000 into shape (625600,21,20,1)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5hDB2U986xq8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}