{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "N411_Reference.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CzIdLqSrQNwo"
      },
      "source": [
        "<img src='https://user-images.githubusercontent.com/6457691/90080969-0f758d00-dd47-11ea-8191-fa12fd2054a7.png' width = '200' align = 'right'>\n",
        "\n",
        "## *DATA SCIENCE / SECTION 4 / SPRINT 1 / NOTE 1 - assignmnet*\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# N411. 인공신경망(Artificial Neural Networks) 과제"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SvNvoQJk-xb-"
      },
      "source": [
        "## 실제 데이터 과제\n",
        " - 아래 주어진 데이터를 신경망을 이용하여 Classification 문제를 풀어보세요.\n",
        " - 또한 머신러닝에서 배운 방법(배우지 않은 머신러닝 방법론(SVM 등)도 가능)을 이용하여 비교해보세요."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pqOkgM9wnmNu"
      },
      "source": [
        "입력 데이터 샘플과 특징점(features): 1077 샘플 x 69 특징점 (변수), \n",
        "mouse_protein_X.xls \n",
        "\n",
        "데이터 label: 다운증후군 (1), 정상군 (2) \n",
        "mouse_protein_label.xls\n",
        "\n",
        "데이터는 다운증후군과 정상군 마우스 피질의 핵 분획에서 검출 가능한 신호를 생성하는 69 개 단백질의 발현 수준으로 구성되어 있다. 38 마리의 대조군 마우스와 34 마리의 trisomic mice (다운 증후군)가 총 72 마리로 각각 15번의 측정치가 등록되어 있는데 그 중에서 3개의 샘플이 측정이 안되어 총 1077개의 샘플이 있다. 라벨로는 다운증후군 1, 정상군 2로 할당 되어 있다. \n",
        "\n",
        "해당데이터는 다음과 같이 볼 수 있다. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gULuO1ETO-6G"
      },
      "source": [
        "import pandas as pd\n",
        "df = pd.read_excel(\"https://ds-lecture-data.s3.ap-northeast-2.amazonaws.com/MouseProtein/mouse_protein_X.xls\", header=None)\n",
        "df_label = pd.read_excel(\"https://ds-lecture-data.s3.ap-northeast-2.amazonaws.com/MouseProtein/mouse_protein_label.xls\", header=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6I-8OQ_APLtG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "outputId": "071e2841-84bc-4e76-b2ae-c5d401869af0"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>40</th>\n",
              "      <th>41</th>\n",
              "      <th>42</th>\n",
              "      <th>43</th>\n",
              "      <th>44</th>\n",
              "      <th>45</th>\n",
              "      <th>46</th>\n",
              "      <th>47</th>\n",
              "      <th>48</th>\n",
              "      <th>49</th>\n",
              "      <th>50</th>\n",
              "      <th>51</th>\n",
              "      <th>52</th>\n",
              "      <th>53</th>\n",
              "      <th>54</th>\n",
              "      <th>55</th>\n",
              "      <th>56</th>\n",
              "      <th>57</th>\n",
              "      <th>58</th>\n",
              "      <th>59</th>\n",
              "      <th>60</th>\n",
              "      <th>61</th>\n",
              "      <th>62</th>\n",
              "      <th>63</th>\n",
              "      <th>64</th>\n",
              "      <th>65</th>\n",
              "      <th>66</th>\n",
              "      <th>67</th>\n",
              "      <th>68</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.50364</td>\n",
              "      <td>0.74719</td>\n",
              "      <td>0.43018</td>\n",
              "      <td>2.8163</td>\n",
              "      <td>5.9902</td>\n",
              "      <td>0.21883</td>\n",
              "      <td>0.17757</td>\n",
              "      <td>2.3737</td>\n",
              "      <td>0.23222</td>\n",
              "      <td>1.7509</td>\n",
              "      <td>0.68791</td>\n",
              "      <td>0.30638</td>\n",
              "      <td>0.40270</td>\n",
              "      <td>0.29693</td>\n",
              "      <td>1.02210</td>\n",
              "      <td>0.60567</td>\n",
              "      <td>1.8777</td>\n",
              "      <td>2.3087</td>\n",
              "      <td>0.44160</td>\n",
              "      <td>0.85937</td>\n",
              "      <td>0.41629</td>\n",
              "      <td>0.36961</td>\n",
              "      <td>0.17894</td>\n",
              "      <td>1.8664</td>\n",
              "      <td>3.6852</td>\n",
              "      <td>1.5372</td>\n",
              "      <td>0.26453</td>\n",
              "      <td>0.31968</td>\n",
              "      <td>0.81387</td>\n",
              "      <td>0.16585</td>\n",
              "      <td>0.45391</td>\n",
              "      <td>3.0376</td>\n",
              "      <td>0.36951</td>\n",
              "      <td>0.45854</td>\n",
              "      <td>0.33534</td>\n",
              "      <td>0.82519</td>\n",
              "      <td>0.57692</td>\n",
              "      <td>0.44810</td>\n",
              "      <td>0.58627</td>\n",
              "      <td>0.39472</td>\n",
              "      <td>0.33957</td>\n",
              "      <td>0.48286</td>\n",
              "      <td>0.29417</td>\n",
              "      <td>0.18215</td>\n",
              "      <td>0.84273</td>\n",
              "      <td>0.19261</td>\n",
              "      <td>1.4431</td>\n",
              "      <td>0.29470</td>\n",
              "      <td>0.35460</td>\n",
              "      <td>1.3391</td>\n",
              "      <td>0.17012</td>\n",
              "      <td>0.15910</td>\n",
              "      <td>0.18885</td>\n",
              "      <td>0.10631</td>\n",
              "      <td>0.14499</td>\n",
              "      <td>0.17667</td>\n",
              "      <td>0.12519</td>\n",
              "      <td>0.11529</td>\n",
              "      <td>0.22804</td>\n",
              "      <td>0.14276</td>\n",
              "      <td>0.43096</td>\n",
              "      <td>0.24754</td>\n",
              "      <td>1.6033</td>\n",
              "      <td>2.0149</td>\n",
              "      <td>0.10823</td>\n",
              "      <td>1.04500</td>\n",
              "      <td>0.83156</td>\n",
              "      <td>0.18885</td>\n",
              "      <td>1.6757</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.51462</td>\n",
              "      <td>0.68906</td>\n",
              "      <td>0.41177</td>\n",
              "      <td>2.7895</td>\n",
              "      <td>5.6850</td>\n",
              "      <td>0.21164</td>\n",
              "      <td>0.17282</td>\n",
              "      <td>2.2921</td>\n",
              "      <td>0.22697</td>\n",
              "      <td>1.5964</td>\n",
              "      <td>0.69501</td>\n",
              "      <td>0.29905</td>\n",
              "      <td>0.38599</td>\n",
              "      <td>0.28132</td>\n",
              "      <td>0.95668</td>\n",
              "      <td>0.58756</td>\n",
              "      <td>1.7258</td>\n",
              "      <td>2.0430</td>\n",
              "      <td>0.44522</td>\n",
              "      <td>0.83466</td>\n",
              "      <td>0.40036</td>\n",
              "      <td>0.35618</td>\n",
              "      <td>0.17368</td>\n",
              "      <td>1.7610</td>\n",
              "      <td>3.4853</td>\n",
              "      <td>1.5092</td>\n",
              "      <td>0.25573</td>\n",
              "      <td>0.30442</td>\n",
              "      <td>0.78050</td>\n",
              "      <td>0.15719</td>\n",
              "      <td>0.43094</td>\n",
              "      <td>2.9219</td>\n",
              "      <td>0.34228</td>\n",
              "      <td>0.42356</td>\n",
              "      <td>0.32483</td>\n",
              "      <td>0.76172</td>\n",
              "      <td>0.54510</td>\n",
              "      <td>0.42088</td>\n",
              "      <td>0.54510</td>\n",
              "      <td>0.36825</td>\n",
              "      <td>0.32196</td>\n",
              "      <td>0.45452</td>\n",
              "      <td>0.27643</td>\n",
              "      <td>0.18209</td>\n",
              "      <td>0.84761</td>\n",
              "      <td>0.19482</td>\n",
              "      <td>1.4395</td>\n",
              "      <td>0.29406</td>\n",
              "      <td>0.35455</td>\n",
              "      <td>1.3063</td>\n",
              "      <td>0.17143</td>\n",
              "      <td>0.15813</td>\n",
              "      <td>0.18457</td>\n",
              "      <td>0.10659</td>\n",
              "      <td>0.15047</td>\n",
              "      <td>0.17831</td>\n",
              "      <td>0.13428</td>\n",
              "      <td>0.11823</td>\n",
              "      <td>0.23807</td>\n",
              "      <td>0.14204</td>\n",
              "      <td>0.45716</td>\n",
              "      <td>0.25763</td>\n",
              "      <td>1.6717</td>\n",
              "      <td>2.0046</td>\n",
              "      <td>0.10975</td>\n",
              "      <td>1.00990</td>\n",
              "      <td>0.84927</td>\n",
              "      <td>0.20040</td>\n",
              "      <td>1.7436</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.50918</td>\n",
              "      <td>0.73025</td>\n",
              "      <td>0.41831</td>\n",
              "      <td>2.6872</td>\n",
              "      <td>5.6221</td>\n",
              "      <td>0.20901</td>\n",
              "      <td>0.17572</td>\n",
              "      <td>2.2833</td>\n",
              "      <td>0.23025</td>\n",
              "      <td>1.5613</td>\n",
              "      <td>0.67735</td>\n",
              "      <td>0.29128</td>\n",
              "      <td>0.38100</td>\n",
              "      <td>0.28171</td>\n",
              "      <td>1.00360</td>\n",
              "      <td>0.60245</td>\n",
              "      <td>1.7319</td>\n",
              "      <td>2.0180</td>\n",
              "      <td>0.46767</td>\n",
              "      <td>0.81433</td>\n",
              "      <td>0.39985</td>\n",
              "      <td>0.36809</td>\n",
              "      <td>0.17390</td>\n",
              "      <td>1.7655</td>\n",
              "      <td>3.5715</td>\n",
              "      <td>1.5012</td>\n",
              "      <td>0.25961</td>\n",
              "      <td>0.31175</td>\n",
              "      <td>0.78515</td>\n",
              "      <td>0.16090</td>\n",
              "      <td>0.42319</td>\n",
              "      <td>2.9441</td>\n",
              "      <td>0.34370</td>\n",
              "      <td>0.42500</td>\n",
              "      <td>0.32485</td>\n",
              "      <td>0.75703</td>\n",
              "      <td>0.54362</td>\n",
              "      <td>0.40463</td>\n",
              "      <td>0.55299</td>\n",
              "      <td>0.36388</td>\n",
              "      <td>0.31309</td>\n",
              "      <td>0.44720</td>\n",
              "      <td>0.25665</td>\n",
              "      <td>0.18439</td>\n",
              "      <td>0.85617</td>\n",
              "      <td>0.20074</td>\n",
              "      <td>1.5244</td>\n",
              "      <td>0.30188</td>\n",
              "      <td>0.38609</td>\n",
              "      <td>1.2796</td>\n",
              "      <td>0.18546</td>\n",
              "      <td>0.14870</td>\n",
              "      <td>0.19053</td>\n",
              "      <td>0.10830</td>\n",
              "      <td>0.14533</td>\n",
              "      <td>0.17621</td>\n",
              "      <td>0.13256</td>\n",
              "      <td>0.11776</td>\n",
              "      <td>0.24482</td>\n",
              "      <td>0.14244</td>\n",
              "      <td>0.51047</td>\n",
              "      <td>0.25534</td>\n",
              "      <td>1.6635</td>\n",
              "      <td>2.0168</td>\n",
              "      <td>0.10820</td>\n",
              "      <td>0.99685</td>\n",
              "      <td>0.84671</td>\n",
              "      <td>0.19368</td>\n",
              "      <td>1.9264</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.44211</td>\n",
              "      <td>0.61708</td>\n",
              "      <td>0.35863</td>\n",
              "      <td>2.4669</td>\n",
              "      <td>4.9795</td>\n",
              "      <td>0.22289</td>\n",
              "      <td>0.17646</td>\n",
              "      <td>2.1523</td>\n",
              "      <td>0.20700</td>\n",
              "      <td>1.5951</td>\n",
              "      <td>0.58328</td>\n",
              "      <td>0.29673</td>\n",
              "      <td>0.37709</td>\n",
              "      <td>0.31383</td>\n",
              "      <td>0.87539</td>\n",
              "      <td>0.52029</td>\n",
              "      <td>1.5669</td>\n",
              "      <td>2.1328</td>\n",
              "      <td>0.47767</td>\n",
              "      <td>0.72770</td>\n",
              "      <td>0.38564</td>\n",
              "      <td>0.36297</td>\n",
              "      <td>0.17945</td>\n",
              "      <td>1.2863</td>\n",
              "      <td>2.9701</td>\n",
              "      <td>1.4197</td>\n",
              "      <td>0.25954</td>\n",
              "      <td>0.27922</td>\n",
              "      <td>0.73449</td>\n",
              "      <td>0.16221</td>\n",
              "      <td>0.41061</td>\n",
              "      <td>2.5002</td>\n",
              "      <td>0.34451</td>\n",
              "      <td>0.42921</td>\n",
              "      <td>0.33012</td>\n",
              "      <td>0.74698</td>\n",
              "      <td>0.54676</td>\n",
              "      <td>0.38686</td>\n",
              "      <td>0.54785</td>\n",
              "      <td>0.36677</td>\n",
              "      <td>0.32849</td>\n",
              "      <td>0.44265</td>\n",
              "      <td>0.39853</td>\n",
              "      <td>0.16177</td>\n",
              "      <td>0.76023</td>\n",
              "      <td>0.18417</td>\n",
              "      <td>1.6124</td>\n",
              "      <td>0.29638</td>\n",
              "      <td>0.29068</td>\n",
              "      <td>1.1988</td>\n",
              "      <td>0.15980</td>\n",
              "      <td>0.16611</td>\n",
              "      <td>0.18532</td>\n",
              "      <td>0.10318</td>\n",
              "      <td>0.14066</td>\n",
              "      <td>0.16380</td>\n",
              "      <td>0.12321</td>\n",
              "      <td>0.11744</td>\n",
              "      <td>0.23495</td>\n",
              "      <td>0.14507</td>\n",
              "      <td>0.43100</td>\n",
              "      <td>0.25110</td>\n",
              "      <td>1.4846</td>\n",
              "      <td>1.9572</td>\n",
              "      <td>0.11988</td>\n",
              "      <td>0.99022</td>\n",
              "      <td>0.83328</td>\n",
              "      <td>0.19211</td>\n",
              "      <td>1.7006</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.43494</td>\n",
              "      <td>0.61743</td>\n",
              "      <td>0.35880</td>\n",
              "      <td>2.3658</td>\n",
              "      <td>4.7187</td>\n",
              "      <td>0.21311</td>\n",
              "      <td>0.17363</td>\n",
              "      <td>2.1340</td>\n",
              "      <td>0.19216</td>\n",
              "      <td>1.5042</td>\n",
              "      <td>0.55096</td>\n",
              "      <td>0.28696</td>\n",
              "      <td>0.36350</td>\n",
              "      <td>0.27796</td>\n",
              "      <td>0.86491</td>\n",
              "      <td>0.50799</td>\n",
              "      <td>1.4801</td>\n",
              "      <td>2.0137</td>\n",
              "      <td>0.48342</td>\n",
              "      <td>0.68779</td>\n",
              "      <td>0.36753</td>\n",
              "      <td>0.35531</td>\n",
              "      <td>0.17484</td>\n",
              "      <td>1.3247</td>\n",
              "      <td>2.8963</td>\n",
              "      <td>1.3599</td>\n",
              "      <td>0.25070</td>\n",
              "      <td>0.27367</td>\n",
              "      <td>0.70270</td>\n",
              "      <td>0.15483</td>\n",
              "      <td>0.39855</td>\n",
              "      <td>2.4566</td>\n",
              "      <td>0.32913</td>\n",
              "      <td>0.40876</td>\n",
              "      <td>0.31341</td>\n",
              "      <td>0.69196</td>\n",
              "      <td>0.53686</td>\n",
              "      <td>0.36082</td>\n",
              "      <td>0.51282</td>\n",
              "      <td>0.35155</td>\n",
              "      <td>0.31221</td>\n",
              "      <td>0.41909</td>\n",
              "      <td>0.39345</td>\n",
              "      <td>0.16020</td>\n",
              "      <td>0.76811</td>\n",
              "      <td>0.18572</td>\n",
              "      <td>1.6458</td>\n",
              "      <td>0.29683</td>\n",
              "      <td>0.30935</td>\n",
              "      <td>1.2070</td>\n",
              "      <td>0.16465</td>\n",
              "      <td>0.16069</td>\n",
              "      <td>0.18822</td>\n",
              "      <td>0.10478</td>\n",
              "      <td>0.14198</td>\n",
              "      <td>0.16771</td>\n",
              "      <td>0.13684</td>\n",
              "      <td>0.11605</td>\n",
              "      <td>0.25553</td>\n",
              "      <td>0.14087</td>\n",
              "      <td>0.48123</td>\n",
              "      <td>0.25177</td>\n",
              "      <td>1.5348</td>\n",
              "      <td>2.0091</td>\n",
              "      <td>0.11952</td>\n",
              "      <td>0.99777</td>\n",
              "      <td>0.87867</td>\n",
              "      <td>0.20560</td>\n",
              "      <td>1.8397</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        0        1        2       3   ...       65       66       67      68\n",
              "0  0.50364  0.74719  0.43018  2.8163  ...  1.04500  0.83156  0.18885  1.6757\n",
              "1  0.51462  0.68906  0.41177  2.7895  ...  1.00990  0.84927  0.20040  1.7436\n",
              "2  0.50918  0.73025  0.41831  2.6872  ...  0.99685  0.84671  0.19368  1.9264\n",
              "3  0.44211  0.61708  0.35863  2.4669  ...  0.99022  0.83328  0.19211  1.7006\n",
              "4  0.43494  0.61743  0.35880  2.3658  ...  0.99777  0.87867  0.20560  1.8397\n",
              "\n",
              "[5 rows x 69 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zrIvw52rPdx4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f38e7292-26a9-4556-8cc7-d3c3c586e606"
      },
      "source": [
        "print(df_label.head())\n",
        "print(df_label.tail())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   0\n",
            "0  1\n",
            "1  1\n",
            "2  1\n",
            "3  1\n",
            "4  1\n",
            "      0\n",
            "1072  2\n",
            "1073  2\n",
            "1074  2\n",
            "1075  2\n",
            "1076  2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A1xg6EPQBXNE"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "df_label = df_label - 1\n",
        "df_label.astype(object)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(df, df_label, test_size=0.2, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yilj1IY3M4Zr"
      },
      "source": [
        "---\n",
        "\n",
        "4-1. 사용한 모델을 입력합니다. \n",
        "\n",
        "4-2. Accuracy를 입력합니다. \n",
        "\n",
        "4-3. Precision 을 입력합니다. \n",
        "\n",
        "4-4. Recall 을 입력합니다.\n",
        "\n",
        "4-5. F1 score 를 입력합니다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9GEEcBniIoGf"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, optimizers, losses\n",
        "from tensorflow.keras.metrics import Precision, Recall\n",
        "\n",
        "tf.random.set_seed(42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dGmqsT3gIXnu"
      },
      "source": [
        "# 레퍼런스는 신경망에 대해서만 제공됩니다. 머신러닝 방법론을 여러가지로 적용해보세요.\n",
        "# 은닉층의 수, 은닉층 내부의 노드 수, 활성화 함수 등을 자유롭게 변형시키며 결과값을 비교해보세요.\n",
        "# 옵티마이저를 다르게 해보거나 층마다 Dropout을 조절하며 결과값을 비교해보세요.\n",
        "\n",
        "model = keras.Sequential(\n",
        "    [\n",
        "        layers.Dense(12, input_dim=69, activation='relu'),\n",
        "        layers.Dense(1, activation='sigmoid')\n",
        "    ]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oCtTAkjvKSPy"
      },
      "source": [
        "# f1_score는 따로 구현하여야 합니다.\n",
        "# 아래 링크를 참고한 후 f1_score까지 구해보세요.\n",
        "# 함수의 파라미터를 늘리면 f_beta_score도 구현할 수 있습니다.\n",
        "\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['Accuracy','Precision','Recall']\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dk_a5A9LAhjW"
      },
      "source": [
        "[f1_score_in_keras](https://aakashgoel12.medium.com/how-to-add-user-defined-function-get-f1-score-in-keras-metrics-3013f979ce0d)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qmvPic3ML5sA"
      },
      "source": [
        "model.fit(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    epochs=10,\n",
        "    batch_size=64,\n",
        "    validation_data=(X_test, y_test)  \n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VZaIoJWgP97P"
      },
      "source": [
        "[링크를 참조하여 손수 작성해 봅니다](https://machinelearningmastery.com/binary-classification-tutorial-with-the-keras-deep-learning-library/)"
      ]
    }
  ]
}