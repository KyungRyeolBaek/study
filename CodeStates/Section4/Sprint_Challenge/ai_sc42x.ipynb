{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xy_9hARVUo9L"
   },
   "source": [
    "# SC42x \n",
    "## 자연어처리 (Natural Language Processing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8dNUXHiLbBdp"
   },
   "source": [
    "# Part 1 : 개념 요약\n",
    "\n",
    "> 다음의 키워드에 대해서 **한 줄**로 간단하게 요약해주세요. (세션 노트를 참고하여도 좋습니다.)<br/>\n",
    "> **Tip : 아래 문제를 먼저 수행한 후 모델 학습 등 시간이 오래 걸리는 셀이 실행되는 동안 아래 내용을 작성하면 시간을 절약할 수 있습니다.**\n",
    "\n",
    "**N421**\n",
    "- Stopwords(불용어)\n",
    "- Stemming과 Lemmatization\n",
    "- Bag-of-Words\n",
    "- TF-IDF\n",
    "\n",
    "**N422**\n",
    "- Word2Vec\n",
    "- fastText\n",
    "\n",
    "**N423**\n",
    "- RNN\n",
    "- LSTM, GRU\n",
    "- Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g07_yjCgbBdp"
   },
   "source": [
    "# Part 2 : Fake/Real News Dataset\n",
    "\n",
    "한 주간 자연어처리 기법을 배우면서 여러분은 다양한 기술들을 접했습니다.<br/>\n",
    "어떻게 텍스트 데이터를 다뤄야 하는지, 텍스트를 벡터화 하는 법, 문서에서 토픽을 모델하는 법 등 다양한 NLP 기법을 배웠는데요.<br/>\n",
    "이번 스프린트 챌린지에선 [Fake/Real News Dataset](https://www.kaggle.com/clmentbisaillon/fake-and-real-news-dataset)을 사용하여 배운 것들을 복습해보는 시간을 갖겠습니다.\n",
    "\n",
    "**주의 : 모델의 성능을 최대한 끌어올리는 것이 아닌 모델 구동에 초점을 맞춰주세요.<br/>\n",
    "모든 문제를 완료한 후에도 \"시간이 남았다면\" 정확도를 올리는 것에 도전하시는 것을 추천드립니다.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "BCX5K0nP0ZKQ"
   },
   "outputs": [],
   "source": [
    "# 코드 실행 전 seed를 지정하겠습니다.\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C08-JiyNbdQy"
   },
   "source": [
    "## 2.0 데이터셋을 불러옵니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HyndWa5hxEmk"
   },
   "source": [
    "- 위 캐글 링크에서 데이터셋을 받아 업로드 합니다.<br/>\n",
    "(직접 업로드하게 되면 시간이 꽤 걸리므로 **drive_mount** 나 **kaggle 연동**하시는 것을 추천드립니다.)\n",
    "\n",
    "- 'label' 열을 만들어 Fake = 1, True = 0 로 레이블링해줍니다.\n",
    "- 두 파일을 합쳐 하나의 데이터프레임에 저장해 준 후 데이터를 섞어줍니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rbxEHBanUo9d"
   },
   "source": [
    "## 2.1 TF-IDF 를 활용하여 특정 뉴스와 유사한 뉴스 검색하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X4R5mLMS5c2I"
   },
   "source": [
    "시간상 특별한 **전처리 없이** 아래 태스크를 수행하겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H2B-6Wkk5YGD"
   },
   "source": [
    "### 2.1.1 TFidfVectorizer를 사용하여 문서-단어 행렬(Document-Term Matrix) 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0Kw9OQwmUo9e"
   },
   "outputs": [],
   "source": [
    "# 이 곳에 답안을 작성하시길 바랍니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oeTMNUMM5WgQ"
   },
   "source": [
    "### 2.1.2 KNN 알고리즘을 사용하여 유사한 문서 검색하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **42번 인덱스의 문서**와 가장 유사한 **5개 문서(42번 포함)의 인덱스**와 **해당 인덱스의 레이블**을 나타내주세요.\n",
    "- NN 모델의 파라미터 중 `algorithm = 'kd_tree'` 로 설정합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "8jjaQO8O6UKd"
   },
   "outputs": [],
   "source": [
    "# 이 곳에 답안을 작성하시길 바랍니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ghQSPbQE7P8b"
   },
   "source": [
    "## 2.2 Keras Embedding을 사용하여 분류하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CEl8iU6j8I4M"
   },
   "source": [
    "### 2.2.0 데이터셋 split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Train, Test 데이터셋으로 분리(Split)하여 주세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "55XSZyY_Sj54"
   },
   "outputs": [],
   "source": [
    "# 이 곳에 답안을 작성하시길 바랍니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-1xXxSMn7fyt"
   },
   "source": [
    "### 2.2.1 단어 벡터의 평균을 이용하여 분류해보기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h_ZsjAVg7ndG"
   },
   "source": [
    "N422에서 했던 단어 임베딩 벡터의 평균을 사용하여 문장을 분류하는 작업을 수행해봅시다.<br/>\n",
    "인스턴스마다 텍스트 길이가 길고 시간이 오래 걸리므로 시간상 epoch 수를 **10 이하**로 하는 것을 추천드립니다.<br/>\n",
    "모델 구동이 목적이므로 임베딩 차원 수를 크지 않게(50이하)로 설정해주세요.<br/>\n",
    "**권장사항 : `max_len` 은 텍스트 길이 평균보다 높게 설정해주세요.**<br/>\n",
    "\n",
    "> **Tip : 모델이 학습하는 동안 2.2.3의 내용을 작성하면 시간을 절약할 수 있습니다.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "id": "dHber3qBBwOl"
   },
   "outputs": [],
   "source": [
    "# 이 곳에 답안을 작성하시길 바랍니다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9SzUwLkcAK1A"
   },
   "source": [
    "### 2.2.2 LSTM을 사용하여 텍스트 분류 수행해보기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z4UZ9ZqOAIjw"
   },
   "source": [
    "N423에서 했던 단어 임베딩 벡터의 평균을 사용하여 문장을 분류하는 작업을 수행해봅시다.<br/>\n",
    "인스턴스마다 텍스트 길이가 길어 시간이 매우 오래 걸리므로 <br/>\n",
    "**층을 최소한으로 쌓고**, epoch 수를 **3 이하**로 하는 것을 추천드립니다.<br/>\n",
    "\n",
    "> **Tip : 모델이 학습하는 동안 2.2.3의 내용을 작성하면 시간을 절약할 수 있습니다.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "id": "9PLNlzEVBSyE"
   },
   "outputs": [],
   "source": [
    "# 이 곳에 답안을 작성하시길 바랍니다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FsNOs2wmBV1z"
   },
   "source": [
    "### 2.2.3 위에서 실행한 내용에 대해 다시 알아봅시다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WMR2t2wOEPYm"
   },
   "source": [
    "#### a) 데이터셋을 학습할 때 사용하는 `pad_sequences`  메서드에 대해 설명해주세요.<br/>어떤 기능을 하나요? 모델을 학습할 때 왜 필요한가요?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G7_ECWSYQ4JV"
   },
   "source": [
    "*이곳에 답안을 입력해주세요*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qeZ6AcloEYD5"
   },
   "source": [
    "#### b) 2.2.1과 2.2.2에서 사용한 각 모델의 evaluation 성능은 어떻게 나왔나요?<br/>각 모델의 장단점은 무엇이라고 생각하나요?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3SyqQzzHQ4EP"
   },
   "source": [
    "*이곳에 답안을 입력해주세요*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TUwKojAGM82f"
   },
   "source": [
    "#### c) 종래의 RNN(Recurrent Neural Networks) 대신 LSTM(Long-Short Term Memory)을 사용하는 이유는 무엇인가요?<br/>(i.e. RNN에 비해 LSTM의 좋은 점을 설명해주세요.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6y44XfugQ_HR"
   },
   "source": [
    "*이곳에 답안을 입력해주세요*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0J1kzTmDEaLU"
   },
   "source": [
    "#### d) LSTM이나 RNN을 사용하는 예시를 **3개**이상 제시하고 해당되는 경우에 왜 LSTM이나 RNN을 사용하는 것 적절한지 간단하게 설명해주세요."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ck8GPjc_Q_vA"
   },
   "source": [
    "*이곳에 답안을 입력해주세요*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p4pP7g8DE0Cz"
   },
   "source": [
    "#### e) 이외에 N424 에서 배운 자연어처리 모델과 관련된 키워드를 3개 이상 적어주세요. <br/> (해당 키워드에 대한 설명은 옵션입니다.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E-sO4mMuRAhp"
   },
   "source": [
    "*이곳에 답안을 입력해주세요*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jRn44qjhUo9j"
   },
   "source": [
    "# Advanced Goals: 3점을 획득하기 위해선 아래의 조건 중 하나 이상을 만족해야합니다\n",
    " \n",
    "- 2.1 에서 TF-IDF(`TfidfVectorizer`)가 아닌 방법을 사용하여 유사도 검색을 수행해보세요.<br/>\n",
    "TF-IDF와 해당 방법의 차이를 설명해주세요. \n",
    "- 2.2 에서 사용한 방법을 재사용하되 하이퍼 파라미터를 조정하거나 모델 구조를 변경하여 성능을 올려봅시다.<br/>**(주의 : GridSearch, RandomSearch 등의 방법을 사용하여도 좋으나 시간이 오래 걸리므로 범위를 잘 선택해야 합니다.)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lz2uaXFYUo9j"
   },
   "outputs": [],
   "source": [
    "# 이 곳에 답안을 작성하시길 바랍니다"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "ai-sc42x.ipynb",
   "provenance": []
  },
  "kernel_info": {
   "name": "u4-s1-nlp"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "nteract": {
   "version": "0.22.4"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
