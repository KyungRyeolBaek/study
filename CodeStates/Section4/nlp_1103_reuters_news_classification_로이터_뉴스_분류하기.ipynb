{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nlp_1103_reuters news classification 로이터 뉴스 분류하기.ipynb",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "QRTyUiLLaj0G"
      },
      "source": [
        "# 1. 데이터 준비"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vJOwwTVpa6WU"
      },
      "source": [
        "from tensorflow.keras.datasets import reuters\n",
        "#matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z0NxyxBCbKts"
      },
      "source": [
        "# 기사 다운로드, 훈련용, 테스용으로 분리\n",
        "\n",
        "# num_words는 이 데이터에서 등장 빈도 순위로 몇 번째에 해당하는 단어까지만 사용할 것인지 조절\n",
        "# 모든 단어를 사용할 것이므로 num_words=None\n",
        "(X_train, y_train), (X_test, y_test) = reuters.load_data(num_words=None, test_split=0.2)\n",
        "\n",
        "print('훈련용 뉴스 기사 : {}'.format(len(X_train)))\n",
        "print('테스트용 뉴스 기사 : {}'.format(len(X_test)))\n",
        "\n",
        "num_classes = max(y_train) + 1\n",
        "print('카테고리 : {}'.format(num_classes))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lUYEsn6sceym"
      },
      "source": [
        "print(X_train[0]) # 첫번째 훈련용 뉴스 기사"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cy2YyQkudFpa"
      },
      "source": [
        "print(y_train[0]) # 첫번째 훈련용 뉴스 기사의 레이블"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TUFVNU6CdIoi"
      },
      "source": [
        "# 8,982개의 훈련용 뉴스 기사의 길이가 대체적으로 어떤 크기를 가지는지 확인\n",
        "\n",
        "print('뉴스 기사의 최대 길이 :{}'.format(max(len(l) for l in X_train)))\n",
        "print('뉴스 기사의 평균 길이 :{}'.format(sum(map(len, X_train))/len(X_train)))\n",
        "\n",
        "plt.hist([len(s) for s in X_train], bins=50)\n",
        "plt.xlabel('length of samples')\n",
        "plt.ylabel('number of samples')\n",
        "plt.show();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rDvY1WCCdrEu"
      },
      "source": [
        "# 각 뉴스가 어떤 종류의 뉴스에 속하는지 기재되어있는 레이블 값의 분포 확인\n",
        "\n",
        "fig, axe = plt.subplots(ncols=1)\n",
        "fig.set_size_inches(12,5)\n",
        "sns.countplot(y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xFyHAyzSeHQz"
      },
      "source": [
        "# 각 레이블에 대한 정확한 개수 확인\n",
        "\n",
        "unique_elements, counts_elements = np.unique(y_train, return_counts=True)\n",
        "print(\"각 레이블에 대한 빈도수:\")\n",
        "print(np.asarray((unique_elements, counts_elements)))\n",
        "# label_cnt=dict(zip(unique_elements, counts_elements))\n",
        "# 아래의 출력 결과가 보기 불편하여 병렬로 보고싶다면 위의 label_cnt를 출력"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UBI9a-DHe23o"
      },
      "source": [
        "# X_train 인덱스와 매치 단어 확인\n",
        "\n",
        "word_to_index = reuters.get_word_index()\n",
        "print(word_to_index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DQZj_dJjft9a"
      },
      "source": [
        "index_to_word = {}\n",
        "for key, value in word_to_index.items():\n",
        "    index_to_word[value] = key"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aAxdq8mhf4PW"
      },
      "source": [
        "print('빈도수 상위 28842번 단어 : {}'.format(index_to_word[28842]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ov2v13suf850"
      },
      "source": [
        "print('빈도수 상위 1번 단어 : {}'.format(index_to_word[1]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVWFqMwxf_7r"
      },
      "source": [
        "# 첫번째 훈련용 뉴스 기사인 X_train[0]가 어떤 단어들로 구성되어있는지를 복원\n",
        "\n",
        "for index, token in enumerate((\"<pad>\", \"<sos>\", \"<unk>\")):\n",
        "  index_to_word[index]=token\n",
        "\n",
        "print(' '.join([index_to_word[index] for index in X_train[0]]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E-l_UNx2ga-v"
      },
      "source": [
        "# LSTM으로 로이터 뉴스 분류하기"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uPcmNPnegueV"
      },
      "source": [
        "from tensorflow.keras.datasets import reuters\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Embedding\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras.models import load_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kol9PixZgwxY"
      },
      "source": [
        "# 등장 빈도 순서가 가장 많은 상위 1 ~ 1,000번째인 단어들만 분리\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = reuters.load_data(num_words=1000, test_split=0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YHM6nJJwhF27"
      },
      "source": [
        "# 패딩 : pad_sequences()를 사용하여 maxlen의 값으로 100\n",
        "\n",
        "max_len = 100\n",
        "\n",
        "X_train = pad_sequences(X_train, maxlen=max_len) # 훈련용 뉴스 기사 패딩\n",
        "X_test = pad_sequences(X_test, maxlen=max_len) # 테스트용 뉴스 기사 패딩"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w0kcwHtwheqG"
      },
      "source": [
        "# 훈련용, 테스트용 뉴스 기사 데이터의 레이블에 원-핫 인코딩\n",
        "\n",
        "y_train = to_categorical(y_train) # 훈련용 뉴스 기사 레이블의 원-핫 인코딩\n",
        "y_test = to_categorical(y_test) # 테스트용 뉴스 기사 레이블의 원-핫 인코딩"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MWLgipH6hofl"
      },
      "source": [
        "# 모델 설계\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(1000, 120))  # (단어집합, 임베딩 벡터 차원)\n",
        "model.add(LSTM(120))\n",
        "model.add(Dense(46, activation='softmax'))  #46개의 카테고리 즉 46개의 뉴런"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dJFRGOzQiQ8x"
      },
      "source": [
        "# 모델 검증\n",
        "\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=4)\n",
        "# 검증 데이터 손실이 4회 증가하면 학습 조기 종료\n",
        "\n",
        "mc = ModelCheckpoint('best_model.h5', monitor='val_acc', mode='max', verbose=1, save_best_only=True)\n",
        "# 검증 데이터의 정확도가 이전보다 좋아질 경우에만 모델 저장"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rfawtcw7isbd"
      },
      "source": [
        "# 모델 훈련\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])\n",
        "# categorical_crossentropy는 모델의 예측값과 실제값에 대해서 두 확률 분포 사이의 거리를 최소화하도록 훈련\n",
        "\n",
        "history = model.fit(X_train, y_train, batch_size=128, epochs=30, callbacks=[es, mc], validation_data=(X_test, y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qMJtrH2bjD10"
      },
      "source": [
        "# 저장된 모델인 'best_model.h5'를 로드하고, 성능을 평가\n",
        "\n",
        "loaded_model = load_model('best_model.h5')\n",
        "print(\"\\n 테스트 정확도: %.4f\" % (loaded_model.evaluate(X_test, y_test)[1]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l32oWYS_kjne"
      },
      "source": [
        "# 에포크마다 변화하는 훈련 데이터와 검증 데이터(테스트 데이터)의 손실을 시각화\n",
        "\n",
        "epochs = range(1, len(history.history['acc']) + 1)\n",
        "plt.plot(epochs, history.history['loss'])\n",
        "plt.plot(epochs, history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q3i11EsZk0OJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}